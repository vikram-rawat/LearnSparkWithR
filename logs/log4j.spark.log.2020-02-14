20/02/14 10:06:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/14 10:06:03 INFO SecurityManager: Changing view acls to: Gigabyte
20/02/14 10:06:03 INFO SecurityManager: Changing modify acls to: Gigabyte
20/02/14 10:06:03 INFO SecurityManager: Changing view acls groups to: 
20/02/14 10:06:03 INFO SecurityManager: Changing modify acls groups to: 
20/02/14 10:06:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Gigabyte); groups with view permissions: Set(); users  with modify permissions: Set(Gigabyte); groups with modify permissions: Set()
20/02/14 10:06:04 INFO SparkContext: Running Spark version 3.0.0-preview
20/02/14 10:06:04 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
20/02/14 10:06:04 INFO ResourceUtils: ==============================================================
20/02/14 10:06:04 INFO ResourceUtils: Resources for spark.driver:

20/02/14 10:06:04 INFO ResourceUtils: ==============================================================
20/02/14 10:06:04 INFO SparkContext: Submitted application: sparklyr
20/02/14 10:06:04 INFO SecurityManager: Changing view acls to: Gigabyte
20/02/14 10:06:04 INFO SecurityManager: Changing modify acls to: Gigabyte
20/02/14 10:06:04 INFO SecurityManager: Changing view acls groups to: 
20/02/14 10:06:04 INFO SecurityManager: Changing modify acls groups to: 
20/02/14 10:06:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Gigabyte); groups with view permissions: Set(); users  with modify permissions: Set(Gigabyte); groups with modify permissions: Set()
20/02/14 10:06:05 INFO Utils: Successfully started service 'sparkDriver' on port 52973.
20/02/14 10:06:05 INFO SparkEnv: Registering MapOutputTracker
20/02/14 10:06:05 INFO SparkEnv: Registering BlockManagerMaster
20/02/14 10:06:05 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/14 10:06:05 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/14 10:06:05 INFO DiskBlockManager: Created local directory at C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\blockmgr-5a455a65-1979-41cd-9293-47f8f10e779c
20/02/14 10:06:05 INFO MemoryStore: MemoryStore started with capacity 413.9 MiB
20/02/14 10:06:05 INFO SparkEnv: Registering OutputCommitCoordinator
20/02/14 10:06:05 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/local]. Please check your configured local directories.
20/02/14 10:06:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/02/14 10:06:05 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
20/02/14 10:06:05 INFO SparkContext: Added JAR file:/C:/Users/Gigabyte/Documents/R/win-library/3.6/sparklyr/java/sparklyr-3.0.0-preview-2.12.jar at spark://127.0.0.1:52973/jars/sparklyr-3.0.0-preview-2.12.jar with timestamp 1581654965617
20/02/14 10:06:05 INFO Executor: Starting executor ID driver on host 127.0.0.1
20/02/14 10:06:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53002.
20/02/14 10:06:05 INFO NettyBlockTransferService: Server created on 127.0.0.1:53002
20/02/14 10:06:05 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/14 10:06:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 53002, None)
20/02/14 10:06:05 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:53002 with 413.9 MiB RAM, BlockManagerId(driver, 127.0.0.1, 53002, None)
20/02/14 10:06:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 53002, None)
20/02/14 10:06:05 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 53002, None)
20/02/14 10:06:06 INFO SharedState: loading hive config file: file:/C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/conf/hive-site.xml
20/02/14 10:06:06 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/hive').
20/02/14 10:06:06 INFO SharedState: Warehouse path is 'C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/hive'.
20/02/14 10:06:06 WARN SharedState: Not allowing to set spark.sql.warehouse.dir or hive.metastore.warehouse.dir in SparkSession's options, it should be set statically for cross-session usages
20/02/14 10:06:21 WARN ProcfsMetricsGetter: Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
20/02/14 10:06:54 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 10:06:54 INFO DAGScheduler: Got job 0 (collect at utils.scala:41) with 1 output partitions
20/02/14 10:06:54 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:41)
20/02/14 10:06:54 INFO DAGScheduler: Parents of final stage: List()
20/02/14 10:06:54 INFO DAGScheduler: Missing parents: List()
20/02/14 10:06:54 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:41), which has no missing parents
20/02/14 10:06:54 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
20/02/14 10:06:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.8 KiB, free 413.9 MiB)
20/02/14 10:06:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.9 MiB)
20/02/14 10:06:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:53002 (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 10:06:55 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1196
20/02/14 10:06:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
20/02/14 10:06:55 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
20/02/14 10:06:55 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7374 bytes)
20/02/14 10:06:55 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/02/14 10:06:55 INFO Executor: Fetching spark://127.0.0.1:52973/jars/sparklyr-3.0.0-preview-2.12.jar with timestamp 1581654965617
20/02/14 10:06:55 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:52973 after 25 ms (0 ms spent in bootstraps)
20/02/14 10:06:55 INFO Utils: Fetching spark://127.0.0.1:52973/jars/sparklyr-3.0.0-preview-2.12.jar to C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-838eb366-5700-41be-9cd2-3505e60f8975\userFiles-2293e3ad-5c52-4641-bc3e-1f6e07867028\fetchFileTemp8776291286704990487.tmp
20/02/14 10:06:55 INFO Executor: Adding file:/C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/local/spark-838eb366-5700-41be-9cd2-3505e60f8975/userFiles-2293e3ad-5c52-4641-bc3e-1f6e07867028/sparklyr-3.0.0-preview-2.12.jar to class loader
20/02/14 10:06:56 INFO CodeGenerator: Code generated in 209.887 ms
20/02/14 10:06:56 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1146 bytes result sent to driver
20/02/14 10:06:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1001 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 10:06:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/02/14 10:06:56 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:41) finished in 1.255 s
20/02/14 10:06:56 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 10:06:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
20/02/14 10:06:56 INFO DAGScheduler: Job 0 finished: collect at utils.scala:41, took 1.341814 s
20/02/14 10:06:56 INFO CodeGenerator: Code generated in 17.4454 ms
20/02/14 10:06:56 INFO CodeGenerator: Code generated in 14.312101 ms
20/02/14 10:06:56 INFO CodeGenerator: Code generated in 14.9803 ms
20/02/14 10:06:56 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/14 10:06:56 INFO DAGScheduler: Registering RDD 15 (sql at <unknown>:0) as input to shuffle 0
20/02/14 10:06:56 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
20/02/14 10:06:56 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
20/02/14 10:06:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
20/02/14 10:06:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
20/02/14 10:06:56 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
20/02/14 10:06:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 43.9 KiB, free 413.9 MiB)
20/02/14 10:06:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 413.9 MiB)
20/02/14 10:06:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:53002 (size: 15.3 KiB, free: 413.9 MiB)
20/02/14 10:06:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1196
20/02/14 10:06:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 10:06:56 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
20/02/14 10:06:56 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 10:06:56 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
20/02/14 10:06:57 INFO CodeGenerator: Code generated in 48.706799 ms
20/02/14 10:06:57 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 3.9 KiB, free 413.9 MiB)
20/02/14 10:06:57 INFO BlockManagerInfo: Added rdd_10_0 in memory on 127.0.0.1:53002 (size: 3.9 KiB, free: 413.9 MiB)
20/02/14 10:06:57 INFO CodeGenerator: Code generated in 6.028401 ms
20/02/14 10:06:57 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2412 bytes result sent to driver
20/02/14 10:06:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 330 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 10:06:57 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/02/14 10:06:57 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.353 s
20/02/14 10:06:57 INFO DAGScheduler: looking for newly runnable stages
20/02/14 10:06:57 INFO DAGScheduler: running: Set()
20/02/14 10:06:57 INFO DAGScheduler: waiting: Set(ResultStage 2)
20/02/14 10:06:57 INFO DAGScheduler: failed: Set()
20/02/14 10:06:57 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[18] at sql at <unknown>:0), which has no missing parents
20/02/14 10:06:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.2 KiB, free 413.8 MiB)
20/02/14 10:06:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
20/02/14 10:06:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:53002 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 10:06:57 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1196
20/02/14 10:06:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[18] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 10:06:57 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
20/02/14 10:06:57 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 10:06:57 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
20/02/14 10:06:57 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 10:06:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
20/02/14 10:06:57 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2846 bytes result sent to driver
20/02/14 10:06:57 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 54 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 10:06:57 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/02/14 10:06:57 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0.064 s
20/02/14 10:06:57 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 10:06:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
20/02/14 10:06:57 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.443985 s
20/02/14 10:06:57 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:53002 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 10:06:57 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:53002 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 10:06:57 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:53002 in memory (size: 15.3 KiB, free: 413.9 MiB)
20/02/14 10:06:57 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/14 10:06:57 INFO DAGScheduler: Registering RDD 23 (collect at utils.scala:204) as input to shuffle 1
20/02/14 10:06:57 INFO DAGScheduler: Got job 2 (collect at utils.scala:204) with 1 output partitions
20/02/14 10:06:57 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:204)
20/02/14 10:06:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
20/02/14 10:06:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
20/02/14 10:06:57 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[23] at collect at utils.scala:204), which has no missing parents
20/02/14 10:06:57 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 43.9 KiB, free 413.9 MiB)
20/02/14 10:06:57 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 413.9 MiB)
20/02/14 10:06:57 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:53002 (size: 15.3 KiB, free: 413.9 MiB)
20/02/14 10:06:57 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1196
20/02/14 10:06:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[23] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/14 10:06:57 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
20/02/14 10:06:57 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 10:06:57 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
20/02/14 10:06:57 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 10:06:57 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2369 bytes result sent to driver
20/02/14 10:06:57 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 22 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 10:06:57 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
20/02/14 10:06:57 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:204) finished in 0.035 s
20/02/14 10:06:57 INFO DAGScheduler: looking for newly runnable stages
20/02/14 10:06:57 INFO DAGScheduler: running: Set()
20/02/14 10:06:57 INFO DAGScheduler: waiting: Set(ResultStage 4)
20/02/14 10:06:57 INFO DAGScheduler: failed: Set()
20/02/14 10:06:57 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[26] at collect at utils.scala:204), which has no missing parents
20/02/14 10:06:57 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/14 10:06:57 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
20/02/14 10:06:57 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:53002 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 10:06:57 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1196
20/02/14 10:06:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[26] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/14 10:06:57 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
20/02/14 10:06:57 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 10:06:57 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
20/02/14 10:06:57 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 10:06:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 10:06:57 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2760 bytes result sent to driver
20/02/14 10:06:57 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 10:06:57 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
20/02/14 10:06:57 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:204) finished in 0.014 s
20/02/14 10:06:57 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 10:06:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
20/02/14 10:06:57 INFO DAGScheduler: Job 2 finished: collect at utils.scala:204, took 0.060649 s
20/02/14 10:06:57 INFO CodeGenerator: Code generated in 5.2903 ms
20/02/14 10:07:09 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:53002 in memory (size: 15.3 KiB, free: 413.9 MiB)
20/02/14 10:07:09 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:53002 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 10:17:20 INFO SparkContext: Invoking stop() from shutdown hook
20/02/14 10:17:20 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
20/02/14 10:17:20 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/02/14 10:17:20 INFO MemoryStore: MemoryStore cleared
20/02/14 10:17:20 INFO BlockManager: BlockManager stopped
20/02/14 10:17:20 INFO BlockManagerMaster: BlockManagerMaster stopped
20/02/14 10:17:20 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/02/14 10:17:20 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-838eb366-5700-41be-9cd2-3505e60f8975\userFiles-2293e3ad-5c52-4641-bc3e-1f6e07867028
java.io.IOException: Failed to delete: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-838eb366-5700-41be-9cd2-3505e60f8975\userFiles-2293e3ad-5c52-4641-bc3e-1f6e07867028\sparklyr-3.0.0-preview-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext.$anonfun$stop$21(SparkContext.scala:2008)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2008)
	at org.apache.spark.SparkContext.$anonfun$new$33(SparkContext.scala:632)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1960)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
20/02/14 10:17:20 INFO SparkContext: Successfully stopped SparkContext
20/02/14 10:17:20 INFO ShutdownHookManager: Shutdown hook called
20/02/14 10:17:20 INFO ShutdownHookManager: Deleting directory C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-838eb366-5700-41be-9cd2-3505e60f8975
20/02/14 10:17:20 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-838eb366-5700-41be-9cd2-3505e60f8975
java.io.IOException: Failed to delete: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-838eb366-5700-41be-9cd2-3505e60f8975\userFiles-2293e3ad-5c52-4641-bc3e-1f6e07867028\sparklyr-3.0.0-preview-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1960)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
20/02/14 10:17:20 INFO ShutdownHookManager: Deleting directory C:\Users\Gigabyte\AppData\Local\Temp\spark-fdc01178-0df1-45ac-b463-4754b861727e
20/02/14 10:17:20 INFO ShutdownHookManager: Deleting directory C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-838eb366-5700-41be-9cd2-3505e60f8975\userFiles-2293e3ad-5c52-4641-bc3e-1f6e07867028
20/02/14 10:17:20 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-838eb366-5700-41be-9cd2-3505e60f8975\userFiles-2293e3ad-5c52-4641-bc3e-1f6e07867028
java.io.IOException: Failed to delete: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-838eb366-5700-41be-9cd2-3505e60f8975\userFiles-2293e3ad-5c52-4641-bc3e-1f6e07867028\sparklyr-3.0.0-preview-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1960)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
20/02/14 11:02:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/14 11:02:54 INFO SecurityManager: Changing view acls to: Gigabyte
20/02/14 11:02:54 INFO SecurityManager: Changing modify acls to: Gigabyte
20/02/14 11:02:54 INFO SecurityManager: Changing view acls groups to: 
20/02/14 11:02:54 INFO SecurityManager: Changing modify acls groups to: 
20/02/14 11:02:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Gigabyte); groups with view permissions: Set(); users  with modify permissions: Set(Gigabyte); groups with modify permissions: Set()
20/02/14 11:02:56 INFO SparkContext: Running Spark version 3.0.0-preview
20/02/14 11:02:56 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
20/02/14 11:02:56 INFO ResourceUtils: ==============================================================
20/02/14 11:02:56 INFO ResourceUtils: Resources for spark.driver:

20/02/14 11:02:56 INFO ResourceUtils: ==============================================================
20/02/14 11:02:56 INFO SparkContext: Submitted application: sparklyr
20/02/14 11:02:56 INFO SecurityManager: Changing view acls to: Gigabyte
20/02/14 11:02:56 INFO SecurityManager: Changing modify acls to: Gigabyte
20/02/14 11:02:56 INFO SecurityManager: Changing view acls groups to: 
20/02/14 11:02:56 INFO SecurityManager: Changing modify acls groups to: 
20/02/14 11:02:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Gigabyte); groups with view permissions: Set(); users  with modify permissions: Set(Gigabyte); groups with modify permissions: Set()
20/02/14 11:02:56 INFO Utils: Successfully started service 'sparkDriver' on port 55411.
20/02/14 11:02:56 INFO SparkEnv: Registering MapOutputTracker
20/02/14 11:02:56 INFO SparkEnv: Registering BlockManagerMaster
20/02/14 11:02:56 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/14 11:02:56 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/14 11:02:56 INFO DiskBlockManager: Created local directory at C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\blockmgr-014e21d3-0ad6-4a05-9185-0c6c50d846e9
20/02/14 11:02:56 INFO MemoryStore: MemoryStore started with capacity 413.9 MiB
20/02/14 11:02:56 INFO SparkEnv: Registering OutputCommitCoordinator
20/02/14 11:02:56 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/local]. Please check your configured local directories.
20/02/14 11:02:57 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/02/14 11:02:57 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
20/02/14 11:02:57 INFO SparkContext: Added JAR file:/C:/Users/Gigabyte/Documents/R/win-library/3.6/sparklyr/java/sparklyr-3.0.0-preview-2.12.jar at spark://127.0.0.1:55411/jars/sparklyr-3.0.0-preview-2.12.jar with timestamp 1581658377212
20/02/14 11:02:57 INFO Executor: Starting executor ID driver on host 127.0.0.1
20/02/14 11:02:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55441.
20/02/14 11:02:57 INFO NettyBlockTransferService: Server created on 127.0.0.1:55441
20/02/14 11:02:57 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/14 11:02:57 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 55441, None)
20/02/14 11:02:57 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:55441 with 413.9 MiB RAM, BlockManagerId(driver, 127.0.0.1, 55441, None)
20/02/14 11:02:57 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 55441, None)
20/02/14 11:02:57 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 55441, None)
20/02/14 11:02:58 INFO SharedState: loading hive config file: file:/C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/conf/hive-site.xml
20/02/14 11:02:58 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/hive').
20/02/14 11:02:58 INFO SharedState: Warehouse path is 'C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/hive'.
20/02/14 11:02:58 WARN SharedState: Not allowing to set spark.sql.warehouse.dir or hive.metastore.warehouse.dir in SparkSession's options, it should be set statically for cross-session usages
20/02/14 11:03:04 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 11:03:04 INFO DAGScheduler: Got job 0 (collect at utils.scala:41) with 1 output partitions
20/02/14 11:03:04 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:41)
20/02/14 11:03:04 INFO DAGScheduler: Parents of final stage: List()
20/02/14 11:03:04 INFO DAGScheduler: Missing parents: List()
20/02/14 11:03:04 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:41), which has no missing parents
20/02/14 11:03:04 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
20/02/14 11:03:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.8 KiB, free 413.9 MiB)
20/02/14 11:03:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.9 MiB)
20/02/14 11:03:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:55441 (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 11:03:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1196
20/02/14 11:03:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
20/02/14 11:03:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
20/02/14 11:03:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7374 bytes)
20/02/14 11:03:04 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/02/14 11:03:04 INFO Executor: Fetching spark://127.0.0.1:55411/jars/sparklyr-3.0.0-preview-2.12.jar with timestamp 1581658377212
20/02/14 11:03:04 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:55411 after 21 ms (0 ms spent in bootstraps)
20/02/14 11:03:04 INFO Utils: Fetching spark://127.0.0.1:55411/jars/sparklyr-3.0.0-preview-2.12.jar to C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-d59c381c-16f7-4df2-8f81-75bfc5d31040\userFiles-b5b0dfb7-308c-4a5d-a331-75486d6d5f97\fetchFileTemp5256551764881248127.tmp
20/02/14 11:03:04 INFO Executor: Adding file:/C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/local/spark-d59c381c-16f7-4df2-8f81-75bfc5d31040/userFiles-b5b0dfb7-308c-4a5d-a331-75486d6d5f97/sparklyr-3.0.0-preview-2.12.jar to class loader
20/02/14 11:03:05 INFO CodeGenerator: Code generated in 215.0766 ms
20/02/14 11:03:05 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1146 bytes result sent to driver
20/02/14 11:03:05 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 820 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:03:05 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/02/14 11:03:05 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:41) finished in 1.028 s
20/02/14 11:03:05 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:03:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
20/02/14 11:03:05 INFO DAGScheduler: Job 0 finished: collect at utils.scala:41, took 1.080912 s
20/02/14 11:03:05 INFO CodeGenerator: Code generated in 18.403201 ms
20/02/14 11:03:05 INFO CodeGenerator: Code generated in 14.546001 ms
20/02/14 11:03:05 INFO CodeGenerator: Code generated in 16.0634 ms
20/02/14 11:03:06 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/14 11:03:06 INFO DAGScheduler: Registering RDD 15 (sql at <unknown>:0) as input to shuffle 0
20/02/14 11:03:06 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
20/02/14 11:03:06 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
20/02/14 11:03:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
20/02/14 11:03:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
20/02/14 11:03:06 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[15] at sql at <unknown>:0), which has no missing parents
20/02/14 11:03:06 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 43.9 KiB, free 413.9 MiB)
20/02/14 11:03:06 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 413.9 MiB)
20/02/14 11:03:06 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:55441 (size: 15.3 KiB, free: 413.9 MiB)
20/02/14 11:03:06 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1196
20/02/14 11:03:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[15] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 11:03:06 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
20/02/14 11:03:06 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:03:06 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
20/02/14 11:03:06 INFO CodeGenerator: Code generated in 62.0269 ms
20/02/14 11:03:06 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 3.9 KiB, free 413.9 MiB)
20/02/14 11:03:06 INFO BlockManagerInfo: Added rdd_10_0 in memory on 127.0.0.1:55441 (size: 3.9 KiB, free: 413.9 MiB)
20/02/14 11:03:06 INFO CodeGenerator: Code generated in 4.214099 ms
20/02/14 11:03:06 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2412 bytes result sent to driver
20/02/14 11:03:06 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 287 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:03:06 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/02/14 11:03:06 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.317 s
20/02/14 11:03:06 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:03:06 INFO DAGScheduler: running: Set()
20/02/14 11:03:06 INFO DAGScheduler: waiting: Set(ResultStage 2)
20/02/14 11:03:06 INFO DAGScheduler: failed: Set()
20/02/14 11:03:06 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[18] at sql at <unknown>:0), which has no missing parents
20/02/14 11:03:06 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.2 KiB, free 413.8 MiB)
20/02/14 11:03:06 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
20/02/14 11:03:06 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 11:03:06 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1196
20/02/14 11:03:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[18] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 11:03:06 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
20/02/14 11:03:06 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:03:06 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
20/02/14 11:03:06 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:03:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
20/02/14 11:03:06 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2803 bytes result sent to driver
20/02/14 11:03:06 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 49 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:03:06 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/02/14 11:03:06 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0.063 s
20/02/14 11:03:06 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:03:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
20/02/14 11:03:06 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.408658 s
20/02/14 11:03:06 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 11:03:06 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/14 11:03:06 INFO DAGScheduler: Registering RDD 23 (collect at utils.scala:204) as input to shuffle 1
20/02/14 11:03:06 INFO DAGScheduler: Got job 2 (collect at utils.scala:204) with 1 output partitions
20/02/14 11:03:06 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:204)
20/02/14 11:03:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
20/02/14 11:03:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
20/02/14 11:03:06 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[23] at collect at utils.scala:204), which has no missing parents
20/02/14 11:03:06 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 43.9 KiB, free 413.8 MiB)
20/02/14 11:03:06 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 413.8 MiB)
20/02/14 11:03:06 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:55441 (size: 15.3 KiB, free: 413.9 MiB)
20/02/14 11:03:06 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1196
20/02/14 11:03:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[23] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/14 11:03:06 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
20/02/14 11:03:06 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:03:06 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
20/02/14 11:03:06 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:03:06 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2369 bytes result sent to driver
20/02/14 11:03:06 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 25 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:03:06 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
20/02/14 11:03:06 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:204) finished in 0.041 s
20/02/14 11:03:06 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:03:06 INFO DAGScheduler: running: Set()
20/02/14 11:03:06 INFO DAGScheduler: waiting: Set(ResultStage 4)
20/02/14 11:03:06 INFO DAGScheduler: failed: Set()
20/02/14 11:03:06 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[26] at collect at utils.scala:204), which has no missing parents
20/02/14 11:03:06 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.2 KiB, free 413.8 MiB)
20/02/14 11:03:06 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
20/02/14 11:03:06 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 11:03:06 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1196
20/02/14 11:03:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[26] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/14 11:03:06 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
20/02/14 11:03:06 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:03:06 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
20/02/14 11:03:06 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:03:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:03:06 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2803 bytes result sent to driver
20/02/14 11:03:06 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 11 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:03:06 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
20/02/14 11:03:06 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:204) finished in 0.026 s
20/02/14 11:03:06 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:03:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
20/02/14 11:03:06 INFO DAGScheduler: Job 2 finished: collect at utils.scala:204, took 0.077647 s
20/02/14 11:03:06 INFO CodeGenerator: Code generated in 8.024001 ms
20/02/14 11:03:07 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:55441 in memory (size: 15.3 KiB, free: 413.9 MiB)
20/02/14 11:03:07 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 11:03:07 INFO CodeGenerator: Code generated in 5.897 ms
20/02/14 11:03:14 WARN ProcfsMetricsGetter: Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
20/02/14 11:07:38 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:55441 in memory (size: 15.3 KiB, free: 413.9 MiB)
20/02/14 11:07:38 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:55441 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 11:07:38 INFO CodeGenerator: Code generated in 22.0558 ms
20/02/14 11:07:38 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/14 11:07:38 INFO DAGScheduler: Got job 3 (collect at utils.scala:204) with 1 output partitions
20/02/14 11:07:38 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:204)
20/02/14 11:07:38 INFO DAGScheduler: Parents of final stage: List()
20/02/14 11:07:38 INFO DAGScheduler: Missing parents: List()
20/02/14 11:07:38 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[31] at collect at utils.scala:204), which has no missing parents
20/02/14 11:07:38 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 47.2 KiB, free 413.9 MiB)
20/02/14 11:07:38 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 413.9 MiB)
20/02/14 11:07:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:55441 (size: 14.8 KiB, free: 413.9 MiB)
20/02/14 11:07:38 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1196
20/02/14 11:07:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[31] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/14 11:07:38 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
20/02/14 11:07:38 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8649 bytes)
20/02/14 11:07:38 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
20/02/14 11:07:38 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:07:38 INFO Executor: 1 block locks were not released by TID = 5:
[rdd_10_0]
20/02/14 11:07:38 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2319 bytes result sent to driver
20/02/14 11:07:38 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 40 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:07:38 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
20/02/14 11:07:38 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:204) finished in 0.090 s
20/02/14 11:07:38 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:07:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
20/02/14 11:07:38 INFO DAGScheduler: Job 3 finished: collect at utils.scala:204, took 0.094631 s
20/02/14 11:07:38 INFO CodeGenerator: Code generated in 7.402801 ms
20/02/14 11:07:39 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:55441 in memory (size: 14.8 KiB, free: 413.9 MiB)
20/02/14 11:07:41 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/14 11:07:41 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
20/02/14 11:07:41 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
20/02/14 11:07:41 INFO DAGScheduler: Parents of final stage: List()
20/02/14 11:07:41 INFO DAGScheduler: Missing parents: List()
20/02/14 11:07:41 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[36] at collect at utils.scala:204), which has no missing parents
20/02/14 11:07:41 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 47.2 KiB, free 413.9 MiB)
20/02/14 11:07:41 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 413.9 MiB)
20/02/14 11:07:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:55441 (size: 14.8 KiB, free: 413.9 MiB)
20/02/14 11:07:41 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1196
20/02/14 11:07:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[36] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/14 11:07:41 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
20/02/14 11:07:41 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8649 bytes)
20/02/14 11:07:41 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
20/02/14 11:07:41 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:07:41 INFO Executor: 1 block locks were not released by TID = 6:
[rdd_10_0]
20/02/14 11:07:41 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2276 bytes result sent to driver
20/02/14 11:07:41 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 9 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:07:41 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
20/02/14 11:07:41 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.018 s
20/02/14 11:07:41 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:07:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
20/02/14 11:07:41 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.024760 s
20/02/14 11:07:42 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:55441 in memory (size: 14.8 KiB, free: 413.9 MiB)
20/02/14 11:07:42 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/14 11:07:42 INFO DAGScheduler: Got job 5 (collect at utils.scala:204) with 1 output partitions
20/02/14 11:07:42 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:204)
20/02/14 11:07:42 INFO DAGScheduler: Parents of final stage: List()
20/02/14 11:07:42 INFO DAGScheduler: Missing parents: List()
20/02/14 11:07:42 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[41] at collect at utils.scala:204), which has no missing parents
20/02/14 11:07:42 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 47.2 KiB, free 413.9 MiB)
20/02/14 11:07:42 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 413.9 MiB)
20/02/14 11:07:42 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:55441 (size: 14.8 KiB, free: 413.9 MiB)
20/02/14 11:07:42 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1196
20/02/14 11:07:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[41] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/14 11:07:42 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
20/02/14 11:07:42 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8649 bytes)
20/02/14 11:07:42 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
20/02/14 11:07:42 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:07:42 INFO Executor: 1 block locks were not released by TID = 7:
[rdd_10_0]
20/02/14 11:07:42 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2233 bytes result sent to driver
20/02/14 11:07:42 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 9 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:07:42 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
20/02/14 11:07:42 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:204) finished in 0.018 s
20/02/14 11:07:42 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:07:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
20/02/14 11:07:42 INFO DAGScheduler: Job 5 finished: collect at utils.scala:204, took 0.022074 s
20/02/14 11:09:46 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:55441 in memory (size: 14.8 KiB, free: 413.9 MiB)
20/02/14 11:09:46 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/14 11:09:46 INFO DAGScheduler: Got job 6 (collect at utils.scala:204) with 1 output partitions
20/02/14 11:09:46 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:204)
20/02/14 11:09:46 INFO DAGScheduler: Parents of final stage: List()
20/02/14 11:09:46 INFO DAGScheduler: Missing parents: List()
20/02/14 11:09:46 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[46] at collect at utils.scala:204), which has no missing parents
20/02/14 11:09:46 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 47.2 KiB, free 413.9 MiB)
20/02/14 11:09:46 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 413.9 MiB)
20/02/14 11:09:46 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:55441 (size: 14.8 KiB, free: 413.9 MiB)
20/02/14 11:09:46 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1196
20/02/14 11:09:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[46] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/14 11:09:46 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
20/02/14 11:09:46 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8649 bytes)
20/02/14 11:09:46 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
20/02/14 11:09:46 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:09:46 INFO Executor: 1 block locks were not released by TID = 8:
[rdd_10_0]
20/02/14 11:09:46 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2276 bytes result sent to driver
20/02/14 11:09:46 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 11 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:09:46 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
20/02/14 11:09:46 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:204) finished in 0.024 s
20/02/14 11:09:46 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:09:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
20/02/14 11:09:46 INFO DAGScheduler: Job 6 finished: collect at utils.scala:204, took 0.029074 s
20/02/14 11:10:39 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:55441 in memory (size: 14.8 KiB, free: 413.9 MiB)
20/02/14 11:10:39 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/14 11:10:39 INFO DAGScheduler: Got job 7 (collect at utils.scala:204) with 1 output partitions
20/02/14 11:10:39 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:204)
20/02/14 11:10:39 INFO DAGScheduler: Parents of final stage: List()
20/02/14 11:10:39 INFO DAGScheduler: Missing parents: List()
20/02/14 11:10:39 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[51] at collect at utils.scala:204), which has no missing parents
20/02/14 11:10:39 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 47.2 KiB, free 413.9 MiB)
20/02/14 11:10:39 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 413.9 MiB)
20/02/14 11:10:39 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:55441 (size: 14.8 KiB, free: 413.9 MiB)
20/02/14 11:10:39 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1196
20/02/14 11:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[51] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/14 11:10:39 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
20/02/14 11:10:39 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8649 bytes)
20/02/14 11:10:39 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
20/02/14 11:10:39 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:10:39 INFO Executor: 1 block locks were not released by TID = 9:
[rdd_10_0]
20/02/14 11:10:39 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2276 bytes result sent to driver
20/02/14 11:10:39 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 9 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:10:39 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
20/02/14 11:10:39 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:204) finished in 0.018 s
20/02/14 11:10:39 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:10:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
20/02/14 11:10:39 INFO DAGScheduler: Job 7 finished: collect at utils.scala:204, took 0.022853 s
20/02/14 11:11:05 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:55441 in memory (size: 14.8 KiB, free: 413.9 MiB)
20/02/14 11:11:05 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/14 11:11:05 INFO DAGScheduler: Registering RDD 56 (collect at utils.scala:204) as input to shuffle 2
20/02/14 11:11:05 INFO DAGScheduler: Got job 8 (collect at utils.scala:204) with 1 output partitions
20/02/14 11:11:05 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:204)
20/02/14 11:11:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
20/02/14 11:11:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
20/02/14 11:11:05 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[56] at collect at utils.scala:204), which has no missing parents
20/02/14 11:11:05 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 43.9 KiB, free 413.9 MiB)
20/02/14 11:11:05 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 413.9 MiB)
20/02/14 11:11:05 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:55441 (size: 15.3 KiB, free: 413.9 MiB)
20/02/14 11:11:05 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1196
20/02/14 11:11:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[56] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/14 11:11:05 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
20/02/14 11:11:05 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:11:05 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
20/02/14 11:11:05 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:11:05 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2369 bytes result sent to driver
20/02/14 11:11:05 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:11:05 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
20/02/14 11:11:05 INFO DAGScheduler: ShuffleMapStage 10 (collect at utils.scala:204) finished in 0.030 s
20/02/14 11:11:05 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:11:05 INFO DAGScheduler: running: Set()
20/02/14 11:11:05 INFO DAGScheduler: waiting: Set(ResultStage 11)
20/02/14 11:11:05 INFO DAGScheduler: failed: Set()
20/02/14 11:11:05 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[59] at collect at utils.scala:204), which has no missing parents
20/02/14 11:11:05 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/14 11:11:05 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
20/02/14 11:11:05 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 11:11:05 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1196
20/02/14 11:11:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[59] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/14 11:11:05 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
20/02/14 11:11:05 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:11:05 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
20/02/14 11:11:05 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:11:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:11:05 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 2760 bytes result sent to driver
20/02/14 11:11:05 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 6 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:11:05 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
20/02/14 11:11:05 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:204) finished in 0.024 s
20/02/14 11:11:05 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:11:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
20/02/14 11:11:05 INFO DAGScheduler: Job 8 finished: collect at utils.scala:204, took 0.060430 s
20/02/14 11:11:11 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 11:11:11 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:55441 in memory (size: 15.3 KiB, free: 413.9 MiB)
20/02/14 11:11:11 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/14 11:11:11 INFO DAGScheduler: Registering RDD 64 (collect at utils.scala:204) as input to shuffle 3
20/02/14 11:11:11 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
20/02/14 11:11:11 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:204)
20/02/14 11:11:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
20/02/14 11:11:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
20/02/14 11:11:11 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[64] at collect at utils.scala:204), which has no missing parents
20/02/14 11:11:11 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 43.9 KiB, free 413.9 MiB)
20/02/14 11:11:11 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 413.9 MiB)
20/02/14 11:11:11 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:55441 (size: 15.3 KiB, free: 413.9 MiB)
20/02/14 11:11:11 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1196
20/02/14 11:11:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[64] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/14 11:11:11 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
20/02/14 11:11:11 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:11:11 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
20/02/14 11:11:11 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:11:11 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2326 bytes result sent to driver
20/02/14 11:11:11 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 25 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:11:11 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
20/02/14 11:11:11 INFO DAGScheduler: ShuffleMapStage 12 (collect at utils.scala:204) finished in 0.034 s
20/02/14 11:11:11 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:11:11 INFO DAGScheduler: running: Set()
20/02/14 11:11:11 INFO DAGScheduler: waiting: Set(ResultStage 13)
20/02/14 11:11:11 INFO DAGScheduler: failed: Set()
20/02/14 11:11:11 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[67] at collect at utils.scala:204), which has no missing parents
20/02/14 11:11:11 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/14 11:11:11 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
20/02/14 11:11:11 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 11:11:11 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1196
20/02/14 11:11:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[67] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/14 11:11:11 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
20/02/14 11:11:11 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:11:11 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
20/02/14 11:11:11 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:11:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:11:11 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2803 bytes result sent to driver
20/02/14 11:11:11 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 6 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:11:11 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
20/02/14 11:11:11 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:204) finished in 0.017 s
20/02/14 11:11:11 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:11:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
20/02/14 11:11:11 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0.056605 s
20/02/14 11:11:16 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:55441 in memory (size: 15.3 KiB, free: 413.9 MiB)
20/02/14 11:11:16 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 11:11:17 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/14 11:11:17 INFO DAGScheduler: Got job 10 (collect at utils.scala:204) with 1 output partitions
20/02/14 11:11:17 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:204)
20/02/14 11:11:17 INFO DAGScheduler: Parents of final stage: List()
20/02/14 11:11:17 INFO DAGScheduler: Missing parents: List()
20/02/14 11:11:17 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[72] at collect at utils.scala:204), which has no missing parents
20/02/14 11:11:17 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 47.3 KiB, free 413.9 MiB)
20/02/14 11:11:17 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 14.8 KiB, free 413.9 MiB)
20/02/14 11:11:17 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:55441 (size: 14.8 KiB, free: 413.9 MiB)
20/02/14 11:11:17 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1196
20/02/14 11:11:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[72] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/14 11:11:17 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
20/02/14 11:11:17 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8649 bytes)
20/02/14 11:11:17 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
20/02/14 11:11:17 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:11:17 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 3118 bytes result sent to driver
20/02/14 11:11:17 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 7 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:11:17 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
20/02/14 11:11:17 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:204) finished in 0.019 s
20/02/14 11:11:17 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:11:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
20/02/14 11:11:17 INFO DAGScheduler: Job 10 finished: collect at utils.scala:204, took 0.022377 s
20/02/14 11:11:40 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:55441 in memory (size: 14.8 KiB, free: 413.9 MiB)
20/02/14 11:11:40 INFO CodeGenerator: Code generated in 18.6066 ms
20/02/14 11:11:40 INFO CodeGenerator: Code generated in 56.8829 ms
20/02/14 11:11:40 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/14 11:11:40 INFO DAGScheduler: Registering RDD 77 (collect at utils.scala:204) as input to shuffle 4
20/02/14 11:11:40 INFO DAGScheduler: Got job 11 (collect at utils.scala:204) with 4 output partitions
20/02/14 11:11:40 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:204)
20/02/14 11:11:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
20/02/14 11:11:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
20/02/14 11:11:40 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[77] at collect at utils.scala:204), which has no missing parents
20/02/14 11:11:40 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 56.0 KiB, free 413.9 MiB)
20/02/14 11:11:40 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 20.2 KiB, free 413.8 MiB)
20/02/14 11:11:40 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:55441 (size: 20.2 KiB, free: 413.9 MiB)
20/02/14 11:11:40 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1196
20/02/14 11:11:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[77] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/14 11:11:40 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
20/02/14 11:11:40 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:11:40 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
20/02/14 11:11:40 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:11:40 INFO CodeGenerator: Code generated in 5.5261 ms
20/02/14 11:11:40 INFO CodeGenerator: Code generated in 4.988901 ms
20/02/14 11:11:40 INFO CodeGenerator: Code generated in 4.6506 ms
20/02/14 11:11:40 INFO CodeGenerator: Code generated in 9.944801 ms
20/02/14 11:11:40 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 2756 bytes result sent to driver
20/02/14 11:11:40 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 98 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:11:40 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
20/02/14 11:11:40 INFO DAGScheduler: ShuffleMapStage 15 (collect at utils.scala:204) finished in 0.106 s
20/02/14 11:11:40 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:11:40 INFO DAGScheduler: running: Set()
20/02/14 11:11:40 INFO DAGScheduler: waiting: Set(ResultStage 16)
20/02/14 11:11:40 INFO DAGScheduler: failed: Set()
20/02/14 11:11:40 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[80] at collect at utils.scala:204), which has no missing parents
20/02/14 11:11:40 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 52.3 KiB, free 413.8 MiB)
20/02/14 11:11:40 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 413.8 MiB)
20/02/14 11:11:40 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:55441 (size: 19.4 KiB, free: 413.9 MiB)
20/02/14 11:11:40 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1196
20/02/14 11:11:40 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 16 (MapPartitionsRDD[80] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 11:11:40 INFO TaskSchedulerImpl: Adding task set 16.0 with 4 tasks
20/02/14 11:11:40 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 16, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7248 bytes)
20/02/14 11:11:40 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 17, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7248 bytes)
20/02/14 11:11:40 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 18, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7248 bytes)
20/02/14 11:11:40 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 19, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7248 bytes)
20/02/14 11:11:40 INFO Executor: Running task 2.0 in stage 16.0 (TID 16)
20/02/14 11:11:40 INFO Executor: Running task 3.0 in stage 16.0 (TID 17)
20/02/14 11:11:40 INFO Executor: Running task 1.0 in stage 16.0 (TID 19)
20/02/14 11:11:40 INFO Executor: Running task 0.0 in stage 16.0 (TID 18)
20/02/14 11:11:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:11:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 11:11:40 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:11:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 11:11:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:11:40 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:11:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:11:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 11:11:40 INFO Executor: Finished task 0.0 in stage 16.0 (TID 18). 4124 bytes result sent to driver
20/02/14 11:11:40 INFO Executor: Finished task 1.0 in stage 16.0 (TID 19). 4124 bytes result sent to driver
20/02/14 11:11:40 INFO Executor: Finished task 2.0 in stage 16.0 (TID 16). 4148 bytes result sent to driver
20/02/14 11:11:40 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 19) in 24 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 11:11:40 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 18) in 24 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 11:11:40 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 16) in 26 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 11:11:40 INFO Executor: Finished task 3.0 in stage 16.0 (TID 17). 4098 bytes result sent to driver
20/02/14 11:11:40 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 17) in 28 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 11:11:40 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
20/02/14 11:11:40 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:204) finished in 0.039 s
20/02/14 11:11:40 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:11:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
20/02/14 11:11:40 INFO DAGScheduler: Job 11 finished: collect at utils.scala:204, took 0.151781 s
20/02/14 11:11:40 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:55441 in memory (size: 20.2 KiB, free: 413.9 MiB)
20/02/14 11:11:40 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:55441 in memory (size: 19.4 KiB, free: 413.9 MiB)
20/02/14 11:11:58 INFO CodeGenerator: Code generated in 15.3619 ms
20/02/14 11:11:58 INFO CodeGenerator: Code generated in 41.212 ms
20/02/14 11:11:58 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/14 11:11:58 INFO DAGScheduler: Registering RDD 85 (collect at utils.scala:204) as input to shuffle 5
20/02/14 11:11:58 INFO DAGScheduler: Got job 12 (collect at utils.scala:204) with 4 output partitions
20/02/14 11:11:58 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:204)
20/02/14 11:11:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
20/02/14 11:11:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
20/02/14 11:11:58 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[85] at collect at utils.scala:204), which has no missing parents
20/02/14 11:11:58 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 62.0 KiB, free 413.9 MiB)
20/02/14 11:11:58 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 21.6 KiB, free 413.8 MiB)
20/02/14 11:11:58 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:55441 (size: 21.6 KiB, free: 413.9 MiB)
20/02/14 11:11:58 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1196
20/02/14 11:11:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[85] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/14 11:11:58 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
20/02/14 11:11:58 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 20, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:11:58 INFO Executor: Running task 0.0 in stage 17.0 (TID 20)
20/02/14 11:11:58 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:11:58 INFO CodeGenerator: Code generated in 6.4581 ms
20/02/14 11:11:58 INFO CodeGenerator: Code generated in 10.7162 ms
20/02/14 11:11:58 INFO Executor: Finished task 0.0 in stage 17.0 (TID 20). 2756 bytes result sent to driver
20/02/14 11:11:58 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 20) in 121 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:11:58 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
20/02/14 11:11:58 INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:204) finished in 0.130 s
20/02/14 11:11:58 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:11:58 INFO DAGScheduler: running: Set()
20/02/14 11:11:58 INFO DAGScheduler: waiting: Set(ResultStage 18)
20/02/14 11:11:58 INFO DAGScheduler: failed: Set()
20/02/14 11:11:58 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[88] at collect at utils.scala:204), which has no missing parents
20/02/14 11:11:58 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 54.4 KiB, free 413.8 MiB)
20/02/14 11:11:58 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 20.1 KiB, free 413.8 MiB)
20/02/14 11:11:58 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:55441 (size: 20.1 KiB, free: 413.9 MiB)
20/02/14 11:11:58 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1196
20/02/14 11:11:58 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 18 (MapPartitionsRDD[88] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 11:11:58 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
20/02/14 11:11:58 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 21, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:11:58 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 22, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7248 bytes)
20/02/14 11:11:58 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 23, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7248 bytes)
20/02/14 11:11:58 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 24, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7248 bytes)
20/02/14 11:11:58 INFO Executor: Running task 2.0 in stage 18.0 (TID 23)
20/02/14 11:11:58 INFO Executor: Running task 1.0 in stage 18.0 (TID 22)
20/02/14 11:11:58 INFO Executor: Running task 3.0 in stage 18.0 (TID 24)
20/02/14 11:11:58 INFO Executor: Running task 0.0 in stage 18.0 (TID 21)
20/02/14 11:11:58 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:11:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:11:58 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:11:58 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:11:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:11:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:11:58 INFO ShuffleBlockFetcherIterator: Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:11:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 11:11:58 INFO Executor: Finished task 3.0 in stage 18.0 (TID 24). 4141 bytes result sent to driver
20/02/14 11:11:58 INFO Executor: Finished task 1.0 in stage 18.0 (TID 22). 4245 bytes result sent to driver
20/02/14 11:11:58 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 24) in 34 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 11:11:58 INFO Executor: Finished task 2.0 in stage 18.0 (TID 23). 4255 bytes result sent to driver
20/02/14 11:11:58 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 22) in 36 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 11:11:58 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 23) in 36 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 11:11:58 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:55441 in memory (size: 21.6 KiB, free: 413.9 MiB)
20/02/14 11:11:58 INFO Executor: Finished task 0.0 in stage 18.0 (TID 21). 4185 bytes result sent to driver
20/02/14 11:11:58 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 21) in 41 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 11:11:58 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
20/02/14 11:11:58 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:204) finished in 0.051 s
20/02/14 11:11:58 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:11:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
20/02/14 11:11:58 INFO DAGScheduler: Job 12 finished: collect at utils.scala:204, took 0.187139 s
20/02/14 11:12:19 INFO CodeGenerator: Code generated in 17.437501 ms
20/02/14 11:12:19 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/14 11:12:19 INFO DAGScheduler: Registering RDD 93 (collect at utils.scala:204) as input to shuffle 6
20/02/14 11:12:19 INFO DAGScheduler: Got job 13 (collect at utils.scala:204) with 4 output partitions
20/02/14 11:12:19 INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:204)
20/02/14 11:12:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
20/02/14 11:12:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
20/02/14 11:12:19 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[93] at collect at utils.scala:204), which has no missing parents
20/02/14 11:12:19 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 62.0 KiB, free 413.8 MiB)
20/02/14 11:12:19 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 21.6 KiB, free 413.8 MiB)
20/02/14 11:12:19 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:55441 (size: 21.6 KiB, free: 413.9 MiB)
20/02/14 11:12:19 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1196
20/02/14 11:12:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[93] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/14 11:12:19 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
20/02/14 11:12:19 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 25, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:12:19 INFO Executor: Running task 0.0 in stage 19.0 (TID 25)
20/02/14 11:12:19 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:12:19 INFO Executor: Finished task 0.0 in stage 19.0 (TID 25). 2713 bytes result sent to driver
20/02/14 11:12:19 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 25) in 42 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:12:19 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
20/02/14 11:12:19 INFO DAGScheduler: ShuffleMapStage 19 (collect at utils.scala:204) finished in 0.059 s
20/02/14 11:12:19 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:12:19 INFO DAGScheduler: running: Set()
20/02/14 11:12:19 INFO DAGScheduler: waiting: Set(ResultStage 20)
20/02/14 11:12:19 INFO DAGScheduler: failed: Set()
20/02/14 11:12:19 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[96] at collect at utils.scala:204), which has no missing parents
20/02/14 11:12:19 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 54.9 KiB, free 413.7 MiB)
20/02/14 11:12:19 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 20.2 KiB, free 413.7 MiB)
20/02/14 11:12:19 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:55441 (size: 20.2 KiB, free: 413.9 MiB)
20/02/14 11:12:19 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1196
20/02/14 11:12:19 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 20 (MapPartitionsRDD[96] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 11:12:19 INFO TaskSchedulerImpl: Adding task set 20.0 with 4 tasks
20/02/14 11:12:19 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 26, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:12:19 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 27, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7248 bytes)
20/02/14 11:12:19 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 28, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7248 bytes)
20/02/14 11:12:19 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 29, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7248 bytes)
20/02/14 11:12:19 INFO Executor: Running task 1.0 in stage 20.0 (TID 27)
20/02/14 11:12:19 INFO Executor: Running task 0.0 in stage 20.0 (TID 26)
20/02/14 11:12:19 INFO Executor: Running task 3.0 in stage 20.0 (TID 29)
20/02/14 11:12:19 INFO Executor: Running task 2.0 in stage 20.0 (TID 28)
20/02/14 11:12:19 INFO ShuffleBlockFetcherIterator: Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:12:19 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:12:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:12:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:12:19 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:12:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
20/02/14 11:12:19 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:12:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:12:19 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:55441 in memory (size: 21.6 KiB, free: 413.9 MiB)
20/02/14 11:12:19 INFO Executor: Finished task 0.0 in stage 20.0 (TID 26). 4248 bytes result sent to driver
20/02/14 11:12:19 INFO Executor: Finished task 2.0 in stage 20.0 (TID 28). 4276 bytes result sent to driver
20/02/14 11:12:19 INFO Executor: Finished task 3.0 in stage 20.0 (TID 29). 4242 bytes result sent to driver
20/02/14 11:12:19 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 26) in 27 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 11:12:19 INFO Executor: Finished task 1.0 in stage 20.0 (TID 27). 4231 bytes result sent to driver
20/02/14 11:12:19 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 29) in 27 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 11:12:19 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 28) in 27 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 11:12:19 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 27) in 29 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 11:12:19 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
20/02/14 11:12:19 INFO DAGScheduler: ResultStage 20 (collect at utils.scala:204) finished in 0.038 s
20/02/14 11:12:19 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:12:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
20/02/14 11:12:19 INFO DAGScheduler: Job 13 finished: collect at utils.scala:204, took 0.103927 s
20/02/14 11:12:19 INFO CodeGenerator: Code generated in 7.5712 ms
20/02/14 11:12:22 INFO SparkContext: Starting job: collect at utils.scala:204
20/02/14 11:12:22 INFO DAGScheduler: Registering RDD 101 (collect at utils.scala:204) as input to shuffle 7
20/02/14 11:12:22 INFO DAGScheduler: Got job 14 (collect at utils.scala:204) with 4 output partitions
20/02/14 11:12:22 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:204)
20/02/14 11:12:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
20/02/14 11:12:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
20/02/14 11:12:22 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[101] at collect at utils.scala:204), which has no missing parents
20/02/14 11:12:22 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 62.0 KiB, free 413.7 MiB)
20/02/14 11:12:22 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 21.6 KiB, free 413.7 MiB)
20/02/14 11:12:22 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:55441 (size: 21.6 KiB, free: 413.9 MiB)
20/02/14 11:12:22 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1196
20/02/14 11:12:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[101] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
20/02/14 11:12:22 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
20/02/14 11:12:22 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 30, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:12:22 INFO Executor: Running task 0.0 in stage 21.0 (TID 30)
20/02/14 11:12:22 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:12:22 INFO Executor: Finished task 0.0 in stage 21.0 (TID 30). 2756 bytes result sent to driver
20/02/14 11:12:22 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 30) in 35 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:12:22 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
20/02/14 11:12:22 INFO DAGScheduler: ShuffleMapStage 21 (collect at utils.scala:204) finished in 0.042 s
20/02/14 11:12:22 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:12:22 INFO DAGScheduler: running: Set()
20/02/14 11:12:22 INFO DAGScheduler: waiting: Set(ResultStage 22)
20/02/14 11:12:22 INFO DAGScheduler: failed: Set()
20/02/14 11:12:22 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[104] at collect at utils.scala:204), which has no missing parents
20/02/14 11:12:22 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 54.9 KiB, free 413.6 MiB)
20/02/14 11:12:22 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 20.1 KiB, free 413.6 MiB)
20/02/14 11:12:22 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:55441 (size: 20.1 KiB, free: 413.8 MiB)
20/02/14 11:12:22 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1196
20/02/14 11:12:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 22 (MapPartitionsRDD[104] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 11:12:22 INFO TaskSchedulerImpl: Adding task set 22.0 with 4 tasks
20/02/14 11:12:22 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 31, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:12:22 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 32, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7248 bytes)
20/02/14 11:12:22 INFO TaskSetManager: Starting task 2.0 in stage 22.0 (TID 33, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7248 bytes)
20/02/14 11:12:22 INFO TaskSetManager: Starting task 3.0 in stage 22.0 (TID 34, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7248 bytes)
20/02/14 11:12:22 INFO Executor: Running task 0.0 in stage 22.0 (TID 31)
20/02/14 11:12:22 INFO Executor: Running task 2.0 in stage 22.0 (TID 33)
20/02/14 11:12:22 INFO Executor: Running task 3.0 in stage 22.0 (TID 34)
20/02/14 11:12:22 INFO Executor: Running task 1.0 in stage 22.0 (TID 32)
20/02/14 11:12:22 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:12:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:12:22 INFO ShuffleBlockFetcherIterator: Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:12:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:12:22 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:12:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:12:22 INFO Executor: Finished task 2.0 in stage 22.0 (TID 33). 4233 bytes result sent to driver
20/02/14 11:12:22 INFO Executor: Finished task 3.0 in stage 22.0 (TID 34). 4156 bytes result sent to driver
20/02/14 11:12:22 INFO TaskSetManager: Finished task 2.0 in stage 22.0 (TID 33) in 17 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 11:12:22 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:12:22 INFO TaskSetManager: Finished task 3.0 in stage 22.0 (TID 34) in 17 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 11:12:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 11:12:22 INFO Executor: Finished task 1.0 in stage 22.0 (TID 32). 4188 bytes result sent to driver
20/02/14 11:12:22 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 32) in 19 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 11:12:22 INFO Executor: Finished task 0.0 in stage 22.0 (TID 31). 4162 bytes result sent to driver
20/02/14 11:12:22 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 31) in 24 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 11:12:22 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
20/02/14 11:12:22 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:204) finished in 0.032 s
20/02/14 11:12:22 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:12:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
20/02/14 11:12:22 INFO DAGScheduler: Job 14 finished: collect at utils.scala:204, took 0.079428 s
20/02/14 11:14:33 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:55441 in memory (size: 20.1 KiB, free: 413.9 MiB)
20/02/14 11:14:34 INFO CodeGenerator: Code generated in 8.016501 ms
20/02/14 11:14:34 INFO CodeGenerator: Code generated in 8.8752 ms
20/02/14 11:14:34 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 11:14:34 INFO DAGScheduler: Registering RDD 109 (collect at arrowconverters.scala:270) as input to shuffle 8
20/02/14 11:14:34 INFO DAGScheduler: Got job 15 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 11:14:34 INFO DAGScheduler: Final stage: ResultStage 24 (collect at arrowconverters.scala:270)
20/02/14 11:14:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
20/02/14 11:14:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
20/02/14 11:14:34 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[109] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:14:34 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 43.9 KiB, free 413.7 MiB)
20/02/14 11:14:34 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 413.6 MiB)
20/02/14 11:14:34 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:55441 (size: 15.3 KiB, free: 413.8 MiB)
20/02/14 11:14:34 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1196
20/02/14 11:14:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[109] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:14:34 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
20/02/14 11:14:34 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 35, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:14:34 INFO Executor: Running task 0.0 in stage 23.0 (TID 35)
20/02/14 11:14:34 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:14:34 INFO Executor: Finished task 0.0 in stage 23.0 (TID 35). 2369 bytes result sent to driver
20/02/14 11:14:34 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 35) in 19 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:14:34 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
20/02/14 11:14:34 INFO DAGScheduler: ShuffleMapStage 23 (collect at arrowconverters.scala:270) finished in 0.027 s
20/02/14 11:14:34 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:14:34 INFO DAGScheduler: running: Set()
20/02/14 11:14:34 INFO DAGScheduler: waiting: Set(ResultStage 24)
20/02/14 11:14:34 INFO DAGScheduler: failed: Set()
20/02/14 11:14:34 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[115] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:14:34 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 54.0 KiB, free 413.6 MiB)
20/02/14 11:14:34 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 413.6 MiB)
20/02/14 11:14:34 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:55441 (size: 19.4 KiB, free: 413.8 MiB)
20/02/14 11:14:34 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1196
20/02/14 11:14:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[115] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:14:34 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
20/02/14 11:14:34 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 36, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:14:34 INFO Executor: Running task 0.0 in stage 24.0 (TID 36)
20/02/14 11:14:34 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:14:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:14:34 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:55441 in memory (size: 15.3 KiB, free: 413.8 MiB)
20/02/14 11:14:34 INFO CodeGenerator: Code generated in 8.9918 ms
20/02/14 11:14:34 INFO Executor: Finished task 0.0 in stage 24.0 (TID 36). 4372 bytes result sent to driver
20/02/14 11:14:34 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 36) in 214 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:14:34 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
20/02/14 11:14:34 INFO DAGScheduler: ResultStage 24 (collect at arrowconverters.scala:270) finished in 0.226 s
20/02/14 11:14:34 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:14:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
20/02/14 11:14:34 INFO DAGScheduler: Job 15 finished: collect at arrowconverters.scala:270, took 0.259690 s
20/02/14 11:14:34 INFO CodeGenerator: Code generated in 7.3302 ms
20/02/14 11:14:36 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:55441 in memory (size: 20.2 KiB, free: 413.9 MiB)
20/02/14 11:14:36 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:55441 in memory (size: 19.4 KiB, free: 413.9 MiB)
20/02/14 11:14:36 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:55441 in memory (size: 21.6 KiB, free: 413.9 MiB)
20/02/14 11:14:36 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:55441 in memory (size: 20.1 KiB, free: 413.9 MiB)
20/02/14 11:14:36 INFO CodeGenerator: Code generated in 13.551899 ms
20/02/14 11:14:36 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 11:14:36 INFO DAGScheduler: Registering RDD 120 (collect at arrowconverters.scala:270) as input to shuffle 9
20/02/14 11:14:36 INFO DAGScheduler: Got job 16 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 11:14:36 INFO DAGScheduler: Final stage: ResultStage 26 (collect at arrowconverters.scala:270)
20/02/14 11:14:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
20/02/14 11:14:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
20/02/14 11:14:36 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[120] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:14:36 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 43.9 KiB, free 413.9 MiB)
20/02/14 11:14:36 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 413.9 MiB)
20/02/14 11:14:36 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:55441 (size: 15.3 KiB, free: 413.9 MiB)
20/02/14 11:14:36 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1196
20/02/14 11:14:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[120] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:14:36 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
20/02/14 11:14:36 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 37, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:14:36 INFO Executor: Running task 0.0 in stage 25.0 (TID 37)
20/02/14 11:14:36 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:14:36 INFO Executor: Finished task 0.0 in stage 25.0 (TID 37). 2369 bytes result sent to driver
20/02/14 11:14:36 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 37) in 14 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:14:36 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
20/02/14 11:14:36 INFO DAGScheduler: ShuffleMapStage 25 (collect at arrowconverters.scala:270) finished in 0.019 s
20/02/14 11:14:36 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:14:36 INFO DAGScheduler: running: Set()
20/02/14 11:14:36 INFO DAGScheduler: waiting: Set(ResultStage 26)
20/02/14 11:14:36 INFO DAGScheduler: failed: Set()
20/02/14 11:14:36 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[126] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:14:36 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 54.0 KiB, free 413.8 MiB)
20/02/14 11:14:36 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 413.8 MiB)
20/02/14 11:14:36 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:55441 (size: 19.4 KiB, free: 413.9 MiB)
20/02/14 11:14:36 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1196
20/02/14 11:14:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[126] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:14:36 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
20/02/14 11:14:36 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 38, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:14:36 INFO Executor: Running task 0.0 in stage 26.0 (TID 38)
20/02/14 11:14:36 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:14:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:14:36 INFO Executor: Finished task 0.0 in stage 26.0 (TID 38). 4243 bytes result sent to driver
20/02/14 11:14:36 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 38) in 14 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:14:36 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
20/02/14 11:14:36 INFO DAGScheduler: ResultStage 26 (collect at arrowconverters.scala:270) finished in 0.024 s
20/02/14 11:14:36 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:14:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
20/02/14 11:14:36 INFO DAGScheduler: Job 16 finished: collect at arrowconverters.scala:270, took 0.050372 s
20/02/14 11:14:40 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:55441 in memory (size: 15.3 KiB, free: 413.9 MiB)
20/02/14 11:14:40 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:55441 in memory (size: 19.4 KiB, free: 413.9 MiB)
20/02/14 11:14:40 INFO CodeGenerator: Code generated in 8.1159 ms
20/02/14 11:14:40 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 11:14:40 INFO DAGScheduler: Registering RDD 131 (collect at arrowconverters.scala:270) as input to shuffle 10
20/02/14 11:14:40 INFO DAGScheduler: Got job 17 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 11:14:40 INFO DAGScheduler: Final stage: ResultStage 28 (collect at arrowconverters.scala:270)
20/02/14 11:14:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
20/02/14 11:14:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 27)
20/02/14 11:14:40 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[131] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:14:40 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 43.9 KiB, free 413.9 MiB)
20/02/14 11:14:40 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 15.3 KiB, free 413.9 MiB)
20/02/14 11:14:40 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:55441 (size: 15.3 KiB, free: 413.9 MiB)
20/02/14 11:14:40 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1196
20/02/14 11:14:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[131] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:14:40 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
20/02/14 11:14:40 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 39, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:14:40 INFO Executor: Running task 0.0 in stage 27.0 (TID 39)
20/02/14 11:14:40 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:14:40 INFO Executor: Finished task 0.0 in stage 27.0 (TID 39). 2369 bytes result sent to driver
20/02/14 11:14:40 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 39) in 13 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:14:40 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
20/02/14 11:14:40 INFO DAGScheduler: ShuffleMapStage 27 (collect at arrowconverters.scala:270) finished in 0.021 s
20/02/14 11:14:40 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:14:40 INFO DAGScheduler: running: Set()
20/02/14 11:14:40 INFO DAGScheduler: waiting: Set(ResultStage 28)
20/02/14 11:14:40 INFO DAGScheduler: failed: Set()
20/02/14 11:14:40 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[137] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:14:40 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 54.0 KiB, free 413.8 MiB)
20/02/14 11:14:40 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 413.8 MiB)
20/02/14 11:14:40 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:55441 (size: 19.4 KiB, free: 413.9 MiB)
20/02/14 11:14:40 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1196
20/02/14 11:14:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[137] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:14:40 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
20/02/14 11:14:40 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 40, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:14:40 INFO Executor: Running task 0.0 in stage 28.0 (TID 40)
20/02/14 11:14:40 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:14:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:14:40 INFO Executor: Finished task 0.0 in stage 28.0 (TID 40). 4286 bytes result sent to driver
20/02/14 11:14:40 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 40) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:14:40 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
20/02/14 11:14:40 INFO DAGScheduler: ResultStage 28 (collect at arrowconverters.scala:270) finished in 0.021 s
20/02/14 11:14:40 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:14:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
20/02/14 11:14:40 INFO DAGScheduler: Job 17 finished: collect at arrowconverters.scala:270, took 0.047886 s
20/02/14 11:14:54 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:55441 in memory (size: 15.3 KiB, free: 413.9 MiB)
20/02/14 11:14:54 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:55441 in memory (size: 19.4 KiB, free: 413.9 MiB)
20/02/14 11:14:54 INFO CodeGenerator: Code generated in 6.4053 ms
20/02/14 11:14:54 INFO CodeGenerator: Code generated in 7.656599 ms
20/02/14 11:14:54 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 11:14:54 INFO DAGScheduler: Registering RDD 142 (collect at arrowconverters.scala:270) as input to shuffle 11
20/02/14 11:14:54 INFO DAGScheduler: Got job 18 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 11:14:54 INFO DAGScheduler: Final stage: ResultStage 30 (collect at arrowconverters.scala:270)
20/02/14 11:14:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
20/02/14 11:14:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
20/02/14 11:14:54 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[142] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:14:54 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 44.3 KiB, free 413.9 MiB)
20/02/14 11:14:54 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.9 MiB)
20/02/14 11:14:54 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 11:14:54 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1196
20/02/14 11:14:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[142] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:14:54 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
20/02/14 11:14:54 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 41, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:14:54 INFO Executor: Running task 0.0 in stage 29.0 (TID 41)
20/02/14 11:14:54 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:14:54 INFO Executor: 1 block locks were not released by TID = 41:
[rdd_10_0]
20/02/14 11:14:54 INFO Executor: Finished task 0.0 in stage 29.0 (TID 41). 2157 bytes result sent to driver
20/02/14 11:14:54 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 41) in 21 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:14:54 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
20/02/14 11:14:54 INFO DAGScheduler: ShuffleMapStage 29 (collect at arrowconverters.scala:270) finished in 0.027 s
20/02/14 11:14:54 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:14:54 INFO DAGScheduler: running: Set()
20/02/14 11:14:54 INFO DAGScheduler: waiting: Set(ResultStage 30)
20/02/14 11:14:54 INFO DAGScheduler: failed: Set()
20/02/14 11:14:54 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[148] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:14:54 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 49.0 KiB, free 413.8 MiB)
20/02/14 11:14:54 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.8 MiB)
20/02/14 11:14:54 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 11:14:54 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1196
20/02/14 11:14:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[148] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:14:54 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
20/02/14 11:14:54 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 42, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:14:54 INFO Executor: Running task 0.0 in stage 30.0 (TID 42)
20/02/14 11:14:54 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:14:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:14:54 INFO CodeGenerator: Code generated in 4.8578 ms
20/02/14 11:14:54 INFO CodeGenerator: Code generated in 11.3486 ms
20/02/14 11:14:54 INFO Executor: Finished task 0.0 in stage 30.0 (TID 42). 3122 bytes result sent to driver
20/02/14 11:14:54 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 42) in 38 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:14:54 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
20/02/14 11:14:54 INFO DAGScheduler: ResultStage 30 (collect at arrowconverters.scala:270) finished in 0.045 s
20/02/14 11:14:54 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:14:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
20/02/14 11:14:54 INFO DAGScheduler: Job 18 finished: collect at arrowconverters.scala:270, took 0.077846 s
20/02/14 11:15:02 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 11:15:02 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 11:15:02 INFO CodeGenerator: Code generated in 5.2641 ms
20/02/14 11:15:02 INFO CodeGenerator: Code generated in 7.1204 ms
20/02/14 11:15:02 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 11:15:02 INFO DAGScheduler: Registering RDD 153 (collect at arrowconverters.scala:270) as input to shuffle 12
20/02/14 11:15:02 INFO DAGScheduler: Got job 19 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 11:15:02 INFO DAGScheduler: Final stage: ResultStage 32 (collect at arrowconverters.scala:270)
20/02/14 11:15:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
20/02/14 11:15:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
20/02/14 11:15:02 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[153] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:15:02 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 44.3 KiB, free 413.9 MiB)
20/02/14 11:15:02 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.9 MiB)
20/02/14 11:15:02 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 11:15:02 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1196
20/02/14 11:15:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[153] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:15:02 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
20/02/14 11:15:02 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 43, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:15:02 INFO Executor: Running task 0.0 in stage 31.0 (TID 43)
20/02/14 11:15:02 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:15:02 INFO Executor: 1 block locks were not released by TID = 43:
[rdd_10_0]
20/02/14 11:15:02 INFO Executor: Finished task 0.0 in stage 31.0 (TID 43). 2157 bytes result sent to driver
20/02/14 11:15:02 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 43) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:15:02 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
20/02/14 11:15:02 INFO DAGScheduler: ShuffleMapStage 31 (collect at arrowconverters.scala:270) finished in 0.022 s
20/02/14 11:15:02 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:15:02 INFO DAGScheduler: running: Set()
20/02/14 11:15:02 INFO DAGScheduler: waiting: Set(ResultStage 32)
20/02/14 11:15:02 INFO DAGScheduler: failed: Set()
20/02/14 11:15:02 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[159] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:15:02 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 49.0 KiB, free 413.8 MiB)
20/02/14 11:15:02 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 16.9 KiB, free 413.8 MiB)
20/02/14 11:15:02 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:55441 (size: 16.9 KiB, free: 413.9 MiB)
20/02/14 11:15:02 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1196
20/02/14 11:15:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[159] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:15:02 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
20/02/14 11:15:02 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 44, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:15:02 INFO Executor: Running task 0.0 in stage 32.0 (TID 44)
20/02/14 11:15:02 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:15:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:15:02 INFO Executor: Finished task 0.0 in stage 32.0 (TID 44). 3122 bytes result sent to driver
20/02/14 11:15:02 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 44) in 19 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:15:02 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
20/02/14 11:15:02 INFO DAGScheduler: ResultStage 32 (collect at arrowconverters.scala:270) finished in 0.026 s
20/02/14 11:15:02 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:15:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
20/02/14 11:15:02 INFO DAGScheduler: Job 19 finished: collect at arrowconverters.scala:270, took 0.054617 s
20/02/14 11:15:56 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 11:15:56 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:55441 in memory (size: 16.9 KiB, free: 413.9 MiB)
20/02/14 11:15:56 INFO CodeGenerator: Code generated in 7.2462 ms
20/02/14 11:15:56 INFO CodeGenerator: Code generated in 7.645 ms
20/02/14 11:15:56 INFO CodeGenerator: Code generated in 18.970799 ms
20/02/14 11:15:56 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 11:15:56 INFO DAGScheduler: Registering RDD 164 (collect at arrowconverters.scala:270) as input to shuffle 13
20/02/14 11:15:56 INFO DAGScheduler: Registering RDD 167 (collect at arrowconverters.scala:270) as input to shuffle 14
20/02/14 11:15:56 INFO DAGScheduler: Got job 20 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 11:15:56 INFO DAGScheduler: Final stage: ResultStage 35 (collect at arrowconverters.scala:270)
20/02/14 11:15:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
20/02/14 11:15:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 34)
20/02/14 11:15:56 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[164] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:15:56 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 56.1 KiB, free 413.9 MiB)
20/02/14 11:15:56 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 20.3 KiB, free 413.8 MiB)
20/02/14 11:15:56 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:55441 (size: 20.3 KiB, free: 413.9 MiB)
20/02/14 11:15:56 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1196
20/02/14 11:15:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[164] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:15:56 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
20/02/14 11:15:56 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 45, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:15:56 INFO Executor: Running task 0.0 in stage 33.0 (TID 45)
20/02/14 11:15:56 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:15:56 INFO Executor: Finished task 0.0 in stage 33.0 (TID 45). 2756 bytes result sent to driver
20/02/14 11:15:56 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 45) in 44 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:15:56 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
20/02/14 11:15:56 INFO DAGScheduler: ShuffleMapStage 33 (collect at arrowconverters.scala:270) finished in 0.054 s
20/02/14 11:15:56 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:15:56 INFO DAGScheduler: running: Set()
20/02/14 11:15:56 INFO DAGScheduler: waiting: Set(ShuffleMapStage 34, ResultStage 35)
20/02/14 11:15:56 INFO DAGScheduler: failed: Set()
20/02/14 11:15:56 INFO DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[167] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:15:56 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 53.4 KiB, free 413.8 MiB)
20/02/14 11:15:56 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 413.8 MiB)
20/02/14 11:15:56 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:55441 (size: 19.9 KiB, free: 413.9 MiB)
20/02/14 11:15:56 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1196
20/02/14 11:15:56 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[167] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 11:15:56 INFO TaskSchedulerImpl: Adding task set 34.0 with 4 tasks
20/02/14 11:15:56 INFO TaskSetManager: Starting task 2.0 in stage 34.0 (TID 46, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7237 bytes)
20/02/14 11:15:56 INFO TaskSetManager: Starting task 3.0 in stage 34.0 (TID 47, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7237 bytes)
20/02/14 11:15:56 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 48, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7237 bytes)
20/02/14 11:15:56 INFO TaskSetManager: Starting task 1.0 in stage 34.0 (TID 49, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7237 bytes)
20/02/14 11:15:56 INFO Executor: Running task 2.0 in stage 34.0 (TID 46)
20/02/14 11:15:56 INFO Executor: Running task 3.0 in stage 34.0 (TID 47)
20/02/14 11:15:56 INFO Executor: Running task 0.0 in stage 34.0 (TID 48)
20/02/14 11:15:56 INFO Executor: Running task 1.0 in stage 34.0 (TID 49)
20/02/14 11:15:56 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:15:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:15:56 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:15:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:15:56 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:15:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 11:15:56 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:15:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:15:56 INFO Executor: Finished task 0.0 in stage 34.0 (TID 48). 4332 bytes result sent to driver
20/02/14 11:15:56 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 48) in 24 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 11:15:56 INFO Executor: Finished task 1.0 in stage 34.0 (TID 49). 4375 bytes result sent to driver
20/02/14 11:15:56 INFO TaskSetManager: Finished task 1.0 in stage 34.0 (TID 49) in 35 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 11:15:56 INFO Executor: Finished task 2.0 in stage 34.0 (TID 46). 4461 bytes result sent to driver
20/02/14 11:15:56 INFO TaskSetManager: Finished task 2.0 in stage 34.0 (TID 46) in 42 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 11:15:56 INFO Executor: Finished task 3.0 in stage 34.0 (TID 47). 4461 bytes result sent to driver
20/02/14 11:15:56 INFO TaskSetManager: Finished task 3.0 in stage 34.0 (TID 47) in 51 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 11:15:56 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
20/02/14 11:15:56 INFO DAGScheduler: ShuffleMapStage 34 (collect at arrowconverters.scala:270) finished in 0.057 s
20/02/14 11:15:56 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:15:56 INFO DAGScheduler: running: Set()
20/02/14 11:15:56 INFO DAGScheduler: waiting: Set(ResultStage 35)
20/02/14 11:15:56 INFO DAGScheduler: failed: Set()
20/02/14 11:15:56 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[173] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:15:56 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 54.8 KiB, free 413.7 MiB)
20/02/14 11:15:56 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 19.8 KiB, free 413.7 MiB)
20/02/14 11:15:56 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:55441 in memory (size: 20.3 KiB, free: 413.9 MiB)
20/02/14 11:15:56 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:55441 (size: 19.8 KiB, free: 413.9 MiB)
20/02/14 11:15:56 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1196
20/02/14 11:15:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[173] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:15:56 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
20/02/14 11:15:56 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 50, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:15:56 INFO Executor: Running task 0.0 in stage 35.0 (TID 50)
20/02/14 11:15:56 INFO ShuffleBlockFetcherIterator: Getting 2 (138.0 B) non-empty blocks including 2 (138.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:15:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:15:56 INFO CodeGenerator: Code generated in 10.3851 ms
20/02/14 11:15:56 INFO CodeGenerator: Code generated in 15.622501 ms
20/02/14 11:15:56 INFO Executor: Finished task 0.0 in stage 35.0 (TID 50). 5377 bytes result sent to driver
20/02/14 11:15:56 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 50) in 59 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:15:56 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
20/02/14 11:15:56 INFO DAGScheduler: ResultStage 35 (collect at arrowconverters.scala:270) finished in 0.076 s
20/02/14 11:15:56 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:15:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
20/02/14 11:15:56 INFO DAGScheduler: Job 20 finished: collect at arrowconverters.scala:270, took 0.198174 s
20/02/14 11:16:18 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:55441 in memory (size: 19.8 KiB, free: 413.9 MiB)
20/02/14 11:16:18 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:55441 in memory (size: 19.9 KiB, free: 413.9 MiB)
20/02/14 11:16:18 INFO CodeGenerator: Code generated in 6.239 ms
20/02/14 11:16:18 INFO CodeGenerator: Code generated in 11.6937 ms
20/02/14 11:16:18 INFO CodeGenerator: Code generated in 38.9823 ms
20/02/14 11:16:18 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 11:16:18 INFO DAGScheduler: Registering RDD 178 (collect at arrowconverters.scala:270) as input to shuffle 15
20/02/14 11:16:18 INFO DAGScheduler: Registering RDD 181 (collect at arrowconverters.scala:270) as input to shuffle 16
20/02/14 11:16:18 INFO DAGScheduler: Got job 21 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 11:16:18 INFO DAGScheduler: Final stage: ResultStage 38 (collect at arrowconverters.scala:270)
20/02/14 11:16:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
20/02/14 11:16:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 37)
20/02/14 11:16:18 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[178] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:16:18 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 58.1 KiB, free 413.9 MiB)
20/02/14 11:16:18 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 20.8 KiB, free 413.8 MiB)
20/02/14 11:16:18 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:55441 (size: 20.8 KiB, free: 413.9 MiB)
20/02/14 11:16:18 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1196
20/02/14 11:16:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[178] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:16:18 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
20/02/14 11:16:18 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 51, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:16:18 INFO Executor: Running task 0.0 in stage 36.0 (TID 51)
20/02/14 11:16:18 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:16:18 INFO CodeGenerator: Code generated in 5.014401 ms
20/02/14 11:16:18 INFO CodeGenerator: Code generated in 12.8158 ms
20/02/14 11:16:18 INFO Executor: Finished task 0.0 in stage 36.0 (TID 51). 2713 bytes result sent to driver
20/02/14 11:16:18 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 51) in 79 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:16:18 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
20/02/14 11:16:18 INFO DAGScheduler: ShuffleMapStage 36 (collect at arrowconverters.scala:270) finished in 0.098 s
20/02/14 11:16:18 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:16:18 INFO DAGScheduler: running: Set()
20/02/14 11:16:18 INFO DAGScheduler: waiting: Set(ShuffleMapStage 37, ResultStage 38)
20/02/14 11:16:18 INFO DAGScheduler: failed: Set()
20/02/14 11:16:18 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[181] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:16:18 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 54.3 KiB, free 413.8 MiB)
20/02/14 11:16:18 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 20.2 KiB, free 413.8 MiB)
20/02/14 11:16:18 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:55441 (size: 20.2 KiB, free: 413.9 MiB)
20/02/14 11:16:18 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1196
20/02/14 11:16:18 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[181] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 11:16:18 INFO TaskSchedulerImpl: Adding task set 37.0 with 4 tasks
20/02/14 11:16:18 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 52, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7237 bytes)
20/02/14 11:16:18 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 53, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7237 bytes)
20/02/14 11:16:18 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 54, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7237 bytes)
20/02/14 11:16:18 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 55, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7237 bytes)
20/02/14 11:16:18 INFO Executor: Running task 1.0 in stage 37.0 (TID 53)
20/02/14 11:16:18 INFO Executor: Running task 0.0 in stage 37.0 (TID 52)
20/02/14 11:16:18 INFO Executor: Running task 3.0 in stage 37.0 (TID 55)
20/02/14 11:16:18 INFO Executor: Running task 2.0 in stage 37.0 (TID 54)
20/02/14 11:16:18 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:16:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:16:18 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:16:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:16:18 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:16:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:16:18 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:16:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 11:16:18 INFO Executor: Finished task 3.0 in stage 37.0 (TID 55). 4375 bytes result sent to driver
20/02/14 11:16:18 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 55) in 47 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 11:16:18 INFO Executor: Finished task 1.0 in stage 37.0 (TID 53). 4504 bytes result sent to driver
20/02/14 11:16:18 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 53) in 58 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 11:16:18 INFO Executor: Finished task 2.0 in stage 37.0 (TID 54). 4504 bytes result sent to driver
20/02/14 11:16:18 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 54) in 65 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 11:16:18 INFO Executor: Finished task 0.0 in stage 37.0 (TID 52). 4504 bytes result sent to driver
20/02/14 11:16:18 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 52) in 74 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 11:16:18 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
20/02/14 11:16:18 INFO DAGScheduler: ShuffleMapStage 37 (collect at arrowconverters.scala:270) finished in 0.089 s
20/02/14 11:16:18 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:16:18 INFO DAGScheduler: running: Set()
20/02/14 11:16:18 INFO DAGScheduler: waiting: Set(ResultStage 38)
20/02/14 11:16:18 INFO DAGScheduler: failed: Set()
20/02/14 11:16:18 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[187] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:16:18 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 55.3 KiB, free 413.7 MiB)
20/02/14 11:16:18 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 413.7 MiB)
20/02/14 11:16:18 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:55441 (size: 19.9 KiB, free: 413.9 MiB)
20/02/14 11:16:18 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1196
20/02/14 11:16:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[187] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:16:18 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
20/02/14 11:16:18 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 56, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:16:18 INFO Executor: Running task 0.0 in stage 38.0 (TID 56)
20/02/14 11:16:18 INFO ShuffleBlockFetcherIterator: Getting 3 (212.0 B) non-empty blocks including 3 (212.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:16:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:16:18 INFO CodeGenerator: Code generated in 9.5068 ms
20/02/14 11:16:18 INFO CodeGenerator: Code generated in 13.8325 ms
20/02/14 11:16:18 INFO Executor: Finished task 0.0 in stage 38.0 (TID 56). 5401 bytes result sent to driver
20/02/14 11:16:18 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 56) in 54 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:16:18 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
20/02/14 11:16:18 INFO DAGScheduler: ResultStage 38 (collect at arrowconverters.scala:270) finished in 0.061 s
20/02/14 11:16:18 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:16:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
20/02/14 11:16:18 INFO DAGScheduler: Job 21 finished: collect at arrowconverters.scala:270, took 0.258974 s
20/02/14 11:16:18 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:55441 in memory (size: 20.2 KiB, free: 413.9 MiB)
20/02/14 11:16:18 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:55441 in memory (size: 19.9 KiB, free: 413.9 MiB)
20/02/14 11:16:18 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:55441 in memory (size: 20.8 KiB, free: 413.9 MiB)
20/02/14 11:16:46 INFO CodeGenerator: Code generated in 5.1911 ms
20/02/14 11:16:46 INFO CodeGenerator: Code generated in 11.017701 ms
20/02/14 11:16:46 INFO CodeGenerator: Code generated in 25.4179 ms
20/02/14 11:16:47 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 11:16:47 INFO DAGScheduler: Registering RDD 192 (collect at arrowconverters.scala:270) as input to shuffle 17
20/02/14 11:16:47 INFO DAGScheduler: Registering RDD 195 (collect at arrowconverters.scala:270) as input to shuffle 18
20/02/14 11:16:47 INFO DAGScheduler: Got job 22 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 11:16:47 INFO DAGScheduler: Final stage: ResultStage 41 (collect at arrowconverters.scala:270)
20/02/14 11:16:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)
20/02/14 11:16:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 40)
20/02/14 11:16:47 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[192] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:16:47 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 62.3 KiB, free 413.9 MiB)
20/02/14 11:16:47 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 22.3 KiB, free 413.8 MiB)
20/02/14 11:16:47 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:55441 (size: 22.3 KiB, free: 413.9 MiB)
20/02/14 11:16:47 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1196
20/02/14 11:16:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[192] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:16:47 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
20/02/14 11:16:47 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 57, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:16:47 INFO Executor: Running task 0.0 in stage 39.0 (TID 57)
20/02/14 11:16:47 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:16:47 INFO CodeGenerator: Code generated in 5.0795 ms
20/02/14 11:16:47 INFO CodeGenerator: Code generated in 5.501301 ms
20/02/14 11:16:47 INFO Executor: Finished task 0.0 in stage 39.0 (TID 57). 2756 bytes result sent to driver
20/02/14 11:16:47 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 57) in 100 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:16:47 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
20/02/14 11:16:47 INFO DAGScheduler: ShuffleMapStage 39 (collect at arrowconverters.scala:270) finished in 0.108 s
20/02/14 11:16:47 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:16:47 INFO DAGScheduler: running: Set()
20/02/14 11:16:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 40, ResultStage 41)
20/02/14 11:16:47 INFO DAGScheduler: failed: Set()
20/02/14 11:16:47 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[195] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:16:47 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 58.7 KiB, free 413.8 MiB)
20/02/14 11:16:47 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 413.8 MiB)
20/02/14 11:16:47 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:55441 (size: 21.9 KiB, free: 413.9 MiB)
20/02/14 11:16:47 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1196
20/02/14 11:16:47 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[195] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 11:16:47 INFO TaskSchedulerImpl: Adding task set 40.0 with 4 tasks
20/02/14 11:16:47 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 58, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7237 bytes)
20/02/14 11:16:47 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 59, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7237 bytes)
20/02/14 11:16:47 INFO TaskSetManager: Starting task 2.0 in stage 40.0 (TID 60, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7237 bytes)
20/02/14 11:16:47 INFO TaskSetManager: Starting task 3.0 in stage 40.0 (TID 61, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7237 bytes)
20/02/14 11:16:47 INFO Executor: Running task 0.0 in stage 40.0 (TID 58)
20/02/14 11:16:47 INFO Executor: Running task 1.0 in stage 40.0 (TID 59)
20/02/14 11:16:47 INFO Executor: Running task 2.0 in stage 40.0 (TID 60)
20/02/14 11:16:47 INFO Executor: Running task 3.0 in stage 40.0 (TID 61)
20/02/14 11:16:47 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:16:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:16:47 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:16:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:16:47 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:16:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:16:47 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:16:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 11:16:47 INFO Executor: Finished task 3.0 in stage 40.0 (TID 61). 4332 bytes result sent to driver
20/02/14 11:16:47 INFO TaskSetManager: Finished task 3.0 in stage 40.0 (TID 61) in 24 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 11:16:47 INFO Executor: Finished task 1.0 in stage 40.0 (TID 59). 4461 bytes result sent to driver
20/02/14 11:16:47 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 59) in 44 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 11:16:47 INFO Executor: Finished task 0.0 in stage 40.0 (TID 58). 4418 bytes result sent to driver
20/02/14 11:16:47 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 58) in 51 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 11:16:47 INFO Executor: Finished task 2.0 in stage 40.0 (TID 60). 4461 bytes result sent to driver
20/02/14 11:16:47 INFO TaskSetManager: Finished task 2.0 in stage 40.0 (TID 60) in 59 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 11:16:47 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
20/02/14 11:16:47 INFO DAGScheduler: ShuffleMapStage 40 (collect at arrowconverters.scala:270) finished in 0.067 s
20/02/14 11:16:47 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:16:47 INFO DAGScheduler: running: Set()
20/02/14 11:16:47 INFO DAGScheduler: waiting: Set(ResultStage 41)
20/02/14 11:16:47 INFO DAGScheduler: failed: Set()
20/02/14 11:16:47 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[201] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:16:47 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 57.3 KiB, free 413.7 MiB)
20/02/14 11:16:47 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 413.7 MiB)
20/02/14 11:16:47 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:55441 (size: 20.7 KiB, free: 413.9 MiB)
20/02/14 11:16:47 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1196
20/02/14 11:16:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[201] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:16:47 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
20/02/14 11:16:47 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 62, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:16:47 INFO Executor: Running task 0.0 in stage 41.0 (TID 62)
20/02/14 11:16:47 INFO ShuffleBlockFetcherIterator: Getting 3 (232.0 B) non-empty blocks including 3 (232.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:16:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:16:47 INFO CodeGenerator: Code generated in 5.94 ms
20/02/14 11:16:47 INFO CodeGenerator: Code generated in 11.6662 ms
20/02/14 11:16:47 INFO Executor: Finished task 0.0 in stage 41.0 (TID 62). 5426 bytes result sent to driver
20/02/14 11:16:47 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 62) in 44 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:16:47 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
20/02/14 11:16:47 INFO DAGScheduler: ResultStage 41 (collect at arrowconverters.scala:270) finished in 0.060 s
20/02/14 11:16:47 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:16:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
20/02/14 11:16:47 INFO DAGScheduler: Job 22 finished: collect at arrowconverters.scala:270, took 0.242607 s
20/02/14 11:17:22 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:55441 in memory (size: 20.7 KiB, free: 413.9 MiB)
20/02/14 11:17:22 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:55441 in memory (size: 21.9 KiB, free: 413.9 MiB)
20/02/14 11:17:22 INFO CodeGenerator: Code generated in 9.3449 ms
20/02/14 11:17:22 INFO CodeGenerator: Code generated in 14.3152 ms
20/02/14 11:17:23 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 11:17:23 INFO DAGScheduler: Registering RDD 206 (collect at arrowconverters.scala:270) as input to shuffle 19
20/02/14 11:17:23 INFO DAGScheduler: Registering RDD 209 (collect at arrowconverters.scala:270) as input to shuffle 20
20/02/14 11:17:23 INFO DAGScheduler: Got job 23 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 11:17:23 INFO DAGScheduler: Final stage: ResultStage 44 (collect at arrowconverters.scala:270)
20/02/14 11:17:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
20/02/14 11:17:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 43)
20/02/14 11:17:23 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[206] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:17:23 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 62.3 KiB, free 413.8 MiB)
20/02/14 11:17:23 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 22.3 KiB, free 413.8 MiB)
20/02/14 11:17:23 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:55441 (size: 22.3 KiB, free: 413.9 MiB)
20/02/14 11:17:23 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1196
20/02/14 11:17:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[206] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:17:23 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
20/02/14 11:17:23 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 63, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:17:23 INFO Executor: Running task 0.0 in stage 42.0 (TID 63)
20/02/14 11:17:23 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:17:23 INFO Executor: Finished task 0.0 in stage 42.0 (TID 63). 2756 bytes result sent to driver
20/02/14 11:17:23 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 63) in 39 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:17:23 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
20/02/14 11:17:23 INFO DAGScheduler: ShuffleMapStage 42 (collect at arrowconverters.scala:270) finished in 0.046 s
20/02/14 11:17:23 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:17:23 INFO DAGScheduler: running: Set()
20/02/14 11:17:23 INFO DAGScheduler: waiting: Set(ShuffleMapStage 43, ResultStage 44)
20/02/14 11:17:23 INFO DAGScheduler: failed: Set()
20/02/14 11:17:23 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[209] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:17:23 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 58.7 KiB, free 413.7 MiB)
20/02/14 11:17:23 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 413.7 MiB)
20/02/14 11:17:23 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:55441 (size: 21.9 KiB, free: 413.9 MiB)
20/02/14 11:17:23 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1196
20/02/14 11:17:23 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[209] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 11:17:23 INFO TaskSchedulerImpl: Adding task set 43.0 with 4 tasks
20/02/14 11:17:23 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 64, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7237 bytes)
20/02/14 11:17:23 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 65, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7237 bytes)
20/02/14 11:17:23 INFO TaskSetManager: Starting task 2.0 in stage 43.0 (TID 66, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7237 bytes)
20/02/14 11:17:23 INFO TaskSetManager: Starting task 3.0 in stage 43.0 (TID 67, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7237 bytes)
20/02/14 11:17:23 INFO Executor: Running task 1.0 in stage 43.0 (TID 65)
20/02/14 11:17:23 INFO Executor: Running task 0.0 in stage 43.0 (TID 64)
20/02/14 11:17:23 INFO Executor: Running task 2.0 in stage 43.0 (TID 66)
20/02/14 11:17:23 INFO Executor: Running task 3.0 in stage 43.0 (TID 67)
20/02/14 11:17:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:17:23 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:17:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:17:23 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:17:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:17:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:17:23 INFO Executor: Finished task 3.0 in stage 43.0 (TID 67). 4289 bytes result sent to driver
20/02/14 11:17:23 INFO TaskSetManager: Finished task 3.0 in stage 43.0 (TID 67) in 29 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 11:17:23 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:17:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:17:23 INFO Executor: Finished task 1.0 in stage 43.0 (TID 65). 4461 bytes result sent to driver
20/02/14 11:17:23 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 65) in 46 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 11:17:23 INFO Executor: Finished task 0.0 in stage 43.0 (TID 64). 4418 bytes result sent to driver
20/02/14 11:17:23 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 64) in 49 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 11:17:23 INFO Executor: Finished task 2.0 in stage 43.0 (TID 66). 4461 bytes result sent to driver
20/02/14 11:17:23 INFO TaskSetManager: Finished task 2.0 in stage 43.0 (TID 66) in 52 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 11:17:23 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
20/02/14 11:17:23 INFO DAGScheduler: ShuffleMapStage 43 (collect at arrowconverters.scala:270) finished in 0.060 s
20/02/14 11:17:23 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:17:23 INFO DAGScheduler: running: Set()
20/02/14 11:17:23 INFO DAGScheduler: waiting: Set(ResultStage 44)
20/02/14 11:17:23 INFO DAGScheduler: failed: Set()
20/02/14 11:17:23 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[215] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:17:23 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 57.3 KiB, free 413.6 MiB)
20/02/14 11:17:23 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 20.8 KiB, free 413.6 MiB)
20/02/14 11:17:23 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:55441 (size: 20.8 KiB, free: 413.8 MiB)
20/02/14 11:17:23 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1196
20/02/14 11:17:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[215] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:17:23 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
20/02/14 11:17:23 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 68, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:17:23 INFO Executor: Running task 0.0 in stage 44.0 (TID 68)
20/02/14 11:17:23 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:55441 in memory (size: 22.3 KiB, free: 413.9 MiB)
20/02/14 11:17:23 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:55441 in memory (size: 21.9 KiB, free: 413.9 MiB)
20/02/14 11:17:23 INFO ShuffleBlockFetcherIterator: Getting 3 (232.0 B) non-empty blocks including 3 (232.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:17:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:17:23 INFO Executor: Finished task 0.0 in stage 44.0 (TID 68). 5512 bytes result sent to driver
20/02/14 11:17:23 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 68) in 35 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:17:23 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
20/02/14 11:17:23 INFO DAGScheduler: ResultStage 44 (collect at arrowconverters.scala:270) finished in 0.041 s
20/02/14 11:17:23 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:17:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
20/02/14 11:17:23 INFO DAGScheduler: Job 23 finished: collect at arrowconverters.scala:270, took 0.155254 s
20/02/14 11:18:06 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:55441 in memory (size: 20.8 KiB, free: 413.9 MiB)
20/02/14 11:18:06 INFO CodeGenerator: Code generated in 14.327501 ms
20/02/14 11:18:06 INFO CodeGenerator: Code generated in 17.3283 ms
20/02/14 11:18:06 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 11:18:06 INFO DAGScheduler: Registering RDD 220 (collect at arrowconverters.scala:270) as input to shuffle 21
20/02/14 11:18:06 INFO DAGScheduler: Registering RDD 223 (collect at arrowconverters.scala:270) as input to shuffle 22
20/02/14 11:18:06 INFO DAGScheduler: Got job 24 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 11:18:06 INFO DAGScheduler: Final stage: ResultStage 47 (collect at arrowconverters.scala:270)
20/02/14 11:18:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
20/02/14 11:18:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 46)
20/02/14 11:18:06 INFO DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[220] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:18:06 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 62.3 KiB, free 413.8 MiB)
20/02/14 11:18:06 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 22.2 KiB, free 413.8 MiB)
20/02/14 11:18:06 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:55441 (size: 22.2 KiB, free: 413.9 MiB)
20/02/14 11:18:06 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1196
20/02/14 11:18:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[220] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:18:06 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
20/02/14 11:18:06 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 69, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:18:06 INFO Executor: Running task 0.0 in stage 45.0 (TID 69)
20/02/14 11:18:06 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:18:06 INFO Executor: Finished task 0.0 in stage 45.0 (TID 69). 2713 bytes result sent to driver
20/02/14 11:18:06 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 69) in 41 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:18:06 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
20/02/14 11:18:06 INFO DAGScheduler: ShuffleMapStage 45 (collect at arrowconverters.scala:270) finished in 0.052 s
20/02/14 11:18:06 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:18:06 INFO DAGScheduler: running: Set()
20/02/14 11:18:06 INFO DAGScheduler: waiting: Set(ShuffleMapStage 46, ResultStage 47)
20/02/14 11:18:06 INFO DAGScheduler: failed: Set()
20/02/14 11:18:06 INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[223] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:18:06 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 58.7 KiB, free 413.7 MiB)
20/02/14 11:18:06 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 413.7 MiB)
20/02/14 11:18:06 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:55441 (size: 21.9 KiB, free: 413.9 MiB)
20/02/14 11:18:06 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1196
20/02/14 11:18:06 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[223] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 11:18:06 INFO TaskSchedulerImpl: Adding task set 46.0 with 4 tasks
20/02/14 11:18:06 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 70, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7237 bytes)
20/02/14 11:18:06 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 71, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7237 bytes)
20/02/14 11:18:06 INFO TaskSetManager: Starting task 2.0 in stage 46.0 (TID 72, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7237 bytes)
20/02/14 11:18:06 INFO TaskSetManager: Starting task 3.0 in stage 46.0 (TID 73, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7237 bytes)
20/02/14 11:18:06 INFO Executor: Running task 0.0 in stage 46.0 (TID 70)
20/02/14 11:18:06 INFO Executor: Running task 1.0 in stage 46.0 (TID 71)
20/02/14 11:18:06 INFO Executor: Running task 3.0 in stage 46.0 (TID 73)
20/02/14 11:18:06 INFO Executor: Running task 2.0 in stage 46.0 (TID 72)
20/02/14 11:18:06 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:18:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:18:06 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:18:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:18:06 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:18:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:18:06 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:18:06 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:55441 in memory (size: 22.2 KiB, free: 413.9 MiB)
20/02/14 11:18:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:18:06 INFO Executor: Finished task 3.0 in stage 46.0 (TID 73). 4418 bytes result sent to driver
20/02/14 11:18:06 INFO TaskSetManager: Finished task 3.0 in stage 46.0 (TID 73) in 36 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 11:18:06 INFO Executor: Finished task 2.0 in stage 46.0 (TID 72). 4504 bytes result sent to driver
20/02/14 11:18:06 INFO TaskSetManager: Finished task 2.0 in stage 46.0 (TID 72) in 46 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 11:18:06 INFO Executor: Finished task 1.0 in stage 46.0 (TID 71). 4547 bytes result sent to driver
20/02/14 11:18:06 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 71) in 50 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 11:18:06 INFO Executor: Finished task 0.0 in stage 46.0 (TID 70). 4504 bytes result sent to driver
20/02/14 11:18:06 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 70) in 53 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 11:18:06 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
20/02/14 11:18:06 INFO DAGScheduler: ShuffleMapStage 46 (collect at arrowconverters.scala:270) finished in 0.060 s
20/02/14 11:18:06 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:18:06 INFO DAGScheduler: running: Set()
20/02/14 11:18:06 INFO DAGScheduler: waiting: Set(ResultStage 47)
20/02/14 11:18:06 INFO DAGScheduler: failed: Set()
20/02/14 11:18:06 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[229] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:18:06 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 57.3 KiB, free 413.7 MiB)
20/02/14 11:18:06 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 413.7 MiB)
20/02/14 11:18:06 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:55441 (size: 20.7 KiB, free: 413.9 MiB)
20/02/14 11:18:06 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1196
20/02/14 11:18:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[229] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:18:06 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
20/02/14 11:18:06 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 74, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:18:06 INFO Executor: Running task 0.0 in stage 47.0 (TID 74)
20/02/14 11:18:06 INFO ShuffleBlockFetcherIterator: Getting 3 (232.0 B) non-empty blocks including 3 (232.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:18:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:18:06 INFO Executor: Finished task 0.0 in stage 47.0 (TID 74). 5469 bytes result sent to driver
20/02/14 11:18:06 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 74) in 26 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:18:06 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
20/02/14 11:18:06 INFO DAGScheduler: ResultStage 47 (collect at arrowconverters.scala:270) finished in 0.034 s
20/02/14 11:18:06 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:18:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
20/02/14 11:18:06 INFO DAGScheduler: Job 24 finished: collect at arrowconverters.scala:270, took 0.153814 s
20/02/14 11:20:47 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:55441 in memory (size: 20.7 KiB, free: 413.9 MiB)
20/02/14 11:20:47 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:55441 in memory (size: 21.9 KiB, free: 413.9 MiB)
20/02/14 11:20:47 INFO CodeGenerator: Code generated in 6.380101 ms
20/02/14 11:20:47 INFO CodeGenerator: Code generated in 14.815099 ms
20/02/14 11:20:47 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 11:20:47 INFO DAGScheduler: Registering RDD 234 (collect at arrowconverters.scala:270) as input to shuffle 23
20/02/14 11:20:47 INFO DAGScheduler: Registering RDD 237 (collect at arrowconverters.scala:270) as input to shuffle 24
20/02/14 11:20:47 INFO DAGScheduler: Got job 25 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 11:20:47 INFO DAGScheduler: Final stage: ResultStage 50 (collect at arrowconverters.scala:270)
20/02/14 11:20:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
20/02/14 11:20:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 49)
20/02/14 11:20:47 INFO DAGScheduler: Submitting ShuffleMapStage 48 (MapPartitionsRDD[234] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:20:47 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 62.3 KiB, free 413.8 MiB)
20/02/14 11:20:47 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 22.2 KiB, free 413.8 MiB)
20/02/14 11:20:47 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:55441 (size: 22.2 KiB, free: 413.9 MiB)
20/02/14 11:20:47 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1196
20/02/14 11:20:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[234] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:20:47 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
20/02/14 11:20:47 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 75, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:20:47 INFO Executor: Running task 0.0 in stage 48.0 (TID 75)
20/02/14 11:20:47 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:20:47 INFO Executor: Finished task 0.0 in stage 48.0 (TID 75). 2756 bytes result sent to driver
20/02/14 11:20:47 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 75) in 32 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:20:47 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
20/02/14 11:20:47 INFO DAGScheduler: ShuffleMapStage 48 (collect at arrowconverters.scala:270) finished in 0.039 s
20/02/14 11:20:47 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:20:47 INFO DAGScheduler: running: Set()
20/02/14 11:20:47 INFO DAGScheduler: waiting: Set(ShuffleMapStage 49, ResultStage 50)
20/02/14 11:20:47 INFO DAGScheduler: failed: Set()
20/02/14 11:20:47 INFO DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[237] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:20:47 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 58.7 KiB, free 413.7 MiB)
20/02/14 11:20:47 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 413.7 MiB)
20/02/14 11:20:47 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:55441 (size: 21.9 KiB, free: 413.9 MiB)
20/02/14 11:20:47 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1196
20/02/14 11:20:47 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[237] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 11:20:47 INFO TaskSchedulerImpl: Adding task set 49.0 with 4 tasks
20/02/14 11:20:47 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 76, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7237 bytes)
20/02/14 11:20:47 INFO TaskSetManager: Starting task 1.0 in stage 49.0 (TID 77, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7237 bytes)
20/02/14 11:20:47 INFO TaskSetManager: Starting task 2.0 in stage 49.0 (TID 78, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7237 bytes)
20/02/14 11:20:47 INFO TaskSetManager: Starting task 3.0 in stage 49.0 (TID 79, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7237 bytes)
20/02/14 11:20:47 INFO Executor: Running task 0.0 in stage 49.0 (TID 76)
20/02/14 11:20:47 INFO Executor: Running task 1.0 in stage 49.0 (TID 77)
20/02/14 11:20:47 INFO Executor: Running task 3.0 in stage 49.0 (TID 79)
20/02/14 11:20:47 INFO Executor: Running task 2.0 in stage 49.0 (TID 78)
20/02/14 11:20:47 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:20:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:20:47 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:20:47 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:20:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 11:20:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:20:47 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:20:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:20:47 INFO Executor: Finished task 3.0 in stage 49.0 (TID 79). 4332 bytes result sent to driver
20/02/14 11:20:47 INFO TaskSetManager: Finished task 3.0 in stage 49.0 (TID 79) in 23 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 11:20:47 INFO Executor: Finished task 1.0 in stage 49.0 (TID 77). 4461 bytes result sent to driver
20/02/14 11:20:47 INFO TaskSetManager: Finished task 1.0 in stage 49.0 (TID 77) in 38 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 11:20:47 INFO Executor: Finished task 2.0 in stage 49.0 (TID 78). 4461 bytes result sent to driver
20/02/14 11:20:47 INFO TaskSetManager: Finished task 2.0 in stage 49.0 (TID 78) in 41 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 11:20:47 INFO Executor: Finished task 0.0 in stage 49.0 (TID 76). 4504 bytes result sent to driver
20/02/14 11:20:47 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 76) in 45 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 11:20:47 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
20/02/14 11:20:47 INFO DAGScheduler: ShuffleMapStage 49 (collect at arrowconverters.scala:270) finished in 0.052 s
20/02/14 11:20:47 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:20:47 INFO DAGScheduler: running: Set()
20/02/14 11:20:47 INFO DAGScheduler: waiting: Set(ResultStage 50)
20/02/14 11:20:47 INFO DAGScheduler: failed: Set()
20/02/14 11:20:47 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[243] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:20:47 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 57.3 KiB, free 413.6 MiB)
20/02/14 11:20:47 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 413.6 MiB)
20/02/14 11:20:47 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:55441 (size: 20.7 KiB, free: 413.8 MiB)
20/02/14 11:20:47 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1196
20/02/14 11:20:47 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:55441 in memory (size: 22.2 KiB, free: 413.9 MiB)
20/02/14 11:20:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[243] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:20:47 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
20/02/14 11:20:47 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 80, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:20:47 INFO Executor: Running task 0.0 in stage 50.0 (TID 80)
20/02/14 11:20:47 INFO ShuffleBlockFetcherIterator: Getting 3 (232.0 B) non-empty blocks including 3 (232.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:20:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:20:47 INFO Executor: Finished task 0.0 in stage 50.0 (TID 80). 5426 bytes result sent to driver
20/02/14 11:20:47 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 80) in 28 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:20:47 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
20/02/14 11:20:47 INFO DAGScheduler: ResultStage 50 (collect at arrowconverters.scala:270) finished in 0.041 s
20/02/14 11:20:47 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:20:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished
20/02/14 11:20:47 INFO DAGScheduler: Job 25 finished: collect at arrowconverters.scala:270, took 0.139098 s
20/02/14 11:32:57 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:55441 in memory (size: 21.9 KiB, free: 413.9 MiB)
20/02/14 11:32:57 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:55441 in memory (size: 22.3 KiB, free: 413.9 MiB)
20/02/14 11:32:57 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:55441 in memory (size: 20.7 KiB, free: 413.9 MiB)
20/02/14 11:57:49 INFO CodeGenerator: Code generated in 8.1857 ms
20/02/14 11:57:49 INFO CodeGenerator: Code generated in 27.007699 ms
20/02/14 11:57:49 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 11:57:49 INFO DAGScheduler: Registering RDD 248 (collect at arrowconverters.scala:270) as input to shuffle 25
20/02/14 11:57:49 INFO DAGScheduler: Registering RDD 251 (collect at arrowconverters.scala:270) as input to shuffle 26
20/02/14 11:57:49 INFO DAGScheduler: Got job 26 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 11:57:49 INFO DAGScheduler: Final stage: ResultStage 53 (collect at arrowconverters.scala:270)
20/02/14 11:57:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
20/02/14 11:57:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 52)
20/02/14 11:57:49 INFO DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[248] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:57:49 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 62.3 KiB, free 413.9 MiB)
20/02/14 11:57:49 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 22.3 KiB, free 413.8 MiB)
20/02/14 11:57:49 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:55441 (size: 22.3 KiB, free: 413.9 MiB)
20/02/14 11:57:49 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1196
20/02/14 11:57:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[248] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:57:49 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
20/02/14 11:57:49 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 81, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 11:57:49 INFO Executor: Running task 0.0 in stage 51.0 (TID 81)
20/02/14 11:57:49 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 11:57:49 INFO Executor: Finished task 0.0 in stage 51.0 (TID 81). 2713 bytes result sent to driver
20/02/14 11:57:49 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 81) in 37 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:57:49 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
20/02/14 11:57:49 INFO DAGScheduler: ShuffleMapStage 51 (collect at arrowconverters.scala:270) finished in 0.046 s
20/02/14 11:57:49 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:57:49 INFO DAGScheduler: running: Set()
20/02/14 11:57:49 INFO DAGScheduler: waiting: Set(ShuffleMapStage 52, ResultStage 53)
20/02/14 11:57:49 INFO DAGScheduler: failed: Set()
20/02/14 11:57:49 INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[251] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:57:49 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 58.7 KiB, free 413.8 MiB)
20/02/14 11:57:49 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 413.8 MiB)
20/02/14 11:57:49 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:55441 (size: 21.9 KiB, free: 413.9 MiB)
20/02/14 11:57:49 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1196
20/02/14 11:57:49 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[251] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 11:57:49 INFO TaskSchedulerImpl: Adding task set 52.0 with 4 tasks
20/02/14 11:57:49 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 82, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7237 bytes)
20/02/14 11:57:49 INFO TaskSetManager: Starting task 1.0 in stage 52.0 (TID 83, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7237 bytes)
20/02/14 11:57:49 INFO TaskSetManager: Starting task 2.0 in stage 52.0 (TID 84, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7237 bytes)
20/02/14 11:57:49 INFO TaskSetManager: Starting task 3.0 in stage 52.0 (TID 85, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7237 bytes)
20/02/14 11:57:49 INFO Executor: Running task 0.0 in stage 52.0 (TID 82)
20/02/14 11:57:49 INFO Executor: Running task 1.0 in stage 52.0 (TID 83)
20/02/14 11:57:49 INFO Executor: Running task 3.0 in stage 52.0 (TID 85)
20/02/14 11:57:49 INFO Executor: Running task 2.0 in stage 52.0 (TID 84)
20/02/14 11:57:49 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:57:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:57:49 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:57:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:57:49 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:57:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:57:49 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:57:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:57:49 INFO Executor: Finished task 3.0 in stage 52.0 (TID 85). 4332 bytes result sent to driver
20/02/14 11:57:49 INFO TaskSetManager: Finished task 3.0 in stage 52.0 (TID 85) in 38 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 11:57:49 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:55441 in memory (size: 22.3 KiB, free: 413.9 MiB)
20/02/14 11:57:49 INFO Executor: Finished task 2.0 in stage 52.0 (TID 84). 4504 bytes result sent to driver
20/02/14 11:57:49 INFO TaskSetManager: Finished task 2.0 in stage 52.0 (TID 84) in 42 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 11:57:49 INFO Executor: Finished task 1.0 in stage 52.0 (TID 83). 4504 bytes result sent to driver
20/02/14 11:57:49 INFO TaskSetManager: Finished task 1.0 in stage 52.0 (TID 83) in 50 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 11:57:49 INFO Executor: Finished task 0.0 in stage 52.0 (TID 82). 4547 bytes result sent to driver
20/02/14 11:57:49 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 82) in 56 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 11:57:49 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
20/02/14 11:57:49 INFO DAGScheduler: ShuffleMapStage 52 (collect at arrowconverters.scala:270) finished in 0.072 s
20/02/14 11:57:49 INFO DAGScheduler: looking for newly runnable stages
20/02/14 11:57:49 INFO DAGScheduler: running: Set()
20/02/14 11:57:49 INFO DAGScheduler: waiting: Set(ResultStage 53)
20/02/14 11:57:49 INFO DAGScheduler: failed: Set()
20/02/14 11:57:49 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[257] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 11:57:49 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 57.3 KiB, free 413.8 MiB)
20/02/14 11:57:49 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 413.8 MiB)
20/02/14 11:57:49 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:55441 (size: 20.7 KiB, free: 413.9 MiB)
20/02/14 11:57:49 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1196
20/02/14 11:57:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[257] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 11:57:49 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
20/02/14 11:57:49 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 86, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 11:57:49 INFO Executor: Running task 0.0 in stage 53.0 (TID 86)
20/02/14 11:57:49 INFO ShuffleBlockFetcherIterator: Getting 3 (232.0 B) non-empty blocks including 3 (232.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 11:57:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 11:57:49 INFO Executor: Finished task 0.0 in stage 53.0 (TID 86). 5426 bytes result sent to driver
20/02/14 11:57:49 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 86) in 29 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 11:57:49 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
20/02/14 11:57:49 INFO DAGScheduler: ResultStage 53 (collect at arrowconverters.scala:270) finished in 0.036 s
20/02/14 11:57:49 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 11:57:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
20/02/14 11:57:49 INFO DAGScheduler: Job 26 finished: collect at arrowconverters.scala:270, took 0.168389 s
20/02/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:55441 in memory (size: 20.7 KiB, free: 413.9 MiB)
20/02/14 12:00:41 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:55441 in memory (size: 21.9 KiB, free: 413.9 MiB)
20/02/14 12:00:41 INFO CodeGenerator: Code generated in 8.206 ms
20/02/14 12:00:41 INFO CodeGenerator: Code generated in 9.656899 ms
20/02/14 12:00:41 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:00:41 INFO DAGScheduler: Registering RDD 262 (collect at arrowconverters.scala:270) as input to shuffle 27
20/02/14 12:00:41 INFO DAGScheduler: Got job 27 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:00:41 INFO DAGScheduler: Final stage: ResultStage 55 (collect at arrowconverters.scala:270)
20/02/14 12:00:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)
20/02/14 12:00:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 54)
20/02/14 12:00:41 INFO DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[262] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:00:41 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 44.3 KiB, free 413.9 MiB)
20/02/14 12:00:41 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.9 MiB)
20/02/14 12:00:41 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:00:41 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1196
20/02/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[262] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
20/02/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 87, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:00:41 INFO Executor: Running task 0.0 in stage 54.0 (TID 87)
20/02/14 12:00:41 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:00:41 INFO Executor: Finished task 0.0 in stage 54.0 (TID 87). 2200 bytes result sent to driver
20/02/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 87) in 22 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
20/02/14 12:00:41 INFO DAGScheduler: ShuffleMapStage 54 (collect at arrowconverters.scala:270) finished in 0.032 s
20/02/14 12:00:41 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:00:41 INFO DAGScheduler: running: Set()
20/02/14 12:00:41 INFO DAGScheduler: waiting: Set(ResultStage 55)
20/02/14 12:00:41 INFO DAGScheduler: failed: Set()
20/02/14 12:00:41 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[268] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:00:41 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 49.9 KiB, free 413.8 MiB)
20/02/14 12:00:41 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 413.8 MiB)
20/02/14 12:00:41 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:55441 (size: 17.2 KiB, free: 413.9 MiB)
20/02/14 12:00:41 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1196
20/02/14 12:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[268] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:00:41 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
20/02/14 12:00:41 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 88, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:00:41 INFO Executor: Running task 0.0 in stage 55.0 (TID 88)
20/02/14 12:00:41 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:00:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:00:41 INFO Executor: Finished task 0.0 in stage 55.0 (TID 88). 3189 bytes result sent to driver
20/02/14 12:00:41 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 88) in 23 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:00:41 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
20/02/14 12:00:41 INFO DAGScheduler: ResultStage 55 (collect at arrowconverters.scala:270) finished in 0.029 s
20/02/14 12:00:41 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:00:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
20/02/14 12:00:41 INFO DAGScheduler: Job 27 finished: collect at arrowconverters.scala:270, took 0.070241 s
20/02/14 12:00:45 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:00:45 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:55441 in memory (size: 17.2 KiB, free: 413.9 MiB)
20/02/14 12:00:45 INFO CodeGenerator: Code generated in 7.7969 ms
20/02/14 12:00:45 INFO CodeGenerator: Code generated in 9.026199 ms
20/02/14 12:00:45 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:00:45 INFO DAGScheduler: Registering RDD 273 (collect at arrowconverters.scala:270) as input to shuffle 28
20/02/14 12:00:45 INFO DAGScheduler: Got job 28 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:00:45 INFO DAGScheduler: Final stage: ResultStage 57 (collect at arrowconverters.scala:270)
20/02/14 12:00:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
20/02/14 12:00:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 56)
20/02/14 12:00:45 INFO DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[273] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:00:45 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 44.3 KiB, free 413.9 MiB)
20/02/14 12:00:45 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.9 MiB)
20/02/14 12:00:45 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:00:45 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1196
20/02/14 12:00:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[273] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:00:45 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
20/02/14 12:00:45 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 89, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:00:45 INFO Executor: Running task 0.0 in stage 56.0 (TID 89)
20/02/14 12:00:45 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:00:45 INFO Executor: Finished task 0.0 in stage 56.0 (TID 89). 2157 bytes result sent to driver
20/02/14 12:00:45 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 89) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:00:45 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
20/02/14 12:00:45 INFO DAGScheduler: ShuffleMapStage 56 (collect at arrowconverters.scala:270) finished in 0.025 s
20/02/14 12:00:45 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:00:45 INFO DAGScheduler: running: Set()
20/02/14 12:00:45 INFO DAGScheduler: waiting: Set(ResultStage 57)
20/02/14 12:00:45 INFO DAGScheduler: failed: Set()
20/02/14 12:00:45 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[279] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:00:45 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 49.9 KiB, free 413.8 MiB)
20/02/14 12:00:45 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 413.8 MiB)
20/02/14 12:00:45 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:55441 (size: 17.2 KiB, free: 413.9 MiB)
20/02/14 12:00:45 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1196
20/02/14 12:00:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[279] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:00:45 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
20/02/14 12:00:45 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 90, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:00:45 INFO Executor: Running task 0.0 in stage 57.0 (TID 90)
20/02/14 12:00:45 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:00:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:00:45 INFO Executor: Finished task 0.0 in stage 57.0 (TID 90). 3189 bytes result sent to driver
20/02/14 12:00:45 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 90) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:00:45 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
20/02/14 12:00:45 INFO DAGScheduler: ResultStage 57 (collect at arrowconverters.scala:270) finished in 0.024 s
20/02/14 12:00:45 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:00:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
20/02/14 12:00:45 INFO DAGScheduler: Job 28 finished: collect at arrowconverters.scala:270, took 0.055266 s
20/02/14 12:00:56 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:55441 in memory (size: 17.2 KiB, free: 413.9 MiB)
20/02/14 12:00:56 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:00:56 INFO CodeGenerator: Code generated in 6.8716 ms
20/02/14 12:00:56 INFO CodeGenerator: Code generated in 8.8627 ms
20/02/14 12:00:56 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:00:56 INFO DAGScheduler: Registering RDD 284 (collect at arrowconverters.scala:270) as input to shuffle 29
20/02/14 12:00:56 INFO DAGScheduler: Got job 29 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:00:56 INFO DAGScheduler: Final stage: ResultStage 59 (collect at arrowconverters.scala:270)
20/02/14 12:00:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)
20/02/14 12:00:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 58)
20/02/14 12:00:56 INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[284] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:00:56 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 44.3 KiB, free 413.9 MiB)
20/02/14 12:00:56 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.9 MiB)
20/02/14 12:00:56 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:00:56 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1196
20/02/14 12:00:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[284] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:00:56 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
20/02/14 12:00:56 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 91, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:00:56 INFO Executor: Running task 0.0 in stage 58.0 (TID 91)
20/02/14 12:00:56 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:00:56 INFO Executor: Finished task 0.0 in stage 58.0 (TID 91). 2200 bytes result sent to driver
20/02/14 12:00:56 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 91) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:00:56 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
20/02/14 12:00:56 INFO DAGScheduler: ShuffleMapStage 58 (collect at arrowconverters.scala:270) finished in 0.023 s
20/02/14 12:00:56 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:00:56 INFO DAGScheduler: running: Set()
20/02/14 12:00:56 INFO DAGScheduler: waiting: Set(ResultStage 59)
20/02/14 12:00:56 INFO DAGScheduler: failed: Set()
20/02/14 12:00:56 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[290] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:00:56 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:00:56 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 413.8 MiB)
20/02/14 12:00:56 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:55441 (size: 17.1 KiB, free: 413.9 MiB)
20/02/14 12:00:56 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1196
20/02/14 12:00:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[290] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:00:56 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
20/02/14 12:00:56 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 92, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:00:56 INFO Executor: Running task 0.0 in stage 59.0 (TID 92)
20/02/14 12:00:56 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:00:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:00:56 INFO Executor: Finished task 0.0 in stage 59.0 (TID 92). 3703 bytes result sent to driver
20/02/14 12:00:56 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 92) in 20 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:00:56 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
20/02/14 12:00:56 INFO DAGScheduler: ResultStage 59 (collect at arrowconverters.scala:270) finished in 0.030 s
20/02/14 12:00:56 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:00:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished
20/02/14 12:00:56 INFO DAGScheduler: Job 29 finished: collect at arrowconverters.scala:270, took 0.062341 s
20/02/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:01:03 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:55441 in memory (size: 17.1 KiB, free: 413.9 MiB)
20/02/14 12:01:03 INFO CodeGenerator: Code generated in 7.872601 ms
20/02/14 12:01:03 INFO CodeGenerator: Code generated in 10.646299 ms
20/02/14 12:01:03 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:01:03 INFO DAGScheduler: Registering RDD 295 (collect at arrowconverters.scala:270) as input to shuffle 30
20/02/14 12:01:03 INFO DAGScheduler: Got job 30 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:01:03 INFO DAGScheduler: Final stage: ResultStage 61 (collect at arrowconverters.scala:270)
20/02/14 12:01:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 60)
20/02/14 12:01:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 60)
20/02/14 12:01:03 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[295] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:01:03 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 44.3 KiB, free 413.9 MiB)
20/02/14 12:01:03 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.9 MiB)
20/02/14 12:01:03 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:01:03 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1196
20/02/14 12:01:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[295] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:01:03 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
20/02/14 12:01:03 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 93, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:01:03 INFO Executor: Running task 0.0 in stage 60.0 (TID 93)
20/02/14 12:01:03 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:01:03 INFO Executor: Finished task 0.0 in stage 60.0 (TID 93). 2200 bytes result sent to driver
20/02/14 12:01:03 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 93) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:01:03 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
20/02/14 12:01:03 INFO DAGScheduler: ShuffleMapStage 60 (collect at arrowconverters.scala:270) finished in 0.023 s
20/02/14 12:01:03 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:01:03 INFO DAGScheduler: running: Set()
20/02/14 12:01:03 INFO DAGScheduler: waiting: Set(ResultStage 61)
20/02/14 12:01:03 INFO DAGScheduler: failed: Set()
20/02/14 12:01:03 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[301] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:01:03 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:01:03 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.8 MiB)
20/02/14 12:01:03 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:01:03 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1196
20/02/14 12:01:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[301] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:01:03 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
20/02/14 12:01:03 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 94, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:01:03 INFO Executor: Running task 0.0 in stage 61.0 (TID 94)
20/02/14 12:01:03 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:01:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:01:03 INFO Executor: Finished task 0.0 in stage 61.0 (TID 94). 3660 bytes result sent to driver
20/02/14 12:01:03 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 94) in 23 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:01:03 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
20/02/14 12:01:03 INFO DAGScheduler: ResultStage 61 (collect at arrowconverters.scala:270) finished in 0.030 s
20/02/14 12:01:03 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:01:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
20/02/14 12:01:03 INFO DAGScheduler: Job 30 finished: collect at arrowconverters.scala:270, took 0.058670 s
20/02/14 12:01:44 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:01:44 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:01:44 INFO CodeGenerator: Code generated in 9.3216 ms
20/02/14 12:01:45 INFO CodeGenerator: Code generated in 9.1144 ms
20/02/14 12:01:45 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:01:45 INFO DAGScheduler: Registering RDD 306 (collect at arrowconverters.scala:270) as input to shuffle 31
20/02/14 12:01:45 INFO DAGScheduler: Got job 31 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:01:45 INFO DAGScheduler: Final stage: ResultStage 63 (collect at arrowconverters.scala:270)
20/02/14 12:01:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
20/02/14 12:01:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 62)
20/02/14 12:01:45 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[306] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:01:45 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 44.3 KiB, free 413.9 MiB)
20/02/14 12:01:45 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.9 MiB)
20/02/14 12:01:45 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:01:45 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1196
20/02/14 12:01:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[306] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:01:45 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
20/02/14 12:01:45 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 95, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:01:45 INFO Executor: Running task 0.0 in stage 62.0 (TID 95)
20/02/14 12:01:45 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:01:45 INFO Executor: Finished task 0.0 in stage 62.0 (TID 95). 2200 bytes result sent to driver
20/02/14 12:01:45 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 95) in 20 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:01:45 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
20/02/14 12:01:45 INFO DAGScheduler: ShuffleMapStage 62 (collect at arrowconverters.scala:270) finished in 0.029 s
20/02/14 12:01:45 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:01:45 INFO DAGScheduler: running: Set()
20/02/14 12:01:45 INFO DAGScheduler: waiting: Set(ResultStage 63)
20/02/14 12:01:45 INFO DAGScheduler: failed: Set()
20/02/14 12:01:45 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[312] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:01:45 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:01:45 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.8 MiB)
20/02/14 12:01:45 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:01:45 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1196
20/02/14 12:01:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[312] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:01:45 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
20/02/14 12:01:45 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 96, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:01:45 INFO Executor: Running task 0.0 in stage 63.0 (TID 96)
20/02/14 12:01:45 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:01:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:01:45 INFO Executor: Finished task 0.0 in stage 63.0 (TID 96). 3660 bytes result sent to driver
20/02/14 12:01:45 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 96) in 22 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:01:45 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
20/02/14 12:01:45 INFO DAGScheduler: ResultStage 63 (collect at arrowconverters.scala:270) finished in 0.028 s
20/02/14 12:01:45 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:01:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
20/02/14 12:01:45 INFO DAGScheduler: Job 31 finished: collect at arrowconverters.scala:270, took 0.064380 s
20/02/14 12:02:33 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:02:33 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:02:33 INFO CodeGenerator: Code generated in 12.034099 ms
20/02/14 12:02:33 INFO CodeGenerator: Code generated in 10.427699 ms
20/02/14 12:02:33 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:02:33 INFO DAGScheduler: Registering RDD 317 (collect at arrowconverters.scala:270) as input to shuffle 32
20/02/14 12:02:33 INFO DAGScheduler: Got job 32 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:02:33 INFO DAGScheduler: Final stage: ResultStage 65 (collect at arrowconverters.scala:270)
20/02/14 12:02:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
20/02/14 12:02:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 64)
20/02/14 12:02:33 INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[317] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:02:33 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 44.3 KiB, free 413.9 MiB)
20/02/14 12:02:33 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.9 MiB)
20/02/14 12:02:33 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:02:33 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1196
20/02/14 12:02:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[317] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:02:33 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
20/02/14 12:02:33 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 97, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:02:33 INFO Executor: Running task 0.0 in stage 64.0 (TID 97)
20/02/14 12:02:33 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:02:33 INFO Executor: Finished task 0.0 in stage 64.0 (TID 97). 2157 bytes result sent to driver
20/02/14 12:02:33 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 97) in 20 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:02:33 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
20/02/14 12:02:33 INFO DAGScheduler: ShuffleMapStage 64 (collect at arrowconverters.scala:270) finished in 0.028 s
20/02/14 12:02:33 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:02:33 INFO DAGScheduler: running: Set()
20/02/14 12:02:33 INFO DAGScheduler: waiting: Set(ResultStage 65)
20/02/14 12:02:33 INFO DAGScheduler: failed: Set()
20/02/14 12:02:33 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[323] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:02:33 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:02:33 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.8 MiB)
20/02/14 12:02:33 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:02:33 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1196
20/02/14 12:02:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[323] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:02:33 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
20/02/14 12:02:33 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 98, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:02:33 INFO Executor: Running task 0.0 in stage 65.0 (TID 98)
20/02/14 12:02:33 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:02:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:02:33 INFO Executor: Finished task 0.0 in stage 65.0 (TID 98). 3660 bytes result sent to driver
20/02/14 12:02:33 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 98) in 22 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:02:33 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
20/02/14 12:02:33 INFO DAGScheduler: ResultStage 65 (collect at arrowconverters.scala:270) finished in 0.029 s
20/02/14 12:02:33 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:02:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished
20/02/14 12:02:33 INFO DAGScheduler: Job 32 finished: collect at arrowconverters.scala:270, took 0.064738 s
20/02/14 12:02:44 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:02:44 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:02:44 INFO CodeGenerator: Code generated in 8.7442 ms
20/02/14 12:02:44 INFO CodeGenerator: Code generated in 11.0915 ms
20/02/14 12:02:44 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:02:44 INFO DAGScheduler: Registering RDD 328 (collect at arrowconverters.scala:270) as input to shuffle 33
20/02/14 12:02:44 INFO DAGScheduler: Got job 33 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:02:44 INFO DAGScheduler: Final stage: ResultStage 67 (collect at arrowconverters.scala:270)
20/02/14 12:02:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)
20/02/14 12:02:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 66)
20/02/14 12:02:44 INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[328] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:02:44 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 44.3 KiB, free 413.9 MiB)
20/02/14 12:02:44 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.9 MiB)
20/02/14 12:02:44 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:02:44 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1196
20/02/14 12:02:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[328] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:02:44 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
20/02/14 12:02:44 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 99, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:02:44 INFO Executor: Running task 0.0 in stage 66.0 (TID 99)
20/02/14 12:02:44 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:02:44 INFO Executor: Finished task 0.0 in stage 66.0 (TID 99). 2157 bytes result sent to driver
20/02/14 12:02:44 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 99) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:02:44 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
20/02/14 12:02:44 INFO DAGScheduler: ShuffleMapStage 66 (collect at arrowconverters.scala:270) finished in 0.020 s
20/02/14 12:02:44 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:02:44 INFO DAGScheduler: running: Set()
20/02/14 12:02:44 INFO DAGScheduler: waiting: Set(ResultStage 67)
20/02/14 12:02:44 INFO DAGScheduler: failed: Set()
20/02/14 12:02:44 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[334] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:02:44 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:02:44 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.8 MiB)
20/02/14 12:02:44 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:02:44 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1196
20/02/14 12:02:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[334] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:02:44 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
20/02/14 12:02:44 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 100, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:02:44 INFO Executor: Running task 0.0 in stage 67.0 (TID 100)
20/02/14 12:02:44 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:02:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:02:44 INFO Executor: Finished task 0.0 in stage 67.0 (TID 100). 3703 bytes result sent to driver
20/02/14 12:02:44 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 100) in 21 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:02:44 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
20/02/14 12:02:44 INFO DAGScheduler: ResultStage 67 (collect at arrowconverters.scala:270) finished in 0.032 s
20/02/14 12:02:44 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:02:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished
20/02/14 12:02:44 INFO DAGScheduler: Job 33 finished: collect at arrowconverters.scala:270, took 0.060542 s
20/02/14 12:02:57 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:02:57 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:02:57 INFO CodeGenerator: Code generated in 10.420099 ms
20/02/14 12:02:57 INFO CodeGenerator: Code generated in 11.3199 ms
20/02/14 12:02:57 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:02:57 INFO DAGScheduler: Registering RDD 339 (collect at arrowconverters.scala:270) as input to shuffle 34
20/02/14 12:02:57 INFO DAGScheduler: Got job 34 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:02:57 INFO DAGScheduler: Final stage: ResultStage 69 (collect at arrowconverters.scala:270)
20/02/14 12:02:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
20/02/14 12:02:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 68)
20/02/14 12:02:57 INFO DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[339] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:02:57 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 44.3 KiB, free 413.9 MiB)
20/02/14 12:02:57 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.9 MiB)
20/02/14 12:02:57 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:02:57 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1196
20/02/14 12:02:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[339] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:02:57 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks
20/02/14 12:02:57 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 101, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:02:57 INFO Executor: Running task 0.0 in stage 68.0 (TID 101)
20/02/14 12:02:57 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:02:57 INFO Executor: Finished task 0.0 in stage 68.0 (TID 101). 2200 bytes result sent to driver
20/02/14 12:02:57 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 101) in 21 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:02:57 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
20/02/14 12:02:57 INFO DAGScheduler: ShuffleMapStage 68 (collect at arrowconverters.scala:270) finished in 0.029 s
20/02/14 12:02:57 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:02:57 INFO DAGScheduler: running: Set()
20/02/14 12:02:57 INFO DAGScheduler: waiting: Set(ResultStage 69)
20/02/14 12:02:57 INFO DAGScheduler: failed: Set()
20/02/14 12:02:57 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[345] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:02:57 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:02:57 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.8 MiB)
20/02/14 12:02:57 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:02:57 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1196
20/02/14 12:02:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[345] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:02:57 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks
20/02/14 12:02:57 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 102, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:02:57 INFO Executor: Running task 0.0 in stage 69.0 (TID 102)
20/02/14 12:02:57 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:02:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:02:57 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:02:57 INFO Executor: Finished task 0.0 in stage 69.0 (TID 102). 3703 bytes result sent to driver
20/02/14 12:02:57 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 102) in 116 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:02:57 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
20/02/14 12:02:57 INFO DAGScheduler: ResultStage 69 (collect at arrowconverters.scala:270) finished in 0.122 s
20/02/14 12:02:57 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:02:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished
20/02/14 12:02:57 INFO DAGScheduler: Job 34 finished: collect at arrowconverters.scala:270, took 0.158130 s
20/02/14 12:03:07 INFO CodeGenerator: Code generated in 7.3423 ms
20/02/14 12:03:07 INFO CodeGenerator: Code generated in 8.331101 ms
20/02/14 12:03:07 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:03:07 INFO DAGScheduler: Registering RDD 350 (collect at arrowconverters.scala:270) as input to shuffle 35
20/02/14 12:03:07 INFO DAGScheduler: Got job 35 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:03:07 INFO DAGScheduler: Final stage: ResultStage 71 (collect at arrowconverters.scala:270)
20/02/14 12:03:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)
20/02/14 12:03:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 70)
20/02/14 12:03:07 INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[350] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:03:07 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:03:07 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:03:07 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:03:07 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1196
20/02/14 12:03:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[350] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:03:07 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks
20/02/14 12:03:07 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 103, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:03:07 INFO Executor: Running task 0.0 in stage 70.0 (TID 103)
20/02/14 12:03:07 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:03:07 INFO Executor: Finished task 0.0 in stage 70.0 (TID 103). 2200 bytes result sent to driver
20/02/14 12:03:07 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 103) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:03:07 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
20/02/14 12:03:07 INFO DAGScheduler: ShuffleMapStage 70 (collect at arrowconverters.scala:270) finished in 0.030 s
20/02/14 12:03:07 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:03:07 INFO DAGScheduler: running: Set()
20/02/14 12:03:07 INFO DAGScheduler: waiting: Set(ResultStage 71)
20/02/14 12:03:07 INFO DAGScheduler: failed: Set()
20/02/14 12:03:07 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[356] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:03:07 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:03:07 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:03:07 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:03:07 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1196
20/02/14 12:03:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[356] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:03:07 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks
20/02/14 12:03:07 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 104, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:03:07 INFO Executor: Running task 0.0 in stage 71.0 (TID 104)
20/02/14 12:03:07 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:03:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:03:07 INFO Executor: Finished task 0.0 in stage 71.0 (TID 104). 3660 bytes result sent to driver
20/02/14 12:03:07 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 104) in 22 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:03:07 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
20/02/14 12:03:07 INFO DAGScheduler: ResultStage 71 (collect at arrowconverters.scala:270) finished in 0.028 s
20/02/14 12:03:07 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:03:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 71: Stage finished
20/02/14 12:03:07 INFO DAGScheduler: Job 35 finished: collect at arrowconverters.scala:270, took 0.065020 s
20/02/14 12:03:17 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:03:17 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:03:17 INFO CodeGenerator: Code generated in 6.846 ms
20/02/14 12:03:17 INFO CodeGenerator: Code generated in 12.7328 ms
20/02/14 12:03:17 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:03:17 INFO DAGScheduler: Registering RDD 361 (collect at arrowconverters.scala:270) as input to shuffle 36
20/02/14 12:03:17 INFO DAGScheduler: Got job 36 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:03:17 INFO DAGScheduler: Final stage: ResultStage 73 (collect at arrowconverters.scala:270)
20/02/14 12:03:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 72)
20/02/14 12:03:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 72)
20/02/14 12:03:17 INFO DAGScheduler: Submitting ShuffleMapStage 72 (MapPartitionsRDD[361] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:03:17 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:03:17 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:03:17 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:03:17 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1196
20/02/14 12:03:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[361] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:03:17 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks
20/02/14 12:03:17 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 105, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:03:17 INFO Executor: Running task 0.0 in stage 72.0 (TID 105)
20/02/14 12:03:17 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:03:17 INFO Executor: Finished task 0.0 in stage 72.0 (TID 105). 2200 bytes result sent to driver
20/02/14 12:03:17 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 105) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:03:17 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
20/02/14 12:03:17 INFO DAGScheduler: ShuffleMapStage 72 (collect at arrowconverters.scala:270) finished in 0.024 s
20/02/14 12:03:17 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:03:17 INFO DAGScheduler: running: Set()
20/02/14 12:03:17 INFO DAGScheduler: waiting: Set(ResultStage 73)
20/02/14 12:03:17 INFO DAGScheduler: failed: Set()
20/02/14 12:03:17 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[367] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:03:17 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:03:17 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 413.7 MiB)
20/02/14 12:03:17 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:55441 (size: 17.1 KiB, free: 413.9 MiB)
20/02/14 12:03:17 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1196
20/02/14 12:03:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[367] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:03:17 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
20/02/14 12:03:17 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 106, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:03:17 INFO Executor: Running task 0.0 in stage 73.0 (TID 106)
20/02/14 12:03:17 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:03:17 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:03:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:03:17 INFO Executor: Finished task 0.0 in stage 73.0 (TID 106). 3703 bytes result sent to driver
20/02/14 12:03:17 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 106) in 26 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:03:17 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
20/02/14 12:03:17 INFO DAGScheduler: ResultStage 73 (collect at arrowconverters.scala:270) finished in 0.033 s
20/02/14 12:03:17 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:03:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 73: Stage finished
20/02/14 12:03:17 INFO DAGScheduler: Job 36 finished: collect at arrowconverters.scala:270, took 0.063235 s
20/02/14 12:04:08 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:55441 in memory (size: 17.1 KiB, free: 413.9 MiB)
20/02/14 12:04:08 INFO CodeGenerator: Code generated in 5.8217 ms
20/02/14 12:04:08 INFO CodeGenerator: Code generated in 7.7139 ms
20/02/14 12:04:08 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:04:08 INFO DAGScheduler: Registering RDD 372 (collect at arrowconverters.scala:270) as input to shuffle 37
20/02/14 12:04:08 INFO DAGScheduler: Got job 37 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:04:08 INFO DAGScheduler: Final stage: ResultStage 75 (collect at arrowconverters.scala:270)
20/02/14 12:04:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 74)
20/02/14 12:04:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 74)
20/02/14 12:04:08 INFO DAGScheduler: Submitting ShuffleMapStage 74 (MapPartitionsRDD[372] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:04:08 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:04:08 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:04:08 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:04:08 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1196
20/02/14 12:04:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 74 (MapPartitionsRDD[372] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:04:08 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks
20/02/14 12:04:08 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 107, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:04:08 INFO Executor: Running task 0.0 in stage 74.0 (TID 107)
20/02/14 12:04:08 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:04:08 INFO Executor: Finished task 0.0 in stage 74.0 (TID 107). 2200 bytes result sent to driver
20/02/14 12:04:08 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 107) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:04:08 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
20/02/14 12:04:08 INFO DAGScheduler: ShuffleMapStage 74 (collect at arrowconverters.scala:270) finished in 0.026 s
20/02/14 12:04:08 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:04:08 INFO DAGScheduler: running: Set()
20/02/14 12:04:08 INFO DAGScheduler: waiting: Set(ResultStage 75)
20/02/14 12:04:08 INFO DAGScheduler: failed: Set()
20/02/14 12:04:08 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[378] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:04:08 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:04:08 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:04:08 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:04:08 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1196
20/02/14 12:04:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[378] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:04:08 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks
20/02/14 12:04:08 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 108, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:04:08 INFO Executor: Running task 0.0 in stage 75.0 (TID 108)
20/02/14 12:04:08 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:04:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:04:08 INFO Executor: Finished task 0.0 in stage 75.0 (TID 108). 3660 bytes result sent to driver
20/02/14 12:04:08 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 108) in 23 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:04:08 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
20/02/14 12:04:08 INFO DAGScheduler: ResultStage 75 (collect at arrowconverters.scala:270) finished in 0.030 s
20/02/14 12:04:08 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:04:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 75: Stage finished
20/02/14 12:04:08 INFO DAGScheduler: Job 37 finished: collect at arrowconverters.scala:270, took 0.063340 s
20/02/14 12:04:17 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:04:17 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:04:17 INFO CodeGenerator: Code generated in 5.4908 ms
20/02/14 12:04:17 INFO CodeGenerator: Code generated in 7.010501 ms
20/02/14 12:04:17 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:04:17 INFO DAGScheduler: Registering RDD 383 (collect at arrowconverters.scala:270) as input to shuffle 38
20/02/14 12:04:17 INFO DAGScheduler: Got job 38 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:04:17 INFO DAGScheduler: Final stage: ResultStage 77 (collect at arrowconverters.scala:270)
20/02/14 12:04:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 76)
20/02/14 12:04:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 76)
20/02/14 12:04:17 INFO DAGScheduler: Submitting ShuffleMapStage 76 (MapPartitionsRDD[383] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:04:17 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:04:17 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:04:17 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:04:17 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1196
20/02/14 12:04:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[383] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:04:17 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks
20/02/14 12:04:17 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 109, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:04:17 INFO Executor: Running task 0.0 in stage 76.0 (TID 109)
20/02/14 12:04:17 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:04:17 INFO Executor: Finished task 0.0 in stage 76.0 (TID 109). 2200 bytes result sent to driver
20/02/14 12:04:17 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 109) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:04:17 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
20/02/14 12:04:17 INFO DAGScheduler: ShuffleMapStage 76 (collect at arrowconverters.scala:270) finished in 0.023 s
20/02/14 12:04:17 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:04:17 INFO DAGScheduler: running: Set()
20/02/14 12:04:17 INFO DAGScheduler: waiting: Set(ResultStage 77)
20/02/14 12:04:17 INFO DAGScheduler: failed: Set()
20/02/14 12:04:17 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[389] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:04:17 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:04:17 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:04:17 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:04:17 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1196
20/02/14 12:04:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[389] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:04:17 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks
20/02/14 12:04:17 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 110, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:04:17 INFO Executor: Running task 0.0 in stage 77.0 (TID 110)
20/02/14 12:04:17 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:04:17 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:04:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:04:17 INFO Executor: Finished task 0.0 in stage 77.0 (TID 110). 3703 bytes result sent to driver
20/02/14 12:04:17 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 110) in 23 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:04:17 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
20/02/14 12:04:18 INFO DAGScheduler: ResultStage 77 (collect at arrowconverters.scala:270) finished in 0.031 s
20/02/14 12:04:18 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:04:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 77: Stage finished
20/02/14 12:04:18 INFO DAGScheduler: Job 38 finished: collect at arrowconverters.scala:270, took 0.059187 s
20/02/14 12:04:56 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:04:56 INFO CodeGenerator: Code generated in 6.0765 ms
20/02/14 12:04:56 INFO CodeGenerator: Code generated in 7.3321 ms
20/02/14 12:04:56 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:04:56 INFO DAGScheduler: Registering RDD 394 (collect at arrowconverters.scala:270) as input to shuffle 39
20/02/14 12:04:56 INFO DAGScheduler: Got job 39 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:04:56 INFO DAGScheduler: Final stage: ResultStage 79 (collect at arrowconverters.scala:270)
20/02/14 12:04:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 78)
20/02/14 12:04:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 78)
20/02/14 12:04:56 INFO DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[394] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:04:56 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:04:56 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:04:56 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:04:56 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1196
20/02/14 12:04:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[394] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:04:56 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks
20/02/14 12:04:56 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 111, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:04:56 INFO Executor: Running task 0.0 in stage 78.0 (TID 111)
20/02/14 12:04:56 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:04:56 INFO Executor: Finished task 0.0 in stage 78.0 (TID 111). 2200 bytes result sent to driver
20/02/14 12:04:56 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 111) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:04:56 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
20/02/14 12:04:56 INFO DAGScheduler: ShuffleMapStage 78 (collect at arrowconverters.scala:270) finished in 0.027 s
20/02/14 12:04:56 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:04:56 INFO DAGScheduler: running: Set()
20/02/14 12:04:56 INFO DAGScheduler: waiting: Set(ResultStage 79)
20/02/14 12:04:56 INFO DAGScheduler: failed: Set()
20/02/14 12:04:56 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[400] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:04:56 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:04:56 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 413.7 MiB)
20/02/14 12:04:56 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:55441 (size: 17.1 KiB, free: 413.9 MiB)
20/02/14 12:04:56 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1196
20/02/14 12:04:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[400] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:04:56 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks
20/02/14 12:04:56 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 112, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:04:56 INFO Executor: Running task 0.0 in stage 79.0 (TID 112)
20/02/14 12:04:56 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:04:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:04:56 INFO Executor: Finished task 0.0 in stage 79.0 (TID 112). 3660 bytes result sent to driver
20/02/14 12:04:56 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 112) in 19 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:04:56 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
20/02/14 12:04:56 INFO DAGScheduler: ResultStage 79 (collect at arrowconverters.scala:270) finished in 0.025 s
20/02/14 12:04:56 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:04:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 79: Stage finished
20/02/14 12:04:56 INFO DAGScheduler: Job 39 finished: collect at arrowconverters.scala:270, took 0.059068 s
20/02/14 12:04:59 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:55441 in memory (size: 17.1 KiB, free: 413.9 MiB)
20/02/14 12:04:59 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:04:59 INFO CodeGenerator: Code generated in 5.2668 ms
20/02/14 12:04:59 INFO CodeGenerator: Code generated in 7.356699 ms
20/02/14 12:04:59 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:04:59 INFO DAGScheduler: Registering RDD 405 (collect at arrowconverters.scala:270) as input to shuffle 40
20/02/14 12:04:59 INFO DAGScheduler: Got job 40 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:04:59 INFO DAGScheduler: Final stage: ResultStage 81 (collect at arrowconverters.scala:270)
20/02/14 12:04:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 80)
20/02/14 12:04:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 80)
20/02/14 12:04:59 INFO DAGScheduler: Submitting ShuffleMapStage 80 (MapPartitionsRDD[405] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:04:59 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:04:59 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:04:59 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:04:59 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1196
20/02/14 12:04:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 80 (MapPartitionsRDD[405] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:04:59 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks
20/02/14 12:04:59 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 113, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:04:59 INFO Executor: Running task 0.0 in stage 80.0 (TID 113)
20/02/14 12:04:59 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:04:59 INFO Executor: Finished task 0.0 in stage 80.0 (TID 113). 2200 bytes result sent to driver
20/02/14 12:04:59 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 113) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:04:59 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
20/02/14 12:04:59 INFO DAGScheduler: ShuffleMapStage 80 (collect at arrowconverters.scala:270) finished in 0.022 s
20/02/14 12:04:59 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:04:59 INFO DAGScheduler: running: Set()
20/02/14 12:04:59 INFO DAGScheduler: waiting: Set(ResultStage 81)
20/02/14 12:04:59 INFO DAGScheduler: failed: Set()
20/02/14 12:04:59 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[411] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:04:59 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:04:59 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:04:59 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:04:59 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1196
20/02/14 12:04:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[411] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:04:59 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks
20/02/14 12:04:59 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 114, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:04:59 INFO Executor: Running task 0.0 in stage 81.0 (TID 114)
20/02/14 12:04:59 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:04:59 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:04:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:04:59 INFO Executor: Finished task 0.0 in stage 81.0 (TID 114). 3660 bytes result sent to driver
20/02/14 12:04:59 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 114) in 25 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:04:59 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
20/02/14 12:04:59 INFO DAGScheduler: ResultStage 81 (collect at arrowconverters.scala:270) finished in 0.032 s
20/02/14 12:04:59 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:04:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished
20/02/14 12:04:59 INFO DAGScheduler: Job 40 finished: collect at arrowconverters.scala:270, took 0.060116 s
20/02/14 12:05:01 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:05:02 INFO CodeGenerator: Code generated in 8.445501 ms
20/02/14 12:05:02 INFO CodeGenerator: Code generated in 8.4378 ms
20/02/14 12:05:02 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:05:02 INFO DAGScheduler: Registering RDD 416 (collect at arrowconverters.scala:270) as input to shuffle 41
20/02/14 12:05:02 INFO DAGScheduler: Got job 41 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:05:02 INFO DAGScheduler: Final stage: ResultStage 83 (collect at arrowconverters.scala:270)
20/02/14 12:05:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 82)
20/02/14 12:05:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 82)
20/02/14 12:05:02 INFO DAGScheduler: Submitting ShuffleMapStage 82 (MapPartitionsRDD[416] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:05:02 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:05:02 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:05:02 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:05:02 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1196
20/02/14 12:05:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[416] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:05:02 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks
20/02/14 12:05:02 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 115, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:05:02 INFO Executor: Running task 0.0 in stage 82.0 (TID 115)
20/02/14 12:05:02 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:05:02 INFO Executor: Finished task 0.0 in stage 82.0 (TID 115). 2200 bytes result sent to driver
20/02/14 12:05:02 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 115) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:05:02 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
20/02/14 12:05:02 INFO DAGScheduler: ShuffleMapStage 82 (collect at arrowconverters.scala:270) finished in 0.029 s
20/02/14 12:05:02 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:05:02 INFO DAGScheduler: running: Set()
20/02/14 12:05:02 INFO DAGScheduler: waiting: Set(ResultStage 83)
20/02/14 12:05:02 INFO DAGScheduler: failed: Set()
20/02/14 12:05:02 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[422] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:05:02 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:05:02 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:05:02 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:05:02 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1196
20/02/14 12:05:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[422] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:05:02 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks
20/02/14 12:05:02 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 116, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:05:02 INFO Executor: Running task 0.0 in stage 83.0 (TID 116)
20/02/14 12:05:02 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:05:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:05:02 INFO Executor: Finished task 0.0 in stage 83.0 (TID 116). 3660 bytes result sent to driver
20/02/14 12:05:02 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 116) in 25 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:05:02 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
20/02/14 12:05:02 INFO DAGScheduler: ResultStage 83 (collect at arrowconverters.scala:270) finished in 0.033 s
20/02/14 12:05:02 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:05:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 83: Stage finished
20/02/14 12:05:02 INFO DAGScheduler: Job 41 finished: collect at arrowconverters.scala:270, took 0.068339 s
20/02/14 12:05:06 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:05:06 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:05:06 INFO CodeGenerator: Code generated in 8.774101 ms
20/02/14 12:05:06 INFO CodeGenerator: Code generated in 15.35 ms
20/02/14 12:05:06 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:05:06 INFO DAGScheduler: Registering RDD 427 (collect at arrowconverters.scala:270) as input to shuffle 42
20/02/14 12:05:06 INFO DAGScheduler: Got job 42 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:05:06 INFO DAGScheduler: Final stage: ResultStage 85 (collect at arrowconverters.scala:270)
20/02/14 12:05:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 84)
20/02/14 12:05:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 84)
20/02/14 12:05:06 INFO DAGScheduler: Submitting ShuffleMapStage 84 (MapPartitionsRDD[427] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:05:06 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:05:06 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:05:06 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:05:06 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1196
20/02/14 12:05:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 84 (MapPartitionsRDD[427] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:05:06 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks
20/02/14 12:05:06 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 117, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:05:06 INFO Executor: Running task 0.0 in stage 84.0 (TID 117)
20/02/14 12:05:06 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:05:06 INFO Executor: Finished task 0.0 in stage 84.0 (TID 117). 2200 bytes result sent to driver
20/02/14 12:05:06 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 117) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:05:06 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
20/02/14 12:05:06 INFO DAGScheduler: ShuffleMapStage 84 (collect at arrowconverters.scala:270) finished in 0.026 s
20/02/14 12:05:06 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:05:06 INFO DAGScheduler: running: Set()
20/02/14 12:05:06 INFO DAGScheduler: waiting: Set(ResultStage 85)
20/02/14 12:05:06 INFO DAGScheduler: failed: Set()
20/02/14 12:05:06 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[433] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:05:06 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:05:06 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:05:06 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:05:06 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1196
20/02/14 12:05:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[433] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:05:06 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks
20/02/14 12:05:06 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 118, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:05:06 INFO Executor: Running task 0.0 in stage 85.0 (TID 118)
20/02/14 12:05:06 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:05:06 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:05:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:05:06 INFO Executor: Finished task 0.0 in stage 85.0 (TID 118). 3703 bytes result sent to driver
20/02/14 12:05:06 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 118) in 29 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:05:06 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
20/02/14 12:05:06 INFO DAGScheduler: ResultStage 85 (collect at arrowconverters.scala:270) finished in 0.037 s
20/02/14 12:05:06 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:05:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished
20/02/14 12:05:06 INFO DAGScheduler: Job 42 finished: collect at arrowconverters.scala:270, took 0.069996 s
20/02/14 12:05:27 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:05:27 INFO CodeGenerator: Code generated in 7.179201 ms
20/02/14 12:05:27 INFO CodeGenerator: Code generated in 6.6271 ms
20/02/14 12:05:28 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:05:28 INFO DAGScheduler: Registering RDD 438 (collect at arrowconverters.scala:270) as input to shuffle 43
20/02/14 12:05:28 INFO DAGScheduler: Got job 43 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:05:28 INFO DAGScheduler: Final stage: ResultStage 87 (collect at arrowconverters.scala:270)
20/02/14 12:05:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 86)
20/02/14 12:05:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 86)
20/02/14 12:05:28 INFO DAGScheduler: Submitting ShuffleMapStage 86 (MapPartitionsRDD[438] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:05:28 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:05:28 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:05:28 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:05:28 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1196
20/02/14 12:05:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[438] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:05:28 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks
20/02/14 12:05:28 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 119, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:05:28 INFO Executor: Running task 0.0 in stage 86.0 (TID 119)
20/02/14 12:05:28 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:05:28 INFO Executor: Finished task 0.0 in stage 86.0 (TID 119). 2200 bytes result sent to driver
20/02/14 12:05:28 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 119) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:05:28 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
20/02/14 12:05:28 INFO DAGScheduler: ShuffleMapStage 86 (collect at arrowconverters.scala:270) finished in 0.027 s
20/02/14 12:05:28 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:05:28 INFO DAGScheduler: running: Set()
20/02/14 12:05:28 INFO DAGScheduler: waiting: Set(ResultStage 87)
20/02/14 12:05:28 INFO DAGScheduler: failed: Set()
20/02/14 12:05:28 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[444] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:05:28 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:05:28 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:05:28 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:05:28 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1196
20/02/14 12:05:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[444] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:05:28 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks
20/02/14 12:05:28 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 120, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:05:28 INFO Executor: Running task 0.0 in stage 87.0 (TID 120)
20/02/14 12:05:28 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:05:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:05:28 INFO Executor: Finished task 0.0 in stage 87.0 (TID 120). 3660 bytes result sent to driver
20/02/14 12:05:28 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 120) in 21 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:05:28 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
20/02/14 12:05:28 INFO DAGScheduler: ResultStage 87 (collect at arrowconverters.scala:270) finished in 0.028 s
20/02/14 12:05:28 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:05:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 87: Stage finished
20/02/14 12:05:28 INFO DAGScheduler: Job 43 finished: collect at arrowconverters.scala:270, took 0.061593 s
20/02/14 12:05:36 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:05:36 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:05:36 INFO CodeGenerator: Code generated in 6.7108 ms
20/02/14 12:05:36 INFO CodeGenerator: Code generated in 12.313501 ms
20/02/14 12:05:36 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:05:36 INFO DAGScheduler: Registering RDD 449 (collect at arrowconverters.scala:270) as input to shuffle 44
20/02/14 12:05:36 INFO DAGScheduler: Got job 44 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:05:36 INFO DAGScheduler: Final stage: ResultStage 89 (collect at arrowconverters.scala:270)
20/02/14 12:05:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)
20/02/14 12:05:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 88)
20/02/14 12:05:36 INFO DAGScheduler: Submitting ShuffleMapStage 88 (MapPartitionsRDD[449] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:05:36 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:05:36 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:05:36 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:05:36 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1196
20/02/14 12:05:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 88 (MapPartitionsRDD[449] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:05:36 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks
20/02/14 12:05:36 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 121, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:05:36 INFO Executor: Running task 0.0 in stage 88.0 (TID 121)
20/02/14 12:05:36 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:05:36 INFO Executor: Finished task 0.0 in stage 88.0 (TID 121). 2200 bytes result sent to driver
20/02/14 12:05:36 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 121) in 14 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:05:36 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
20/02/14 12:05:36 INFO DAGScheduler: ShuffleMapStage 88 (collect at arrowconverters.scala:270) finished in 0.021 s
20/02/14 12:05:36 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:05:36 INFO DAGScheduler: running: Set()
20/02/14 12:05:36 INFO DAGScheduler: waiting: Set(ResultStage 89)
20/02/14 12:05:36 INFO DAGScheduler: failed: Set()
20/02/14 12:05:36 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[455] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:05:36 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:05:36 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:05:36 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:05:36 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1196
20/02/14 12:05:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[455] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:05:36 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks
20/02/14 12:05:36 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 122, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:05:36 INFO Executor: Running task 0.0 in stage 89.0 (TID 122)
20/02/14 12:05:36 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:05:36 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:05:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:05:36 INFO Executor: Finished task 0.0 in stage 89.0 (TID 122). 3703 bytes result sent to driver
20/02/14 12:05:36 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 122) in 23 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:05:36 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
20/02/14 12:05:36 INFO DAGScheduler: ResultStage 89 (collect at arrowconverters.scala:270) finished in 0.032 s
20/02/14 12:05:36 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:05:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 89: Stage finished
20/02/14 12:05:36 INFO DAGScheduler: Job 44 finished: collect at arrowconverters.scala:270, took 0.059113 s
20/02/14 12:05:44 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:05:44 INFO CodeGenerator: Code generated in 6.2549 ms
20/02/14 12:05:44 INFO CodeGenerator: Code generated in 7.4671 ms
20/02/14 12:05:44 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:05:44 INFO DAGScheduler: Registering RDD 460 (collect at arrowconverters.scala:270) as input to shuffle 45
20/02/14 12:05:44 INFO DAGScheduler: Got job 45 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:05:44 INFO DAGScheduler: Final stage: ResultStage 91 (collect at arrowconverters.scala:270)
20/02/14 12:05:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 90)
20/02/14 12:05:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 90)
20/02/14 12:05:44 INFO DAGScheduler: Submitting ShuffleMapStage 90 (MapPartitionsRDD[460] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:05:44 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:05:44 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:05:44 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:05:44 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1196
20/02/14 12:05:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 90 (MapPartitionsRDD[460] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:05:44 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks
20/02/14 12:05:44 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 123, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:05:44 INFO Executor: Running task 0.0 in stage 90.0 (TID 123)
20/02/14 12:05:44 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:05:44 INFO Executor: Finished task 0.0 in stage 90.0 (TID 123). 2200 bytes result sent to driver
20/02/14 12:05:44 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 123) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:05:44 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
20/02/14 12:05:44 INFO DAGScheduler: ShuffleMapStage 90 (collect at arrowconverters.scala:270) finished in 0.028 s
20/02/14 12:05:44 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:05:44 INFO DAGScheduler: running: Set()
20/02/14 12:05:44 INFO DAGScheduler: waiting: Set(ResultStage 91)
20/02/14 12:05:44 INFO DAGScheduler: failed: Set()
20/02/14 12:05:44 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[466] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:05:44 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:05:44 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 413.7 MiB)
20/02/14 12:05:44 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:55441 (size: 17.1 KiB, free: 413.9 MiB)
20/02/14 12:05:44 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1196
20/02/14 12:05:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[466] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:05:44 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks
20/02/14 12:05:44 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 124, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:05:44 INFO Executor: Running task 0.0 in stage 91.0 (TID 124)
20/02/14 12:05:44 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:05:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:05:44 INFO Executor: Finished task 0.0 in stage 91.0 (TID 124). 3660 bytes result sent to driver
20/02/14 12:05:44 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 124) in 23 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:05:44 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
20/02/14 12:05:44 INFO DAGScheduler: ResultStage 91 (collect at arrowconverters.scala:270) finished in 0.030 s
20/02/14 12:05:44 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:05:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished
20/02/14 12:05:44 INFO DAGScheduler: Job 45 finished: collect at arrowconverters.scala:270, took 0.065205 s
20/02/14 12:05:49 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:55441 in memory (size: 17.1 KiB, free: 413.9 MiB)
20/02/14 12:05:49 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:05:50 INFO CodeGenerator: Code generated in 5.9815 ms
20/02/14 12:05:50 INFO CodeGenerator: Code generated in 8.3096 ms
20/02/14 12:05:50 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:05:50 INFO DAGScheduler: Registering RDD 471 (collect at arrowconverters.scala:270) as input to shuffle 46
20/02/14 12:05:50 INFO DAGScheduler: Got job 46 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:05:50 INFO DAGScheduler: Final stage: ResultStage 93 (collect at arrowconverters.scala:270)
20/02/14 12:05:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 92)
20/02/14 12:05:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 92)
20/02/14 12:05:50 INFO DAGScheduler: Submitting ShuffleMapStage 92 (MapPartitionsRDD[471] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:05:50 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:05:50 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:05:50 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:05:50 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1196
20/02/14 12:05:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 92 (MapPartitionsRDD[471] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:05:50 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks
20/02/14 12:05:50 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 125, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:05:50 INFO Executor: Running task 0.0 in stage 92.0 (TID 125)
20/02/14 12:05:50 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:05:50 INFO Executor: Finished task 0.0 in stage 92.0 (TID 125). 2200 bytes result sent to driver
20/02/14 12:05:50 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 125) in 19 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:05:50 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
20/02/14 12:05:50 INFO DAGScheduler: ShuffleMapStage 92 (collect at arrowconverters.scala:270) finished in 0.026 s
20/02/14 12:05:50 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:05:50 INFO DAGScheduler: running: Set()
20/02/14 12:05:50 INFO DAGScheduler: waiting: Set(ResultStage 93)
20/02/14 12:05:50 INFO DAGScheduler: failed: Set()
20/02/14 12:05:50 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[477] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:05:50 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:05:50 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 413.7 MiB)
20/02/14 12:05:50 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:55441 (size: 17.1 KiB, free: 413.9 MiB)
20/02/14 12:05:50 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1196
20/02/14 12:05:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[477] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:05:50 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks
20/02/14 12:05:50 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 126, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:05:50 INFO Executor: Running task 0.0 in stage 93.0 (TID 126)
20/02/14 12:05:50 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:05:50 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:05:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:05:50 INFO Executor: Finished task 0.0 in stage 93.0 (TID 126). 3660 bytes result sent to driver
20/02/14 12:05:50 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 126) in 25 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:05:50 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
20/02/14 12:05:50 INFO DAGScheduler: ResultStage 93 (collect at arrowconverters.scala:270) finished in 0.033 s
20/02/14 12:05:50 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:05:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 93: Stage finished
20/02/14 12:05:50 INFO DAGScheduler: Job 46 finished: collect at arrowconverters.scala:270, took 0.064928 s
20/02/14 12:05:54 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 127.0.0.1:55441 in memory (size: 17.1 KiB, free: 413.9 MiB)
20/02/14 12:05:54 INFO CodeGenerator: Code generated in 6.411501 ms
20/02/14 12:05:54 INFO CodeGenerator: Code generated in 9.3404 ms
20/02/14 12:05:54 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:05:54 INFO DAGScheduler: Registering RDD 482 (collect at arrowconverters.scala:270) as input to shuffle 47
20/02/14 12:05:54 INFO DAGScheduler: Got job 47 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:05:54 INFO DAGScheduler: Final stage: ResultStage 95 (collect at arrowconverters.scala:270)
20/02/14 12:05:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 94)
20/02/14 12:05:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 94)
20/02/14 12:05:54 INFO DAGScheduler: Submitting ShuffleMapStage 94 (MapPartitionsRDD[482] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:05:54 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:05:54 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:05:54 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:05:54 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1196
20/02/14 12:05:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 94 (MapPartitionsRDD[482] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:05:54 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks
20/02/14 12:05:54 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 127, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:05:54 INFO Executor: Running task 0.0 in stage 94.0 (TID 127)
20/02/14 12:05:54 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:05:54 INFO Executor: Finished task 0.0 in stage 94.0 (TID 127). 2157 bytes result sent to driver
20/02/14 12:05:54 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 127) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:05:54 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
20/02/14 12:05:54 INFO DAGScheduler: ShuffleMapStage 94 (collect at arrowconverters.scala:270) finished in 0.027 s
20/02/14 12:05:54 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:05:54 INFO DAGScheduler: running: Set()
20/02/14 12:05:54 INFO DAGScheduler: waiting: Set(ResultStage 95)
20/02/14 12:05:54 INFO DAGScheduler: failed: Set()
20/02/14 12:05:54 INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[488] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:05:54 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:05:54 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 413.7 MiB)
20/02/14 12:05:54 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:55441 (size: 17.1 KiB, free: 413.9 MiB)
20/02/14 12:05:54 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1196
20/02/14 12:05:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[488] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:05:54 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks
20/02/14 12:05:54 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 128, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:05:54 INFO Executor: Running task 0.0 in stage 95.0 (TID 128)
20/02/14 12:05:54 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:05:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:05:54 INFO Executor: Finished task 0.0 in stage 95.0 (TID 128). 3660 bytes result sent to driver
20/02/14 12:05:54 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 128) in 18 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:05:54 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
20/02/14 12:05:54 INFO DAGScheduler: ResultStage 95 (collect at arrowconverters.scala:270) finished in 0.023 s
20/02/14 12:05:54 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:05:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 95: Stage finished
20/02/14 12:05:54 INFO DAGScheduler: Job 47 finished: collect at arrowconverters.scala:270, took 0.056969 s
20/02/14 12:05:58 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:55441 in memory (size: 17.1 KiB, free: 413.9 MiB)
20/02/14 12:05:58 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:05:58 INFO CodeGenerator: Code generated in 8.8248 ms
20/02/14 12:05:58 INFO CodeGenerator: Code generated in 11.966399 ms
20/02/14 12:05:58 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:05:58 INFO DAGScheduler: Registering RDD 493 (collect at arrowconverters.scala:270) as input to shuffle 48
20/02/14 12:05:58 INFO DAGScheduler: Got job 48 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:05:58 INFO DAGScheduler: Final stage: ResultStage 97 (collect at arrowconverters.scala:270)
20/02/14 12:05:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 96)
20/02/14 12:05:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 96)
20/02/14 12:05:58 INFO DAGScheduler: Submitting ShuffleMapStage 96 (MapPartitionsRDD[493] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:05:58 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:05:58 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:05:58 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:05:58 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1196
20/02/14 12:05:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 96 (MapPartitionsRDD[493] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:05:58 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks
20/02/14 12:05:58 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 129, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:05:58 INFO Executor: Running task 0.0 in stage 96.0 (TID 129)
20/02/14 12:05:58 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:05:58 INFO Executor: Finished task 0.0 in stage 96.0 (TID 129). 2200 bytes result sent to driver
20/02/14 12:05:58 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 129) in 19 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:05:58 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
20/02/14 12:05:58 INFO DAGScheduler: ShuffleMapStage 96 (collect at arrowconverters.scala:270) finished in 0.026 s
20/02/14 12:05:58 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:05:58 INFO DAGScheduler: running: Set()
20/02/14 12:05:58 INFO DAGScheduler: waiting: Set(ResultStage 97)
20/02/14 12:05:58 INFO DAGScheduler: failed: Set()
20/02/14 12:05:58 INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[499] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:05:58 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:05:58 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:05:58 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:05:58 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1196
20/02/14 12:05:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[499] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:05:58 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks
20/02/14 12:05:58 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 130, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:05:58 INFO Executor: Running task 0.0 in stage 97.0 (TID 130)
20/02/14 12:05:58 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:05:58 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:05:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:05:58 INFO Executor: Finished task 0.0 in stage 97.0 (TID 130). 3703 bytes result sent to driver
20/02/14 12:05:58 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 130) in 26 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:05:58 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
20/02/14 12:05:58 INFO DAGScheduler: ResultStage 97 (collect at arrowconverters.scala:270) finished in 0.032 s
20/02/14 12:05:58 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:05:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 97: Stage finished
20/02/14 12:05:58 INFO DAGScheduler: Job 48 finished: collect at arrowconverters.scala:270, took 0.064836 s
20/02/14 12:06:05 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:06:05 INFO CodeGenerator: Code generated in 5.941001 ms
20/02/14 12:06:05 INFO CodeGenerator: Code generated in 8.0996 ms
20/02/14 12:06:05 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:06:05 INFO DAGScheduler: Registering RDD 504 (collect at arrowconverters.scala:270) as input to shuffle 49
20/02/14 12:06:05 INFO DAGScheduler: Got job 49 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:06:05 INFO DAGScheduler: Final stage: ResultStage 99 (collect at arrowconverters.scala:270)
20/02/14 12:06:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 98)
20/02/14 12:06:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 98)
20/02/14 12:06:05 INFO DAGScheduler: Submitting ShuffleMapStage 98 (MapPartitionsRDD[504] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:06:05 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:06:05 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:06:05 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:06:05 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1196
20/02/14 12:06:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 98 (MapPartitionsRDD[504] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:06:05 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks
20/02/14 12:06:05 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 131, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:06:05 INFO Executor: Running task 0.0 in stage 98.0 (TID 131)
20/02/14 12:06:05 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:06:05 INFO Executor: Finished task 0.0 in stage 98.0 (TID 131). 2200 bytes result sent to driver
20/02/14 12:06:05 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 131) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:06:05 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
20/02/14 12:06:05 INFO DAGScheduler: ShuffleMapStage 98 (collect at arrowconverters.scala:270) finished in 0.027 s
20/02/14 12:06:05 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:06:05 INFO DAGScheduler: running: Set()
20/02/14 12:06:05 INFO DAGScheduler: waiting: Set(ResultStage 99)
20/02/14 12:06:05 INFO DAGScheduler: failed: Set()
20/02/14 12:06:05 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[510] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:06:05 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:06:05 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:06:05 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:06:05 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1196
20/02/14 12:06:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[510] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:06:05 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks
20/02/14 12:06:05 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 132, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:06:05 INFO Executor: Running task 0.0 in stage 99.0 (TID 132)
20/02/14 12:06:05 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:06:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:06:05 INFO Executor: Finished task 0.0 in stage 99.0 (TID 132). 3660 bytes result sent to driver
20/02/14 12:06:05 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 132) in 19 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:06:05 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
20/02/14 12:06:05 INFO DAGScheduler: ResultStage 99 (collect at arrowconverters.scala:270) finished in 0.027 s
20/02/14 12:06:05 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:06:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 99: Stage finished
20/02/14 12:06:05 INFO DAGScheduler: Job 49 finished: collect at arrowconverters.scala:270, took 0.060073 s
20/02/14 12:06:08 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:06:08 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:06:08 INFO CodeGenerator: Code generated in 8.4133 ms
20/02/14 12:06:08 INFO CodeGenerator: Code generated in 16.1255 ms
20/02/14 12:06:08 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:06:08 INFO DAGScheduler: Registering RDD 515 (collect at arrowconverters.scala:270) as input to shuffle 50
20/02/14 12:06:08 INFO DAGScheduler: Got job 50 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:06:08 INFO DAGScheduler: Final stage: ResultStage 101 (collect at arrowconverters.scala:270)
20/02/14 12:06:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 100)
20/02/14 12:06:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 100)
20/02/14 12:06:08 INFO DAGScheduler: Submitting ShuffleMapStage 100 (MapPartitionsRDD[515] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:06:08 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:06:08 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:06:08 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:06:08 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1196
20/02/14 12:06:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[515] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:06:08 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks
20/02/14 12:06:08 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 133, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:06:08 INFO Executor: Running task 0.0 in stage 100.0 (TID 133)
20/02/14 12:06:08 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:06:08 INFO Executor: Finished task 0.0 in stage 100.0 (TID 133). 2200 bytes result sent to driver
20/02/14 12:06:08 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 133) in 19 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:06:08 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
20/02/14 12:06:08 INFO DAGScheduler: ShuffleMapStage 100 (collect at arrowconverters.scala:270) finished in 0.029 s
20/02/14 12:06:08 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:06:08 INFO DAGScheduler: running: Set()
20/02/14 12:06:08 INFO DAGScheduler: waiting: Set(ResultStage 101)
20/02/14 12:06:08 INFO DAGScheduler: failed: Set()
20/02/14 12:06:08 INFO DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[521] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:06:08 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:06:08 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:06:08 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:06:08 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1196
20/02/14 12:06:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[521] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:06:08 INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks
20/02/14 12:06:08 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 134, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:06:08 INFO Executor: Running task 0.0 in stage 101.0 (TID 134)
20/02/14 12:06:08 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:06:08 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:06:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:06:08 INFO Executor: Finished task 0.0 in stage 101.0 (TID 134). 3703 bytes result sent to driver
20/02/14 12:06:08 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 134) in 27 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:06:08 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
20/02/14 12:06:08 INFO DAGScheduler: ResultStage 101 (collect at arrowconverters.scala:270) finished in 0.034 s
20/02/14 12:06:08 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:06:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 101: Stage finished
20/02/14 12:06:08 INFO DAGScheduler: Job 50 finished: collect at arrowconverters.scala:270, took 0.067684 s
20/02/14 12:06:13 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:06:13 INFO CodeGenerator: Code generated in 7.6641 ms
20/02/14 12:06:13 INFO CodeGenerator: Code generated in 12.407299 ms
20/02/14 12:06:13 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:06:13 INFO DAGScheduler: Registering RDD 526 (collect at arrowconverters.scala:270) as input to shuffle 51
20/02/14 12:06:13 INFO DAGScheduler: Got job 51 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:06:13 INFO DAGScheduler: Final stage: ResultStage 103 (collect at arrowconverters.scala:270)
20/02/14 12:06:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 102)
20/02/14 12:06:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 102)
20/02/14 12:06:13 INFO DAGScheduler: Submitting ShuffleMapStage 102 (MapPartitionsRDD[526] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:06:13 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:06:13 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:06:13 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:06:13 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1196
20/02/14 12:06:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 102 (MapPartitionsRDD[526] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:06:13 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks
20/02/14 12:06:13 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 135, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:06:13 INFO Executor: Running task 0.0 in stage 102.0 (TID 135)
20/02/14 12:06:13 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:06:13 INFO Executor: Finished task 0.0 in stage 102.0 (TID 135). 2200 bytes result sent to driver
20/02/14 12:06:13 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 135) in 20 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:06:13 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
20/02/14 12:06:13 INFO DAGScheduler: ShuffleMapStage 102 (collect at arrowconverters.scala:270) finished in 0.038 s
20/02/14 12:06:13 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:06:13 INFO DAGScheduler: running: Set()
20/02/14 12:06:13 INFO DAGScheduler: waiting: Set(ResultStage 103)
20/02/14 12:06:13 INFO DAGScheduler: failed: Set()
20/02/14 12:06:13 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[532] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:06:13 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:06:13 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:06:13 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:06:13 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1196
20/02/14 12:06:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[532] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:06:13 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks
20/02/14 12:06:13 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 136, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:06:13 INFO Executor: Running task 0.0 in stage 103.0 (TID 136)
20/02/14 12:06:13 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:06:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:06:13 INFO Executor: Finished task 0.0 in stage 103.0 (TID 136). 3703 bytes result sent to driver
20/02/14 12:06:13 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 136) in 26 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:06:13 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
20/02/14 12:06:13 INFO DAGScheduler: ResultStage 103 (collect at arrowconverters.scala:270) finished in 0.034 s
20/02/14 12:06:13 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:06:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished
20/02/14 12:06:13 INFO DAGScheduler: Job 51 finished: collect at arrowconverters.scala:270, took 0.080515 s
20/02/14 12:06:20 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:06:20 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:06:20 INFO CodeGenerator: Code generated in 6.233999 ms
20/02/14 12:06:20 INFO CodeGenerator: Code generated in 14.171299 ms
20/02/14 12:06:20 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:06:20 INFO DAGScheduler: Registering RDD 537 (collect at arrowconverters.scala:270) as input to shuffle 52
20/02/14 12:06:20 INFO DAGScheduler: Got job 52 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:06:20 INFO DAGScheduler: Final stage: ResultStage 105 (collect at arrowconverters.scala:270)
20/02/14 12:06:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 104)
20/02/14 12:06:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 104)
20/02/14 12:06:20 INFO DAGScheduler: Submitting ShuffleMapStage 104 (MapPartitionsRDD[537] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:06:20 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:06:20 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:06:20 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:06:20 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1196
20/02/14 12:06:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 104 (MapPartitionsRDD[537] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:06:20 INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks
20/02/14 12:06:20 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 137, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:06:20 INFO Executor: Running task 0.0 in stage 104.0 (TID 137)
20/02/14 12:06:20 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:06:20 INFO Executor: Finished task 0.0 in stage 104.0 (TID 137). 2200 bytes result sent to driver
20/02/14 12:06:20 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 137) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:06:20 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
20/02/14 12:06:20 INFO DAGScheduler: ShuffleMapStage 104 (collect at arrowconverters.scala:270) finished in 0.023 s
20/02/14 12:06:20 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:06:20 INFO DAGScheduler: running: Set()
20/02/14 12:06:20 INFO DAGScheduler: waiting: Set(ResultStage 105)
20/02/14 12:06:20 INFO DAGScheduler: failed: Set()
20/02/14 12:06:20 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[543] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:06:20 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:06:20 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:06:20 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:06:20 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1196
20/02/14 12:06:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[543] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:06:20 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks
20/02/14 12:06:20 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 138, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:06:20 INFO Executor: Running task 0.0 in stage 105.0 (TID 138)
20/02/14 12:06:20 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:06:20 INFO Executor: Finished task 0.0 in stage 105.0 (TID 138). 3746 bytes result sent to driver
20/02/14 12:06:20 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 138) in 29 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:06:20 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
20/02/14 12:06:20 INFO DAGScheduler: ResultStage 105 (collect at arrowconverters.scala:270) finished in 0.035 s
20/02/14 12:06:20 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:06:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished
20/02/14 12:06:20 INFO DAGScheduler: Job 52 finished: collect at arrowconverters.scala:270, took 0.065191 s
20/02/14 12:06:24 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:06:25 INFO CodeGenerator: Code generated in 9.351901 ms
20/02/14 12:06:25 INFO CodeGenerator: Code generated in 10.7924 ms
20/02/14 12:06:25 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:06:25 INFO DAGScheduler: Registering RDD 548 (collect at arrowconverters.scala:270) as input to shuffle 53
20/02/14 12:06:25 INFO DAGScheduler: Got job 53 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:06:25 INFO DAGScheduler: Final stage: ResultStage 107 (collect at arrowconverters.scala:270)
20/02/14 12:06:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 106)
20/02/14 12:06:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 106)
20/02/14 12:06:25 INFO DAGScheduler: Submitting ShuffleMapStage 106 (MapPartitionsRDD[548] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:06:25 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:06:25 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:06:25 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:06:25 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1196
20/02/14 12:06:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 106 (MapPartitionsRDD[548] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:06:25 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks
20/02/14 12:06:25 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 139, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:06:25 INFO Executor: Running task 0.0 in stage 106.0 (TID 139)
20/02/14 12:06:25 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:06:25 INFO Executor: Finished task 0.0 in stage 106.0 (TID 139). 2200 bytes result sent to driver
20/02/14 12:06:25 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 139) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:06:25 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
20/02/14 12:06:25 INFO DAGScheduler: ShuffleMapStage 106 (collect at arrowconverters.scala:270) finished in 0.029 s
20/02/14 12:06:25 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:06:25 INFO DAGScheduler: running: Set()
20/02/14 12:06:25 INFO DAGScheduler: waiting: Set(ResultStage 107)
20/02/14 12:06:25 INFO DAGScheduler: failed: Set()
20/02/14 12:06:25 INFO DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[554] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:06:25 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:06:25 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:06:25 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:06:25 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1196
20/02/14 12:06:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[554] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:06:25 INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks
20/02/14 12:06:25 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 140, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:06:25 INFO Executor: Running task 0.0 in stage 107.0 (TID 140)
20/02/14 12:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:06:25 INFO Executor: Finished task 0.0 in stage 107.0 (TID 140). 3660 bytes result sent to driver
20/02/14 12:06:25 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 140) in 19 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:06:25 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
20/02/14 12:06:25 INFO DAGScheduler: ResultStage 107 (collect at arrowconverters.scala:270) finished in 0.025 s
20/02/14 12:06:25 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:06:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 107: Stage finished
20/02/14 12:06:25 INFO DAGScheduler: Job 53 finished: collect at arrowconverters.scala:270, took 0.060347 s
20/02/14 12:06:33 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:06:33 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:06:33 INFO CodeGenerator: Code generated in 5.8897 ms
20/02/14 12:06:33 INFO CodeGenerator: Code generated in 12.745701 ms
20/02/14 12:06:33 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:06:33 INFO DAGScheduler: Registering RDD 559 (collect at arrowconverters.scala:270) as input to shuffle 54
20/02/14 12:06:33 INFO DAGScheduler: Got job 54 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:06:33 INFO DAGScheduler: Final stage: ResultStage 109 (collect at arrowconverters.scala:270)
20/02/14 12:06:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 108)
20/02/14 12:06:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 108)
20/02/14 12:06:33 INFO DAGScheduler: Submitting ShuffleMapStage 108 (MapPartitionsRDD[559] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:06:33 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:06:33 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:06:33 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:06:33 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1196
20/02/14 12:06:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 108 (MapPartitionsRDD[559] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:06:33 INFO TaskSchedulerImpl: Adding task set 108.0 with 1 tasks
20/02/14 12:06:33 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 141, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:06:33 INFO Executor: Running task 0.0 in stage 108.0 (TID 141)
20/02/14 12:06:33 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:06:33 INFO Executor: Finished task 0.0 in stage 108.0 (TID 141). 2157 bytes result sent to driver
20/02/14 12:06:33 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 141) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:06:33 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
20/02/14 12:06:33 INFO DAGScheduler: ShuffleMapStage 108 (collect at arrowconverters.scala:270) finished in 0.022 s
20/02/14 12:06:33 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:06:33 INFO DAGScheduler: running: Set()
20/02/14 12:06:33 INFO DAGScheduler: waiting: Set(ResultStage 109)
20/02/14 12:06:33 INFO DAGScheduler: failed: Set()
20/02/14 12:06:33 INFO DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[565] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:06:33 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:06:33 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:06:33 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:06:33 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1196
20/02/14 12:06:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[565] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:06:33 INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks
20/02/14 12:06:33 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 142, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:06:33 INFO Executor: Running task 0.0 in stage 109.0 (TID 142)
20/02/14 12:06:33 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:06:33 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:06:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:06:33 INFO Executor: Finished task 0.0 in stage 109.0 (TID 142). 3746 bytes result sent to driver
20/02/14 12:06:33 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 142) in 25 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:06:33 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
20/02/14 12:06:33 INFO DAGScheduler: ResultStage 109 (collect at arrowconverters.scala:270) finished in 0.030 s
20/02/14 12:06:33 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:06:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 109: Stage finished
20/02/14 12:06:33 INFO DAGScheduler: Job 54 finished: collect at arrowconverters.scala:270, took 0.057659 s
20/02/14 12:06:37 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:06:37 INFO CodeGenerator: Code generated in 6.5865 ms
20/02/14 12:06:37 INFO CodeGenerator: Code generated in 8.5757 ms
20/02/14 12:06:37 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:06:37 INFO DAGScheduler: Registering RDD 570 (collect at arrowconverters.scala:270) as input to shuffle 55
20/02/14 12:06:37 INFO DAGScheduler: Got job 55 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:06:37 INFO DAGScheduler: Final stage: ResultStage 111 (collect at arrowconverters.scala:270)
20/02/14 12:06:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 110)
20/02/14 12:06:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 110)
20/02/14 12:06:37 INFO DAGScheduler: Submitting ShuffleMapStage 110 (MapPartitionsRDD[570] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:06:37 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:06:37 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:06:37 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:06:37 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1196
20/02/14 12:06:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 110 (MapPartitionsRDD[570] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:06:37 INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks
20/02/14 12:06:37 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 143, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:06:37 INFO Executor: Running task 0.0 in stage 110.0 (TID 143)
20/02/14 12:06:37 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:06:37 INFO Executor: Finished task 0.0 in stage 110.0 (TID 143). 2200 bytes result sent to driver
20/02/14 12:06:37 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 143) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:06:37 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
20/02/14 12:06:37 INFO DAGScheduler: ShuffleMapStage 110 (collect at arrowconverters.scala:270) finished in 0.027 s
20/02/14 12:06:37 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:06:37 INFO DAGScheduler: running: Set()
20/02/14 12:06:37 INFO DAGScheduler: waiting: Set(ResultStage 111)
20/02/14 12:06:37 INFO DAGScheduler: failed: Set()
20/02/14 12:06:37 INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[576] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:06:37 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:06:37 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:06:37 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:06:37 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1196
20/02/14 12:06:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[576] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:06:37 INFO TaskSchedulerImpl: Adding task set 111.0 with 1 tasks
20/02/14 12:06:37 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 144, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:06:37 INFO Executor: Running task 0.0 in stage 111.0 (TID 144)
20/02/14 12:06:37 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:06:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:06:37 INFO Executor: Finished task 0.0 in stage 111.0 (TID 144). 3660 bytes result sent to driver
20/02/14 12:06:37 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 144) in 23 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:06:37 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
20/02/14 12:06:37 INFO DAGScheduler: ResultStage 111 (collect at arrowconverters.scala:270) finished in 0.029 s
20/02/14 12:06:37 INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:06:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 111: Stage finished
20/02/14 12:06:37 INFO DAGScheduler: Job 55 finished: collect at arrowconverters.scala:270, took 0.061965 s
20/02/14 12:07:09 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:07:09 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:07:09 INFO CodeGenerator: Code generated in 5.4202 ms
20/02/14 12:07:09 INFO CodeGenerator: Code generated in 11.9416 ms
20/02/14 12:07:09 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:07:09 INFO DAGScheduler: Registering RDD 581 (collect at arrowconverters.scala:270) as input to shuffle 56
20/02/14 12:07:09 INFO DAGScheduler: Got job 56 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:07:09 INFO DAGScheduler: Final stage: ResultStage 113 (collect at arrowconverters.scala:270)
20/02/14 12:07:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 112)
20/02/14 12:07:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 112)
20/02/14 12:07:09 INFO DAGScheduler: Submitting ShuffleMapStage 112 (MapPartitionsRDD[581] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:07:09 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:07:09 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:07:09 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:07:09 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1196
20/02/14 12:07:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 112 (MapPartitionsRDD[581] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:07:09 INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks
20/02/14 12:07:09 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 145, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:07:09 INFO Executor: Running task 0.0 in stage 112.0 (TID 145)
20/02/14 12:07:09 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:07:09 INFO Executor: Finished task 0.0 in stage 112.0 (TID 145). 2200 bytes result sent to driver
20/02/14 12:07:09 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 145) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:07:09 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
20/02/14 12:07:09 INFO DAGScheduler: ShuffleMapStage 112 (collect at arrowconverters.scala:270) finished in 0.021 s
20/02/14 12:07:09 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:07:09 INFO DAGScheduler: running: Set()
20/02/14 12:07:09 INFO DAGScheduler: waiting: Set(ResultStage 113)
20/02/14 12:07:09 INFO DAGScheduler: failed: Set()
20/02/14 12:07:09 INFO DAGScheduler: Submitting ResultStage 113 (MapPartitionsRDD[587] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:07:09 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:07:09 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:07:09 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:07:09 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1196
20/02/14 12:07:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 113 (MapPartitionsRDD[587] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:07:09 INFO TaskSchedulerImpl: Adding task set 113.0 with 1 tasks
20/02/14 12:07:09 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 146, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:07:09 INFO Executor: Running task 0.0 in stage 113.0 (TID 146)
20/02/14 12:07:09 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:07:09 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:07:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 12:07:09 INFO Executor: Finished task 0.0 in stage 113.0 (TID 146). 3703 bytes result sent to driver
20/02/14 12:07:09 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 146) in 39 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:07:09 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
20/02/14 12:07:09 INFO DAGScheduler: ResultStage 113 (collect at arrowconverters.scala:270) finished in 0.045 s
20/02/14 12:07:09 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:07:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 113: Stage finished
20/02/14 12:07:09 INFO DAGScheduler: Job 56 finished: collect at arrowconverters.scala:270, took 0.071616 s
20/02/14 12:08:01 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:08:01 INFO CodeGenerator: Code generated in 6.5693 ms
20/02/14 12:08:01 INFO CodeGenerator: Code generated in 8.6073 ms
20/02/14 12:08:01 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:08:01 INFO DAGScheduler: Registering RDD 592 (collect at arrowconverters.scala:270) as input to shuffle 57
20/02/14 12:08:01 INFO DAGScheduler: Got job 57 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:08:01 INFO DAGScheduler: Final stage: ResultStage 115 (collect at arrowconverters.scala:270)
20/02/14 12:08:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 114)
20/02/14 12:08:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 114)
20/02/14 12:08:01 INFO DAGScheduler: Submitting ShuffleMapStage 114 (MapPartitionsRDD[592] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:08:01 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:08:01 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:08:01 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:08:01 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1196
20/02/14 12:08:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 114 (MapPartitionsRDD[592] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:08:01 INFO TaskSchedulerImpl: Adding task set 114.0 with 1 tasks
20/02/14 12:08:01 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 147, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:08:01 INFO Executor: Running task 0.0 in stage 114.0 (TID 147)
20/02/14 12:08:01 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:08:01 INFO Executor: Finished task 0.0 in stage 114.0 (TID 147). 2157 bytes result sent to driver
20/02/14 12:08:01 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 147) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:08:01 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
20/02/14 12:08:01 INFO DAGScheduler: ShuffleMapStage 114 (collect at arrowconverters.scala:270) finished in 0.027 s
20/02/14 12:08:01 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:08:01 INFO DAGScheduler: running: Set()
20/02/14 12:08:01 INFO DAGScheduler: waiting: Set(ResultStage 115)
20/02/14 12:08:01 INFO DAGScheduler: failed: Set()
20/02/14 12:08:01 INFO DAGScheduler: Submitting ResultStage 115 (MapPartitionsRDD[598] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:08:01 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:08:01 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:08:01 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:08:01 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1196
20/02/14 12:08:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[598] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:08:01 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks
20/02/14 12:08:01 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 148, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:08:01 INFO Executor: Running task 0.0 in stage 115.0 (TID 148)
20/02/14 12:08:01 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:08:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:08:01 INFO Executor: Finished task 0.0 in stage 115.0 (TID 148). 3660 bytes result sent to driver
20/02/14 12:08:01 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 148) in 24 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:08:01 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
20/02/14 12:08:01 INFO DAGScheduler: ResultStage 115 (collect at arrowconverters.scala:270) finished in 0.030 s
20/02/14 12:08:01 INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:08:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 115: Stage finished
20/02/14 12:08:01 INFO DAGScheduler: Job 57 finished: collect at arrowconverters.scala:270, took 0.062608 s
20/02/14 12:08:10 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:08:10 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:08:10 INFO CodeGenerator: Code generated in 6.2845 ms
20/02/14 12:08:10 INFO CodeGenerator: Code generated in 12.2768 ms
20/02/14 12:08:10 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:08:10 INFO DAGScheduler: Registering RDD 603 (collect at arrowconverters.scala:270) as input to shuffle 58
20/02/14 12:08:10 INFO DAGScheduler: Got job 58 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:08:10 INFO DAGScheduler: Final stage: ResultStage 117 (collect at arrowconverters.scala:270)
20/02/14 12:08:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 116)
20/02/14 12:08:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 116)
20/02/14 12:08:10 INFO DAGScheduler: Submitting ShuffleMapStage 116 (MapPartitionsRDD[603] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:08:10 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:08:10 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:08:10 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:08:10 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1196
20/02/14 12:08:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 116 (MapPartitionsRDD[603] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:08:10 INFO TaskSchedulerImpl: Adding task set 116.0 with 1 tasks
20/02/14 12:08:10 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 149, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:08:10 INFO Executor: Running task 0.0 in stage 116.0 (TID 149)
20/02/14 12:08:10 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:08:10 INFO Executor: Finished task 0.0 in stage 116.0 (TID 149). 2200 bytes result sent to driver
20/02/14 12:08:10 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 149) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:08:10 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
20/02/14 12:08:10 INFO DAGScheduler: ShuffleMapStage 116 (collect at arrowconverters.scala:270) finished in 0.022 s
20/02/14 12:08:10 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:08:10 INFO DAGScheduler: running: Set()
20/02/14 12:08:10 INFO DAGScheduler: waiting: Set(ResultStage 117)
20/02/14 12:08:10 INFO DAGScheduler: failed: Set()
20/02/14 12:08:10 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[609] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:08:10 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:08:10 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:08:10 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:08:10 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1196
20/02/14 12:08:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[609] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:08:10 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks
20/02/14 12:08:10 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 150, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:08:10 INFO Executor: Running task 0.0 in stage 117.0 (TID 150)
20/02/14 12:08:10 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:08:10 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:08:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:08:10 INFO Executor: Finished task 0.0 in stage 117.0 (TID 150). 3746 bytes result sent to driver
20/02/14 12:08:10 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 150) in 28 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:08:10 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
20/02/14 12:08:10 INFO DAGScheduler: ResultStage 117 (collect at arrowconverters.scala:270) finished in 0.035 s
20/02/14 12:08:10 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:08:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 117: Stage finished
20/02/14 12:08:10 INFO DAGScheduler: Job 58 finished: collect at arrowconverters.scala:270, took 0.063752 s
20/02/14 12:09:27 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:09:27 INFO CodeGenerator: Code generated in 7.902101 ms
20/02/14 12:09:27 INFO CodeGenerator: Code generated in 7.6649 ms
20/02/14 12:09:28 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:09:28 INFO DAGScheduler: Registering RDD 614 (collect at arrowconverters.scala:270) as input to shuffle 59
20/02/14 12:09:28 INFO DAGScheduler: Got job 59 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:09:28 INFO DAGScheduler: Final stage: ResultStage 119 (collect at arrowconverters.scala:270)
20/02/14 12:09:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 118)
20/02/14 12:09:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 118)
20/02/14 12:09:28 INFO DAGScheduler: Submitting ShuffleMapStage 118 (MapPartitionsRDD[614] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:09:28 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:09:28 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:09:28 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:09:28 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1196
20/02/14 12:09:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 118 (MapPartitionsRDD[614] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:09:28 INFO TaskSchedulerImpl: Adding task set 118.0 with 1 tasks
20/02/14 12:09:28 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 151, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:09:28 INFO Executor: Running task 0.0 in stage 118.0 (TID 151)
20/02/14 12:09:28 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:09:28 INFO Executor: Finished task 0.0 in stage 118.0 (TID 151). 2200 bytes result sent to driver
20/02/14 12:09:28 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 151) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:09:28 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
20/02/14 12:09:28 INFO DAGScheduler: ShuffleMapStage 118 (collect at arrowconverters.scala:270) finished in 0.028 s
20/02/14 12:09:28 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:09:28 INFO DAGScheduler: running: Set()
20/02/14 12:09:28 INFO DAGScheduler: waiting: Set(ResultStage 119)
20/02/14 12:09:28 INFO DAGScheduler: failed: Set()
20/02/14 12:09:28 INFO DAGScheduler: Submitting ResultStage 119 (MapPartitionsRDD[620] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:09:28 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:09:28 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:09:28 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:09:28 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1196
20/02/14 12:09:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 119 (MapPartitionsRDD[620] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:09:28 INFO TaskSchedulerImpl: Adding task set 119.0 with 1 tasks
20/02/14 12:09:28 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 152, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:09:28 INFO Executor: Running task 0.0 in stage 119.0 (TID 152)
20/02/14 12:09:28 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:09:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:09:28 INFO Executor: Finished task 0.0 in stage 119.0 (TID 152). 3660 bytes result sent to driver
20/02/14 12:09:28 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 152) in 22 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:09:28 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
20/02/14 12:09:28 INFO DAGScheduler: ResultStage 119 (collect at arrowconverters.scala:270) finished in 0.029 s
20/02/14 12:09:28 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:09:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 119: Stage finished
20/02/14 12:09:28 INFO DAGScheduler: Job 59 finished: collect at arrowconverters.scala:270, took 0.062537 s
20/02/14 12:09:34 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:09:34 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:09:34 INFO CodeGenerator: Code generated in 5.9765 ms
20/02/14 12:09:34 INFO CodeGenerator: Code generated in 12.492499 ms
20/02/14 12:09:34 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:09:34 INFO DAGScheduler: Registering RDD 625 (collect at arrowconverters.scala:270) as input to shuffle 60
20/02/14 12:09:34 INFO DAGScheduler: Got job 60 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:09:34 INFO DAGScheduler: Final stage: ResultStage 121 (collect at arrowconverters.scala:270)
20/02/14 12:09:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 120)
20/02/14 12:09:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 120)
20/02/14 12:09:34 INFO DAGScheduler: Submitting ShuffleMapStage 120 (MapPartitionsRDD[625] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:09:34 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:09:34 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:09:34 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:09:34 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1196
20/02/14 12:09:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 120 (MapPartitionsRDD[625] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:09:34 INFO TaskSchedulerImpl: Adding task set 120.0 with 1 tasks
20/02/14 12:09:34 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 153, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:09:34 INFO Executor: Running task 0.0 in stage 120.0 (TID 153)
20/02/14 12:09:34 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:09:34 INFO Executor: Finished task 0.0 in stage 120.0 (TID 153). 2200 bytes result sent to driver
20/02/14 12:09:34 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 153) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:09:34 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
20/02/14 12:09:34 INFO DAGScheduler: ShuffleMapStage 120 (collect at arrowconverters.scala:270) finished in 0.024 s
20/02/14 12:09:34 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:09:34 INFO DAGScheduler: running: Set()
20/02/14 12:09:34 INFO DAGScheduler: waiting: Set(ResultStage 121)
20/02/14 12:09:34 INFO DAGScheduler: failed: Set()
20/02/14 12:09:34 INFO DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[631] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:09:34 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:09:34 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 413.7 MiB)
20/02/14 12:09:34 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 127.0.0.1:55441 (size: 17.1 KiB, free: 413.9 MiB)
20/02/14 12:09:34 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1196
20/02/14 12:09:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[631] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:09:34 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks
20/02/14 12:09:34 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 154, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:09:34 INFO Executor: Running task 0.0 in stage 121.0 (TID 154)
20/02/14 12:09:34 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:09:34 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:09:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:09:34 INFO Executor: Finished task 0.0 in stage 121.0 (TID 154). 3746 bytes result sent to driver
20/02/14 12:09:34 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 154) in 23 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:09:34 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
20/02/14 12:09:34 INFO DAGScheduler: ResultStage 121 (collect at arrowconverters.scala:270) finished in 0.030 s
20/02/14 12:09:34 INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:09:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 121: Stage finished
20/02/14 12:09:34 INFO DAGScheduler: Job 60 finished: collect at arrowconverters.scala:270, took 0.060458 s
20/02/14 12:09:39 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 127.0.0.1:55441 in memory (size: 17.1 KiB, free: 413.9 MiB)
20/02/14 12:09:39 INFO CodeGenerator: Code generated in 8.115099 ms
20/02/14 12:09:39 INFO CodeGenerator: Code generated in 10.4268 ms
20/02/14 12:09:40 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:09:40 INFO DAGScheduler: Registering RDD 636 (collect at arrowconverters.scala:270) as input to shuffle 61
20/02/14 12:09:40 INFO DAGScheduler: Got job 61 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:09:40 INFO DAGScheduler: Final stage: ResultStage 123 (collect at arrowconverters.scala:270)
20/02/14 12:09:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 122)
20/02/14 12:09:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 122)
20/02/14 12:09:40 INFO DAGScheduler: Submitting ShuffleMapStage 122 (MapPartitionsRDD[636] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:09:40 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:09:40 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:09:40 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:09:40 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1196
20/02/14 12:09:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 122 (MapPartitionsRDD[636] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:09:40 INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks
20/02/14 12:09:40 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 155, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:09:40 INFO Executor: Running task 0.0 in stage 122.0 (TID 155)
20/02/14 12:09:40 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:09:40 INFO Executor: Finished task 0.0 in stage 122.0 (TID 155). 2200 bytes result sent to driver
20/02/14 12:09:40 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 155) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:09:40 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
20/02/14 12:09:40 INFO DAGScheduler: ShuffleMapStage 122 (collect at arrowconverters.scala:270) finished in 0.029 s
20/02/14 12:09:40 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:09:40 INFO DAGScheduler: running: Set()
20/02/14 12:09:40 INFO DAGScheduler: waiting: Set(ResultStage 123)
20/02/14 12:09:40 INFO DAGScheduler: failed: Set()
20/02/14 12:09:40 INFO DAGScheduler: Submitting ResultStage 123 (MapPartitionsRDD[642] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:09:40 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:09:40 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:09:40 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:09:40 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1196
20/02/14 12:09:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 123 (MapPartitionsRDD[642] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:09:40 INFO TaskSchedulerImpl: Adding task set 123.0 with 1 tasks
20/02/14 12:09:40 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 156, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:09:40 INFO Executor: Running task 0.0 in stage 123.0 (TID 156)
20/02/14 12:09:40 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:09:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:09:40 INFO Executor: Finished task 0.0 in stage 123.0 (TID 156). 3660 bytes result sent to driver
20/02/14 12:09:40 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 156) in 19 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:09:40 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool 
20/02/14 12:09:40 INFO DAGScheduler: ResultStage 123 (collect at arrowconverters.scala:270) finished in 0.026 s
20/02/14 12:09:40 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:09:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 123: Stage finished
20/02/14 12:09:40 INFO DAGScheduler: Job 61 finished: collect at arrowconverters.scala:270, took 0.061602 s
20/02/14 12:09:48 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:09:48 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:09:49 INFO CodeGenerator: Code generated in 7.4487 ms
20/02/14 12:09:49 INFO CodeGenerator: Code generated in 13.250101 ms
20/02/14 12:09:49 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:09:49 INFO DAGScheduler: Registering RDD 647 (collect at arrowconverters.scala:270) as input to shuffle 62
20/02/14 12:09:49 INFO DAGScheduler: Got job 62 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:09:49 INFO DAGScheduler: Final stage: ResultStage 125 (collect at arrowconverters.scala:270)
20/02/14 12:09:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 124)
20/02/14 12:09:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 124)
20/02/14 12:09:49 INFO DAGScheduler: Submitting ShuffleMapStage 124 (MapPartitionsRDD[647] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:09:49 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:09:49 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:09:49 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:09:49 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1196
20/02/14 12:09:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 124 (MapPartitionsRDD[647] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:09:49 INFO TaskSchedulerImpl: Adding task set 124.0 with 1 tasks
20/02/14 12:09:49 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 157, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:09:49 INFO Executor: Running task 0.0 in stage 124.0 (TID 157)
20/02/14 12:09:49 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:09:49 INFO Executor: Finished task 0.0 in stage 124.0 (TID 157). 2200 bytes result sent to driver
20/02/14 12:09:49 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 157) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:09:49 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool 
20/02/14 12:09:49 INFO DAGScheduler: ShuffleMapStage 124 (collect at arrowconverters.scala:270) finished in 0.023 s
20/02/14 12:09:49 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:09:49 INFO DAGScheduler: running: Set()
20/02/14 12:09:49 INFO DAGScheduler: waiting: Set(ResultStage 125)
20/02/14 12:09:49 INFO DAGScheduler: failed: Set()
20/02/14 12:09:49 INFO DAGScheduler: Submitting ResultStage 125 (MapPartitionsRDD[653] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:09:49 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:09:49 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:09:49 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:09:49 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1196
20/02/14 12:09:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 125 (MapPartitionsRDD[653] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:09:49 INFO TaskSchedulerImpl: Adding task set 125.0 with 1 tasks
20/02/14 12:09:49 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 158, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:09:49 INFO Executor: Running task 0.0 in stage 125.0 (TID 158)
20/02/14 12:09:49 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:09:49 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:09:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:09:49 INFO Executor: Finished task 0.0 in stage 125.0 (TID 158). 3703 bytes result sent to driver
20/02/14 12:09:49 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 158) in 23 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:09:49 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool 
20/02/14 12:09:49 INFO DAGScheduler: ResultStage 125 (collect at arrowconverters.scala:270) finished in 0.031 s
20/02/14 12:09:49 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:09:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 125: Stage finished
20/02/14 12:09:49 INFO DAGScheduler: Job 62 finished: collect at arrowconverters.scala:270, took 0.059739 s
20/02/14 12:09:52 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:09:52 INFO CodeGenerator: Code generated in 10.3958 ms
20/02/14 12:09:52 INFO CodeGenerator: Code generated in 7.8184 ms
20/02/14 12:09:53 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:09:53 INFO DAGScheduler: Registering RDD 658 (collect at arrowconverters.scala:270) as input to shuffle 63
20/02/14 12:09:53 INFO DAGScheduler: Got job 63 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:09:53 INFO DAGScheduler: Final stage: ResultStage 127 (collect at arrowconverters.scala:270)
20/02/14 12:09:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 126)
20/02/14 12:09:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 126)
20/02/14 12:09:53 INFO DAGScheduler: Submitting ShuffleMapStage 126 (MapPartitionsRDD[658] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:09:53 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:09:53 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:09:53 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:09:53 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1196
20/02/14 12:09:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 126 (MapPartitionsRDD[658] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:09:53 INFO TaskSchedulerImpl: Adding task set 126.0 with 1 tasks
20/02/14 12:09:53 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 159, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:09:53 INFO Executor: Running task 0.0 in stage 126.0 (TID 159)
20/02/14 12:09:53 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:09:53 INFO Executor: Finished task 0.0 in stage 126.0 (TID 159). 2157 bytes result sent to driver
20/02/14 12:09:53 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 159) in 18 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:09:53 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
20/02/14 12:09:53 INFO DAGScheduler: ShuffleMapStage 126 (collect at arrowconverters.scala:270) finished in 0.028 s
20/02/14 12:09:53 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:09:53 INFO DAGScheduler: running: Set()
20/02/14 12:09:53 INFO DAGScheduler: waiting: Set(ResultStage 127)
20/02/14 12:09:53 INFO DAGScheduler: failed: Set()
20/02/14 12:09:53 INFO DAGScheduler: Submitting ResultStage 127 (MapPartitionsRDD[664] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:09:53 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:09:53 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 413.7 MiB)
20/02/14 12:09:53 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 127.0.0.1:55441 (size: 17.1 KiB, free: 413.9 MiB)
20/02/14 12:09:53 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1196
20/02/14 12:09:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 127 (MapPartitionsRDD[664] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:09:53 INFO TaskSchedulerImpl: Adding task set 127.0 with 1 tasks
20/02/14 12:09:53 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 160, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:09:53 INFO Executor: Running task 0.0 in stage 127.0 (TID 160)
20/02/14 12:09:53 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:09:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:09:53 INFO Executor: Finished task 0.0 in stage 127.0 (TID 160). 3660 bytes result sent to driver
20/02/14 12:09:53 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 160) in 20 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:09:53 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool 
20/02/14 12:09:53 INFO DAGScheduler: ResultStage 127 (collect at arrowconverters.scala:270) finished in 0.028 s
20/02/14 12:09:53 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:09:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 127: Stage finished
20/02/14 12:09:53 INFO DAGScheduler: Job 63 finished: collect at arrowconverters.scala:270, took 0.062866 s
20/02/14 12:09:59 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:09:59 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 127.0.0.1:55441 in memory (size: 17.1 KiB, free: 413.9 MiB)
20/02/14 12:09:59 INFO CodeGenerator: Code generated in 5.533599 ms
20/02/14 12:09:59 INFO CodeGenerator: Code generated in 6.906299 ms
20/02/14 12:09:59 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:09:59 INFO DAGScheduler: Registering RDD 669 (collect at arrowconverters.scala:270) as input to shuffle 64
20/02/14 12:09:59 INFO DAGScheduler: Got job 64 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:09:59 INFO DAGScheduler: Final stage: ResultStage 129 (collect at arrowconverters.scala:270)
20/02/14 12:09:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 128)
20/02/14 12:09:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 128)
20/02/14 12:09:59 INFO DAGScheduler: Submitting ShuffleMapStage 128 (MapPartitionsRDD[669] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:09:59 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:09:59 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:09:59 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:09:59 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1196
20/02/14 12:09:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 128 (MapPartitionsRDD[669] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:09:59 INFO TaskSchedulerImpl: Adding task set 128.0 with 1 tasks
20/02/14 12:09:59 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 161, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:09:59 INFO Executor: Running task 0.0 in stage 128.0 (TID 161)
20/02/14 12:09:59 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:09:59 INFO Executor: Finished task 0.0 in stage 128.0 (TID 161). 2157 bytes result sent to driver
20/02/14 12:09:59 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 161) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:09:59 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool 
20/02/14 12:09:59 INFO DAGScheduler: ShuffleMapStage 128 (collect at arrowconverters.scala:270) finished in 0.026 s
20/02/14 12:09:59 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:09:59 INFO DAGScheduler: running: Set()
20/02/14 12:09:59 INFO DAGScheduler: waiting: Set(ResultStage 129)
20/02/14 12:09:59 INFO DAGScheduler: failed: Set()
20/02/14 12:09:59 INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[675] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:09:59 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:09:59 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:09:59 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:09:59 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1196
20/02/14 12:09:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[675] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:09:59 INFO TaskSchedulerImpl: Adding task set 129.0 with 1 tasks
20/02/14 12:09:59 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 162, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:09:59 INFO Executor: Running task 0.0 in stage 129.0 (TID 162)
20/02/14 12:09:59 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:09:59 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:09:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:09:59 INFO Executor: Finished task 0.0 in stage 129.0 (TID 162). 3703 bytes result sent to driver
20/02/14 12:09:59 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 162) in 26 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:09:59 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool 
20/02/14 12:09:59 INFO DAGScheduler: ResultStage 129 (collect at arrowconverters.scala:270) finished in 0.032 s
20/02/14 12:09:59 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:09:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 129: Stage finished
20/02/14 12:09:59 INFO DAGScheduler: Job 64 finished: collect at arrowconverters.scala:270, took 0.063151 s
20/02/14 12:10:24 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:10:24 INFO CodeGenerator: Code generated in 9.529401 ms
20/02/14 12:10:24 INFO CodeGenerator: Code generated in 11.8997 ms
20/02/14 12:10:24 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:10:24 INFO DAGScheduler: Registering RDD 680 (collect at arrowconverters.scala:270) as input to shuffle 65
20/02/14 12:10:24 INFO DAGScheduler: Got job 65 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:10:24 INFO DAGScheduler: Final stage: ResultStage 131 (collect at arrowconverters.scala:270)
20/02/14 12:10:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 130)
20/02/14 12:10:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 130)
20/02/14 12:10:24 INFO DAGScheduler: Submitting ShuffleMapStage 130 (MapPartitionsRDD[680] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:10:24 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:10:24 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:10:24 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:10:24 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1196
20/02/14 12:10:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 130 (MapPartitionsRDD[680] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:10:24 INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks
20/02/14 12:10:24 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 163, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:10:24 INFO Executor: Running task 0.0 in stage 130.0 (TID 163)
20/02/14 12:10:24 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:10:24 INFO Executor: Finished task 0.0 in stage 130.0 (TID 163). 2200 bytes result sent to driver
20/02/14 12:10:24 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 163) in 20 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:10:24 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool 
20/02/14 12:10:24 INFO DAGScheduler: ShuffleMapStage 130 (collect at arrowconverters.scala:270) finished in 0.033 s
20/02/14 12:10:24 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:10:24 INFO DAGScheduler: running: Set()
20/02/14 12:10:24 INFO DAGScheduler: waiting: Set(ResultStage 131)
20/02/14 12:10:24 INFO DAGScheduler: failed: Set()
20/02/14 12:10:24 INFO DAGScheduler: Submitting ResultStage 131 (MapPartitionsRDD[686] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:10:24 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:10:24 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:10:24 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:10:24 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1196
20/02/14 12:10:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 131 (MapPartitionsRDD[686] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:10:24 INFO TaskSchedulerImpl: Adding task set 131.0 with 1 tasks
20/02/14 12:10:24 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 164, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:10:24 INFO Executor: Running task 0.0 in stage 131.0 (TID 164)
20/02/14 12:10:24 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:10:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:10:24 INFO Executor: Finished task 0.0 in stage 131.0 (TID 164). 3617 bytes result sent to driver
20/02/14 12:10:24 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 164) in 20 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:10:24 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool 
20/02/14 12:10:24 INFO DAGScheduler: ResultStage 131 (collect at arrowconverters.scala:270) finished in 0.028 s
20/02/14 12:10:24 INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:10:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 131: Stage finished
20/02/14 12:10:24 INFO DAGScheduler: Job 65 finished: collect at arrowconverters.scala:270, took 0.066514 s
20/02/14 12:10:29 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:10:29 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:10:29 INFO CodeGenerator: Code generated in 6.8879 ms
20/02/14 12:10:29 INFO CodeGenerator: Code generated in 12.8664 ms
20/02/14 12:10:29 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:10:29 INFO DAGScheduler: Registering RDD 691 (collect at arrowconverters.scala:270) as input to shuffle 66
20/02/14 12:10:29 INFO DAGScheduler: Got job 66 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:10:29 INFO DAGScheduler: Final stage: ResultStage 133 (collect at arrowconverters.scala:270)
20/02/14 12:10:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 132)
20/02/14 12:10:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 132)
20/02/14 12:10:29 INFO DAGScheduler: Submitting ShuffleMapStage 132 (MapPartitionsRDD[691] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:10:29 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:10:29 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:10:29 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:10:29 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1196
20/02/14 12:10:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 132 (MapPartitionsRDD[691] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:10:29 INFO TaskSchedulerImpl: Adding task set 132.0 with 1 tasks
20/02/14 12:10:29 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 165, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:10:29 INFO Executor: Running task 0.0 in stage 132.0 (TID 165)
20/02/14 12:10:29 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:10:29 INFO Executor: Finished task 0.0 in stage 132.0 (TID 165). 2157 bytes result sent to driver
20/02/14 12:10:29 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 165) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:10:29 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool 
20/02/14 12:10:29 INFO DAGScheduler: ShuffleMapStage 132 (collect at arrowconverters.scala:270) finished in 0.026 s
20/02/14 12:10:29 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:10:29 INFO DAGScheduler: running: Set()
20/02/14 12:10:29 INFO DAGScheduler: waiting: Set(ResultStage 133)
20/02/14 12:10:29 INFO DAGScheduler: failed: Set()
20/02/14 12:10:29 INFO DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[697] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:10:29 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:10:29 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 413.7 MiB)
20/02/14 12:10:29 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 127.0.0.1:55441 (size: 17.1 KiB, free: 413.9 MiB)
20/02/14 12:10:29 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1196
20/02/14 12:10:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[697] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:10:29 INFO TaskSchedulerImpl: Adding task set 133.0 with 1 tasks
20/02/14 12:10:29 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 166, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:10:29 INFO Executor: Running task 0.0 in stage 133.0 (TID 166)
20/02/14 12:10:29 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:10:29 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:10:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:10:29 INFO Executor: Finished task 0.0 in stage 133.0 (TID 166). 3746 bytes result sent to driver
20/02/14 12:10:29 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 166) in 25 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:10:29 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool 
20/02/14 12:10:29 INFO DAGScheduler: ResultStage 133 (collect at arrowconverters.scala:270) finished in 0.033 s
20/02/14 12:10:29 INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:10:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 133: Stage finished
20/02/14 12:10:29 INFO DAGScheduler: Job 66 finished: collect at arrowconverters.scala:270, took 0.064920 s
20/02/14 12:10:31 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 127.0.0.1:55441 in memory (size: 17.1 KiB, free: 413.9 MiB)
20/02/14 12:10:31 INFO CodeGenerator: Code generated in 6.4014 ms
20/02/14 12:10:31 INFO CodeGenerator: Code generated in 8.543499 ms
20/02/14 12:10:31 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:10:31 INFO DAGScheduler: Registering RDD 702 (collect at arrowconverters.scala:270) as input to shuffle 67
20/02/14 12:10:31 INFO DAGScheduler: Got job 67 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:10:31 INFO DAGScheduler: Final stage: ResultStage 135 (collect at arrowconverters.scala:270)
20/02/14 12:10:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 134)
20/02/14 12:10:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 134)
20/02/14 12:10:31 INFO DAGScheduler: Submitting ShuffleMapStage 134 (MapPartitionsRDD[702] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:10:31 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:10:31 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:10:31 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:10:31 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1196
20/02/14 12:10:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 134 (MapPartitionsRDD[702] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:10:31 INFO TaskSchedulerImpl: Adding task set 134.0 with 1 tasks
20/02/14 12:10:31 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 167, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:10:31 INFO Executor: Running task 0.0 in stage 134.0 (TID 167)
20/02/14 12:10:31 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:10:31 INFO Executor: Finished task 0.0 in stage 134.0 (TID 167). 2200 bytes result sent to driver
20/02/14 12:10:31 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 167) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:10:31 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool 
20/02/14 12:10:31 INFO DAGScheduler: ShuffleMapStage 134 (collect at arrowconverters.scala:270) finished in 0.028 s
20/02/14 12:10:31 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:10:31 INFO DAGScheduler: running: Set()
20/02/14 12:10:31 INFO DAGScheduler: waiting: Set(ResultStage 135)
20/02/14 12:10:31 INFO DAGScheduler: failed: Set()
20/02/14 12:10:31 INFO DAGScheduler: Submitting ResultStage 135 (MapPartitionsRDD[708] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:10:31 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:10:31 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:10:31 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:10:31 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1196
20/02/14 12:10:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 135 (MapPartitionsRDD[708] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:10:31 INFO TaskSchedulerImpl: Adding task set 135.0 with 1 tasks
20/02/14 12:10:31 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 168, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:10:31 INFO Executor: Running task 0.0 in stage 135.0 (TID 168)
20/02/14 12:10:31 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:10:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:10:31 INFO Executor: Finished task 0.0 in stage 135.0 (TID 168). 3660 bytes result sent to driver
20/02/14 12:10:31 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 168) in 18 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:10:31 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool 
20/02/14 12:10:31 INFO DAGScheduler: ResultStage 135 (collect at arrowconverters.scala:270) finished in 0.023 s
20/02/14 12:10:31 INFO DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:10:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 135: Stage finished
20/02/14 12:10:31 INFO DAGScheduler: Job 67 finished: collect at arrowconverters.scala:270, took 0.057795 s
20/02/14 12:10:33 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:10:33 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:10:33 INFO CodeGenerator: Code generated in 5.896799 ms
20/02/14 12:10:33 INFO CodeGenerator: Code generated in 13.1829 ms
20/02/14 12:10:33 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:10:33 INFO DAGScheduler: Registering RDD 713 (collect at arrowconverters.scala:270) as input to shuffle 68
20/02/14 12:10:33 INFO DAGScheduler: Got job 68 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:10:33 INFO DAGScheduler: Final stage: ResultStage 137 (collect at arrowconverters.scala:270)
20/02/14 12:10:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 136)
20/02/14 12:10:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 136)
20/02/14 12:10:33 INFO DAGScheduler: Submitting ShuffleMapStage 136 (MapPartitionsRDD[713] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:10:33 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:10:33 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:10:33 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:10:33 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1196
20/02/14 12:10:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 136 (MapPartitionsRDD[713] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:10:33 INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks
20/02/14 12:10:33 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 169, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:10:33 INFO Executor: Running task 0.0 in stage 136.0 (TID 169)
20/02/14 12:10:33 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:10:33 INFO Executor: Finished task 0.0 in stage 136.0 (TID 169). 2200 bytes result sent to driver
20/02/14 12:10:33 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 169) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:10:33 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool 
20/02/14 12:10:33 INFO DAGScheduler: ShuffleMapStage 136 (collect at arrowconverters.scala:270) finished in 0.023 s
20/02/14 12:10:33 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:10:33 INFO DAGScheduler: running: Set()
20/02/14 12:10:33 INFO DAGScheduler: waiting: Set(ResultStage 137)
20/02/14 12:10:33 INFO DAGScheduler: failed: Set()
20/02/14 12:10:33 INFO DAGScheduler: Submitting ResultStage 137 (MapPartitionsRDD[719] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:10:33 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:10:33 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:10:33 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:10:33 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1196
20/02/14 12:10:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 137 (MapPartitionsRDD[719] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:10:33 INFO TaskSchedulerImpl: Adding task set 137.0 with 1 tasks
20/02/14 12:10:33 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 170, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:10:33 INFO Executor: Running task 0.0 in stage 137.0 (TID 170)
20/02/14 12:10:33 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:10:33 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:10:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:10:33 INFO Executor: Finished task 0.0 in stage 137.0 (TID 170). 3660 bytes result sent to driver
20/02/14 12:10:33 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 170) in 25 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:10:33 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool 
20/02/14 12:10:33 INFO DAGScheduler: ResultStage 137 (collect at arrowconverters.scala:270) finished in 0.035 s
20/02/14 12:10:33 INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:10:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 137: Stage finished
20/02/14 12:10:33 INFO DAGScheduler: Job 68 finished: collect at arrowconverters.scala:270, took 0.064518 s
20/02/14 12:16:23 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:16:23 INFO CodeGenerator: Code generated in 7.532699 ms
20/02/14 12:16:23 INFO CodeGenerator: Code generated in 8.2596 ms
20/02/14 12:16:23 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:16:23 INFO DAGScheduler: Registering RDD 724 (collect at arrowconverters.scala:270) as input to shuffle 69
20/02/14 12:16:23 INFO DAGScheduler: Got job 69 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:16:23 INFO DAGScheduler: Final stage: ResultStage 139 (collect at arrowconverters.scala:270)
20/02/14 12:16:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 138)
20/02/14 12:16:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 138)
20/02/14 12:16:23 INFO DAGScheduler: Submitting ShuffleMapStage 138 (MapPartitionsRDD[724] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:16:23 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 44.3 KiB, free 413.8 MiB)
20/02/14 12:16:23 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 12:16:23 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:16:23 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1196
20/02/14 12:16:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 138 (MapPartitionsRDD[724] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:16:23 INFO TaskSchedulerImpl: Adding task set 138.0 with 1 tasks
20/02/14 12:16:23 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 171, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:16:23 INFO Executor: Running task 0.0 in stage 138.0 (TID 171)
20/02/14 12:16:23 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:16:23 INFO Executor: Finished task 0.0 in stage 138.0 (TID 171). 2200 bytes result sent to driver
20/02/14 12:16:23 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 171) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:16:23 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool 
20/02/14 12:16:23 INFO DAGScheduler: ShuffleMapStage 138 (collect at arrowconverters.scala:270) finished in 0.028 s
20/02/14 12:16:23 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:16:23 INFO DAGScheduler: running: Set()
20/02/14 12:16:23 INFO DAGScheduler: waiting: Set(ResultStage 139)
20/02/14 12:16:23 INFO DAGScheduler: failed: Set()
20/02/14 12:16:23 INFO DAGScheduler: Submitting ResultStage 139 (MapPartitionsRDD[730] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:16:23 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 49.3 KiB, free 413.8 MiB)
20/02/14 12:16:23 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 17.0 KiB, free 413.7 MiB)
20/02/14 12:16:23 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 127.0.0.1:55441 (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:16:23 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1196
20/02/14 12:16:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 139 (MapPartitionsRDD[730] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:16:23 INFO TaskSchedulerImpl: Adding task set 139.0 with 1 tasks
20/02/14 12:16:23 INFO TaskSetManager: Starting task 0.0 in stage 139.0 (TID 172, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:16:23 INFO Executor: Running task 0.0 in stage 139.0 (TID 172)
20/02/14 12:16:23 INFO ShuffleBlockFetcherIterator: Getting 1 (490.0 B) non-empty blocks including 1 (490.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:16:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:16:23 INFO Executor: Finished task 0.0 in stage 139.0 (TID 172). 3660 bytes result sent to driver
20/02/14 12:16:23 INFO TaskSetManager: Finished task 0.0 in stage 139.0 (TID 172) in 19 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:16:23 INFO TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool 
20/02/14 12:16:23 INFO DAGScheduler: ResultStage 139 (collect at arrowconverters.scala:270) finished in 0.024 s
20/02/14 12:16:23 INFO DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:16:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 139: Stage finished
20/02/14 12:16:23 INFO DAGScheduler: Job 69 finished: collect at arrowconverters.scala:270, took 0.058133 s
20/02/14 12:16:44 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 12:16:44 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:16:44 INFO CodeGenerator: Code generated in 6.124801 ms
20/02/14 12:16:44 INFO CodeGenerator: Code generated in 7.871401 ms
20/02/14 12:16:44 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:16:44 INFO DAGScheduler: Got job 70 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:16:44 INFO DAGScheduler: Final stage: ResultStage 140 (collect at arrowconverters.scala:270)
20/02/14 12:16:44 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:16:44 INFO DAGScheduler: Missing parents: List()
20/02/14 12:16:44 INFO DAGScheduler: Submitting ResultStage 140 (MapPartitionsRDD[738] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:16:44 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 46.7 KiB, free 413.8 MiB)
20/02/14 12:16:44 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 413.8 MiB)
20/02/14 12:16:44 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 127.0.0.1:55441 (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:16:44 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1196
20/02/14 12:16:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 140 (MapPartitionsRDD[738] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:16:44 INFO TaskSchedulerImpl: Adding task set 140.0 with 1 tasks
20/02/14 12:16:44 INFO TaskSetManager: Starting task 0.0 in stage 140.0 (TID 173, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8649 bytes)
20/02/14 12:16:44 INFO Executor: Running task 0.0 in stage 140.0 (TID 173)
20/02/14 12:16:44 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:16:44 INFO Executor: Finished task 0.0 in stage 140.0 (TID 173). 2342 bytes result sent to driver
20/02/14 12:16:44 INFO TaskSetManager: Finished task 0.0 in stage 140.0 (TID 173) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:16:44 INFO TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool 
20/02/14 12:16:44 INFO DAGScheduler: ResultStage 140 (collect at arrowconverters.scala:270) finished in 0.023 s
20/02/14 12:16:44 INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:16:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 140: Stage finished
20/02/14 12:16:44 INFO DAGScheduler: Job 70 finished: collect at arrowconverters.scala:270, took 0.026804 s
20/02/14 12:32:57 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 127.0.0.1:55441 in memory (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:32:57 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:55441 in memory (size: 17.0 KiB, free: 413.9 MiB)
20/02/14 12:41:23 INFO CodeGenerator: Code generated in 41.9203 ms
20/02/14 12:41:24 INFO CodeGenerator: Code generated in 73.1733 ms
20/02/14 12:41:24 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:41:24 INFO DAGScheduler: Registering RDD 743 (collect at arrowconverters.scala:270) as input to shuffle 70
20/02/14 12:41:24 INFO DAGScheduler: Got job 71 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/14 12:41:24 INFO DAGScheduler: Final stage: ResultStage 142 (collect at arrowconverters.scala:270)
20/02/14 12:41:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 141)
20/02/14 12:41:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 141)
20/02/14 12:41:24 INFO DAGScheduler: Submitting ShuffleMapStage 141 (MapPartitionsRDD[743] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:41:24 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 62.0 KiB, free 413.9 MiB)
20/02/14 12:41:24 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 21.6 KiB, free 413.8 MiB)
20/02/14 12:41:24 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 127.0.0.1:55441 (size: 21.6 KiB, free: 413.9 MiB)
20/02/14 12:41:24 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1196
20/02/14 12:41:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 141 (MapPartitionsRDD[743] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:41:24 INFO TaskSchedulerImpl: Adding task set 141.0 with 1 tasks
20/02/14 12:41:24 INFO TaskSetManager: Starting task 0.0 in stage 141.0 (TID 174, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:41:24 INFO Executor: Running task 0.0 in stage 141.0 (TID 174)
20/02/14 12:41:24 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:41:24 INFO CodeGenerator: Code generated in 10.9399 ms
20/02/14 12:41:24 INFO CodeGenerator: Code generated in 5.7559 ms
20/02/14 12:41:24 INFO CodeGenerator: Code generated in 9.451 ms
20/02/14 12:41:24 INFO CodeGenerator: Code generated in 13.6914 ms
20/02/14 12:41:24 INFO Executor: Finished task 0.0 in stage 141.0 (TID 174). 2799 bytes result sent to driver
20/02/14 12:41:24 INFO TaskSetManager: Finished task 0.0 in stage 141.0 (TID 174) in 113 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:41:24 INFO TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool 
20/02/14 12:41:24 INFO DAGScheduler: ShuffleMapStage 141 (collect at arrowconverters.scala:270) finished in 0.122 s
20/02/14 12:41:24 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:41:24 INFO DAGScheduler: running: Set()
20/02/14 12:41:24 INFO DAGScheduler: waiting: Set(ResultStage 142)
20/02/14 12:41:24 INFO DAGScheduler: failed: Set()
20/02/14 12:41:24 INFO DAGScheduler: Submitting ResultStage 142 (MapPartitionsRDD[749] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:41:24 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 58.8 KiB, free 413.8 MiB)
20/02/14 12:41:24 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 21.1 KiB, free 413.8 MiB)
20/02/14 12:41:24 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 127.0.0.1:55441 (size: 21.1 KiB, free: 413.9 MiB)
20/02/14 12:41:24 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1196
20/02/14 12:41:24 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 142 (MapPartitionsRDD[749] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 12:41:24 INFO TaskSchedulerImpl: Adding task set 142.0 with 4 tasks
20/02/14 12:41:24 INFO TaskSetManager: Starting task 0.0 in stage 142.0 (TID 175, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:41:24 INFO TaskSetManager: Starting task 1.0 in stage 142.0 (TID 176, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7248 bytes)
20/02/14 12:41:24 INFO TaskSetManager: Starting task 2.0 in stage 142.0 (TID 177, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7248 bytes)
20/02/14 12:41:24 INFO TaskSetManager: Starting task 3.0 in stage 142.0 (TID 178, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7248 bytes)
20/02/14 12:41:24 INFO Executor: Running task 0.0 in stage 142.0 (TID 175)
20/02/14 12:41:24 INFO Executor: Running task 2.0 in stage 142.0 (TID 177)
20/02/14 12:41:24 INFO Executor: Running task 1.0 in stage 142.0 (TID 176)
20/02/14 12:41:24 INFO Executor: Running task 3.0 in stage 142.0 (TID 178)
20/02/14 12:41:24 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:41:24 INFO ShuffleBlockFetcherIterator: Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:41:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:41:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:41:24 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:41:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
20/02/14 12:41:24 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:41:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:41:24 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 127.0.0.1:55441 in memory (size: 21.6 KiB, free: 413.9 MiB)
20/02/14 12:41:24 INFO CodeGenerator: Code generated in 20.083 ms
20/02/14 12:41:24 INFO CodeGenerator: Code generated in 26.6285 ms
20/02/14 12:41:24 INFO Executor: Finished task 2.0 in stage 142.0 (TID 177). 4590 bytes result sent to driver
20/02/14 12:41:24 INFO Executor: Finished task 1.0 in stage 142.0 (TID 176). 4541 bytes result sent to driver
20/02/14 12:41:24 INFO Executor: Finished task 3.0 in stage 142.0 (TID 178). 4501 bytes result sent to driver
20/02/14 12:41:24 INFO Executor: Finished task 0.0 in stage 142.0 (TID 175). 4526 bytes result sent to driver
20/02/14 12:41:24 INFO TaskSetManager: Finished task 2.0 in stage 142.0 (TID 177) in 145 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 12:41:24 INFO TaskSetManager: Finished task 1.0 in stage 142.0 (TID 176) in 145 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 12:41:24 INFO TaskSetManager: Finished task 0.0 in stage 142.0 (TID 175) in 146 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 12:41:24 INFO TaskSetManager: Finished task 3.0 in stage 142.0 (TID 178) in 145 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 12:41:24 INFO TaskSchedulerImpl: Removed TaskSet 142.0, whose tasks have all completed, from pool 
20/02/14 12:41:24 INFO DAGScheduler: ResultStage 142 (collect at arrowconverters.scala:270) finished in 0.158 s
20/02/14 12:41:24 INFO DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:41:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 142: Stage finished
20/02/14 12:41:24 INFO DAGScheduler: Job 71 finished: collect at arrowconverters.scala:270, took 0.289560 s
20/02/14 12:41:25 INFO CodeGenerator: Code generated in 6.9568 ms
20/02/14 12:41:25 INFO CodeGenerator: Code generated in 13.9756 ms
20/02/14 12:41:25 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:41:25 INFO DAGScheduler: Registering RDD 754 (collect at arrowconverters.scala:270) as input to shuffle 71
20/02/14 12:41:25 INFO DAGScheduler: Registering RDD 757 (collect at arrowconverters.scala:270) as input to shuffle 72
20/02/14 12:41:25 INFO DAGScheduler: Got job 72 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:41:25 INFO DAGScheduler: Final stage: ResultStage 145 (collect at arrowconverters.scala:270)
20/02/14 12:41:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 144)
20/02/14 12:41:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 144)
20/02/14 12:41:25 INFO DAGScheduler: Submitting ShuffleMapStage 143 (MapPartitionsRDD[754] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:41:25 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 62.3 KiB, free 413.8 MiB)
20/02/14 12:41:25 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 22.3 KiB, free 413.8 MiB)
20/02/14 12:41:25 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 127.0.0.1:55441 (size: 22.3 KiB, free: 413.9 MiB)
20/02/14 12:41:25 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1196
20/02/14 12:41:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 143 (MapPartitionsRDD[754] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:41:25 INFO TaskSchedulerImpl: Adding task set 143.0 with 1 tasks
20/02/14 12:41:25 INFO TaskSetManager: Starting task 0.0 in stage 143.0 (TID 179, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:41:25 INFO Executor: Running task 0.0 in stage 143.0 (TID 179)
20/02/14 12:41:25 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:41:25 INFO CodeGenerator: Code generated in 6.7741 ms
20/02/14 12:41:25 INFO CodeGenerator: Code generated in 5.8999 ms
20/02/14 12:41:25 INFO Executor: Finished task 0.0 in stage 143.0 (TID 179). 2713 bytes result sent to driver
20/02/14 12:41:25 INFO TaskSetManager: Finished task 0.0 in stage 143.0 (TID 179) in 71 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:41:25 INFO TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool 
20/02/14 12:41:25 INFO DAGScheduler: ShuffleMapStage 143 (collect at arrowconverters.scala:270) finished in 0.083 s
20/02/14 12:41:25 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:41:25 INFO DAGScheduler: running: Set()
20/02/14 12:41:25 INFO DAGScheduler: waiting: Set(ShuffleMapStage 144, ResultStage 145)
20/02/14 12:41:25 INFO DAGScheduler: failed: Set()
20/02/14 12:41:25 INFO DAGScheduler: Submitting ShuffleMapStage 144 (MapPartitionsRDD[757] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:41:25 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 58.7 KiB, free 413.7 MiB)
20/02/14 12:41:25 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 413.7 MiB)
20/02/14 12:41:25 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 127.0.0.1:55441 (size: 21.9 KiB, free: 413.9 MiB)
20/02/14 12:41:25 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1196
20/02/14 12:41:25 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 144 (MapPartitionsRDD[757] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 12:41:25 INFO TaskSchedulerImpl: Adding task set 144.0 with 4 tasks
20/02/14 12:41:25 INFO TaskSetManager: Starting task 0.0 in stage 144.0 (TID 180, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7237 bytes)
20/02/14 12:41:25 INFO TaskSetManager: Starting task 1.0 in stage 144.0 (TID 181, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7237 bytes)
20/02/14 12:41:25 INFO TaskSetManager: Starting task 2.0 in stage 144.0 (TID 182, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7237 bytes)
20/02/14 12:41:25 INFO TaskSetManager: Starting task 3.0 in stage 144.0 (TID 183, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7237 bytes)
20/02/14 12:41:25 INFO Executor: Running task 0.0 in stage 144.0 (TID 180)
20/02/14 12:41:25 INFO Executor: Running task 1.0 in stage 144.0 (TID 181)
20/02/14 12:41:25 INFO Executor: Running task 3.0 in stage 144.0 (TID 183)
20/02/14 12:41:25 INFO Executor: Running task 2.0 in stage 144.0 (TID 182)
20/02/14 12:41:25 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:41:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 12:41:25 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:41:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:41:25 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:41:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:41:25 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:41:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:41:25 INFO Executor: Finished task 3.0 in stage 144.0 (TID 183). 4332 bytes result sent to driver
20/02/14 12:41:25 INFO TaskSetManager: Finished task 3.0 in stage 144.0 (TID 183) in 29 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 12:41:25 INFO Executor: Finished task 2.0 in stage 144.0 (TID 182). 4461 bytes result sent to driver
20/02/14 12:41:25 INFO TaskSetManager: Finished task 2.0 in stage 144.0 (TID 182) in 42 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 12:41:25 INFO Executor: Finished task 1.0 in stage 144.0 (TID 181). 4418 bytes result sent to driver
20/02/14 12:41:25 INFO TaskSetManager: Finished task 1.0 in stage 144.0 (TID 181) in 47 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 12:41:25 INFO Executor: Finished task 0.0 in stage 144.0 (TID 180). 4461 bytes result sent to driver
20/02/14 12:41:25 INFO TaskSetManager: Finished task 0.0 in stage 144.0 (TID 180) in 52 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 12:41:25 INFO TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool 
20/02/14 12:41:25 INFO DAGScheduler: ShuffleMapStage 144 (collect at arrowconverters.scala:270) finished in 0.064 s
20/02/14 12:41:25 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:41:25 INFO DAGScheduler: running: Set()
20/02/14 12:41:25 INFO DAGScheduler: waiting: Set(ResultStage 145)
20/02/14 12:41:25 INFO DAGScheduler: failed: Set()
20/02/14 12:41:25 INFO DAGScheduler: Submitting ResultStage 145 (MapPartitionsRDD[763] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:41:25 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 57.3 KiB, free 413.6 MiB)
20/02/14 12:41:25 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 413.6 MiB)
20/02/14 12:41:25 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 127.0.0.1:55441 (size: 20.7 KiB, free: 413.8 MiB)
20/02/14 12:41:25 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1196
20/02/14 12:41:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 145 (MapPartitionsRDD[763] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:41:25 INFO TaskSchedulerImpl: Adding task set 145.0 with 1 tasks
20/02/14 12:41:25 INFO TaskSetManager: Starting task 0.0 in stage 145.0 (TID 184, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:41:25 INFO Executor: Running task 0.0 in stage 145.0 (TID 184)
20/02/14 12:41:25 INFO ShuffleBlockFetcherIterator: Getting 3 (232.0 B) non-empty blocks including 3 (232.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:41:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:41:25 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 127.0.0.1:55441 in memory (size: 21.9 KiB, free: 413.9 MiB)
20/02/14 12:41:25 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 127.0.0.1:55441 in memory (size: 22.3 KiB, free: 413.9 MiB)
20/02/14 12:41:25 INFO CodeGenerator: Code generated in 32.9269 ms
20/02/14 12:41:25 INFO Executor: Finished task 0.0 in stage 145.0 (TID 184). 5469 bytes result sent to driver
20/02/14 12:41:25 INFO TaskSetManager: Finished task 0.0 in stage 145.0 (TID 184) in 76 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:41:25 INFO TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool 
20/02/14 12:41:25 INFO DAGScheduler: ResultStage 145 (collect at arrowconverters.scala:270) finished in 0.090 s
20/02/14 12:41:25 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:41:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 145: Stage finished
20/02/14 12:41:25 INFO DAGScheduler: Job 72 finished: collect at arrowconverters.scala:270, took 0.247640 s
20/02/14 12:41:26 INFO BlockManagerInfo: Removed broadcast_145_piece0 on 127.0.0.1:55441 in memory (size: 20.7 KiB, free: 413.9 MiB)
20/02/14 12:41:26 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:41:26 INFO DAGScheduler: Got job 73 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:41:26 INFO DAGScheduler: Final stage: ResultStage 146 (collect at arrowconverters.scala:270)
20/02/14 12:41:26 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:41:26 INFO DAGScheduler: Missing parents: List()
20/02/14 12:41:26 INFO DAGScheduler: Submitting ResultStage 146 (MapPartitionsRDD[771] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:41:26 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 46.7 KiB, free 413.8 MiB)
20/02/14 12:41:26 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 413.8 MiB)
20/02/14 12:41:26 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 127.0.0.1:55441 (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:41:26 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1196
20/02/14 12:41:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 146 (MapPartitionsRDD[771] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:41:26 INFO TaskSchedulerImpl: Adding task set 146.0 with 1 tasks
20/02/14 12:41:26 INFO TaskSetManager: Starting task 0.0 in stage 146.0 (TID 185, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8649 bytes)
20/02/14 12:41:26 INFO Executor: Running task 0.0 in stage 146.0 (TID 185)
20/02/14 12:41:26 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:41:26 INFO Executor: Finished task 0.0 in stage 146.0 (TID 185). 2342 bytes result sent to driver
20/02/14 12:41:26 INFO TaskSetManager: Finished task 0.0 in stage 146.0 (TID 185) in 13 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:41:26 INFO TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool 
20/02/14 12:41:26 INFO DAGScheduler: ResultStage 146 (collect at arrowconverters.scala:270) finished in 0.021 s
20/02/14 12:41:26 INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:41:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 146: Stage finished
20/02/14 12:41:26 INFO DAGScheduler: Job 73 finished: collect at arrowconverters.scala:270, took 0.025414 s
20/02/14 12:41:30 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 127.0.0.1:55441 in memory (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:41:30 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:41:30 INFO DAGScheduler: Got job 74 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:41:30 INFO DAGScheduler: Final stage: ResultStage 147 (collect at arrowconverters.scala:270)
20/02/14 12:41:30 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:41:30 INFO DAGScheduler: Missing parents: List()
20/02/14 12:41:30 INFO DAGScheduler: Submitting ResultStage 147 (MapPartitionsRDD[779] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:41:30 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 46.7 KiB, free 413.8 MiB)
20/02/14 12:41:30 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 413.8 MiB)
20/02/14 12:41:30 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 127.0.0.1:55441 (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:41:30 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:1196
20/02/14 12:41:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 147 (MapPartitionsRDD[779] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:41:30 INFO TaskSchedulerImpl: Adding task set 147.0 with 1 tasks
20/02/14 12:41:30 INFO TaskSetManager: Starting task 0.0 in stage 147.0 (TID 186, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8649 bytes)
20/02/14 12:41:30 INFO Executor: Running task 0.0 in stage 147.0 (TID 186)
20/02/14 12:41:30 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:41:30 INFO Executor: Finished task 0.0 in stage 147.0 (TID 186). 2342 bytes result sent to driver
20/02/14 12:41:30 INFO TaskSetManager: Finished task 0.0 in stage 147.0 (TID 186) in 21 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:41:30 INFO TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool 
20/02/14 12:41:30 INFO DAGScheduler: ResultStage 147 (collect at arrowconverters.scala:270) finished in 0.029 s
20/02/14 12:41:30 INFO DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:41:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 147: Stage finished
20/02/14 12:41:30 INFO DAGScheduler: Job 74 finished: collect at arrowconverters.scala:270, took 0.033115 s
20/02/14 12:41:35 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 127.0.0.1:55441 in memory (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:41:35 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:41:35 INFO DAGScheduler: Got job 75 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:41:35 INFO DAGScheduler: Final stage: ResultStage 148 (collect at arrowconverters.scala:270)
20/02/14 12:41:35 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:41:35 INFO DAGScheduler: Missing parents: List()
20/02/14 12:41:35 INFO DAGScheduler: Submitting ResultStage 148 (MapPartitionsRDD[787] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:41:35 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 46.7 KiB, free 413.8 MiB)
20/02/14 12:41:35 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 413.8 MiB)
20/02/14 12:41:35 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 127.0.0.1:55441 (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:41:35 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1196
20/02/14 12:41:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 148 (MapPartitionsRDD[787] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:41:35 INFO TaskSchedulerImpl: Adding task set 148.0 with 1 tasks
20/02/14 12:41:35 INFO TaskSetManager: Starting task 0.0 in stage 148.0 (TID 187, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8649 bytes)
20/02/14 12:41:35 INFO Executor: Running task 0.0 in stage 148.0 (TID 187)
20/02/14 12:41:35 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:41:35 INFO Executor: Finished task 0.0 in stage 148.0 (TID 187). 2342 bytes result sent to driver
20/02/14 12:41:35 INFO TaskSetManager: Finished task 0.0 in stage 148.0 (TID 187) in 24 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:41:35 INFO TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool 
20/02/14 12:41:35 INFO DAGScheduler: ResultStage 148 (collect at arrowconverters.scala:270) finished in 0.033 s
20/02/14 12:41:35 INFO DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:41:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 148: Stage finished
20/02/14 12:41:35 INFO DAGScheduler: Job 75 finished: collect at arrowconverters.scala:270, took 0.036705 s
20/02/14 12:41:41 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 127.0.0.1:55441 in memory (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:41:41 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:41:41 INFO DAGScheduler: Got job 76 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:41:41 INFO DAGScheduler: Final stage: ResultStage 149 (collect at arrowconverters.scala:270)
20/02/14 12:41:41 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:41:41 INFO DAGScheduler: Missing parents: List()
20/02/14 12:41:41 INFO DAGScheduler: Submitting ResultStage 149 (MapPartitionsRDD[795] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:41:41 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 46.7 KiB, free 413.8 MiB)
20/02/14 12:41:41 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 413.8 MiB)
20/02/14 12:41:41 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 127.0.0.1:55441 (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:41:41 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1196
20/02/14 12:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 149 (MapPartitionsRDD[795] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:41:41 INFO TaskSchedulerImpl: Adding task set 149.0 with 1 tasks
20/02/14 12:41:41 INFO TaskSetManager: Starting task 0.0 in stage 149.0 (TID 188, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8649 bytes)
20/02/14 12:41:41 INFO Executor: Running task 0.0 in stage 149.0 (TID 188)
20/02/14 12:41:41 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:41:41 INFO Executor: Finished task 0.0 in stage 149.0 (TID 188). 2342 bytes result sent to driver
20/02/14 12:41:41 INFO TaskSetManager: Finished task 0.0 in stage 149.0 (TID 188) in 21 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:41:41 INFO TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool 
20/02/14 12:41:41 INFO DAGScheduler: ResultStage 149 (collect at arrowconverters.scala:270) finished in 0.028 s
20/02/14 12:41:41 INFO DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:41:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 149: Stage finished
20/02/14 12:41:41 INFO DAGScheduler: Job 76 finished: collect at arrowconverters.scala:270, took 0.031956 s
20/02/14 12:42:08 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 127.0.0.1:55441 in memory (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:42:08 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:42:08 INFO DAGScheduler: Got job 77 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:42:08 INFO DAGScheduler: Final stage: ResultStage 150 (collect at arrowconverters.scala:270)
20/02/14 12:42:08 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:42:08 INFO DAGScheduler: Missing parents: List()
20/02/14 12:42:08 INFO DAGScheduler: Submitting ResultStage 150 (MapPartitionsRDD[803] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:42:08 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 46.7 KiB, free 413.8 MiB)
20/02/14 12:42:08 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 413.8 MiB)
20/02/14 12:42:08 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 127.0.0.1:55441 (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:42:08 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1196
20/02/14 12:42:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 150 (MapPartitionsRDD[803] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:42:08 INFO TaskSchedulerImpl: Adding task set 150.0 with 1 tasks
20/02/14 12:42:08 INFO TaskSetManager: Starting task 0.0 in stage 150.0 (TID 189, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8649 bytes)
20/02/14 12:42:08 INFO Executor: Running task 0.0 in stage 150.0 (TID 189)
20/02/14 12:42:08 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:42:08 INFO Executor: Finished task 0.0 in stage 150.0 (TID 189). 2342 bytes result sent to driver
20/02/14 12:42:08 INFO TaskSetManager: Finished task 0.0 in stage 150.0 (TID 189) in 20 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:42:08 INFO TaskSchedulerImpl: Removed TaskSet 150.0, whose tasks have all completed, from pool 
20/02/14 12:42:08 INFO DAGScheduler: ResultStage 150 (collect at arrowconverters.scala:270) finished in 0.031 s
20/02/14 12:42:08 INFO DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:42:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 150: Stage finished
20/02/14 12:42:08 INFO DAGScheduler: Job 77 finished: collect at arrowconverters.scala:270, took 0.036137 s
20/02/14 12:42:11 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 127.0.0.1:55441 in memory (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:42:11 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:42:11 INFO DAGScheduler: Got job 78 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:42:11 INFO DAGScheduler: Final stage: ResultStage 151 (collect at arrowconverters.scala:270)
20/02/14 12:42:11 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:42:11 INFO DAGScheduler: Missing parents: List()
20/02/14 12:42:11 INFO DAGScheduler: Submitting ResultStage 151 (MapPartitionsRDD[811] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:42:11 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 46.7 KiB, free 413.8 MiB)
20/02/14 12:42:11 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 413.8 MiB)
20/02/14 12:42:11 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 127.0.0.1:55441 (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:42:11 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1196
20/02/14 12:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 151 (MapPartitionsRDD[811] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:42:11 INFO TaskSchedulerImpl: Adding task set 151.0 with 1 tasks
20/02/14 12:42:11 INFO TaskSetManager: Starting task 0.0 in stage 151.0 (TID 190, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8649 bytes)
20/02/14 12:42:11 INFO Executor: Running task 0.0 in stage 151.0 (TID 190)
20/02/14 12:42:11 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:42:11 INFO Executor: Finished task 0.0 in stage 151.0 (TID 190). 2342 bytes result sent to driver
20/02/14 12:42:11 INFO TaskSetManager: Finished task 0.0 in stage 151.0 (TID 190) in 20 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:42:11 INFO TaskSchedulerImpl: Removed TaskSet 151.0, whose tasks have all completed, from pool 
20/02/14 12:42:11 INFO DAGScheduler: ResultStage 151 (collect at arrowconverters.scala:270) finished in 0.031 s
20/02/14 12:42:11 INFO DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 151: Stage finished
20/02/14 12:42:11 INFO DAGScheduler: Job 78 finished: collect at arrowconverters.scala:270, took 0.036318 s
20/02/14 12:42:19 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 127.0.0.1:55441 in memory (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:42:19 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:42:19 INFO DAGScheduler: Got job 79 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:42:19 INFO DAGScheduler: Final stage: ResultStage 152 (collect at arrowconverters.scala:270)
20/02/14 12:42:19 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:42:19 INFO DAGScheduler: Missing parents: List()
20/02/14 12:42:19 INFO DAGScheduler: Submitting ResultStage 152 (MapPartitionsRDD[819] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:42:19 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 46.7 KiB, free 413.8 MiB)
20/02/14 12:42:19 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 413.8 MiB)
20/02/14 12:42:19 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 127.0.0.1:55441 (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:42:19 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1196
20/02/14 12:42:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 152 (MapPartitionsRDD[819] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:42:19 INFO TaskSchedulerImpl: Adding task set 152.0 with 1 tasks
20/02/14 12:42:19 INFO TaskSetManager: Starting task 0.0 in stage 152.0 (TID 191, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8649 bytes)
20/02/14 12:42:19 INFO Executor: Running task 0.0 in stage 152.0 (TID 191)
20/02/14 12:42:19 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:42:19 INFO Executor: Finished task 0.0 in stage 152.0 (TID 191). 2342 bytes result sent to driver
20/02/14 12:42:19 INFO TaskSetManager: Finished task 0.0 in stage 152.0 (TID 191) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:42:19 INFO TaskSchedulerImpl: Removed TaskSet 152.0, whose tasks have all completed, from pool 
20/02/14 12:42:19 INFO DAGScheduler: ResultStage 152 (collect at arrowconverters.scala:270) finished in 0.031 s
20/02/14 12:42:19 INFO DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:42:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 152: Stage finished
20/02/14 12:42:19 INFO DAGScheduler: Job 79 finished: collect at arrowconverters.scala:270, took 0.035201 s
20/02/14 12:42:24 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 127.0.0.1:55441 in memory (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:42:24 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:42:24 INFO DAGScheduler: Got job 80 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:42:24 INFO DAGScheduler: Final stage: ResultStage 153 (collect at arrowconverters.scala:270)
20/02/14 12:42:24 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:42:24 INFO DAGScheduler: Missing parents: List()
20/02/14 12:42:24 INFO DAGScheduler: Submitting ResultStage 153 (MapPartitionsRDD[827] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:42:24 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 46.7 KiB, free 413.8 MiB)
20/02/14 12:42:24 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 413.8 MiB)
20/02/14 12:42:24 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 127.0.0.1:55441 (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:42:24 INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:1196
20/02/14 12:42:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 153 (MapPartitionsRDD[827] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:42:24 INFO TaskSchedulerImpl: Adding task set 153.0 with 1 tasks
20/02/14 12:42:24 INFO TaskSetManager: Starting task 0.0 in stage 153.0 (TID 192, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8649 bytes)
20/02/14 12:42:24 INFO Executor: Running task 0.0 in stage 153.0 (TID 192)
20/02/14 12:42:24 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:42:24 INFO Executor: Finished task 0.0 in stage 153.0 (TID 192). 2342 bytes result sent to driver
20/02/14 12:42:24 INFO TaskSetManager: Finished task 0.0 in stage 153.0 (TID 192) in 20 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:42:24 INFO TaskSchedulerImpl: Removed TaskSet 153.0, whose tasks have all completed, from pool 
20/02/14 12:42:24 INFO DAGScheduler: ResultStage 153 (collect at arrowconverters.scala:270) finished in 0.033 s
20/02/14 12:42:24 INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:42:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 153: Stage finished
20/02/14 12:42:24 INFO DAGScheduler: Job 80 finished: collect at arrowconverters.scala:270, took 0.037360 s
20/02/14 12:48:21 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 127.0.0.1:55441 in memory (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:48:21 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:48:21 INFO DAGScheduler: Registering RDD 832 (collect at arrowconverters.scala:270) as input to shuffle 73
20/02/14 12:48:21 INFO DAGScheduler: Got job 81 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/14 12:48:21 INFO DAGScheduler: Final stage: ResultStage 155 (collect at arrowconverters.scala:270)
20/02/14 12:48:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 154)
20/02/14 12:48:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 154)
20/02/14 12:48:21 INFO DAGScheduler: Submitting ShuffleMapStage 154 (MapPartitionsRDD[832] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:48:21 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 62.0 KiB, free 413.8 MiB)
20/02/14 12:48:21 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 21.6 KiB, free 413.8 MiB)
20/02/14 12:48:21 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 127.0.0.1:55441 (size: 21.6 KiB, free: 413.9 MiB)
20/02/14 12:48:21 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1196
20/02/14 12:48:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 154 (MapPartitionsRDD[832] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:48:21 INFO TaskSchedulerImpl: Adding task set 154.0 with 1 tasks
20/02/14 12:48:21 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 193, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:48:21 INFO Executor: Running task 0.0 in stage 154.0 (TID 193)
20/02/14 12:48:21 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:48:21 INFO Executor: Finished task 0.0 in stage 154.0 (TID 193). 2713 bytes result sent to driver
20/02/14 12:48:21 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 193) in 60 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:48:21 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool 
20/02/14 12:48:21 INFO DAGScheduler: ShuffleMapStage 154 (collect at arrowconverters.scala:270) finished in 0.069 s
20/02/14 12:48:21 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:48:21 INFO DAGScheduler: running: Set()
20/02/14 12:48:21 INFO DAGScheduler: waiting: Set(ResultStage 155)
20/02/14 12:48:21 INFO DAGScheduler: failed: Set()
20/02/14 12:48:21 INFO DAGScheduler: Submitting ResultStage 155 (MapPartitionsRDD[838] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:48:21 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 58.8 KiB, free 413.7 MiB)
20/02/14 12:48:21 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 21.1 KiB, free 413.7 MiB)
20/02/14 12:48:21 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 127.0.0.1:55441 (size: 21.1 KiB, free: 413.9 MiB)
20/02/14 12:48:21 INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:1196
20/02/14 12:48:21 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 155 (MapPartitionsRDD[838] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 12:48:21 INFO TaskSchedulerImpl: Adding task set 155.0 with 4 tasks
20/02/14 12:48:21 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 194, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:48:21 INFO TaskSetManager: Starting task 1.0 in stage 155.0 (TID 195, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7248 bytes)
20/02/14 12:48:21 INFO TaskSetManager: Starting task 2.0 in stage 155.0 (TID 196, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7248 bytes)
20/02/14 12:48:21 INFO TaskSetManager: Starting task 3.0 in stage 155.0 (TID 197, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7248 bytes)
20/02/14 12:48:21 INFO Executor: Running task 0.0 in stage 155.0 (TID 194)
20/02/14 12:48:21 INFO Executor: Running task 1.0 in stage 155.0 (TID 195)
20/02/14 12:48:21 INFO Executor: Running task 2.0 in stage 155.0 (TID 196)
20/02/14 12:48:21 INFO Executor: Running task 3.0 in stage 155.0 (TID 197)
20/02/14 12:48:21 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:48:21 INFO ShuffleBlockFetcherIterator: Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:48:21 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:48:21 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:48:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
20/02/14 12:48:21 INFO Executor: Finished task 1.0 in stage 155.0 (TID 195). 4498 bytes result sent to driver
20/02/14 12:48:21 INFO Executor: Finished task 3.0 in stage 155.0 (TID 197). 4458 bytes result sent to driver
20/02/14 12:48:21 INFO TaskSetManager: Finished task 1.0 in stage 155.0 (TID 195) in 56 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 12:48:21 INFO TaskSetManager: Finished task 3.0 in stage 155.0 (TID 197) in 57 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 12:48:21 INFO Executor: Finished task 0.0 in stage 155.0 (TID 194). 4483 bytes result sent to driver
20/02/14 12:48:21 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 194) in 59 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 12:48:21 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 127.0.0.1:55441 in memory (size: 21.6 KiB, free: 413.9 MiB)
20/02/14 12:48:21 INFO Executor: Finished task 2.0 in stage 155.0 (TID 196). 4547 bytes result sent to driver
20/02/14 12:48:21 INFO TaskSetManager: Finished task 2.0 in stage 155.0 (TID 196) in 61 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 12:48:21 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool 
20/02/14 12:48:21 INFO DAGScheduler: ResultStage 155 (collect at arrowconverters.scala:270) finished in 0.074 s
20/02/14 12:48:21 INFO DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:48:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 155: Stage finished
20/02/14 12:48:21 INFO DAGScheduler: Job 81 finished: collect at arrowconverters.scala:270, took 0.151566 s
20/02/14 12:48:23 INFO CodeGenerator: Code generated in 13.5897 ms
20/02/14 12:48:23 INFO CodeGenerator: Code generated in 17.1199 ms
20/02/14 12:48:23 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:48:23 INFO DAGScheduler: Registering RDD 843 (collect at arrowconverters.scala:270) as input to shuffle 74
20/02/14 12:48:23 INFO DAGScheduler: Registering RDD 846 (collect at arrowconverters.scala:270) as input to shuffle 75
20/02/14 12:48:23 INFO DAGScheduler: Got job 82 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:48:23 INFO DAGScheduler: Final stage: ResultStage 158 (collect at arrowconverters.scala:270)
20/02/14 12:48:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 157)
20/02/14 12:48:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 157)
20/02/14 12:48:23 INFO DAGScheduler: Submitting ShuffleMapStage 156 (MapPartitionsRDD[843] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:48:23 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 62.3 KiB, free 413.7 MiB)
20/02/14 12:48:23 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 22.3 KiB, free 413.7 MiB)
20/02/14 12:48:23 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 127.0.0.1:55441 (size: 22.3 KiB, free: 413.9 MiB)
20/02/14 12:48:23 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1196
20/02/14 12:48:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 156 (MapPartitionsRDD[843] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:48:23 INFO TaskSchedulerImpl: Adding task set 156.0 with 1 tasks
20/02/14 12:48:23 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 198, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:48:23 INFO Executor: Running task 0.0 in stage 156.0 (TID 198)
20/02/14 12:48:23 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:48:23 INFO Executor: Finished task 0.0 in stage 156.0 (TID 198). 2713 bytes result sent to driver
20/02/14 12:48:23 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 198) in 46 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:48:23 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool 
20/02/14 12:48:23 INFO DAGScheduler: ShuffleMapStage 156 (collect at arrowconverters.scala:270) finished in 0.061 s
20/02/14 12:48:23 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:48:23 INFO DAGScheduler: running: Set()
20/02/14 12:48:23 INFO DAGScheduler: waiting: Set(ShuffleMapStage 157, ResultStage 158)
20/02/14 12:48:23 INFO DAGScheduler: failed: Set()
20/02/14 12:48:23 INFO DAGScheduler: Submitting ShuffleMapStage 157 (MapPartitionsRDD[846] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:48:23 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 58.7 KiB, free 413.6 MiB)
20/02/14 12:48:23 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 413.6 MiB)
20/02/14 12:48:23 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 127.0.0.1:55441 (size: 21.9 KiB, free: 413.8 MiB)
20/02/14 12:48:23 INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:1196
20/02/14 12:48:23 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 157 (MapPartitionsRDD[846] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 12:48:23 INFO TaskSchedulerImpl: Adding task set 157.0 with 4 tasks
20/02/14 12:48:23 INFO TaskSetManager: Starting task 0.0 in stage 157.0 (TID 199, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7237 bytes)
20/02/14 12:48:23 INFO TaskSetManager: Starting task 1.0 in stage 157.0 (TID 200, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7237 bytes)
20/02/14 12:48:23 INFO TaskSetManager: Starting task 2.0 in stage 157.0 (TID 201, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7237 bytes)
20/02/14 12:48:23 INFO TaskSetManager: Starting task 3.0 in stage 157.0 (TID 202, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7237 bytes)
20/02/14 12:48:23 INFO Executor: Running task 0.0 in stage 157.0 (TID 199)
20/02/14 12:48:23 INFO Executor: Running task 1.0 in stage 157.0 (TID 200)
20/02/14 12:48:23 INFO Executor: Running task 3.0 in stage 157.0 (TID 202)
20/02/14 12:48:23 INFO Executor: Running task 2.0 in stage 157.0 (TID 201)
20/02/14 12:48:23 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:48:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:48:23 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:48:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:48:23 INFO ShuffleBlockFetcherIterator: Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:48:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 12:48:23 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:48:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:48:23 INFO Executor: Finished task 3.0 in stage 157.0 (TID 202). 4289 bytes result sent to driver
20/02/14 12:48:23 INFO TaskSetManager: Finished task 3.0 in stage 157.0 (TID 202) in 33 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 12:48:23 INFO Executor: Finished task 0.0 in stage 157.0 (TID 199). 4461 bytes result sent to driver
20/02/14 12:48:23 INFO TaskSetManager: Finished task 0.0 in stage 157.0 (TID 199) in 43 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 12:48:23 INFO Executor: Finished task 2.0 in stage 157.0 (TID 201). 4418 bytes result sent to driver
20/02/14 12:48:23 INFO TaskSetManager: Finished task 2.0 in stage 157.0 (TID 201) in 46 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 12:48:23 INFO Executor: Finished task 1.0 in stage 157.0 (TID 200). 4461 bytes result sent to driver
20/02/14 12:48:23 INFO TaskSetManager: Finished task 1.0 in stage 157.0 (TID 200) in 50 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 12:48:23 INFO TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool 
20/02/14 12:48:23 INFO DAGScheduler: ShuffleMapStage 157 (collect at arrowconverters.scala:270) finished in 0.062 s
20/02/14 12:48:23 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:48:23 INFO DAGScheduler: running: Set()
20/02/14 12:48:23 INFO DAGScheduler: waiting: Set(ResultStage 158)
20/02/14 12:48:23 INFO DAGScheduler: failed: Set()
20/02/14 12:48:23 INFO DAGScheduler: Submitting ResultStage 158 (MapPartitionsRDD[852] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:48:23 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 57.3 KiB, free 413.5 MiB)
20/02/14 12:48:23 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 20.7 KiB, free 413.5 MiB)
20/02/14 12:48:23 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 127.0.0.1:55441 in memory (size: 22.3 KiB, free: 413.9 MiB)
20/02/14 12:48:23 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 127.0.0.1:55441 (size: 20.7 KiB, free: 413.8 MiB)
20/02/14 12:48:23 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1196
20/02/14 12:48:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 158 (MapPartitionsRDD[852] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:48:23 INFO TaskSchedulerImpl: Adding task set 158.0 with 1 tasks
20/02/14 12:48:23 INFO TaskSetManager: Starting task 0.0 in stage 158.0 (TID 203, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:48:23 INFO Executor: Running task 0.0 in stage 158.0 (TID 203)
20/02/14 12:48:23 INFO ShuffleBlockFetcherIterator: Getting 3 (232.0 B) non-empty blocks including 3 (232.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:48:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:48:23 INFO Executor: Finished task 0.0 in stage 158.0 (TID 203). 5426 bytes result sent to driver
20/02/14 12:48:23 INFO TaskSetManager: Finished task 0.0 in stage 158.0 (TID 203) in 25 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:48:23 INFO TaskSchedulerImpl: Removed TaskSet 158.0, whose tasks have all completed, from pool 
20/02/14 12:48:23 INFO DAGScheduler: ResultStage 158 (collect at arrowconverters.scala:270) finished in 0.036 s
20/02/14 12:48:23 INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:48:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 158: Stage finished
20/02/14 12:48:23 INFO DAGScheduler: Job 82 finished: collect at arrowconverters.scala:270, took 0.167604 s
20/02/14 12:48:24 INFO BlockManagerInfo: Removed broadcast_158_piece0 on 127.0.0.1:55441 in memory (size: 20.7 KiB, free: 413.9 MiB)
20/02/14 12:48:24 INFO BlockManagerInfo: Removed broadcast_157_piece0 on 127.0.0.1:55441 in memory (size: 21.9 KiB, free: 413.9 MiB)
20/02/14 12:48:24 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:48:24 INFO DAGScheduler: Got job 83 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:48:24 INFO DAGScheduler: Final stage: ResultStage 159 (collect at arrowconverters.scala:270)
20/02/14 12:48:24 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:48:24 INFO DAGScheduler: Missing parents: List()
20/02/14 12:48:24 INFO DAGScheduler: Submitting ResultStage 159 (MapPartitionsRDD[860] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:48:24 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 46.7 KiB, free 413.7 MiB)
20/02/14 12:48:24 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 413.7 MiB)
20/02/14 12:48:24 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 127.0.0.1:55441 (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:48:24 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:1196
20/02/14 12:48:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 159 (MapPartitionsRDD[860] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:48:24 INFO TaskSchedulerImpl: Adding task set 159.0 with 1 tasks
20/02/14 12:48:24 INFO TaskSetManager: Starting task 0.0 in stage 159.0 (TID 204, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8649 bytes)
20/02/14 12:48:24 INFO Executor: Running task 0.0 in stage 159.0 (TID 204)
20/02/14 12:48:24 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:48:24 INFO Executor: Finished task 0.0 in stage 159.0 (TID 204). 2342 bytes result sent to driver
20/02/14 12:48:24 INFO TaskSetManager: Finished task 0.0 in stage 159.0 (TID 204) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:48:24 INFO TaskSchedulerImpl: Removed TaskSet 159.0, whose tasks have all completed, from pool 
20/02/14 12:48:24 INFO DAGScheduler: ResultStage 159 (collect at arrowconverters.scala:270) finished in 0.026 s
20/02/14 12:48:24 INFO DAGScheduler: Job 83 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:48:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 159: Stage finished
20/02/14 12:48:24 INFO DAGScheduler: Job 83 finished: collect at arrowconverters.scala:270, took 0.029478 s
20/02/14 12:48:45 INFO BlockManagerInfo: Removed broadcast_159_piece0 on 127.0.0.1:55441 in memory (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:48:45 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:48:45 INFO DAGScheduler: Got job 84 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:48:45 INFO DAGScheduler: Final stage: ResultStage 160 (collect at arrowconverters.scala:270)
20/02/14 12:48:45 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:48:45 INFO DAGScheduler: Missing parents: List()
20/02/14 12:48:45 INFO DAGScheduler: Submitting ResultStage 160 (MapPartitionsRDD[868] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:48:45 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 46.7 KiB, free 413.7 MiB)
20/02/14 12:48:45 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 413.7 MiB)
20/02/14 12:48:45 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 127.0.0.1:55441 (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:48:45 INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1196
20/02/14 12:48:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 160 (MapPartitionsRDD[868] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:48:45 INFO TaskSchedulerImpl: Adding task set 160.0 with 1 tasks
20/02/14 12:48:45 INFO TaskSetManager: Starting task 0.0 in stage 160.0 (TID 205, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8649 bytes)
20/02/14 12:48:45 INFO Executor: Running task 0.0 in stage 160.0 (TID 205)
20/02/14 12:48:45 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:48:45 INFO Executor: Finished task 0.0 in stage 160.0 (TID 205). 2342 bytes result sent to driver
20/02/14 12:48:45 INFO TaskSetManager: Finished task 0.0 in stage 160.0 (TID 205) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:48:45 INFO TaskSchedulerImpl: Removed TaskSet 160.0, whose tasks have all completed, from pool 
20/02/14 12:48:45 INFO DAGScheduler: ResultStage 160 (collect at arrowconverters.scala:270) finished in 0.027 s
20/02/14 12:48:45 INFO DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:48:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 160: Stage finished
20/02/14 12:48:45 INFO DAGScheduler: Job 84 finished: collect at arrowconverters.scala:270, took 0.031372 s
20/02/14 12:50:40 INFO BlockManagerInfo: Removed broadcast_160_piece0 on 127.0.0.1:55441 in memory (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:50:40 INFO CodeGenerator: Code generated in 5.9512 ms
20/02/14 12:50:40 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 12:50:40 INFO DAGScheduler: Got job 85 (collect at utils.scala:41) with 1 output partitions
20/02/14 12:50:40 INFO DAGScheduler: Final stage: ResultStage 161 (collect at utils.scala:41)
20/02/14 12:50:40 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:50:40 INFO DAGScheduler: Missing parents: List()
20/02/14 12:50:40 INFO DAGScheduler: Submitting ResultStage 161 (MapPartitionsRDD[874] at map at utils.scala:41), which has no missing parents
20/02/14 12:50:40 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 8.8 KiB, free 413.8 MiB)
20/02/14 12:50:40 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.8 MiB)
20/02/14 12:50:40 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 127.0.0.1:55441 (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 12:50:40 INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:1196
20/02/14 12:50:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 161 (MapPartitionsRDD[874] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
20/02/14 12:50:40 INFO TaskSchedulerImpl: Adding task set 161.0 with 1 tasks
20/02/14 12:50:40 INFO TaskSetManager: Starting task 0.0 in stage 161.0 (TID 206, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7533 bytes)
20/02/14 12:50:40 INFO Executor: Running task 0.0 in stage 161.0 (TID 206)
20/02/14 12:50:40 INFO CodeGenerator: Code generated in 6.3248 ms
20/02/14 12:50:40 INFO Executor: Finished task 0.0 in stage 161.0 (TID 206). 1069 bytes result sent to driver
20/02/14 12:50:40 INFO TaskSetManager: Finished task 0.0 in stage 161.0 (TID 206) in 19 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:50:40 INFO TaskSchedulerImpl: Removed TaskSet 161.0, whose tasks have all completed, from pool 
20/02/14 12:50:40 INFO DAGScheduler: ResultStage 161 (collect at utils.scala:41) finished in 0.023 s
20/02/14 12:50:40 INFO DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:50:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 161: Stage finished
20/02/14 12:50:40 INFO DAGScheduler: Job 85 finished: collect at utils.scala:41, took 0.025769 s
20/02/14 12:50:46 INFO BlockManagerInfo: Removed broadcast_161_piece0 on 127.0.0.1:55441 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 12:50:46 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:50:46 INFO DAGScheduler: Registering RDD 879 (collect at arrowconverters.scala:270) as input to shuffle 76
20/02/14 12:50:46 INFO DAGScheduler: Got job 86 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/14 12:50:46 INFO DAGScheduler: Final stage: ResultStage 163 (collect at arrowconverters.scala:270)
20/02/14 12:50:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 162)
20/02/14 12:50:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 162)
20/02/14 12:50:46 INFO DAGScheduler: Submitting ShuffleMapStage 162 (MapPartitionsRDD[879] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:50:46 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 62.0 KiB, free 413.7 MiB)
20/02/14 12:50:46 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 21.6 KiB, free 413.7 MiB)
20/02/14 12:50:46 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 127.0.0.1:55441 (size: 21.6 KiB, free: 413.9 MiB)
20/02/14 12:50:46 INFO SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:1196
20/02/14 12:50:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 162 (MapPartitionsRDD[879] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:50:46 INFO TaskSchedulerImpl: Adding task set 162.0 with 1 tasks
20/02/14 12:50:46 INFO TaskSetManager: Starting task 0.0 in stage 162.0 (TID 207, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 8638 bytes)
20/02/14 12:50:46 INFO Executor: Running task 0.0 in stage 162.0 (TID 207)
20/02/14 12:50:46 INFO BlockManager: Found block rdd_10_0 locally
20/02/14 12:50:46 INFO Executor: Finished task 0.0 in stage 162.0 (TID 207). 2713 bytes result sent to driver
20/02/14 12:50:46 INFO TaskSetManager: Finished task 0.0 in stage 162.0 (TID 207) in 38 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:50:46 INFO TaskSchedulerImpl: Removed TaskSet 162.0, whose tasks have all completed, from pool 
20/02/14 12:50:46 INFO DAGScheduler: ShuffleMapStage 162 (collect at arrowconverters.scala:270) finished in 0.044 s
20/02/14 12:50:46 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:50:46 INFO DAGScheduler: running: Set()
20/02/14 12:50:46 INFO DAGScheduler: waiting: Set(ResultStage 163)
20/02/14 12:50:46 INFO DAGScheduler: failed: Set()
20/02/14 12:50:46 INFO DAGScheduler: Submitting ResultStage 163 (MapPartitionsRDD[885] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:50:46 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 58.8 KiB, free 413.6 MiB)
20/02/14 12:50:46 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 21.1 KiB, free 413.6 MiB)
20/02/14 12:50:46 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 127.0.0.1:55441 (size: 21.1 KiB, free: 413.8 MiB)
20/02/14 12:50:46 INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:1196
20/02/14 12:50:46 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 163 (MapPartitionsRDD[885] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 12:50:46 INFO TaskSchedulerImpl: Adding task set 163.0 with 4 tasks
20/02/14 12:50:46 INFO TaskSetManager: Starting task 0.0 in stage 163.0 (TID 208, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:50:46 INFO TaskSetManager: Starting task 1.0 in stage 163.0 (TID 209, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7248 bytes)
20/02/14 12:50:46 INFO TaskSetManager: Starting task 2.0 in stage 163.0 (TID 210, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7248 bytes)
20/02/14 12:50:46 INFO TaskSetManager: Starting task 3.0 in stage 163.0 (TID 211, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7248 bytes)
20/02/14 12:50:46 INFO Executor: Running task 0.0 in stage 163.0 (TID 208)
20/02/14 12:50:46 INFO Executor: Running task 2.0 in stage 163.0 (TID 210)
20/02/14 12:50:46 INFO Executor: Running task 3.0 in stage 163.0 (TID 211)
20/02/14 12:50:46 INFO Executor: Running task 1.0 in stage 163.0 (TID 209)
20/02/14 12:50:46 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:50:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:50:46 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:50:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:50:46 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:50:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
20/02/14 12:50:46 INFO ShuffleBlockFetcherIterator: Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:50:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:50:46 INFO BlockManagerInfo: Removed broadcast_162_piece0 on 127.0.0.1:55441 in memory (size: 21.6 KiB, free: 413.9 MiB)
20/02/14 12:50:46 INFO Executor: Finished task 3.0 in stage 163.0 (TID 211). 4458 bytes result sent to driver
20/02/14 12:50:46 INFO Executor: Finished task 0.0 in stage 163.0 (TID 208). 4483 bytes result sent to driver
20/02/14 12:50:46 INFO TaskSetManager: Finished task 3.0 in stage 163.0 (TID 211) in 53 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 12:50:46 INFO Executor: Finished task 1.0 in stage 163.0 (TID 209). 4498 bytes result sent to driver
20/02/14 12:50:46 INFO TaskSetManager: Finished task 0.0 in stage 163.0 (TID 208) in 53 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 12:50:46 INFO TaskSetManager: Finished task 1.0 in stage 163.0 (TID 209) in 53 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 12:50:46 INFO Executor: Finished task 2.0 in stage 163.0 (TID 210). 4547 bytes result sent to driver
20/02/14 12:50:46 INFO TaskSetManager: Finished task 2.0 in stage 163.0 (TID 210) in 57 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 12:50:46 INFO TaskSchedulerImpl: Removed TaskSet 163.0, whose tasks have all completed, from pool 
20/02/14 12:50:46 INFO DAGScheduler: ResultStage 163 (collect at arrowconverters.scala:270) finished in 0.064 s
20/02/14 12:50:46 INFO DAGScheduler: Job 86 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:50:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 163: Stage finished
20/02/14 12:50:46 INFO DAGScheduler: Job 86 finished: collect at arrowconverters.scala:270, took 0.117873 s
20/02/14 12:51:09 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 12:51:09 INFO DAGScheduler: Got job 87 (collect at utils.scala:41) with 1 output partitions
20/02/14 12:51:09 INFO DAGScheduler: Final stage: ResultStage 164 (collect at utils.scala:41)
20/02/14 12:51:09 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:51:09 INFO DAGScheduler: Missing parents: List()
20/02/14 12:51:09 INFO DAGScheduler: Submitting ResultStage 164 (MapPartitionsRDD[891] at map at utils.scala:41), which has no missing parents
20/02/14 12:51:09 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 8.8 KiB, free 413.7 MiB)
20/02/14 12:51:09 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.7 MiB)
20/02/14 12:51:09 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 127.0.0.1:55441 (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 12:51:09 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1196
20/02/14 12:51:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 164 (MapPartitionsRDD[891] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
20/02/14 12:51:09 INFO TaskSchedulerImpl: Adding task set 164.0 with 1 tasks
20/02/14 12:51:09 INFO TaskSetManager: Starting task 0.0 in stage 164.0 (TID 212, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7533 bytes)
20/02/14 12:51:09 INFO Executor: Running task 0.0 in stage 164.0 (TID 212)
20/02/14 12:51:09 INFO Executor: Finished task 0.0 in stage 164.0 (TID 212). 1026 bytes result sent to driver
20/02/14 12:51:09 INFO TaskSetManager: Finished task 0.0 in stage 164.0 (TID 212) in 6 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:51:09 INFO TaskSchedulerImpl: Removed TaskSet 164.0, whose tasks have all completed, from pool 
20/02/14 12:51:09 INFO DAGScheduler: ResultStage 164 (collect at utils.scala:41) finished in 0.014 s
20/02/14 12:51:09 INFO DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:51:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 164: Stage finished
20/02/14 12:51:09 INFO DAGScheduler: Job 87 finished: collect at utils.scala:41, took 0.016361 s
20/02/14 12:51:17 INFO BlockManagerInfo: Removed broadcast_164_piece0 on 127.0.0.1:55441 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 12:51:17 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 12:51:17 INFO DAGScheduler: Got job 88 (collect at utils.scala:41) with 1 output partitions
20/02/14 12:51:17 INFO DAGScheduler: Final stage: ResultStage 165 (collect at utils.scala:41)
20/02/14 12:51:17 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:51:17 INFO DAGScheduler: Missing parents: List()
20/02/14 12:51:17 INFO DAGScheduler: Submitting ResultStage 165 (MapPartitionsRDD[897] at map at utils.scala:41), which has no missing parents
20/02/14 12:51:17 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 8.8 KiB, free 413.7 MiB)
20/02/14 12:51:17 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.7 MiB)
20/02/14 12:51:17 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 127.0.0.1:55441 (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 12:51:17 INFO SparkContext: Created broadcast 165 from broadcast at DAGScheduler.scala:1196
20/02/14 12:51:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 165 (MapPartitionsRDD[897] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
20/02/14 12:51:17 INFO TaskSchedulerImpl: Adding task set 165.0 with 1 tasks
20/02/14 12:51:17 INFO TaskSetManager: Starting task 0.0 in stage 165.0 (TID 213, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7533 bytes)
20/02/14 12:51:17 INFO Executor: Running task 0.0 in stage 165.0 (TID 213)
20/02/14 12:51:17 INFO Executor: Finished task 0.0 in stage 165.0 (TID 213). 1069 bytes result sent to driver
20/02/14 12:51:17 INFO TaskSetManager: Finished task 0.0 in stage 165.0 (TID 213) in 4 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:51:17 INFO TaskSchedulerImpl: Removed TaskSet 165.0, whose tasks have all completed, from pool 
20/02/14 12:51:17 INFO DAGScheduler: ResultStage 165 (collect at utils.scala:41) finished in 0.008 s
20/02/14 12:51:17 INFO DAGScheduler: Job 88 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:51:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 165: Stage finished
20/02/14 12:51:17 INFO DAGScheduler: Job 88 finished: collect at utils.scala:41, took 0.011618 s
20/02/14 12:51:17 INFO BlockManagerInfo: Removed broadcast_165_piece0 on 127.0.0.1:55441 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 12:51:17 INFO MapPartitionsRDD: Removing RDD 10 from persistence list
20/02/14 12:51:17 INFO BlockManager: Removing RDD 10
20/02/14 12:51:18 INFO CodeGenerator: Code generated in 12.8399 ms
20/02/14 12:51:18 INFO CodeGenerator: Code generated in 14.1309 ms
20/02/14 12:51:18 INFO CodeGenerator: Code generated in 14.4535 ms
20/02/14 12:51:18 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/14 12:51:18 INFO DAGScheduler: Registering RDD 906 (sql at <unknown>:0) as input to shuffle 77
20/02/14 12:51:18 INFO DAGScheduler: Got job 89 (sql at <unknown>:0) with 1 output partitions
20/02/14 12:51:18 INFO DAGScheduler: Final stage: ResultStage 167 (sql at <unknown>:0)
20/02/14 12:51:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 166)
20/02/14 12:51:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 166)
20/02/14 12:51:18 INFO DAGScheduler: Submitting ShuffleMapStage 166 (MapPartitionsRDD[906] at sql at <unknown>:0), which has no missing parents
20/02/14 12:51:18 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 26.8 KiB, free 413.7 MiB)
20/02/14 12:51:18 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.7 MiB)
20/02/14 12:51:18 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 127.0.0.1:55441 (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 12:51:18 INFO SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:1196
20/02/14 12:51:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 166 (MapPartitionsRDD[906] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 12:51:18 INFO TaskSchedulerImpl: Adding task set 166.0 with 1 tasks
20/02/14 12:51:18 INFO TaskSetManager: Starting task 0.0 in stage 166.0 (TID 214, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 12:51:18 INFO Executor: Running task 0.0 in stage 166.0 (TID 214)
20/02/14 12:51:18 INFO BlockManagerInfo: Removed broadcast_155_piece0 on 127.0.0.1:55441 in memory (size: 21.1 KiB, free: 413.9 MiB)
20/02/14 12:51:18 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 127.0.0.1:55441 in memory (size: 21.1 KiB, free: 413.9 MiB)
20/02/14 12:51:18 INFO BlockManager: Removing RDD 10
20/02/14 12:51:18 INFO BlockManagerInfo: Removed broadcast_163_piece0 on 127.0.0.1:55441 in memory (size: 21.1 KiB, free: 413.9 MiB)
20/02/14 12:51:18 INFO MemoryStore: Block rdd_901_0 stored as values in memory (estimated size 3.9 KiB, free 413.9 MiB)
20/02/14 12:51:18 INFO BlockManagerInfo: Added rdd_901_0 in memory on 127.0.0.1:55441 (size: 3.9 KiB, free: 413.9 MiB)
20/02/14 12:51:18 INFO Executor: Finished task 0.0 in stage 166.0 (TID 214). 2326 bytes result sent to driver
20/02/14 12:51:18 INFO TaskSetManager: Finished task 0.0 in stage 166.0 (TID 214) in 219 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:51:18 INFO TaskSchedulerImpl: Removed TaskSet 166.0, whose tasks have all completed, from pool 
20/02/14 12:51:18 INFO DAGScheduler: ShuffleMapStage 166 (sql at <unknown>:0) finished in 0.327 s
20/02/14 12:51:18 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:51:18 INFO DAGScheduler: running: Set()
20/02/14 12:51:18 INFO DAGScheduler: waiting: Set(ResultStage 167)
20/02/14 12:51:18 INFO DAGScheduler: failed: Set()
20/02/14 12:51:18 INFO DAGScheduler: Submitting ResultStage 167 (MapPartitionsRDD[909] at sql at <unknown>:0), which has no missing parents
20/02/14 12:51:18 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/14 12:51:18 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
20/02/14 12:51:18 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 12:51:18 INFO SparkContext: Created broadcast 167 from broadcast at DAGScheduler.scala:1196
20/02/14 12:51:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 167 (MapPartitionsRDD[909] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 12:51:18 INFO TaskSchedulerImpl: Adding task set 167.0 with 1 tasks
20/02/14 12:51:18 INFO TaskSetManager: Starting task 0.0 in stage 167.0 (TID 215, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:51:18 INFO Executor: Running task 0.0 in stage 167.0 (TID 215)
20/02/14 12:51:18 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:51:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:51:18 INFO Executor: Finished task 0.0 in stage 167.0 (TID 215). 2760 bytes result sent to driver
20/02/14 12:51:18 INFO TaskSetManager: Finished task 0.0 in stage 167.0 (TID 215) in 6 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:51:18 INFO TaskSchedulerImpl: Removed TaskSet 167.0, whose tasks have all completed, from pool 
20/02/14 12:51:18 INFO DAGScheduler: ResultStage 167 (sql at <unknown>:0) finished in 0.010 s
20/02/14 12:51:18 INFO DAGScheduler: Job 89 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:51:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 167: Stage finished
20/02/14 12:51:18 INFO DAGScheduler: Job 89 finished: sql at <unknown>:0, took 0.345339 s
20/02/14 12:51:18 INFO BlockManagerInfo: Removed broadcast_167_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 12:51:18 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:51:18 INFO DAGScheduler: Registering RDD 914 (collect at arrowconverters.scala:270) as input to shuffle 78
20/02/14 12:51:18 INFO DAGScheduler: Got job 90 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:51:18 INFO DAGScheduler: Final stage: ResultStage 169 (collect at arrowconverters.scala:270)
20/02/14 12:51:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 168)
20/02/14 12:51:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 168)
20/02/14 12:51:18 INFO DAGScheduler: Submitting ShuffleMapStage 168 (MapPartitionsRDD[914] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:51:18 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 26.8 KiB, free 413.9 MiB)
20/02/14 12:51:18 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.8 MiB)
20/02/14 12:51:18 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 127.0.0.1:55441 (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 12:51:18 INFO SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:1196
20/02/14 12:51:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 168 (MapPartitionsRDD[914] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:51:18 INFO TaskSchedulerImpl: Adding task set 168.0 with 1 tasks
20/02/14 12:51:18 INFO TaskSetManager: Starting task 0.0 in stage 168.0 (TID 216, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 12:51:18 INFO Executor: Running task 0.0 in stage 168.0 (TID 216)
20/02/14 12:51:18 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 12:51:18 INFO Executor: Finished task 0.0 in stage 168.0 (TID 216). 2369 bytes result sent to driver
20/02/14 12:51:18 INFO TaskSetManager: Finished task 0.0 in stage 168.0 (TID 216) in 13 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:51:18 INFO TaskSchedulerImpl: Removed TaskSet 168.0, whose tasks have all completed, from pool 
20/02/14 12:51:18 INFO DAGScheduler: ShuffleMapStage 168 (collect at arrowconverters.scala:270) finished in 0.018 s
20/02/14 12:51:18 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:51:18 INFO DAGScheduler: running: Set()
20/02/14 12:51:18 INFO DAGScheduler: waiting: Set(ResultStage 169)
20/02/14 12:51:18 INFO DAGScheduler: failed: Set()
20/02/14 12:51:18 INFO DAGScheduler: Submitting ResultStage 169 (MapPartitionsRDD[920] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:51:18 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 36.7 KiB, free 413.8 MiB)
20/02/14 12:51:18 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 413.8 MiB)
20/02/14 12:51:18 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 127.0.0.1:55441 (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:51:18 INFO SparkContext: Created broadcast 169 from broadcast at DAGScheduler.scala:1196
20/02/14 12:51:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 169 (MapPartitionsRDD[920] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:51:18 INFO TaskSchedulerImpl: Adding task set 169.0 with 1 tasks
20/02/14 12:51:18 INFO TaskSetManager: Starting task 0.0 in stage 169.0 (TID 217, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:51:18 INFO Executor: Running task 0.0 in stage 169.0 (TID 217)
20/02/14 12:51:18 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:51:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:51:18 INFO CodeGenerator: Code generated in 5.7769 ms
20/02/14 12:51:18 INFO CodeGenerator: Code generated in 9.9416 ms
20/02/14 12:51:18 INFO Executor: Finished task 0.0 in stage 169.0 (TID 217). 4329 bytes result sent to driver
20/02/14 12:51:18 INFO TaskSetManager: Finished task 0.0 in stage 169.0 (TID 217) in 29 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:51:18 INFO TaskSchedulerImpl: Removed TaskSet 169.0, whose tasks have all completed, from pool 
20/02/14 12:51:18 INFO DAGScheduler: ResultStage 169 (collect at arrowconverters.scala:270) finished in 0.035 s
20/02/14 12:51:18 INFO DAGScheduler: Job 90 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:51:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 169: Stage finished
20/02/14 12:51:18 INFO DAGScheduler: Job 90 finished: collect at arrowconverters.scala:270, took 0.063179 s
20/02/14 12:51:18 INFO BlockManagerInfo: Removed broadcast_168_piece0 on 127.0.0.1:55441 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 12:51:19 INFO BlockManagerInfo: Removed broadcast_169_piece0 on 127.0.0.1:55441 in memory (size: 15.6 KiB, free: 413.9 MiB)
20/02/14 12:51:19 INFO CodeGenerator: Code generated in 4.9076 ms
20/02/14 12:51:19 INFO CodeGenerator: Code generated in 5.6941 ms
20/02/14 12:51:19 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:51:19 INFO DAGScheduler: Got job 91 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:51:19 INFO DAGScheduler: Final stage: ResultStage 170 (collect at arrowconverters.scala:270)
20/02/14 12:51:19 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:51:19 INFO DAGScheduler: Missing parents: List()
20/02/14 12:51:19 INFO DAGScheduler: Submitting ResultStage 170 (MapPartitionsRDD[926] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:51:19 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 11.1 KiB, free 413.9 MiB)
20/02/14 12:51:19 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
20/02/14 12:51:19 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 127.0.0.1:55441 (size: 5.2 KiB, free: 413.9 MiB)
20/02/14 12:51:19 INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:1196
20/02/14 12:51:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 170 (MapPartitionsRDD[926] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:51:19 INFO TaskSchedulerImpl: Adding task set 170.0 with 1 tasks
20/02/14 12:51:19 INFO TaskSetManager: Starting task 0.0 in stage 170.0 (TID 218, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7549 bytes)
20/02/14 12:51:19 INFO Executor: Running task 0.0 in stage 170.0 (TID 218)
20/02/14 12:51:19 INFO CodeGenerator: Code generated in 5.5372 ms
20/02/14 12:51:19 INFO CodeGenerator: Code generated in 14.3997 ms
20/02/14 12:51:19 INFO Executor: Finished task 0.0 in stage 170.0 (TID 218). 1543 bytes result sent to driver
20/02/14 12:51:19 INFO TaskSetManager: Finished task 0.0 in stage 170.0 (TID 218) in 69 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:51:19 INFO TaskSchedulerImpl: Removed TaskSet 170.0, whose tasks have all completed, from pool 
20/02/14 12:51:19 INFO DAGScheduler: ResultStage 170 (collect at arrowconverters.scala:270) finished in 0.075 s
20/02/14 12:51:19 INFO DAGScheduler: Job 91 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:51:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 170: Stage finished
20/02/14 12:51:19 INFO DAGScheduler: Job 91 finished: collect at arrowconverters.scala:270, took 0.077184 s
20/02/14 12:51:20 INFO BlockManagerInfo: Removed broadcast_170_piece0 on 127.0.0.1:55441 in memory (size: 5.2 KiB, free: 413.9 MiB)
20/02/14 12:51:20 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:51:20 INFO DAGScheduler: Registering RDD 931 (collect at arrowconverters.scala:270) as input to shuffle 79
20/02/14 12:51:20 INFO DAGScheduler: Got job 92 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/14 12:51:20 INFO DAGScheduler: Final stage: ResultStage 172 (collect at arrowconverters.scala:270)
20/02/14 12:51:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 171)
20/02/14 12:51:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 171)
20/02/14 12:51:20 INFO DAGScheduler: Submitting ShuffleMapStage 171 (MapPartitionsRDD[931] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:51:20 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 45.3 KiB, free 413.8 MiB)
20/02/14 12:51:20 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 18.3 KiB, free 413.8 MiB)
20/02/14 12:51:20 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 127.0.0.1:55441 (size: 18.3 KiB, free: 413.9 MiB)
20/02/14 12:51:20 INFO SparkContext: Created broadcast 171 from broadcast at DAGScheduler.scala:1196
20/02/14 12:51:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 171 (MapPartitionsRDD[931] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:51:20 INFO TaskSchedulerImpl: Adding task set 171.0 with 1 tasks
20/02/14 12:51:20 INFO TaskSetManager: Starting task 0.0 in stage 171.0 (TID 219, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 12:51:20 INFO Executor: Running task 0.0 in stage 171.0 (TID 219)
20/02/14 12:51:20 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 12:51:20 INFO Executor: Finished task 0.0 in stage 171.0 (TID 219). 2713 bytes result sent to driver
20/02/14 12:51:20 INFO TaskSetManager: Finished task 0.0 in stage 171.0 (TID 219) in 30 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:51:20 INFO TaskSchedulerImpl: Removed TaskSet 171.0, whose tasks have all completed, from pool 
20/02/14 12:51:20 INFO DAGScheduler: ShuffleMapStage 171 (collect at arrowconverters.scala:270) finished in 0.041 s
20/02/14 12:51:20 INFO DAGScheduler: looking for newly runnable stages
20/02/14 12:51:20 INFO DAGScheduler: running: Set()
20/02/14 12:51:20 INFO DAGScheduler: waiting: Set(ResultStage 172)
20/02/14 12:51:20 INFO DAGScheduler: failed: Set()
20/02/14 12:51:20 INFO DAGScheduler: Submitting ResultStage 172 (MapPartitionsRDD[937] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:51:20 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 42.4 KiB, free 413.8 MiB)
20/02/14 12:51:20 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 413.8 MiB)
20/02/14 12:51:20 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 127.0.0.1:55441 (size: 17.6 KiB, free: 413.9 MiB)
20/02/14 12:51:20 INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:1196
20/02/14 12:51:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 172 (MapPartitionsRDD[937] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 12:51:20 INFO TaskSchedulerImpl: Adding task set 172.0 with 4 tasks
20/02/14 12:51:20 INFO TaskSetManager: Starting task 0.0 in stage 172.0 (TID 220, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 12:51:20 INFO TaskSetManager: Starting task 1.0 in stage 172.0 (TID 221, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7248 bytes)
20/02/14 12:51:20 INFO TaskSetManager: Starting task 2.0 in stage 172.0 (TID 222, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7248 bytes)
20/02/14 12:51:20 INFO TaskSetManager: Starting task 3.0 in stage 172.0 (TID 223, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7248 bytes)
20/02/14 12:51:20 INFO Executor: Running task 0.0 in stage 172.0 (TID 220)
20/02/14 12:51:20 INFO Executor: Running task 2.0 in stage 172.0 (TID 222)
20/02/14 12:51:20 INFO Executor: Running task 3.0 in stage 172.0 (TID 223)
20/02/14 12:51:20 INFO Executor: Running task 1.0 in stage 172.0 (TID 221)
20/02/14 12:51:20 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:51:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:51:20 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:51:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:51:20 INFO ShuffleBlockFetcherIterator: Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:51:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:51:20 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 12:51:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 12:51:20 INFO Executor: Finished task 3.0 in stage 172.0 (TID 223). 4458 bytes result sent to driver
20/02/14 12:51:20 INFO Executor: Finished task 1.0 in stage 172.0 (TID 221). 4498 bytes result sent to driver
20/02/14 12:51:20 INFO BlockManagerInfo: Removed broadcast_171_piece0 on 127.0.0.1:55441 in memory (size: 18.3 KiB, free: 413.9 MiB)
20/02/14 12:51:20 INFO Executor: Finished task 2.0 in stage 172.0 (TID 222). 4547 bytes result sent to driver
20/02/14 12:51:20 INFO TaskSetManager: Finished task 3.0 in stage 172.0 (TID 223) in 54 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 12:51:20 INFO TaskSetManager: Finished task 2.0 in stage 172.0 (TID 222) in 55 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 12:51:20 INFO TaskSetManager: Finished task 1.0 in stage 172.0 (TID 221) in 55 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 12:51:20 INFO Executor: Finished task 0.0 in stage 172.0 (TID 220). 4483 bytes result sent to driver
20/02/14 12:51:20 INFO TaskSetManager: Finished task 0.0 in stage 172.0 (TID 220) in 65 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 12:51:20 INFO TaskSchedulerImpl: Removed TaskSet 172.0, whose tasks have all completed, from pool 
20/02/14 12:51:20 INFO DAGScheduler: ResultStage 172 (collect at arrowconverters.scala:270) finished in 0.071 s
20/02/14 12:51:20 INFO DAGScheduler: Job 92 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:51:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 172: Stage finished
20/02/14 12:51:20 INFO DAGScheduler: Job 92 finished: collect at arrowconverters.scala:270, took 0.118271 s
20/02/14 12:51:21 INFO BlockManagerInfo: Removed broadcast_172_piece0 on 127.0.0.1:55441 in memory (size: 17.6 KiB, free: 413.9 MiB)
20/02/14 12:51:21 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:51:21 INFO DAGScheduler: Got job 93 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:51:21 INFO DAGScheduler: Final stage: ResultStage 173 (collect at arrowconverters.scala:270)
20/02/14 12:51:21 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:51:21 INFO DAGScheduler: Missing parents: List()
20/02/14 12:51:21 INFO DAGScheduler: Submitting ResultStage 173 (MapPartitionsRDD[945] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:51:21 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 29.9 KiB, free 413.9 MiB)
20/02/14 12:51:21 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 413.8 MiB)
20/02/14 12:51:21 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 127.0.0.1:55441 (size: 11.2 KiB, free: 413.9 MiB)
20/02/14 12:51:21 INFO SparkContext: Created broadcast 173 from broadcast at DAGScheduler.scala:1196
20/02/14 12:51:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 173 (MapPartitionsRDD[945] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:51:21 INFO TaskSchedulerImpl: Adding task set 173.0 with 1 tasks
20/02/14 12:51:21 INFO TaskSetManager: Starting task 0.0 in stage 173.0 (TID 224, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 12:51:21 INFO Executor: Running task 0.0 in stage 173.0 (TID 224)
20/02/14 12:51:21 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 12:51:21 INFO Executor: Finished task 0.0 in stage 173.0 (TID 224). 2342 bytes result sent to driver
20/02/14 12:51:21 INFO TaskSetManager: Finished task 0.0 in stage 173.0 (TID 224) in 23 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:51:21 INFO TaskSchedulerImpl: Removed TaskSet 173.0, whose tasks have all completed, from pool 
20/02/14 12:51:21 INFO DAGScheduler: ResultStage 173 (collect at arrowconverters.scala:270) finished in 0.029 s
20/02/14 12:51:21 INFO DAGScheduler: Job 93 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:51:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 173: Stage finished
20/02/14 12:51:21 INFO DAGScheduler: Job 93 finished: collect at arrowconverters.scala:270, took 0.032910 s
20/02/14 12:52:02 INFO BlockManagerInfo: Removed broadcast_173_piece0 on 127.0.0.1:55441 in memory (size: 11.2 KiB, free: 413.9 MiB)
20/02/14 12:52:02 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:52:02 INFO DAGScheduler: Got job 94 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:52:02 INFO DAGScheduler: Final stage: ResultStage 174 (collect at arrowconverters.scala:270)
20/02/14 12:52:02 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:52:02 INFO DAGScheduler: Missing parents: List()
20/02/14 12:52:02 INFO DAGScheduler: Submitting ResultStage 174 (MapPartitionsRDD[953] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:52:02 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 29.9 KiB, free 413.9 MiB)
20/02/14 12:52:02 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 413.8 MiB)
20/02/14 12:52:02 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 127.0.0.1:55441 (size: 11.2 KiB, free: 413.9 MiB)
20/02/14 12:52:02 INFO SparkContext: Created broadcast 174 from broadcast at DAGScheduler.scala:1196
20/02/14 12:52:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 174 (MapPartitionsRDD[953] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:52:02 INFO TaskSchedulerImpl: Adding task set 174.0 with 1 tasks
20/02/14 12:52:02 INFO TaskSetManager: Starting task 0.0 in stage 174.0 (TID 225, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 12:52:02 INFO Executor: Running task 0.0 in stage 174.0 (TID 225)
20/02/14 12:52:02 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 12:52:02 INFO Executor: Finished task 0.0 in stage 174.0 (TID 225). 2342 bytes result sent to driver
20/02/14 12:52:02 INFO TaskSetManager: Finished task 0.0 in stage 174.0 (TID 225) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:52:02 INFO TaskSchedulerImpl: Removed TaskSet 174.0, whose tasks have all completed, from pool 
20/02/14 12:52:02 INFO DAGScheduler: ResultStage 174 (collect at arrowconverters.scala:270) finished in 0.025 s
20/02/14 12:52:02 INFO DAGScheduler: Job 94 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:52:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 174: Stage finished
20/02/14 12:52:02 INFO DAGScheduler: Job 94 finished: collect at arrowconverters.scala:270, took 0.028817 s
20/02/14 12:52:20 INFO BlockManagerInfo: Removed broadcast_174_piece0 on 127.0.0.1:55441 in memory (size: 11.2 KiB, free: 413.9 MiB)
20/02/14 12:52:20 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:52:20 INFO DAGScheduler: Got job 95 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:52:20 INFO DAGScheduler: Final stage: ResultStage 175 (collect at arrowconverters.scala:270)
20/02/14 12:52:20 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:52:20 INFO DAGScheduler: Missing parents: List()
20/02/14 12:52:20 INFO DAGScheduler: Submitting ResultStage 175 (MapPartitionsRDD[961] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:52:20 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 29.9 KiB, free 413.9 MiB)
20/02/14 12:52:20 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 413.8 MiB)
20/02/14 12:52:20 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 127.0.0.1:55441 (size: 11.2 KiB, free: 413.9 MiB)
20/02/14 12:52:20 INFO SparkContext: Created broadcast 175 from broadcast at DAGScheduler.scala:1196
20/02/14 12:52:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 175 (MapPartitionsRDD[961] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:52:20 INFO TaskSchedulerImpl: Adding task set 175.0 with 1 tasks
20/02/14 12:52:20 INFO TaskSetManager: Starting task 0.0 in stage 175.0 (TID 226, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 12:52:20 INFO Executor: Running task 0.0 in stage 175.0 (TID 226)
20/02/14 12:52:20 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 12:52:20 INFO Executor: Finished task 0.0 in stage 175.0 (TID 226). 2342 bytes result sent to driver
20/02/14 12:52:20 INFO TaskSetManager: Finished task 0.0 in stage 175.0 (TID 226) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:52:20 INFO TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool 
20/02/14 12:52:20 INFO DAGScheduler: ResultStage 175 (collect at arrowconverters.scala:270) finished in 0.027 s
20/02/14 12:52:20 INFO DAGScheduler: Job 95 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:52:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 175: Stage finished
20/02/14 12:52:20 INFO DAGScheduler: Job 95 finished: collect at arrowconverters.scala:270, took 0.031523 s
20/02/14 12:52:31 INFO BlockManagerInfo: Removed broadcast_175_piece0 on 127.0.0.1:55441 in memory (size: 11.2 KiB, free: 413.9 MiB)
20/02/14 12:52:31 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 12:52:31 INFO DAGScheduler: Got job 96 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 12:52:31 INFO DAGScheduler: Final stage: ResultStage 176 (collect at arrowconverters.scala:270)
20/02/14 12:52:31 INFO DAGScheduler: Parents of final stage: List()
20/02/14 12:52:31 INFO DAGScheduler: Missing parents: List()
20/02/14 12:52:31 INFO DAGScheduler: Submitting ResultStage 176 (MapPartitionsRDD[969] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 12:52:31 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 29.9 KiB, free 413.9 MiB)
20/02/14 12:52:31 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 413.8 MiB)
20/02/14 12:52:31 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 127.0.0.1:55441 (size: 11.2 KiB, free: 413.9 MiB)
20/02/14 12:52:31 INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1196
20/02/14 12:52:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 176 (MapPartitionsRDD[969] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 12:52:31 INFO TaskSchedulerImpl: Adding task set 176.0 with 1 tasks
20/02/14 12:52:31 INFO TaskSetManager: Starting task 0.0 in stage 176.0 (TID 227, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 12:52:31 INFO Executor: Running task 0.0 in stage 176.0 (TID 227)
20/02/14 12:52:31 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 12:52:31 INFO Executor: Finished task 0.0 in stage 176.0 (TID 227). 2342 bytes result sent to driver
20/02/14 12:52:31 INFO TaskSetManager: Finished task 0.0 in stage 176.0 (TID 227) in 22 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 12:52:31 INFO TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have all completed, from pool 
20/02/14 12:52:31 INFO DAGScheduler: ResultStage 176 (collect at arrowconverters.scala:270) finished in 0.030 s
20/02/14 12:52:31 INFO DAGScheduler: Job 96 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 12:52:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 176: Stage finished
20/02/14 12:52:31 INFO DAGScheduler: Job 96 finished: collect at arrowconverters.scala:270, took 0.034526 s
20/02/14 13:02:57 INFO BlockManagerInfo: Removed broadcast_166_piece0 on 127.0.0.1:55441 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 13:02:57 INFO BlockManagerInfo: Removed broadcast_176_piece0 on 127.0.0.1:55441 in memory (size: 11.2 KiB, free: 413.9 MiB)
20/02/14 14:13:49 INFO Instrumentation: [468ca575] training finished
20/02/14 14:13:50 INFO Instrumentation: [7b2cd071] training finished
20/02/14 14:13:50 INFO CodeGenerator: Code generated in 116.5071 ms
20/02/14 14:13:50 INFO SparkContext: Starting job: first at LinearRegression.scala:321
20/02/14 14:13:50 INFO DAGScheduler: Got job 97 (first at LinearRegression.scala:321) with 1 output partitions
20/02/14 14:13:50 INFO DAGScheduler: Final stage: ResultStage 177 (first at LinearRegression.scala:321)
20/02/14 14:13:50 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:13:50 INFO DAGScheduler: Missing parents: List()
20/02/14 14:13:50 INFO DAGScheduler: Submitting ResultStage 177 (MapPartitionsRDD[974] at first at LinearRegression.scala:321), which has no missing parents
20/02/14 14:13:50 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 36.0 KiB, free 413.9 MiB)
20/02/14 14:13:50 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 413.9 MiB)
20/02/14 14:13:50 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 127.0.0.1:55441 (size: 13.4 KiB, free: 413.9 MiB)
20/02/14 14:13:50 INFO SparkContext: Created broadcast 177 from broadcast at DAGScheduler.scala:1196
20/02/14 14:13:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 177 (MapPartitionsRDD[974] at first at LinearRegression.scala:321) (first 15 tasks are for partitions Vector(0))
20/02/14 14:13:50 INFO TaskSchedulerImpl: Adding task set 177.0 with 1 tasks
20/02/14 14:13:50 INFO TaskSetManager: Starting task 0.0 in stage 177.0 (TID 228, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 14:13:50 INFO Executor: Running task 0.0 in stage 177.0 (TID 228)
20/02/14 14:13:50 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:13:50 INFO Executor: 1 block locks were not released by TID = 228:
[rdd_901_0]
20/02/14 14:13:50 INFO Executor: Finished task 0.0 in stage 177.0 (TID 228). 1881 bytes result sent to driver
20/02/14 14:13:50 INFO TaskSetManager: Finished task 0.0 in stage 177.0 (TID 228) in 186 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:13:50 INFO TaskSchedulerImpl: Removed TaskSet 177.0, whose tasks have all completed, from pool 
20/02/14 14:13:50 INFO DAGScheduler: ResultStage 177 (first at LinearRegression.scala:321) finished in 0.226 s
20/02/14 14:13:50 INFO DAGScheduler: Job 97 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:13:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 177: Stage finished
20/02/14 14:13:50 INFO DAGScheduler: Job 97 finished: first at LinearRegression.scala:321, took 0.230805 s
20/02/14 14:13:50 INFO CodeGenerator: Code generated in 12.1325 ms
20/02/14 14:13:50 INFO BlockManagerInfo: Removed broadcast_177_piece0 on 127.0.0.1:55441 in memory (size: 13.4 KiB, free: 413.9 MiB)
20/02/14 14:13:50 INFO CodeGenerator: Code generated in 26.5369 ms
20/02/14 14:13:50 INFO Instrumentation: [7ddddfcb] Stage class: LinearRegression
20/02/14 14:13:50 INFO Instrumentation: [7ddddfcb] Stage uid: linear_regression_2b785f5661da
20/02/14 14:13:50 INFO CodeGenerator: Code generated in 33.5298 ms
20/02/14 14:13:51 INFO Instrumentation: [7ddddfcb] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
20/02/14 14:13:51 INFO Instrumentation: [7ddddfcb] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
20/02/14 14:13:51 INFO Instrumentation: [7ddddfcb] {"numFeatures":1}
20/02/14 14:13:51 WARN Instrumentation: [7ddddfcb] regParam is zero, which might cause numerical instability and overfitting.
20/02/14 14:13:51 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:105
20/02/14 14:13:51 INFO DAGScheduler: Got job 98 (treeAggregate at WeightedLeastSquares.scala:105) with 1 output partitions
20/02/14 14:13:51 INFO DAGScheduler: Final stage: ResultStage 178 (treeAggregate at WeightedLeastSquares.scala:105)
20/02/14 14:13:51 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:13:51 INFO DAGScheduler: Missing parents: List()
20/02/14 14:13:51 INFO DAGScheduler: Submitting ResultStage 178 (MapPartitionsRDD[990] at treeAggregate at WeightedLeastSquares.scala:105), which has no missing parents
20/02/14 14:13:51 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 44.5 KiB, free 413.9 MiB)
20/02/14 14:13:51 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 413.9 MiB)
20/02/14 14:13:51 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 127.0.0.1:55441 (size: 17.4 KiB, free: 413.9 MiB)
20/02/14 14:13:51 INFO SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:1196
20/02/14 14:13:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 178 (MapPartitionsRDD[990] at treeAggregate at WeightedLeastSquares.scala:105) (first 15 tasks are for partitions Vector(0))
20/02/14 14:13:51 INFO TaskSchedulerImpl: Adding task set 178.0 with 1 tasks
20/02/14 14:13:51 INFO TaskSetManager: Starting task 0.0 in stage 178.0 (TID 229, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 14:13:51 INFO Executor: Running task 0.0 in stage 178.0 (TID 229)
20/02/14 14:13:51 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:13:51 INFO CodeGenerator: Code generated in 8.2901 ms
20/02/14 14:13:51 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
20/02/14 14:13:51 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
20/02/14 14:13:51 INFO Executor: Finished task 0.0 in stage 178.0 (TID 229). 2082 bytes result sent to driver
20/02/14 14:13:51 INFO TaskSetManager: Finished task 0.0 in stage 178.0 (TID 229) in 205 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:13:51 INFO TaskSchedulerImpl: Removed TaskSet 178.0, whose tasks have all completed, from pool 
20/02/14 14:13:51 INFO DAGScheduler: ResultStage 178 (treeAggregate at WeightedLeastSquares.scala:105) finished in 0.247 s
20/02/14 14:13:51 INFO DAGScheduler: Job 98 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:13:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 178: Stage finished
20/02/14 14:13:51 INFO DAGScheduler: Job 98 finished: treeAggregate at WeightedLeastSquares.scala:105, took 0.253387 s
20/02/14 14:13:51 INFO Instrumentation: [7ddddfcb] Number of instances: 32.
20/02/14 14:13:51 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
20/02/14 14:13:51 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
20/02/14 14:13:51 INFO BlockManagerInfo: Removed broadcast_178_piece0 on 127.0.0.1:55441 in memory (size: 17.4 KiB, free: 413.9 MiB)
20/02/14 14:13:52 INFO CodeGenerator: Code generated in 20.6422 ms
20/02/14 14:13:52 INFO SparkContext: Starting job: treeAggregate at RegressionMetrics.scala:68
20/02/14 14:13:52 INFO DAGScheduler: Got job 99 (treeAggregate at RegressionMetrics.scala:68) with 1 output partitions
20/02/14 14:13:52 INFO DAGScheduler: Final stage: ResultStage 179 (treeAggregate at RegressionMetrics.scala:68)
20/02/14 14:13:52 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:13:52 INFO DAGScheduler: Missing parents: List()
20/02/14 14:13:52 INFO DAGScheduler: Submitting ResultStage 179 (MapPartitionsRDD[1000] at treeAggregate at RegressionMetrics.scala:68), which has no missing parents
20/02/14 14:13:52 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 46.2 KiB, free 413.9 MiB)
20/02/14 14:13:52 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 413.9 MiB)
20/02/14 14:13:52 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on 127.0.0.1:55441 (size: 18.9 KiB, free: 413.9 MiB)
20/02/14 14:13:52 INFO SparkContext: Created broadcast 179 from broadcast at DAGScheduler.scala:1196
20/02/14 14:13:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 179 (MapPartitionsRDD[1000] at treeAggregate at RegressionMetrics.scala:68) (first 15 tasks are for partitions Vector(0))
20/02/14 14:13:52 INFO TaskSchedulerImpl: Adding task set 179.0 with 1 tasks
20/02/14 14:13:52 INFO TaskSetManager: Starting task 0.0 in stage 179.0 (TID 230, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 14:13:52 INFO Executor: Running task 0.0 in stage 179.0 (TID 230)
20/02/14 14:13:52 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:13:52 INFO CodeGenerator: Code generated in 10.1898 ms
20/02/14 14:13:52 INFO Executor: Finished task 0.0 in stage 179.0 (TID 230). 2199 bytes result sent to driver
20/02/14 14:13:52 INFO TaskSetManager: Finished task 0.0 in stage 179.0 (TID 230) in 93 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:13:52 INFO TaskSchedulerImpl: Removed TaskSet 179.0, whose tasks have all completed, from pool 
20/02/14 14:13:52 INFO DAGScheduler: ResultStage 179 (treeAggregate at RegressionMetrics.scala:68) finished in 0.105 s
20/02/14 14:13:52 INFO DAGScheduler: Job 99 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:13:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 179: Stage finished
20/02/14 14:13:52 INFO DAGScheduler: Job 99 finished: treeAggregate at RegressionMetrics.scala:68, took 0.111227 s
20/02/14 14:13:52 INFO BlockManagerInfo: Removed broadcast_179_piece0 on 127.0.0.1:55441 in memory (size: 18.9 KiB, free: 413.9 MiB)
20/02/14 14:13:52 INFO SparkContext: Starting job: count at LinearRegression.scala:930
20/02/14 14:13:52 INFO DAGScheduler: Registering RDD 1005 (count at LinearRegression.scala:930) as input to shuffle 80
20/02/14 14:13:52 INFO DAGScheduler: Got job 100 (count at LinearRegression.scala:930) with 1 output partitions
20/02/14 14:13:52 INFO DAGScheduler: Final stage: ResultStage 181 (count at LinearRegression.scala:930)
20/02/14 14:13:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 180)
20/02/14 14:13:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 180)
20/02/14 14:13:52 INFO DAGScheduler: Submitting ShuffleMapStage 180 (MapPartitionsRDD[1005] at count at LinearRegression.scala:930), which has no missing parents
20/02/14 14:13:52 INFO MemoryStore: Block broadcast_180 stored as values in memory (estimated size 26.9 KiB, free 413.9 MiB)
20/02/14 14:13:52 INFO MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 413.9 MiB)
20/02/14 14:13:52 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on 127.0.0.1:55441 (size: 10.9 KiB, free: 413.9 MiB)
20/02/14 14:13:52 INFO SparkContext: Created broadcast 180 from broadcast at DAGScheduler.scala:1196
20/02/14 14:13:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 180 (MapPartitionsRDD[1005] at count at LinearRegression.scala:930) (first 15 tasks are for partitions Vector(0))
20/02/14 14:13:52 INFO TaskSchedulerImpl: Adding task set 180.0 with 1 tasks
20/02/14 14:13:52 INFO TaskSetManager: Starting task 0.0 in stage 180.0 (TID 231, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 14:13:52 INFO Executor: Running task 0.0 in stage 180.0 (TID 231)
20/02/14 14:13:52 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:13:52 INFO Executor: Finished task 0.0 in stage 180.0 (TID 231). 2326 bytes result sent to driver
20/02/14 14:13:52 INFO TaskSetManager: Finished task 0.0 in stage 180.0 (TID 231) in 30 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:13:52 INFO TaskSchedulerImpl: Removed TaskSet 180.0, whose tasks have all completed, from pool 
20/02/14 14:13:52 INFO DAGScheduler: ShuffleMapStage 180 (count at LinearRegression.scala:930) finished in 0.038 s
20/02/14 14:13:52 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:13:52 INFO DAGScheduler: running: Set()
20/02/14 14:13:52 INFO DAGScheduler: waiting: Set(ResultStage 181)
20/02/14 14:13:52 INFO DAGScheduler: failed: Set()
20/02/14 14:13:52 INFO DAGScheduler: Submitting ResultStage 181 (MapPartitionsRDD[1008] at count at LinearRegression.scala:930), which has no missing parents
20/02/14 14:13:52 INFO MemoryStore: Block broadcast_181 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/14 14:13:52 INFO MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
20/02/14 14:13:52 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:13:52 INFO SparkContext: Created broadcast 181 from broadcast at DAGScheduler.scala:1196
20/02/14 14:13:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 181 (MapPartitionsRDD[1008] at count at LinearRegression.scala:930) (first 15 tasks are for partitions Vector(0))
20/02/14 14:13:52 INFO TaskSchedulerImpl: Adding task set 181.0 with 1 tasks
20/02/14 14:13:52 INFO TaskSetManager: Starting task 0.0 in stage 181.0 (TID 232, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:13:52 INFO Executor: Running task 0.0 in stage 181.0 (TID 232)
20/02/14 14:13:52 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:13:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:13:52 INFO Executor: Finished task 0.0 in stage 181.0 (TID 232). 2803 bytes result sent to driver
20/02/14 14:13:52 INFO TaskSetManager: Finished task 0.0 in stage 181.0 (TID 232) in 7 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:13:52 INFO TaskSchedulerImpl: Removed TaskSet 181.0, whose tasks have all completed, from pool 
20/02/14 14:13:52 INFO DAGScheduler: ResultStage 181 (count at LinearRegression.scala:930) finished in 0.018 s
20/02/14 14:13:52 INFO DAGScheduler: Job 100 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:13:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 181: Stage finished
20/02/14 14:13:52 INFO DAGScheduler: Job 100 finished: count at LinearRegression.scala:930, took 0.062394 s
20/02/14 14:13:52 INFO Instrumentation: [408f236b] training finished
20/02/14 14:13:52 INFO Instrumentation: [f5fcb317] training finished
20/02/14 14:13:53 INFO BlockManagerInfo: Removed broadcast_181_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:13:53 INFO BlockManagerInfo: Removed broadcast_180_piece0 on 127.0.0.1:55441 in memory (size: 10.9 KiB, free: 413.9 MiB)
20/02/14 14:14:02 INFO SparkContext: Starting job: count at <unknown>:0
20/02/14 14:14:02 INFO DAGScheduler: Registering RDD 1013 (count at <unknown>:0) as input to shuffle 81
20/02/14 14:14:02 INFO DAGScheduler: Got job 101 (count at <unknown>:0) with 1 output partitions
20/02/14 14:14:02 INFO DAGScheduler: Final stage: ResultStage 183 (count at <unknown>:0)
20/02/14 14:14:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 182)
20/02/14 14:14:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 182)
20/02/14 14:14:02 INFO DAGScheduler: Submitting ShuffleMapStage 182 (MapPartitionsRDD[1013] at count at <unknown>:0), which has no missing parents
20/02/14 14:14:02 INFO MemoryStore: Block broadcast_182 stored as values in memory (estimated size 26.8 KiB, free 413.9 MiB)
20/02/14 14:14:02 INFO MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 413.9 MiB)
20/02/14 14:14:02 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on 127.0.0.1:55441 (size: 10.9 KiB, free: 413.9 MiB)
20/02/14 14:14:02 INFO SparkContext: Created broadcast 182 from broadcast at DAGScheduler.scala:1196
20/02/14 14:14:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 182 (MapPartitionsRDD[1013] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:14:02 INFO TaskSchedulerImpl: Adding task set 182.0 with 1 tasks
20/02/14 14:14:02 INFO TaskSetManager: Starting task 0.0 in stage 182.0 (TID 233, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 14:14:02 INFO Executor: Running task 0.0 in stage 182.0 (TID 233)
20/02/14 14:14:02 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:14:02 INFO Executor: Finished task 0.0 in stage 182.0 (TID 233). 2369 bytes result sent to driver
20/02/14 14:14:02 INFO TaskSetManager: Finished task 0.0 in stage 182.0 (TID 233) in 14 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:14:02 INFO TaskSchedulerImpl: Removed TaskSet 182.0, whose tasks have all completed, from pool 
20/02/14 14:14:02 INFO DAGScheduler: ShuffleMapStage 182 (count at <unknown>:0) finished in 0.022 s
20/02/14 14:14:02 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:14:02 INFO DAGScheduler: running: Set()
20/02/14 14:14:02 INFO DAGScheduler: waiting: Set(ResultStage 183)
20/02/14 14:14:02 INFO DAGScheduler: failed: Set()
20/02/14 14:14:02 INFO DAGScheduler: Submitting ResultStage 183 (MapPartitionsRDD[1016] at count at <unknown>:0), which has no missing parents
20/02/14 14:14:02 INFO MemoryStore: Block broadcast_183 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/14 14:14:02 INFO MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
20/02/14 14:14:02 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:14:02 INFO SparkContext: Created broadcast 183 from broadcast at DAGScheduler.scala:1196
20/02/14 14:14:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 183 (MapPartitionsRDD[1016] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:14:02 INFO TaskSchedulerImpl: Adding task set 183.0 with 1 tasks
20/02/14 14:14:02 INFO TaskSetManager: Starting task 0.0 in stage 183.0 (TID 234, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:14:02 INFO Executor: Running task 0.0 in stage 183.0 (TID 234)
20/02/14 14:14:02 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:14:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:14:02 INFO Executor: Finished task 0.0 in stage 183.0 (TID 234). 2760 bytes result sent to driver
20/02/14 14:14:02 INFO TaskSetManager: Finished task 0.0 in stage 183.0 (TID 234) in 7 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:14:02 INFO TaskSchedulerImpl: Removed TaskSet 183.0, whose tasks have all completed, from pool 
20/02/14 14:14:02 INFO DAGScheduler: ResultStage 183 (count at <unknown>:0) finished in 0.017 s
20/02/14 14:14:02 INFO DAGScheduler: Job 101 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:14:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 183: Stage finished
20/02/14 14:14:02 INFO DAGScheduler: Job 101 finished: count at <unknown>:0, took 0.046016 s
20/02/14 14:14:02 INFO BlockManagerInfo: Removed broadcast_183_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:14:02 INFO BlockManagerInfo: Removed broadcast_182_piece0 on 127.0.0.1:55441 in memory (size: 10.9 KiB, free: 413.9 MiB)
20/02/14 14:14:02 INFO CodeGenerator: Code generated in 19.0351 ms
20/02/14 14:14:02 INFO SparkContext: Starting job: collect at utils.scala:34
20/02/14 14:14:02 INFO DAGScheduler: Got job 102 (collect at utils.scala:34) with 1 output partitions
20/02/14 14:14:02 INFO DAGScheduler: Final stage: ResultStage 184 (collect at utils.scala:34)
20/02/14 14:14:02 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:14:02 INFO DAGScheduler: Missing parents: List()
20/02/14 14:14:02 INFO DAGScheduler: Submitting ResultStage 184 (MapPartitionsRDD[1024] at map at utils.scala:34), which has no missing parents
20/02/14 14:14:02 INFO MemoryStore: Block broadcast_184 stored as values in memory (estimated size 46.8 KiB, free 413.9 MiB)
20/02/14 14:14:02 INFO MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 19.3 KiB, free 413.9 MiB)
20/02/14 14:14:02 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on 127.0.0.1:55441 (size: 19.3 KiB, free: 413.9 MiB)
20/02/14 14:14:02 INFO SparkContext: Created broadcast 184 from broadcast at DAGScheduler.scala:1196
20/02/14 14:14:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 184 (MapPartitionsRDD[1024] at map at utils.scala:34) (first 15 tasks are for partitions Vector(0))
20/02/14 14:14:02 INFO TaskSchedulerImpl: Adding task set 184.0 with 1 tasks
20/02/14 14:14:02 INFO TaskSetManager: Starting task 0.0 in stage 184.0 (TID 235, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 14:14:02 INFO Executor: Running task 0.0 in stage 184.0 (TID 235)
20/02/14 14:14:02 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:14:02 INFO CodeGenerator: Code generated in 5.6538 ms
20/02/14 14:14:02 INFO Executor: Finished task 0.0 in stage 184.0 (TID 235). 1908 bytes result sent to driver
20/02/14 14:14:02 INFO TaskSetManager: Finished task 0.0 in stage 184.0 (TID 235) in 24 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:14:02 INFO TaskSchedulerImpl: Removed TaskSet 184.0, whose tasks have all completed, from pool 
20/02/14 14:14:02 INFO DAGScheduler: ResultStage 184 (collect at utils.scala:34) finished in 0.032 s
20/02/14 14:14:02 INFO DAGScheduler: Job 102 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:14:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 184: Stage finished
20/02/14 14:14:02 INFO DAGScheduler: Job 102 finished: collect at utils.scala:34, took 0.036320 s
20/02/14 14:14:11 INFO BlockManagerInfo: Removed broadcast_184_piece0 on 127.0.0.1:55441 in memory (size: 19.3 KiB, free: 413.9 MiB)
20/02/14 14:14:11 INFO SparkContext: Starting job: count at <unknown>:0
20/02/14 14:14:11 INFO DAGScheduler: Registering RDD 1029 (count at <unknown>:0) as input to shuffle 82
20/02/14 14:14:11 INFO DAGScheduler: Got job 103 (count at <unknown>:0) with 1 output partitions
20/02/14 14:14:11 INFO DAGScheduler: Final stage: ResultStage 186 (count at <unknown>:0)
20/02/14 14:14:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 185)
20/02/14 14:14:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 185)
20/02/14 14:14:11 INFO DAGScheduler: Submitting ShuffleMapStage 185 (MapPartitionsRDD[1029] at count at <unknown>:0), which has no missing parents
20/02/14 14:14:11 INFO MemoryStore: Block broadcast_185 stored as values in memory (estimated size 26.8 KiB, free 413.9 MiB)
20/02/14 14:14:11 INFO MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.9 MiB)
20/02/14 14:14:11 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on 127.0.0.1:55441 (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 14:14:11 INFO SparkContext: Created broadcast 185 from broadcast at DAGScheduler.scala:1196
20/02/14 14:14:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 185 (MapPartitionsRDD[1029] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:14:11 INFO TaskSchedulerImpl: Adding task set 185.0 with 1 tasks
20/02/14 14:14:11 INFO TaskSetManager: Starting task 0.0 in stage 185.0 (TID 236, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 14:14:11 INFO Executor: Running task 0.0 in stage 185.0 (TID 236)
20/02/14 14:14:11 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:14:11 INFO Executor: Finished task 0.0 in stage 185.0 (TID 236). 2369 bytes result sent to driver
20/02/14 14:14:11 INFO TaskSetManager: Finished task 0.0 in stage 185.0 (TID 236) in 14 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:14:11 INFO TaskSchedulerImpl: Removed TaskSet 185.0, whose tasks have all completed, from pool 
20/02/14 14:14:11 INFO DAGScheduler: ShuffleMapStage 185 (count at <unknown>:0) finished in 0.020 s
20/02/14 14:14:11 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:14:11 INFO DAGScheduler: running: Set()
20/02/14 14:14:11 INFO DAGScheduler: waiting: Set(ResultStage 186)
20/02/14 14:14:11 INFO DAGScheduler: failed: Set()
20/02/14 14:14:11 INFO DAGScheduler: Submitting ResultStage 186 (MapPartitionsRDD[1032] at count at <unknown>:0), which has no missing parents
20/02/14 14:14:11 INFO MemoryStore: Block broadcast_186 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/14 14:14:11 INFO MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
20/02/14 14:14:11 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:14:11 INFO SparkContext: Created broadcast 186 from broadcast at DAGScheduler.scala:1196
20/02/14 14:14:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 186 (MapPartitionsRDD[1032] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:14:11 INFO TaskSchedulerImpl: Adding task set 186.0 with 1 tasks
20/02/14 14:14:11 INFO TaskSetManager: Starting task 0.0 in stage 186.0 (TID 237, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:14:11 INFO Executor: Running task 0.0 in stage 186.0 (TID 237)
20/02/14 14:14:11 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:14:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:14:11 INFO Executor: Finished task 0.0 in stage 186.0 (TID 237). 2760 bytes result sent to driver
20/02/14 14:14:11 INFO TaskSetManager: Finished task 0.0 in stage 186.0 (TID 237) in 6 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:14:11 INFO TaskSchedulerImpl: Removed TaskSet 186.0, whose tasks have all completed, from pool 
20/02/14 14:14:11 INFO DAGScheduler: ResultStage 186 (count at <unknown>:0) finished in 0.016 s
20/02/14 14:14:11 INFO DAGScheduler: Job 103 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:14:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 186: Stage finished
20/02/14 14:14:11 INFO DAGScheduler: Job 103 finished: count at <unknown>:0, took 0.042772 s
20/02/14 14:14:11 INFO BlockManagerInfo: Removed broadcast_186_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:14:11 INFO BlockManagerInfo: Removed broadcast_185_piece0 on 127.0.0.1:55441 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 14:14:12 INFO SparkContext: Starting job: collect at utils.scala:34
20/02/14 14:14:12 INFO DAGScheduler: Got job 104 (collect at utils.scala:34) with 1 output partitions
20/02/14 14:14:12 INFO DAGScheduler: Final stage: ResultStage 187 (collect at utils.scala:34)
20/02/14 14:14:12 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:14:12 INFO DAGScheduler: Missing parents: List()
20/02/14 14:14:12 INFO DAGScheduler: Submitting ResultStage 187 (MapPartitionsRDD[1040] at map at utils.scala:34), which has no missing parents
20/02/14 14:14:12 INFO MemoryStore: Block broadcast_187 stored as values in memory (estimated size 46.8 KiB, free 413.9 MiB)
20/02/14 14:14:12 INFO MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 19.3 KiB, free 413.9 MiB)
20/02/14 14:14:12 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on 127.0.0.1:55441 (size: 19.3 KiB, free: 413.9 MiB)
20/02/14 14:14:12 INFO SparkContext: Created broadcast 187 from broadcast at DAGScheduler.scala:1196
20/02/14 14:14:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 187 (MapPartitionsRDD[1040] at map at utils.scala:34) (first 15 tasks are for partitions Vector(0))
20/02/14 14:14:12 INFO TaskSchedulerImpl: Adding task set 187.0 with 1 tasks
20/02/14 14:14:12 INFO TaskSetManager: Starting task 0.0 in stage 187.0 (TID 238, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 14:14:12 INFO Executor: Running task 0.0 in stage 187.0 (TID 238)
20/02/14 14:14:12 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:14:12 INFO Executor: Finished task 0.0 in stage 187.0 (TID 238). 1865 bytes result sent to driver
20/02/14 14:14:12 INFO TaskSetManager: Finished task 0.0 in stage 187.0 (TID 238) in 12 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:14:12 INFO TaskSchedulerImpl: Removed TaskSet 187.0, whose tasks have all completed, from pool 
20/02/14 14:14:12 INFO DAGScheduler: ResultStage 187 (collect at utils.scala:34) finished in 0.020 s
20/02/14 14:14:12 INFO DAGScheduler: Job 104 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:14:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 187: Stage finished
20/02/14 14:14:12 INFO DAGScheduler: Job 104 finished: collect at utils.scala:34, took 0.024117 s
20/02/14 14:14:23 INFO BlockManagerInfo: Removed broadcast_187_piece0 on 127.0.0.1:55441 in memory (size: 19.3 KiB, free: 413.9 MiB)
20/02/14 14:14:23 INFO SparkContext: Starting job: count at <unknown>:0
20/02/14 14:14:23 INFO DAGScheduler: Registering RDD 1045 (count at <unknown>:0) as input to shuffle 83
20/02/14 14:14:23 INFO DAGScheduler: Got job 105 (count at <unknown>:0) with 1 output partitions
20/02/14 14:14:23 INFO DAGScheduler: Final stage: ResultStage 189 (count at <unknown>:0)
20/02/14 14:14:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 188)
20/02/14 14:14:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 188)
20/02/14 14:14:23 INFO DAGScheduler: Submitting ShuffleMapStage 188 (MapPartitionsRDD[1045] at count at <unknown>:0), which has no missing parents
20/02/14 14:14:23 INFO MemoryStore: Block broadcast_188 stored as values in memory (estimated size 26.8 KiB, free 413.9 MiB)
20/02/14 14:14:23 INFO MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.9 MiB)
20/02/14 14:14:23 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on 127.0.0.1:55441 (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 14:14:23 INFO SparkContext: Created broadcast 188 from broadcast at DAGScheduler.scala:1196
20/02/14 14:14:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 188 (MapPartitionsRDD[1045] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:14:23 INFO TaskSchedulerImpl: Adding task set 188.0 with 1 tasks
20/02/14 14:14:23 INFO TaskSetManager: Starting task 0.0 in stage 188.0 (TID 239, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 14:14:23 INFO Executor: Running task 0.0 in stage 188.0 (TID 239)
20/02/14 14:14:23 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:14:23 INFO Executor: Finished task 0.0 in stage 188.0 (TID 239). 2369 bytes result sent to driver
20/02/14 14:14:23 INFO TaskSetManager: Finished task 0.0 in stage 188.0 (TID 239) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:14:23 INFO TaskSchedulerImpl: Removed TaskSet 188.0, whose tasks have all completed, from pool 
20/02/14 14:14:23 INFO DAGScheduler: ShuffleMapStage 188 (count at <unknown>:0) finished in 0.021 s
20/02/14 14:14:23 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:14:23 INFO DAGScheduler: running: Set()
20/02/14 14:14:23 INFO DAGScheduler: waiting: Set(ResultStage 189)
20/02/14 14:14:23 INFO DAGScheduler: failed: Set()
20/02/14 14:14:23 INFO DAGScheduler: Submitting ResultStage 189 (MapPartitionsRDD[1048] at count at <unknown>:0), which has no missing parents
20/02/14 14:14:23 INFO MemoryStore: Block broadcast_189 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/14 14:14:23 INFO MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
20/02/14 14:14:23 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:14:23 INFO SparkContext: Created broadcast 189 from broadcast at DAGScheduler.scala:1196
20/02/14 14:14:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 189 (MapPartitionsRDD[1048] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:14:23 INFO TaskSchedulerImpl: Adding task set 189.0 with 1 tasks
20/02/14 14:14:23 INFO TaskSetManager: Starting task 0.0 in stage 189.0 (TID 240, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:14:23 INFO Executor: Running task 0.0 in stage 189.0 (TID 240)
20/02/14 14:14:23 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:14:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:14:23 INFO Executor: Finished task 0.0 in stage 189.0 (TID 240). 2760 bytes result sent to driver
20/02/14 14:14:23 INFO TaskSetManager: Finished task 0.0 in stage 189.0 (TID 240) in 6 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:14:23 INFO TaskSchedulerImpl: Removed TaskSet 189.0, whose tasks have all completed, from pool 
20/02/14 14:14:23 INFO DAGScheduler: ResultStage 189 (count at <unknown>:0) finished in 0.011 s
20/02/14 14:14:23 INFO DAGScheduler: Job 105 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:14:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 189: Stage finished
20/02/14 14:14:23 INFO DAGScheduler: Job 105 finished: count at <unknown>:0, took 0.038564 s
20/02/14 14:14:23 INFO BlockManagerInfo: Removed broadcast_189_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:14:23 INFO BlockManagerInfo: Removed broadcast_188_piece0 on 127.0.0.1:55441 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 14:14:23 INFO SparkContext: Starting job: collect at utils.scala:34
20/02/14 14:14:23 INFO DAGScheduler: Got job 106 (collect at utils.scala:34) with 1 output partitions
20/02/14 14:14:23 INFO DAGScheduler: Final stage: ResultStage 190 (collect at utils.scala:34)
20/02/14 14:14:23 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:14:23 INFO DAGScheduler: Missing parents: List()
20/02/14 14:14:23 INFO DAGScheduler: Submitting ResultStage 190 (MapPartitionsRDD[1056] at map at utils.scala:34), which has no missing parents
20/02/14 14:14:23 INFO MemoryStore: Block broadcast_190 stored as values in memory (estimated size 46.8 KiB, free 413.9 MiB)
20/02/14 14:14:23 INFO MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 19.3 KiB, free 413.9 MiB)
20/02/14 14:14:23 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on 127.0.0.1:55441 (size: 19.3 KiB, free: 413.9 MiB)
20/02/14 14:14:23 INFO SparkContext: Created broadcast 190 from broadcast at DAGScheduler.scala:1196
20/02/14 14:14:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 190 (MapPartitionsRDD[1056] at map at utils.scala:34) (first 15 tasks are for partitions Vector(0))
20/02/14 14:14:23 INFO TaskSchedulerImpl: Adding task set 190.0 with 1 tasks
20/02/14 14:14:23 INFO TaskSetManager: Starting task 0.0 in stage 190.0 (TID 241, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 14:14:23 INFO Executor: Running task 0.0 in stage 190.0 (TID 241)
20/02/14 14:14:23 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:14:23 INFO Executor: Finished task 0.0 in stage 190.0 (TID 241). 1822 bytes result sent to driver
20/02/14 14:14:23 INFO TaskSetManager: Finished task 0.0 in stage 190.0 (TID 241) in 12 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:14:23 INFO TaskSchedulerImpl: Removed TaskSet 190.0, whose tasks have all completed, from pool 
20/02/14 14:14:23 INFO DAGScheduler: ResultStage 190 (collect at utils.scala:34) finished in 0.024 s
20/02/14 14:14:23 INFO DAGScheduler: Job 106 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:14:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 190: Stage finished
20/02/14 14:14:23 INFO DAGScheduler: Job 106 finished: collect at utils.scala:34, took 0.027904 s
20/02/14 14:14:33 INFO BlockManagerInfo: Removed broadcast_190_piece0 on 127.0.0.1:55441 in memory (size: 19.3 KiB, free: 413.9 MiB)
20/02/14 14:14:33 INFO SparkContext: Starting job: count at <unknown>:0
20/02/14 14:14:33 INFO DAGScheduler: Registering RDD 1061 (count at <unknown>:0) as input to shuffle 84
20/02/14 14:14:33 INFO DAGScheduler: Got job 107 (count at <unknown>:0) with 1 output partitions
20/02/14 14:14:33 INFO DAGScheduler: Final stage: ResultStage 192 (count at <unknown>:0)
20/02/14 14:14:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 191)
20/02/14 14:14:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 191)
20/02/14 14:14:33 INFO DAGScheduler: Submitting ShuffleMapStage 191 (MapPartitionsRDD[1061] at count at <unknown>:0), which has no missing parents
20/02/14 14:14:33 INFO MemoryStore: Block broadcast_191 stored as values in memory (estimated size 26.8 KiB, free 413.9 MiB)
20/02/14 14:14:33 INFO MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.9 MiB)
20/02/14 14:14:33 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on 127.0.0.1:55441 (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 14:14:33 INFO SparkContext: Created broadcast 191 from broadcast at DAGScheduler.scala:1196
20/02/14 14:14:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 191 (MapPartitionsRDD[1061] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:14:33 INFO TaskSchedulerImpl: Adding task set 191.0 with 1 tasks
20/02/14 14:14:33 INFO TaskSetManager: Starting task 0.0 in stage 191.0 (TID 242, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 14:14:33 INFO Executor: Running task 0.0 in stage 191.0 (TID 242)
20/02/14 14:14:33 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:14:33 INFO Executor: Finished task 0.0 in stage 191.0 (TID 242). 2326 bytes result sent to driver
20/02/14 14:14:33 INFO TaskSetManager: Finished task 0.0 in stage 191.0 (TID 242) in 13 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:14:33 INFO TaskSchedulerImpl: Removed TaskSet 191.0, whose tasks have all completed, from pool 
20/02/14 14:14:33 INFO DAGScheduler: ShuffleMapStage 191 (count at <unknown>:0) finished in 0.019 s
20/02/14 14:14:33 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:14:33 INFO DAGScheduler: running: Set()
20/02/14 14:14:33 INFO DAGScheduler: waiting: Set(ResultStage 192)
20/02/14 14:14:33 INFO DAGScheduler: failed: Set()
20/02/14 14:14:33 INFO DAGScheduler: Submitting ResultStage 192 (MapPartitionsRDD[1064] at count at <unknown>:0), which has no missing parents
20/02/14 14:14:33 INFO MemoryStore: Block broadcast_192 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/14 14:14:33 INFO MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
20/02/14 14:14:33 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:14:33 INFO SparkContext: Created broadcast 192 from broadcast at DAGScheduler.scala:1196
20/02/14 14:14:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 192 (MapPartitionsRDD[1064] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:14:33 INFO TaskSchedulerImpl: Adding task set 192.0 with 1 tasks
20/02/14 14:14:33 INFO TaskSetManager: Starting task 0.0 in stage 192.0 (TID 243, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:14:33 INFO Executor: Running task 0.0 in stage 192.0 (TID 243)
20/02/14 14:14:33 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:14:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:14:33 INFO Executor: Finished task 0.0 in stage 192.0 (TID 243). 2760 bytes result sent to driver
20/02/14 14:14:33 INFO TaskSetManager: Finished task 0.0 in stage 192.0 (TID 243) in 6 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:14:33 INFO TaskSchedulerImpl: Removed TaskSet 192.0, whose tasks have all completed, from pool 
20/02/14 14:14:33 INFO DAGScheduler: ResultStage 192 (count at <unknown>:0) finished in 0.012 s
20/02/14 14:14:33 INFO DAGScheduler: Job 107 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:14:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 192: Stage finished
20/02/14 14:14:33 INFO DAGScheduler: Job 107 finished: count at <unknown>:0, took 0.036267 s
20/02/14 14:14:33 INFO BlockManagerInfo: Removed broadcast_192_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:14:33 INFO BlockManagerInfo: Removed broadcast_191_piece0 on 127.0.0.1:55441 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 14:14:33 INFO SparkContext: Starting job: collect at utils.scala:34
20/02/14 14:14:33 INFO DAGScheduler: Got job 108 (collect at utils.scala:34) with 1 output partitions
20/02/14 14:14:33 INFO DAGScheduler: Final stage: ResultStage 193 (collect at utils.scala:34)
20/02/14 14:14:33 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:14:33 INFO DAGScheduler: Missing parents: List()
20/02/14 14:14:33 INFO DAGScheduler: Submitting ResultStage 193 (MapPartitionsRDD[1072] at map at utils.scala:34), which has no missing parents
20/02/14 14:14:33 INFO MemoryStore: Block broadcast_193 stored as values in memory (estimated size 46.8 KiB, free 413.9 MiB)
20/02/14 14:14:33 INFO MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 19.3 KiB, free 413.9 MiB)
20/02/14 14:14:33 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on 127.0.0.1:55441 (size: 19.3 KiB, free: 413.9 MiB)
20/02/14 14:14:33 INFO SparkContext: Created broadcast 193 from broadcast at DAGScheduler.scala:1196
20/02/14 14:14:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 193 (MapPartitionsRDD[1072] at map at utils.scala:34) (first 15 tasks are for partitions Vector(0))
20/02/14 14:14:33 INFO TaskSchedulerImpl: Adding task set 193.0 with 1 tasks
20/02/14 14:14:33 INFO TaskSetManager: Starting task 0.0 in stage 193.0 (TID 244, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 14:14:33 INFO Executor: Running task 0.0 in stage 193.0 (TID 244)
20/02/14 14:14:33 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:14:33 INFO Executor: Finished task 0.0 in stage 193.0 (TID 244). 1865 bytes result sent to driver
20/02/14 14:14:33 INFO TaskSetManager: Finished task 0.0 in stage 193.0 (TID 244) in 11 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:14:33 INFO TaskSchedulerImpl: Removed TaskSet 193.0, whose tasks have all completed, from pool 
20/02/14 14:14:33 INFO DAGScheduler: ResultStage 193 (collect at utils.scala:34) finished in 0.018 s
20/02/14 14:14:33 INFO DAGScheduler: Job 108 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:14:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 193: Stage finished
20/02/14 14:14:33 INFO DAGScheduler: Job 108 finished: collect at utils.scala:34, took 0.022799 s
20/02/14 14:14:44 INFO BlockManagerInfo: Removed broadcast_193_piece0 on 127.0.0.1:55441 in memory (size: 19.3 KiB, free: 413.9 MiB)
20/02/14 14:14:44 INFO SparkContext: Starting job: count at <unknown>:0
20/02/14 14:14:44 INFO DAGScheduler: Registering RDD 1077 (count at <unknown>:0) as input to shuffle 85
20/02/14 14:14:44 INFO DAGScheduler: Got job 109 (count at <unknown>:0) with 1 output partitions
20/02/14 14:14:44 INFO DAGScheduler: Final stage: ResultStage 195 (count at <unknown>:0)
20/02/14 14:14:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 194)
20/02/14 14:14:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 194)
20/02/14 14:14:44 INFO DAGScheduler: Submitting ShuffleMapStage 194 (MapPartitionsRDD[1077] at count at <unknown>:0), which has no missing parents
20/02/14 14:14:44 INFO MemoryStore: Block broadcast_194 stored as values in memory (estimated size 26.8 KiB, free 413.9 MiB)
20/02/14 14:14:44 INFO MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.9 MiB)
20/02/14 14:14:44 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on 127.0.0.1:55441 (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 14:14:44 INFO SparkContext: Created broadcast 194 from broadcast at DAGScheduler.scala:1196
20/02/14 14:14:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 194 (MapPartitionsRDD[1077] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:14:44 INFO TaskSchedulerImpl: Adding task set 194.0 with 1 tasks
20/02/14 14:14:44 INFO TaskSetManager: Starting task 0.0 in stage 194.0 (TID 245, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 14:14:44 INFO Executor: Running task 0.0 in stage 194.0 (TID 245)
20/02/14 14:14:44 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:14:44 INFO Executor: Finished task 0.0 in stage 194.0 (TID 245). 2326 bytes result sent to driver
20/02/14 14:14:44 INFO TaskSetManager: Finished task 0.0 in stage 194.0 (TID 245) in 12 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:14:44 INFO TaskSchedulerImpl: Removed TaskSet 194.0, whose tasks have all completed, from pool 
20/02/14 14:14:44 INFO DAGScheduler: ShuffleMapStage 194 (count at <unknown>:0) finished in 0.018 s
20/02/14 14:14:44 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:14:44 INFO DAGScheduler: running: Set()
20/02/14 14:14:44 INFO DAGScheduler: waiting: Set(ResultStage 195)
20/02/14 14:14:44 INFO DAGScheduler: failed: Set()
20/02/14 14:14:44 INFO DAGScheduler: Submitting ResultStage 195 (MapPartitionsRDD[1080] at count at <unknown>:0), which has no missing parents
20/02/14 14:14:44 INFO MemoryStore: Block broadcast_195 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/14 14:14:44 INFO MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
20/02/14 14:14:44 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:14:44 INFO SparkContext: Created broadcast 195 from broadcast at DAGScheduler.scala:1196
20/02/14 14:14:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 195 (MapPartitionsRDD[1080] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:14:44 INFO TaskSchedulerImpl: Adding task set 195.0 with 1 tasks
20/02/14 14:14:44 INFO TaskSetManager: Starting task 0.0 in stage 195.0 (TID 246, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:14:44 INFO Executor: Running task 0.0 in stage 195.0 (TID 246)
20/02/14 14:14:44 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:14:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:14:44 INFO Executor: Finished task 0.0 in stage 195.0 (TID 246). 2760 bytes result sent to driver
20/02/14 14:14:44 INFO TaskSetManager: Finished task 0.0 in stage 195.0 (TID 246) in 6 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:14:44 INFO TaskSchedulerImpl: Removed TaskSet 195.0, whose tasks have all completed, from pool 
20/02/14 14:14:44 INFO DAGScheduler: ResultStage 195 (count at <unknown>:0) finished in 0.015 s
20/02/14 14:14:44 INFO DAGScheduler: Job 109 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:14:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 195: Stage finished
20/02/14 14:14:44 INFO DAGScheduler: Job 109 finished: count at <unknown>:0, took 0.040223 s
20/02/14 14:14:45 INFO BlockManagerInfo: Removed broadcast_195_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:14:45 INFO BlockManagerInfo: Removed broadcast_194_piece0 on 127.0.0.1:55441 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 14:14:45 INFO SparkContext: Starting job: collect at utils.scala:34
20/02/14 14:14:45 INFO DAGScheduler: Got job 110 (collect at utils.scala:34) with 1 output partitions
20/02/14 14:14:45 INFO DAGScheduler: Final stage: ResultStage 196 (collect at utils.scala:34)
20/02/14 14:14:45 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:14:45 INFO DAGScheduler: Missing parents: List()
20/02/14 14:14:45 INFO DAGScheduler: Submitting ResultStage 196 (MapPartitionsRDD[1088] at map at utils.scala:34), which has no missing parents
20/02/14 14:14:45 INFO MemoryStore: Block broadcast_196 stored as values in memory (estimated size 46.8 KiB, free 413.9 MiB)
20/02/14 14:14:45 INFO MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 19.3 KiB, free 413.9 MiB)
20/02/14 14:14:45 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on 127.0.0.1:55441 (size: 19.3 KiB, free: 413.9 MiB)
20/02/14 14:14:45 INFO SparkContext: Created broadcast 196 from broadcast at DAGScheduler.scala:1196
20/02/14 14:14:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 196 (MapPartitionsRDD[1088] at map at utils.scala:34) (first 15 tasks are for partitions Vector(0))
20/02/14 14:14:45 INFO TaskSchedulerImpl: Adding task set 196.0 with 1 tasks
20/02/14 14:14:45 INFO TaskSetManager: Starting task 0.0 in stage 196.0 (TID 247, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 14:14:45 INFO Executor: Running task 0.0 in stage 196.0 (TID 247)
20/02/14 14:14:45 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:14:45 INFO Executor: Finished task 0.0 in stage 196.0 (TID 247). 1865 bytes result sent to driver
20/02/14 14:14:45 INFO TaskSetManager: Finished task 0.0 in stage 196.0 (TID 247) in 9 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:14:45 INFO TaskSchedulerImpl: Removed TaskSet 196.0, whose tasks have all completed, from pool 
20/02/14 14:14:45 INFO DAGScheduler: ResultStage 196 (collect at utils.scala:34) finished in 0.016 s
20/02/14 14:14:45 INFO DAGScheduler: Job 110 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:14:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 196: Stage finished
20/02/14 14:14:45 INFO DAGScheduler: Job 110 finished: collect at utils.scala:34, took 0.019644 s
20/02/14 14:14:49 INFO BlockManagerInfo: Removed broadcast_196_piece0 on 127.0.0.1:55441 in memory (size: 19.3 KiB, free: 413.9 MiB)
20/02/14 14:14:49 INFO SparkContext: Starting job: count at <unknown>:0
20/02/14 14:14:49 INFO DAGScheduler: Registering RDD 1093 (count at <unknown>:0) as input to shuffle 86
20/02/14 14:14:49 INFO DAGScheduler: Got job 111 (count at <unknown>:0) with 1 output partitions
20/02/14 14:14:49 INFO DAGScheduler: Final stage: ResultStage 198 (count at <unknown>:0)
20/02/14 14:14:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 197)
20/02/14 14:14:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 197)
20/02/14 14:14:49 INFO DAGScheduler: Submitting ShuffleMapStage 197 (MapPartitionsRDD[1093] at count at <unknown>:0), which has no missing parents
20/02/14 14:14:49 INFO MemoryStore: Block broadcast_197 stored as values in memory (estimated size 26.8 KiB, free 413.9 MiB)
20/02/14 14:14:49 INFO MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.9 MiB)
20/02/14 14:14:49 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on 127.0.0.1:55441 (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 14:14:49 INFO SparkContext: Created broadcast 197 from broadcast at DAGScheduler.scala:1196
20/02/14 14:14:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 197 (MapPartitionsRDD[1093] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:14:49 INFO TaskSchedulerImpl: Adding task set 197.0 with 1 tasks
20/02/14 14:14:49 INFO TaskSetManager: Starting task 0.0 in stage 197.0 (TID 248, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 14:14:49 INFO Executor: Running task 0.0 in stage 197.0 (TID 248)
20/02/14 14:14:49 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:14:49 INFO Executor: Finished task 0.0 in stage 197.0 (TID 248). 2326 bytes result sent to driver
20/02/14 14:14:49 INFO TaskSetManager: Finished task 0.0 in stage 197.0 (TID 248) in 12 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:14:49 INFO TaskSchedulerImpl: Removed TaskSet 197.0, whose tasks have all completed, from pool 
20/02/14 14:14:49 INFO DAGScheduler: ShuffleMapStage 197 (count at <unknown>:0) finished in 0.018 s
20/02/14 14:14:49 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:14:49 INFO DAGScheduler: running: Set()
20/02/14 14:14:49 INFO DAGScheduler: waiting: Set(ResultStage 198)
20/02/14 14:14:49 INFO DAGScheduler: failed: Set()
20/02/14 14:14:49 INFO DAGScheduler: Submitting ResultStage 198 (MapPartitionsRDD[1096] at count at <unknown>:0), which has no missing parents
20/02/14 14:14:49 INFO MemoryStore: Block broadcast_198 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/14 14:14:49 INFO MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
20/02/14 14:14:49 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:14:49 INFO SparkContext: Created broadcast 198 from broadcast at DAGScheduler.scala:1196
20/02/14 14:14:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 198 (MapPartitionsRDD[1096] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:14:49 INFO TaskSchedulerImpl: Adding task set 198.0 with 1 tasks
20/02/14 14:14:49 INFO TaskSetManager: Starting task 0.0 in stage 198.0 (TID 249, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:14:49 INFO Executor: Running task 0.0 in stage 198.0 (TID 249)
20/02/14 14:14:49 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:14:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:14:49 INFO Executor: Finished task 0.0 in stage 198.0 (TID 249). 2760 bytes result sent to driver
20/02/14 14:14:49 INFO TaskSetManager: Finished task 0.0 in stage 198.0 (TID 249) in 5 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:14:49 INFO TaskSchedulerImpl: Removed TaskSet 198.0, whose tasks have all completed, from pool 
20/02/14 14:14:49 INFO DAGScheduler: ResultStage 198 (count at <unknown>:0) finished in 0.010 s
20/02/14 14:14:49 INFO DAGScheduler: Job 111 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:14:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 198: Stage finished
20/02/14 14:14:49 INFO DAGScheduler: Job 111 finished: count at <unknown>:0, took 0.033067 s
20/02/14 14:14:49 INFO BlockManagerInfo: Removed broadcast_197_piece0 on 127.0.0.1:55441 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 14:14:49 INFO BlockManagerInfo: Removed broadcast_198_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:14:49 INFO SparkContext: Starting job: collect at utils.scala:34
20/02/14 14:14:49 INFO DAGScheduler: Got job 112 (collect at utils.scala:34) with 1 output partitions
20/02/14 14:14:49 INFO DAGScheduler: Final stage: ResultStage 199 (collect at utils.scala:34)
20/02/14 14:14:49 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:14:49 INFO DAGScheduler: Missing parents: List()
20/02/14 14:14:49 INFO DAGScheduler: Submitting ResultStage 199 (MapPartitionsRDD[1104] at map at utils.scala:34), which has no missing parents
20/02/14 14:14:49 INFO MemoryStore: Block broadcast_199 stored as values in memory (estimated size 46.8 KiB, free 413.9 MiB)
20/02/14 14:14:49 INFO MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 19.3 KiB, free 413.9 MiB)
20/02/14 14:14:49 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on 127.0.0.1:55441 (size: 19.3 KiB, free: 413.9 MiB)
20/02/14 14:14:49 INFO SparkContext: Created broadcast 199 from broadcast at DAGScheduler.scala:1196
20/02/14 14:14:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 199 (MapPartitionsRDD[1104] at map at utils.scala:34) (first 15 tasks are for partitions Vector(0))
20/02/14 14:14:49 INFO TaskSchedulerImpl: Adding task set 199.0 with 1 tasks
20/02/14 14:14:49 INFO TaskSetManager: Starting task 0.0 in stage 199.0 (TID 250, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 14:14:49 INFO Executor: Running task 0.0 in stage 199.0 (TID 250)
20/02/14 14:14:49 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:14:49 INFO Executor: Finished task 0.0 in stage 199.0 (TID 250). 1822 bytes result sent to driver
20/02/14 14:14:49 INFO TaskSetManager: Finished task 0.0 in stage 199.0 (TID 250) in 11 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:14:49 INFO TaskSchedulerImpl: Removed TaskSet 199.0, whose tasks have all completed, from pool 
20/02/14 14:14:49 INFO DAGScheduler: ResultStage 199 (collect at utils.scala:34) finished in 0.021 s
20/02/14 14:14:49 INFO DAGScheduler: Job 112 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:14:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 199: Stage finished
20/02/14 14:14:49 INFO DAGScheduler: Job 112 finished: collect at utils.scala:34, took 0.025379 s
20/02/14 14:15:27 INFO BlockManagerInfo: Removed broadcast_199_piece0 on 127.0.0.1:55441 in memory (size: 19.3 KiB, free: 413.9 MiB)
20/02/14 14:15:27 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 14:15:27 INFO DAGScheduler: Got job 113 (collect at utils.scala:41) with 4 output partitions
20/02/14 14:15:27 INFO DAGScheduler: Final stage: ResultStage 200 (collect at utils.scala:41)
20/02/14 14:15:27 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:15:27 INFO DAGScheduler: Missing parents: List()
20/02/14 14:15:27 INFO DAGScheduler: Submitting ResultStage 200 (MapPartitionsRDD[1110] at map at utils.scala:41), which has no missing parents
20/02/14 14:15:27 INFO MemoryStore: Block broadcast_200 stored as values in memory (estimated size 8.8 KiB, free 413.9 MiB)
20/02/14 14:15:27 INFO MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.9 MiB)
20/02/14 14:15:27 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on 127.0.0.1:55441 (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 14:15:27 INFO SparkContext: Created broadcast 200 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 200 (MapPartitionsRDD[1110] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 14:15:27 INFO TaskSchedulerImpl: Adding task set 200.0 with 4 tasks
20/02/14 14:15:27 INFO TaskSetManager: Starting task 0.0 in stage 200.0 (TID 251, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7598 bytes)
20/02/14 14:15:27 INFO TaskSetManager: Starting task 1.0 in stage 200.0 (TID 252, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7687 bytes)
20/02/14 14:15:27 INFO TaskSetManager: Starting task 2.0 in stage 200.0 (TID 253, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7622 bytes)
20/02/14 14:15:27 INFO TaskSetManager: Starting task 3.0 in stage 200.0 (TID 254, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7679 bytes)
20/02/14 14:15:27 INFO Executor: Running task 0.0 in stage 200.0 (TID 251)
20/02/14 14:15:27 INFO Executor: Running task 1.0 in stage 200.0 (TID 252)
20/02/14 14:15:27 INFO Executor: Running task 3.0 in stage 200.0 (TID 254)
20/02/14 14:15:27 INFO Executor: Running task 2.0 in stage 200.0 (TID 253)
20/02/14 14:15:27 INFO Executor: Finished task 1.0 in stage 200.0 (TID 252). 1101 bytes result sent to driver
20/02/14 14:15:27 INFO Executor: Finished task 3.0 in stage 200.0 (TID 254). 1100 bytes result sent to driver
20/02/14 14:15:27 INFO Executor: Finished task 2.0 in stage 200.0 (TID 253). 1073 bytes result sent to driver
20/02/14 14:15:27 INFO TaskSetManager: Finished task 1.0 in stage 200.0 (TID 252) in 8 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 14:15:27 INFO TaskSetManager: Finished task 3.0 in stage 200.0 (TID 254) in 8 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 14:15:27 INFO TaskSetManager: Finished task 2.0 in stage 200.0 (TID 253) in 9 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 14:15:27 INFO Executor: Finished task 0.0 in stage 200.0 (TID 251). 1097 bytes result sent to driver
20/02/14 14:15:27 INFO TaskSetManager: Finished task 0.0 in stage 200.0 (TID 251) in 12 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 14:15:27 INFO TaskSchedulerImpl: Removed TaskSet 200.0, whose tasks have all completed, from pool 
20/02/14 14:15:27 INFO DAGScheduler: ResultStage 200 (collect at utils.scala:41) finished in 0.016 s
20/02/14 14:15:27 INFO DAGScheduler: Job 113 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:15:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 200: Stage finished
20/02/14 14:15:27 INFO DAGScheduler: Job 113 finished: collect at utils.scala:41, took 0.018918 s
20/02/14 14:15:27 INFO BlockManagerInfo: Removed broadcast_200_piece0 on 127.0.0.1:55441 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 14:15:28 INFO CodeGenerator: Code generated in 6.0338 ms
20/02/14 14:15:28 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/14 14:15:28 INFO DAGScheduler: Registering RDD 1119 (sql at <unknown>:0) as input to shuffle 87
20/02/14 14:15:28 INFO DAGScheduler: Got job 114 (sql at <unknown>:0) with 1 output partitions
20/02/14 14:15:28 INFO DAGScheduler: Final stage: ResultStage 202 (sql at <unknown>:0)
20/02/14 14:15:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 201)
20/02/14 14:15:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 201)
20/02/14 14:15:28 INFO DAGScheduler: Submitting ShuffleMapStage 201 (MapPartitionsRDD[1119] at sql at <unknown>:0), which has no missing parents
20/02/14 14:15:28 INFO MemoryStore: Block broadcast_201 stored as values in memory (estimated size 18.9 KiB, free 413.9 MiB)
20/02/14 14:15:28 INFO MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.9 MiB)
20/02/14 14:15:28 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:15:28 INFO SparkContext: Created broadcast 201 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 201 (MapPartitionsRDD[1119] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:28 INFO TaskSchedulerImpl: Adding task set 201.0 with 1 tasks
20/02/14 14:15:28 INFO TaskSetManager: Starting task 0.0 in stage 201.0 (TID 255, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:15:28 INFO Executor: Running task 0.0 in stage 201.0 (TID 255)
20/02/14 14:15:28 INFO MemoryStore: Block rdd_1114_0 stored as values in memory (estimated size 312.0 B, free 413.9 MiB)
20/02/14 14:15:28 INFO BlockManagerInfo: Added rdd_1114_0 in memory on 127.0.0.1:55441 (size: 312.0 B, free: 413.9 MiB)
20/02/14 14:15:28 INFO Executor: Finished task 0.0 in stage 201.0 (TID 255). 2240 bytes result sent to driver
20/02/14 14:15:28 INFO TaskSetManager: Finished task 0.0 in stage 201.0 (TID 255) in 20 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:28 INFO TaskSchedulerImpl: Removed TaskSet 201.0, whose tasks have all completed, from pool 
20/02/14 14:15:28 INFO DAGScheduler: ShuffleMapStage 201 (sql at <unknown>:0) finished in 0.030 s
20/02/14 14:15:28 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:15:28 INFO DAGScheduler: running: Set()
20/02/14 14:15:28 INFO DAGScheduler: waiting: Set(ResultStage 202)
20/02/14 14:15:28 INFO DAGScheduler: failed: Set()
20/02/14 14:15:28 INFO DAGScheduler: Submitting ResultStage 202 (MapPartitionsRDD[1122] at sql at <unknown>:0), which has no missing parents
20/02/14 14:15:28 INFO MemoryStore: Block broadcast_202 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/14 14:15:28 INFO MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
20/02/14 14:15:28 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:15:28 INFO SparkContext: Created broadcast 202 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 202 (MapPartitionsRDD[1122] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:28 INFO TaskSchedulerImpl: Adding task set 202.0 with 1 tasks
20/02/14 14:15:28 INFO TaskSetManager: Starting task 0.0 in stage 202.0 (TID 256, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:15:28 INFO Executor: Running task 0.0 in stage 202.0 (TID 256)
20/02/14 14:15:28 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:15:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:15:28 INFO Executor: Finished task 0.0 in stage 202.0 (TID 256). 2803 bytes result sent to driver
20/02/14 14:15:28 INFO TaskSetManager: Finished task 0.0 in stage 202.0 (TID 256) in 5 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:28 INFO TaskSchedulerImpl: Removed TaskSet 202.0, whose tasks have all completed, from pool 
20/02/14 14:15:28 INFO DAGScheduler: ResultStage 202 (sql at <unknown>:0) finished in 0.010 s
20/02/14 14:15:28 INFO DAGScheduler: Job 114 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:15:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 202: Stage finished
20/02/14 14:15:28 INFO DAGScheduler: Job 114 finished: sql at <unknown>:0, took 0.044961 s
20/02/14 14:15:28 INFO BlockManagerInfo: Removed broadcast_201_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:15:28 INFO BlockManagerInfo: Removed broadcast_202_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:15:28 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 14:15:28 INFO DAGScheduler: Registering RDD 1127 (collect at arrowconverters.scala:270) as input to shuffle 88
20/02/14 14:15:28 INFO DAGScheduler: Got job 115 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 14:15:28 INFO DAGScheduler: Final stage: ResultStage 204 (collect at arrowconverters.scala:270)
20/02/14 14:15:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 203)
20/02/14 14:15:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 203)
20/02/14 14:15:28 INFO DAGScheduler: Submitting ShuffleMapStage 203 (MapPartitionsRDD[1127] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:15:28 INFO MemoryStore: Block broadcast_203 stored as values in memory (estimated size 18.9 KiB, free 413.9 MiB)
20/02/14 14:15:28 INFO MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.9 MiB)
20/02/14 14:15:28 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:15:28 INFO SparkContext: Created broadcast 203 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 203 (MapPartitionsRDD[1127] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:28 INFO TaskSchedulerImpl: Adding task set 203.0 with 1 tasks
20/02/14 14:15:28 INFO TaskSetManager: Starting task 0.0 in stage 203.0 (TID 257, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:15:28 INFO Executor: Running task 0.0 in stage 203.0 (TID 257)
20/02/14 14:15:28 INFO BlockManager: Found block rdd_1114_0 locally
20/02/14 14:15:28 INFO Executor: Finished task 0.0 in stage 203.0 (TID 257). 2369 bytes result sent to driver
20/02/14 14:15:28 INFO TaskSetManager: Finished task 0.0 in stage 203.0 (TID 257) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:28 INFO TaskSchedulerImpl: Removed TaskSet 203.0, whose tasks have all completed, from pool 
20/02/14 14:15:28 INFO DAGScheduler: ShuffleMapStage 203 (collect at arrowconverters.scala:270) finished in 0.022 s
20/02/14 14:15:28 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:15:28 INFO DAGScheduler: running: Set()
20/02/14 14:15:28 INFO DAGScheduler: waiting: Set(ResultStage 204)
20/02/14 14:15:28 INFO DAGScheduler: failed: Set()
20/02/14 14:15:28 INFO DAGScheduler: Submitting ResultStage 204 (MapPartitionsRDD[1133] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:15:28 INFO MemoryStore: Block broadcast_204 stored as values in memory (estimated size 28.9 KiB, free 413.9 MiB)
20/02/14 14:15:28 INFO MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 12.0 KiB, free 413.9 MiB)
20/02/14 14:15:28 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on 127.0.0.1:55441 (size: 12.0 KiB, free: 413.9 MiB)
20/02/14 14:15:28 INFO SparkContext: Created broadcast 204 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 204 (MapPartitionsRDD[1133] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:28 INFO TaskSchedulerImpl: Adding task set 204.0 with 1 tasks
20/02/14 14:15:28 INFO TaskSetManager: Starting task 0.0 in stage 204.0 (TID 258, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:15:28 INFO Executor: Running task 0.0 in stage 204.0 (TID 258)
20/02/14 14:15:28 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:15:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:15:28 INFO Executor: Finished task 0.0 in stage 204.0 (TID 258). 4285 bytes result sent to driver
20/02/14 14:15:28 INFO TaskSetManager: Finished task 0.0 in stage 204.0 (TID 258) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:28 INFO TaskSchedulerImpl: Removed TaskSet 204.0, whose tasks have all completed, from pool 
20/02/14 14:15:28 INFO DAGScheduler: ResultStage 204 (collect at arrowconverters.scala:270) finished in 0.024 s
20/02/14 14:15:28 INFO DAGScheduler: Job 115 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:15:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 204: Stage finished
20/02/14 14:15:28 INFO DAGScheduler: Job 115 finished: collect at arrowconverters.scala:270, took 0.050927 s
20/02/14 14:15:28 INFO Instrumentation: [a48aa597] training finished
20/02/14 14:15:28 INFO Instrumentation: [c80984c0] training finished
20/02/14 14:15:28 INFO BlockManagerInfo: Removed broadcast_203_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:15:28 INFO BlockManagerInfo: Removed broadcast_204_piece0 on 127.0.0.1:55441 in memory (size: 12.0 KiB, free: 413.9 MiB)
20/02/14 14:15:28 INFO CodeGenerator: Code generated in 6.8244 ms
20/02/14 14:15:28 INFO CodeGenerator: Code generated in 14.1926 ms
20/02/14 14:15:28 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 14:15:28 INFO DAGScheduler: Registering RDD 1138 (collect at arrowconverters.scala:270) as input to shuffle 89
20/02/14 14:15:28 INFO DAGScheduler: Got job 116 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 14:15:28 INFO DAGScheduler: Final stage: ResultStage 206 (collect at arrowconverters.scala:270)
20/02/14 14:15:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 205)
20/02/14 14:15:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 205)
20/02/14 14:15:28 INFO DAGScheduler: Submitting ShuffleMapStage 205 (MapPartitionsRDD[1138] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:15:28 INFO MemoryStore: Block broadcast_205 stored as values in memory (estimated size 31.9 KiB, free 413.9 MiB)
20/02/14 14:15:28 INFO MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 13.3 KiB, free 413.9 MiB)
20/02/14 14:15:28 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on 127.0.0.1:55441 (size: 13.3 KiB, free: 413.9 MiB)
20/02/14 14:15:28 INFO SparkContext: Created broadcast 205 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 205 (MapPartitionsRDD[1138] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:28 INFO TaskSchedulerImpl: Adding task set 205.0 with 1 tasks
20/02/14 14:15:28 INFO TaskSetManager: Starting task 0.0 in stage 205.0 (TID 259, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:15:28 INFO Executor: Running task 0.0 in stage 205.0 (TID 259)
20/02/14 14:15:28 INFO BlockManager: Found block rdd_1114_0 locally
20/02/14 14:15:29 INFO Executor: Finished task 0.0 in stage 205.0 (TID 259). 2157 bytes result sent to driver
20/02/14 14:15:29 INFO TaskSetManager: Finished task 0.0 in stage 205.0 (TID 259) in 19 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:29 INFO TaskSchedulerImpl: Removed TaskSet 205.0, whose tasks have all completed, from pool 
20/02/14 14:15:29 INFO DAGScheduler: ShuffleMapStage 205 (collect at arrowconverters.scala:270) finished in 0.030 s
20/02/14 14:15:29 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:15:29 INFO DAGScheduler: running: Set()
20/02/14 14:15:29 INFO DAGScheduler: waiting: Set(ResultStage 206)
20/02/14 14:15:29 INFO DAGScheduler: failed: Set()
20/02/14 14:15:29 INFO DAGScheduler: Submitting ResultStage 206 (MapPartitionsRDD[1144] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:15:29 INFO MemoryStore: Block broadcast_206 stored as values in memory (estimated size 33.7 KiB, free 413.8 MiB)
20/02/14 14:15:29 INFO MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 14:15:29 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 14:15:29 INFO SparkContext: Created broadcast 206 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 206 (MapPartitionsRDD[1144] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:29 INFO TaskSchedulerImpl: Adding task set 206.0 with 1 tasks
20/02/14 14:15:29 INFO TaskSetManager: Starting task 0.0 in stage 206.0 (TID 260, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:15:29 INFO Executor: Running task 0.0 in stage 206.0 (TID 260)
20/02/14 14:15:29 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:15:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:15:29 INFO CodeGenerator: Code generated in 5.1456 ms
20/02/14 14:15:29 INFO CodeGenerator: Code generated in 10.629 ms
20/02/14 14:15:29 INFO Executor: Finished task 0.0 in stage 206.0 (TID 260). 3558 bytes result sent to driver
20/02/14 14:15:29 INFO TaskSetManager: Finished task 0.0 in stage 206.0 (TID 260) in 33 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:29 INFO TaskSchedulerImpl: Removed TaskSet 206.0, whose tasks have all completed, from pool 
20/02/14 14:15:29 INFO DAGScheduler: ResultStage 206 (collect at arrowconverters.scala:270) finished in 0.038 s
20/02/14 14:15:29 INFO DAGScheduler: Job 116 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:15:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 206: Stage finished
20/02/14 14:15:29 INFO DAGScheduler: Job 116 finished: collect at arrowconverters.scala:270, took 0.074648 s
20/02/14 14:15:33 INFO BlockManagerInfo: Removed broadcast_206_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 14:15:33 INFO BlockManagerInfo: Removed broadcast_205_piece0 on 127.0.0.1:55441 in memory (size: 13.3 KiB, free: 413.9 MiB)
20/02/14 14:15:33 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 14:15:33 INFO DAGScheduler: Got job 117 (collect at utils.scala:41) with 4 output partitions
20/02/14 14:15:33 INFO DAGScheduler: Final stage: ResultStage 207 (collect at utils.scala:41)
20/02/14 14:15:33 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:15:33 INFO DAGScheduler: Missing parents: List()
20/02/14 14:15:33 INFO DAGScheduler: Submitting ResultStage 207 (MapPartitionsRDD[1150] at map at utils.scala:41), which has no missing parents
20/02/14 14:15:33 INFO MemoryStore: Block broadcast_207 stored as values in memory (estimated size 8.8 KiB, free 413.9 MiB)
20/02/14 14:15:33 INFO MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.9 MiB)
20/02/14 14:15:33 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on 127.0.0.1:55441 (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 14:15:33 INFO SparkContext: Created broadcast 207 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:33 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 207 (MapPartitionsRDD[1150] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 14:15:33 INFO TaskSchedulerImpl: Adding task set 207.0 with 4 tasks
20/02/14 14:15:33 INFO TaskSetManager: Starting task 0.0 in stage 207.0 (TID 261, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7663 bytes)
20/02/14 14:15:33 INFO TaskSetManager: Starting task 1.0 in stage 207.0 (TID 262, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7687 bytes)
20/02/14 14:15:33 INFO TaskSetManager: Starting task 2.0 in stage 207.0 (TID 263, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7687 bytes)
20/02/14 14:15:33 INFO TaskSetManager: Starting task 3.0 in stage 207.0 (TID 264, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7679 bytes)
20/02/14 14:15:33 INFO Executor: Running task 1.0 in stage 207.0 (TID 262)
20/02/14 14:15:33 INFO Executor: Running task 0.0 in stage 207.0 (TID 261)
20/02/14 14:15:33 INFO Executor: Running task 3.0 in stage 207.0 (TID 264)
20/02/14 14:15:33 INFO Executor: Running task 2.0 in stage 207.0 (TID 263)
20/02/14 14:15:33 INFO Executor: Finished task 1.0 in stage 207.0 (TID 262). 1101 bytes result sent to driver
20/02/14 14:15:33 INFO Executor: Finished task 0.0 in stage 207.0 (TID 261). 1082 bytes result sent to driver
20/02/14 14:15:33 INFO Executor: Finished task 2.0 in stage 207.0 (TID 263). 1101 bytes result sent to driver
20/02/14 14:15:33 INFO TaskSetManager: Finished task 1.0 in stage 207.0 (TID 262) in 7 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 14:15:33 INFO TaskSetManager: Finished task 2.0 in stage 207.0 (TID 263) in 7 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 14:15:33 INFO TaskSetManager: Finished task 0.0 in stage 207.0 (TID 261) in 7 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 14:15:33 INFO Executor: Finished task 3.0 in stage 207.0 (TID 264). 1143 bytes result sent to driver
20/02/14 14:15:33 INFO TaskSetManager: Finished task 3.0 in stage 207.0 (TID 264) in 10 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 14:15:33 INFO TaskSchedulerImpl: Removed TaskSet 207.0, whose tasks have all completed, from pool 
20/02/14 14:15:33 INFO DAGScheduler: ResultStage 207 (collect at utils.scala:41) finished in 0.020 s
20/02/14 14:15:33 INFO DAGScheduler: Job 117 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:15:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 207: Stage finished
20/02/14 14:15:33 INFO DAGScheduler: Job 117 finished: collect at utils.scala:41, took 0.023330 s
20/02/14 14:15:33 INFO BlockManagerInfo: Removed broadcast_207_piece0 on 127.0.0.1:55441 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 14:15:33 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/14 14:15:33 INFO DAGScheduler: Registering RDD 1159 (sql at <unknown>:0) as input to shuffle 90
20/02/14 14:15:33 INFO DAGScheduler: Got job 118 (sql at <unknown>:0) with 1 output partitions
20/02/14 14:15:33 INFO DAGScheduler: Final stage: ResultStage 209 (sql at <unknown>:0)
20/02/14 14:15:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 208)
20/02/14 14:15:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 208)
20/02/14 14:15:33 INFO DAGScheduler: Submitting ShuffleMapStage 208 (MapPartitionsRDD[1159] at sql at <unknown>:0), which has no missing parents
20/02/14 14:15:33 INFO MemoryStore: Block broadcast_208 stored as values in memory (estimated size 18.9 KiB, free 413.9 MiB)
20/02/14 14:15:33 INFO MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.9 MiB)
20/02/14 14:15:33 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:15:33 INFO SparkContext: Created broadcast 208 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 208 (MapPartitionsRDD[1159] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:33 INFO TaskSchedulerImpl: Adding task set 208.0 with 1 tasks
20/02/14 14:15:33 INFO TaskSetManager: Starting task 0.0 in stage 208.0 (TID 265, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:15:33 INFO Executor: Running task 0.0 in stage 208.0 (TID 265)
20/02/14 14:15:33 INFO MemoryStore: Block rdd_1154_0 stored as values in memory (estimated size 312.0 B, free 413.9 MiB)
20/02/14 14:15:33 INFO BlockManagerInfo: Added rdd_1154_0 in memory on 127.0.0.1:55441 (size: 312.0 B, free: 413.9 MiB)
20/02/14 14:15:33 INFO Executor: Finished task 0.0 in stage 208.0 (TID 265). 2240 bytes result sent to driver
20/02/14 14:15:33 INFO TaskSetManager: Finished task 0.0 in stage 208.0 (TID 265) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:33 INFO TaskSchedulerImpl: Removed TaskSet 208.0, whose tasks have all completed, from pool 
20/02/14 14:15:33 INFO DAGScheduler: ShuffleMapStage 208 (sql at <unknown>:0) finished in 0.020 s
20/02/14 14:15:33 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:15:33 INFO DAGScheduler: running: Set()
20/02/14 14:15:33 INFO DAGScheduler: waiting: Set(ResultStage 209)
20/02/14 14:15:33 INFO DAGScheduler: failed: Set()
20/02/14 14:15:33 INFO DAGScheduler: Submitting ResultStage 209 (MapPartitionsRDD[1162] at sql at <unknown>:0), which has no missing parents
20/02/14 14:15:33 INFO MemoryStore: Block broadcast_209 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/14 14:15:33 INFO MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
20/02/14 14:15:33 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:15:33 INFO SparkContext: Created broadcast 209 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 209 (MapPartitionsRDD[1162] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:33 INFO TaskSchedulerImpl: Adding task set 209.0 with 1 tasks
20/02/14 14:15:33 INFO TaskSetManager: Starting task 0.0 in stage 209.0 (TID 266, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:15:33 INFO Executor: Running task 0.0 in stage 209.0 (TID 266)
20/02/14 14:15:33 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:15:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:15:33 INFO Executor: Finished task 0.0 in stage 209.0 (TID 266). 2803 bytes result sent to driver
20/02/14 14:15:33 INFO TaskSetManager: Finished task 0.0 in stage 209.0 (TID 266) in 4 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:33 INFO TaskSchedulerImpl: Removed TaskSet 209.0, whose tasks have all completed, from pool 
20/02/14 14:15:33 INFO DAGScheduler: ResultStage 209 (sql at <unknown>:0) finished in 0.010 s
20/02/14 14:15:33 INFO DAGScheduler: Job 118 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:15:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 209: Stage finished
20/02/14 14:15:33 INFO DAGScheduler: Job 118 finished: sql at <unknown>:0, took 0.035459 s
20/02/14 14:15:33 INFO BlockManagerInfo: Removed broadcast_208_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:15:33 INFO BlockManagerInfo: Removed broadcast_209_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:15:33 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 14:15:33 INFO DAGScheduler: Registering RDD 1167 (collect at arrowconverters.scala:270) as input to shuffle 91
20/02/14 14:15:33 INFO DAGScheduler: Got job 119 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 14:15:33 INFO DAGScheduler: Final stage: ResultStage 211 (collect at arrowconverters.scala:270)
20/02/14 14:15:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 210)
20/02/14 14:15:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 210)
20/02/14 14:15:33 INFO DAGScheduler: Submitting ShuffleMapStage 210 (MapPartitionsRDD[1167] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:15:33 INFO MemoryStore: Block broadcast_210 stored as values in memory (estimated size 18.9 KiB, free 413.9 MiB)
20/02/14 14:15:33 INFO MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.9 MiB)
20/02/14 14:15:33 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:15:33 INFO SparkContext: Created broadcast 210 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 210 (MapPartitionsRDD[1167] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:33 INFO TaskSchedulerImpl: Adding task set 210.0 with 1 tasks
20/02/14 14:15:33 INFO TaskSetManager: Starting task 0.0 in stage 210.0 (TID 267, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:15:33 INFO Executor: Running task 0.0 in stage 210.0 (TID 267)
20/02/14 14:15:33 INFO BlockManager: Found block rdd_1154_0 locally
20/02/14 14:15:33 INFO Executor: Finished task 0.0 in stage 210.0 (TID 267). 2369 bytes result sent to driver
20/02/14 14:15:33 INFO TaskSetManager: Finished task 0.0 in stage 210.0 (TID 267) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:33 INFO TaskSchedulerImpl: Removed TaskSet 210.0, whose tasks have all completed, from pool 
20/02/14 14:15:33 INFO DAGScheduler: ShuffleMapStage 210 (collect at arrowconverters.scala:270) finished in 0.023 s
20/02/14 14:15:33 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:15:33 INFO DAGScheduler: running: Set()
20/02/14 14:15:33 INFO DAGScheduler: waiting: Set(ResultStage 211)
20/02/14 14:15:33 INFO DAGScheduler: failed: Set()
20/02/14 14:15:33 INFO DAGScheduler: Submitting ResultStage 211 (MapPartitionsRDD[1173] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:15:33 INFO MemoryStore: Block broadcast_211 stored as values in memory (estimated size 28.9 KiB, free 413.9 MiB)
20/02/14 14:15:33 INFO MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 12.0 KiB, free 413.9 MiB)
20/02/14 14:15:33 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on 127.0.0.1:55441 (size: 12.0 KiB, free: 413.9 MiB)
20/02/14 14:15:33 INFO SparkContext: Created broadcast 211 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 211 (MapPartitionsRDD[1173] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:33 INFO TaskSchedulerImpl: Adding task set 211.0 with 1 tasks
20/02/14 14:15:33 INFO TaskSetManager: Starting task 0.0 in stage 211.0 (TID 268, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:15:33 INFO Executor: Running task 0.0 in stage 211.0 (TID 268)
20/02/14 14:15:33 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:15:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:15:33 INFO Executor: Finished task 0.0 in stage 211.0 (TID 268). 4285 bytes result sent to driver
20/02/14 14:15:33 INFO TaskSetManager: Finished task 0.0 in stage 211.0 (TID 268) in 14 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:33 INFO TaskSchedulerImpl: Removed TaskSet 211.0, whose tasks have all completed, from pool 
20/02/14 14:15:33 INFO DAGScheduler: ResultStage 211 (collect at arrowconverters.scala:270) finished in 0.029 s
20/02/14 14:15:33 INFO DAGScheduler: Job 119 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:15:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 211: Stage finished
20/02/14 14:15:33 INFO DAGScheduler: Job 119 finished: collect at arrowconverters.scala:270, took 0.058486 s
20/02/14 14:15:34 INFO Instrumentation: [ab17a5a4] training finished
20/02/14 14:15:34 INFO Instrumentation: [d718ee7a] training finished
20/02/14 14:15:34 INFO BlockManagerInfo: Removed broadcast_211_piece0 on 127.0.0.1:55441 in memory (size: 12.0 KiB, free: 413.9 MiB)
20/02/14 14:15:34 INFO BlockManagerInfo: Removed broadcast_210_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:15:34 INFO CodeGenerator: Code generated in 5.8452 ms
20/02/14 14:15:34 INFO CodeGenerator: Code generated in 13.2824 ms
20/02/14 14:15:34 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 14:15:34 INFO DAGScheduler: Registering RDD 1178 (collect at arrowconverters.scala:270) as input to shuffle 92
20/02/14 14:15:34 INFO DAGScheduler: Got job 120 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 14:15:34 INFO DAGScheduler: Final stage: ResultStage 213 (collect at arrowconverters.scala:270)
20/02/14 14:15:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 212)
20/02/14 14:15:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 212)
20/02/14 14:15:34 INFO DAGScheduler: Submitting ShuffleMapStage 212 (MapPartitionsRDD[1178] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:15:34 INFO MemoryStore: Block broadcast_212 stored as values in memory (estimated size 31.9 KiB, free 413.9 MiB)
20/02/14 14:15:34 INFO MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 13.3 KiB, free 413.9 MiB)
20/02/14 14:15:34 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on 127.0.0.1:55441 (size: 13.3 KiB, free: 413.9 MiB)
20/02/14 14:15:34 INFO SparkContext: Created broadcast 212 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 212 (MapPartitionsRDD[1178] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:34 INFO TaskSchedulerImpl: Adding task set 212.0 with 1 tasks
20/02/14 14:15:34 INFO TaskSetManager: Starting task 0.0 in stage 212.0 (TID 269, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:15:34 INFO Executor: Running task 0.0 in stage 212.0 (TID 269)
20/02/14 14:15:34 INFO BlockManager: Found block rdd_1154_0 locally
20/02/14 14:15:34 INFO Executor: Finished task 0.0 in stage 212.0 (TID 269). 2157 bytes result sent to driver
20/02/14 14:15:34 INFO TaskSetManager: Finished task 0.0 in stage 212.0 (TID 269) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:34 INFO TaskSchedulerImpl: Removed TaskSet 212.0, whose tasks have all completed, from pool 
20/02/14 14:15:34 INFO DAGScheduler: ShuffleMapStage 212 (collect at arrowconverters.scala:270) finished in 0.021 s
20/02/14 14:15:34 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:15:34 INFO DAGScheduler: running: Set()
20/02/14 14:15:34 INFO DAGScheduler: waiting: Set(ResultStage 213)
20/02/14 14:15:34 INFO DAGScheduler: failed: Set()
20/02/14 14:15:34 INFO DAGScheduler: Submitting ResultStage 213 (MapPartitionsRDD[1184] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:15:34 INFO MemoryStore: Block broadcast_213 stored as values in memory (estimated size 33.7 KiB, free 413.8 MiB)
20/02/14 14:15:34 INFO MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 413.8 MiB)
20/02/14 14:15:34 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on 127.0.0.1:55441 (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 14:15:34 INFO SparkContext: Created broadcast 213 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 213 (MapPartitionsRDD[1184] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:34 INFO TaskSchedulerImpl: Adding task set 213.0 with 1 tasks
20/02/14 14:15:34 INFO TaskSetManager: Starting task 0.0 in stage 213.0 (TID 270, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:15:34 INFO Executor: Running task 0.0 in stage 213.0 (TID 270)
20/02/14 14:15:34 INFO ShuffleBlockFetcherIterator: Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:15:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:15:34 INFO Executor: Finished task 0.0 in stage 213.0 (TID 270). 3515 bytes result sent to driver
20/02/14 14:15:34 INFO TaskSetManager: Finished task 0.0 in stage 213.0 (TID 270) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:34 INFO TaskSchedulerImpl: Removed TaskSet 213.0, whose tasks have all completed, from pool 
20/02/14 14:15:34 INFO DAGScheduler: ResultStage 213 (collect at arrowconverters.scala:270) finished in 0.022 s
20/02/14 14:15:34 INFO DAGScheduler: Job 120 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:15:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 213: Stage finished
20/02/14 14:15:34 INFO DAGScheduler: Job 120 finished: collect at arrowconverters.scala:270, took 0.049800 s
20/02/14 14:15:53 INFO BlockManagerInfo: Removed broadcast_212_piece0 on 127.0.0.1:55441 in memory (size: 13.3 KiB, free: 413.9 MiB)
20/02/14 14:15:53 INFO BlockManagerInfo: Removed broadcast_213_piece0 on 127.0.0.1:55441 in memory (size: 15.2 KiB, free: 413.9 MiB)
20/02/14 14:15:53 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 14:15:53 INFO DAGScheduler: Got job 121 (collect at utils.scala:41) with 4 output partitions
20/02/14 14:15:53 INFO DAGScheduler: Final stage: ResultStage 214 (collect at utils.scala:41)
20/02/14 14:15:53 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:15:53 INFO DAGScheduler: Missing parents: List()
20/02/14 14:15:53 INFO DAGScheduler: Submitting ResultStage 214 (MapPartitionsRDD[1190] at map at utils.scala:41), which has no missing parents
20/02/14 14:15:53 INFO MemoryStore: Block broadcast_214 stored as values in memory (estimated size 8.8 KiB, free 413.9 MiB)
20/02/14 14:15:53 INFO MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.9 MiB)
20/02/14 14:15:53 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on 127.0.0.1:55441 (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 14:15:53 INFO SparkContext: Created broadcast 214 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:53 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 214 (MapPartitionsRDD[1190] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 14:15:53 INFO TaskSchedulerImpl: Adding task set 214.0 with 4 tasks
20/02/14 14:15:53 INFO TaskSetManager: Starting task 0.0 in stage 214.0 (TID 271, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7663 bytes)
20/02/14 14:15:53 INFO TaskSetManager: Starting task 1.0 in stage 214.0 (TID 272, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7752 bytes)
20/02/14 14:15:53 INFO TaskSetManager: Starting task 2.0 in stage 214.0 (TID 273, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7679 bytes)
20/02/14 14:15:53 INFO TaskSetManager: Starting task 3.0 in stage 214.0 (TID 274, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7744 bytes)
20/02/14 14:15:53 INFO Executor: Running task 0.0 in stage 214.0 (TID 271)
20/02/14 14:15:53 INFO Executor: Running task 3.0 in stage 214.0 (TID 274)
20/02/14 14:15:53 INFO Executor: Running task 2.0 in stage 214.0 (TID 273)
20/02/14 14:15:53 INFO Executor: Running task 1.0 in stage 214.0 (TID 272)
20/02/14 14:15:53 INFO Executor: Finished task 2.0 in stage 214.0 (TID 273). 1100 bytes result sent to driver
20/02/14 14:15:53 INFO Executor: Finished task 1.0 in stage 214.0 (TID 272). 1129 bytes result sent to driver
20/02/14 14:15:53 INFO Executor: Finished task 0.0 in stage 214.0 (TID 271). 1082 bytes result sent to driver
20/02/14 14:15:53 INFO TaskSetManager: Finished task 2.0 in stage 214.0 (TID 273) in 9 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 14:15:53 INFO Executor: Finished task 3.0 in stage 214.0 (TID 274). 1128 bytes result sent to driver
20/02/14 14:15:53 INFO TaskSetManager: Finished task 0.0 in stage 214.0 (TID 271) in 10 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 14:15:53 INFO TaskSetManager: Finished task 1.0 in stage 214.0 (TID 272) in 10 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 14:15:53 INFO TaskSetManager: Finished task 3.0 in stage 214.0 (TID 274) in 10 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 14:15:53 INFO TaskSchedulerImpl: Removed TaskSet 214.0, whose tasks have all completed, from pool 
20/02/14 14:15:53 INFO DAGScheduler: ResultStage 214 (collect at utils.scala:41) finished in 0.019 s
20/02/14 14:15:53 INFO DAGScheduler: Job 121 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:15:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 214: Stage finished
20/02/14 14:15:53 INFO DAGScheduler: Job 121 finished: collect at utils.scala:41, took 0.022602 s
20/02/14 14:15:53 INFO BlockManagerInfo: Removed broadcast_214_piece0 on 127.0.0.1:55441 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 14:15:53 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/14 14:15:53 INFO DAGScheduler: Registering RDD 1199 (sql at <unknown>:0) as input to shuffle 93
20/02/14 14:15:53 INFO DAGScheduler: Got job 122 (sql at <unknown>:0) with 1 output partitions
20/02/14 14:15:53 INFO DAGScheduler: Final stage: ResultStage 216 (sql at <unknown>:0)
20/02/14 14:15:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 215)
20/02/14 14:15:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 215)
20/02/14 14:15:53 INFO DAGScheduler: Submitting ShuffleMapStage 215 (MapPartitionsRDD[1199] at sql at <unknown>:0), which has no missing parents
20/02/14 14:15:53 INFO MemoryStore: Block broadcast_215 stored as values in memory (estimated size 18.9 KiB, free 413.9 MiB)
20/02/14 14:15:53 INFO MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.9 MiB)
20/02/14 14:15:53 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:15:53 INFO SparkContext: Created broadcast 215 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 215 (MapPartitionsRDD[1199] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:53 INFO TaskSchedulerImpl: Adding task set 215.0 with 1 tasks
20/02/14 14:15:53 INFO TaskSetManager: Starting task 0.0 in stage 215.0 (TID 275, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:15:53 INFO Executor: Running task 0.0 in stage 215.0 (TID 275)
20/02/14 14:15:53 INFO MemoryStore: Block rdd_1194_0 stored as values in memory (estimated size 312.0 B, free 413.9 MiB)
20/02/14 14:15:53 INFO BlockManagerInfo: Added rdd_1194_0 in memory on 127.0.0.1:55441 (size: 312.0 B, free: 413.9 MiB)
20/02/14 14:15:53 INFO Executor: Finished task 0.0 in stage 215.0 (TID 275). 2240 bytes result sent to driver
20/02/14 14:15:53 INFO TaskSetManager: Finished task 0.0 in stage 215.0 (TID 275) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:53 INFO TaskSchedulerImpl: Removed TaskSet 215.0, whose tasks have all completed, from pool 
20/02/14 14:15:53 INFO DAGScheduler: ShuffleMapStage 215 (sql at <unknown>:0) finished in 0.022 s
20/02/14 14:15:53 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:15:53 INFO DAGScheduler: running: Set()
20/02/14 14:15:53 INFO DAGScheduler: waiting: Set(ResultStage 216)
20/02/14 14:15:53 INFO DAGScheduler: failed: Set()
20/02/14 14:15:53 INFO DAGScheduler: Submitting ResultStage 216 (MapPartitionsRDD[1202] at sql at <unknown>:0), which has no missing parents
20/02/14 14:15:53 INFO MemoryStore: Block broadcast_216 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/14 14:15:53 INFO MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
20/02/14 14:15:53 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:15:53 INFO SparkContext: Created broadcast 216 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 216 (MapPartitionsRDD[1202] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:53 INFO TaskSchedulerImpl: Adding task set 216.0 with 1 tasks
20/02/14 14:15:53 INFO TaskSetManager: Starting task 0.0 in stage 216.0 (TID 276, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:15:53 INFO Executor: Running task 0.0 in stage 216.0 (TID 276)
20/02/14 14:15:53 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:15:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:15:53 INFO Executor: Finished task 0.0 in stage 216.0 (TID 276). 2760 bytes result sent to driver
20/02/14 14:15:53 INFO TaskSetManager: Finished task 0.0 in stage 216.0 (TID 276) in 5 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:53 INFO TaskSchedulerImpl: Removed TaskSet 216.0, whose tasks have all completed, from pool 
20/02/14 14:15:53 INFO DAGScheduler: ResultStage 216 (sql at <unknown>:0) finished in 0.010 s
20/02/14 14:15:53 INFO DAGScheduler: Job 122 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:15:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 216: Stage finished
20/02/14 14:15:53 INFO DAGScheduler: Job 122 finished: sql at <unknown>:0, took 0.037372 s
20/02/14 14:15:53 INFO BlockManagerInfo: Removed broadcast_215_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:15:53 INFO BlockManagerInfo: Removed broadcast_216_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:15:53 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 14:15:53 INFO DAGScheduler: Registering RDD 1207 (collect at arrowconverters.scala:270) as input to shuffle 94
20/02/14 14:15:53 INFO DAGScheduler: Got job 123 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 14:15:53 INFO DAGScheduler: Final stage: ResultStage 218 (collect at arrowconverters.scala:270)
20/02/14 14:15:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 217)
20/02/14 14:15:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 217)
20/02/14 14:15:53 INFO DAGScheduler: Submitting ShuffleMapStage 217 (MapPartitionsRDD[1207] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:15:53 INFO MemoryStore: Block broadcast_217 stored as values in memory (estimated size 18.9 KiB, free 413.9 MiB)
20/02/14 14:15:53 INFO MemoryStore: Block broadcast_217_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.9 MiB)
20/02/14 14:15:53 INFO BlockManagerInfo: Added broadcast_217_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:15:53 INFO SparkContext: Created broadcast 217 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 217 (MapPartitionsRDD[1207] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:53 INFO TaskSchedulerImpl: Adding task set 217.0 with 1 tasks
20/02/14 14:15:53 INFO TaskSetManager: Starting task 0.0 in stage 217.0 (TID 277, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:15:53 INFO Executor: Running task 0.0 in stage 217.0 (TID 277)
20/02/14 14:15:53 INFO BlockManager: Found block rdd_1194_0 locally
20/02/14 14:15:53 INFO Executor: Finished task 0.0 in stage 217.0 (TID 277). 2326 bytes result sent to driver
20/02/14 14:15:53 INFO TaskSetManager: Finished task 0.0 in stage 217.0 (TID 277) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:53 INFO TaskSchedulerImpl: Removed TaskSet 217.0, whose tasks have all completed, from pool 
20/02/14 14:15:53 INFO DAGScheduler: ShuffleMapStage 217 (collect at arrowconverters.scala:270) finished in 0.024 s
20/02/14 14:15:53 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:15:53 INFO DAGScheduler: running: Set()
20/02/14 14:15:53 INFO DAGScheduler: waiting: Set(ResultStage 218)
20/02/14 14:15:53 INFO DAGScheduler: failed: Set()
20/02/14 14:15:53 INFO DAGScheduler: Submitting ResultStage 218 (MapPartitionsRDD[1213] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:15:53 INFO MemoryStore: Block broadcast_218 stored as values in memory (estimated size 28.9 KiB, free 413.9 MiB)
20/02/14 14:15:53 INFO MemoryStore: Block broadcast_218_piece0 stored as bytes in memory (estimated size 12.0 KiB, free 413.9 MiB)
20/02/14 14:15:53 INFO BlockManagerInfo: Added broadcast_218_piece0 in memory on 127.0.0.1:55441 (size: 12.0 KiB, free: 413.9 MiB)
20/02/14 14:15:53 INFO SparkContext: Created broadcast 218 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 218 (MapPartitionsRDD[1213] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:53 INFO TaskSchedulerImpl: Adding task set 218.0 with 1 tasks
20/02/14 14:15:53 INFO TaskSetManager: Starting task 0.0 in stage 218.0 (TID 278, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:15:53 INFO Executor: Running task 0.0 in stage 218.0 (TID 278)
20/02/14 14:15:53 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:15:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:15:53 INFO Executor: Finished task 0.0 in stage 218.0 (TID 278). 4328 bytes result sent to driver
20/02/14 14:15:53 INFO TaskSetManager: Finished task 0.0 in stage 218.0 (TID 278) in 28 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:53 INFO TaskSchedulerImpl: Removed TaskSet 218.0, whose tasks have all completed, from pool 
20/02/14 14:15:53 INFO DAGScheduler: ResultStage 218 (collect at arrowconverters.scala:270) finished in 0.047 s
20/02/14 14:15:53 INFO DAGScheduler: Job 123 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:15:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 218: Stage finished
20/02/14 14:15:53 INFO DAGScheduler: Job 123 finished: collect at arrowconverters.scala:270, took 0.076332 s
20/02/14 14:15:54 INFO Instrumentation: [e5f60c64] training finished
20/02/14 14:15:54 INFO Instrumentation: [6201100b] training finished
20/02/14 14:15:54 INFO BlockManagerInfo: Removed broadcast_217_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:15:54 INFO BlockManagerInfo: Removed broadcast_218_piece0 on 127.0.0.1:55441 in memory (size: 12.0 KiB, free: 413.9 MiB)
20/02/14 14:15:55 INFO CodeGenerator: Code generated in 12.6881 ms
20/02/14 14:15:55 INFO CodeGenerator: Code generated in 8.1326 ms
20/02/14 14:15:55 INFO CodeGenerator: Code generated in 19.5197 ms
20/02/14 14:15:55 INFO CodeGenerator: Code generated in 53.9794 ms
20/02/14 14:15:55 INFO CodeGenerator: Code generated in 37.1539 ms
20/02/14 14:15:55 INFO CodeGenerator: Code generated in 9.898 ms
20/02/14 14:15:55 INFO CodeGenerator: Code generated in 7.9588 ms
20/02/14 14:15:55 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 14:15:55 INFO DAGScheduler: Registering RDD 1225 (collect at arrowconverters.scala:270) as input to shuffle 96
20/02/14 14:15:55 INFO DAGScheduler: Registering RDD 1218 (collect at arrowconverters.scala:270) as input to shuffle 95
20/02/14 14:15:55 INFO DAGScheduler: Registering RDD 1230 (collect at arrowconverters.scala:270) as input to shuffle 97
20/02/14 14:15:55 INFO DAGScheduler: Got job 124 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 14:15:55 INFO DAGScheduler: Final stage: ResultStage 222 (collect at arrowconverters.scala:270)
20/02/14 14:15:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 221)
20/02/14 14:15:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 221)
20/02/14 14:15:55 INFO DAGScheduler: Submitting ShuffleMapStage 219 (MapPartitionsRDD[1225] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:15:55 INFO MemoryStore: Block broadcast_219 stored as values in memory (estimated size 27.4 KiB, free 413.9 MiB)
20/02/14 14:15:55 INFO MemoryStore: Block broadcast_219_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.9 MiB)
20/02/14 14:15:55 INFO BlockManagerInfo: Added broadcast_219_piece0 in memory on 127.0.0.1:55441 (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 14:15:55 INFO SparkContext: Created broadcast 219 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 219 (MapPartitionsRDD[1225] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:55 INFO TaskSchedulerImpl: Adding task set 219.0 with 1 tasks
20/02/14 14:15:55 INFO TaskSetManager: Starting task 0.0 in stage 219.0 (TID 279, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 14:15:55 INFO DAGScheduler: Submitting ShuffleMapStage 220 (MapPartitionsRDD[1218] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:15:55 INFO Executor: Running task 0.0 in stage 219.0 (TID 279)
20/02/14 14:15:55 INFO MemoryStore: Block broadcast_220 stored as values in memory (estimated size 32.1 KiB, free 413.9 MiB)
20/02/14 14:15:55 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:15:55 INFO MemoryStore: Block broadcast_220_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 413.8 MiB)
20/02/14 14:15:55 INFO BlockManagerInfo: Added broadcast_220_piece0 in memory on 127.0.0.1:55441 (size: 13.5 KiB, free: 413.9 MiB)
20/02/14 14:15:55 INFO SparkContext: Created broadcast 220 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 220 (MapPartitionsRDD[1218] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:55 INFO TaskSchedulerImpl: Adding task set 220.0 with 1 tasks
20/02/14 14:15:55 INFO TaskSetManager: Starting task 0.0 in stage 220.0 (TID 280, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:15:55 INFO Executor: Running task 0.0 in stage 220.0 (TID 280)
20/02/14 14:15:55 INFO BlockManager: Found block rdd_1194_0 locally
20/02/14 14:15:55 INFO CodeGenerator: Code generated in 16.4849 ms
20/02/14 14:15:55 INFO CodeGenerator: Code generated in 19.934 ms
20/02/14 14:15:55 INFO Executor: Finished task 0.0 in stage 219.0 (TID 279). 2246 bytes result sent to driver
20/02/14 14:15:55 INFO TaskSetManager: Finished task 0.0 in stage 219.0 (TID 279) in 84 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:55 INFO TaskSchedulerImpl: Removed TaskSet 219.0, whose tasks have all completed, from pool 
20/02/14 14:15:55 INFO DAGScheduler: ShuffleMapStage 219 (collect at arrowconverters.scala:270) finished in 0.091 s
20/02/14 14:15:55 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:15:55 INFO DAGScheduler: running: Set(ShuffleMapStage 220)
20/02/14 14:15:55 INFO DAGScheduler: waiting: Set(ResultStage 222, ShuffleMapStage 221)
20/02/14 14:15:55 INFO DAGScheduler: failed: Set()
20/02/14 14:15:55 INFO Executor: Finished task 0.0 in stage 220.0 (TID 280). 2246 bytes result sent to driver
20/02/14 14:15:55 INFO TaskSetManager: Finished task 0.0 in stage 220.0 (TID 280) in 82 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:55 INFO TaskSchedulerImpl: Removed TaskSet 220.0, whose tasks have all completed, from pool 
20/02/14 14:15:55 INFO DAGScheduler: ShuffleMapStage 220 (collect at arrowconverters.scala:270) finished in 0.090 s
20/02/14 14:15:55 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:15:55 INFO DAGScheduler: running: Set()
20/02/14 14:15:55 INFO DAGScheduler: waiting: Set(ResultStage 222, ShuffleMapStage 221)
20/02/14 14:15:55 INFO DAGScheduler: failed: Set()
20/02/14 14:15:55 INFO DAGScheduler: Submitting ShuffleMapStage 221 (MapPartitionsRDD[1230] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:15:55 INFO MemoryStore: Block broadcast_221 stored as values in memory (estimated size 52.6 KiB, free 413.8 MiB)
20/02/14 14:15:55 INFO MemoryStore: Block broadcast_221_piece0 stored as bytes in memory (estimated size 22.1 KiB, free 413.8 MiB)
20/02/14 14:15:55 INFO BlockManagerInfo: Added broadcast_221_piece0 in memory on 127.0.0.1:55441 (size: 22.1 KiB, free: 413.9 MiB)
20/02/14 14:15:55 INFO SparkContext: Created broadcast 221 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:55 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 221 (MapPartitionsRDD[1230] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 14:15:55 INFO TaskSchedulerImpl: Adding task set 221.0 with 4 tasks
20/02/14 14:15:55 INFO TaskSetManager: Starting task 0.0 in stage 221.0 (TID 281, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7517 bytes)
20/02/14 14:15:55 INFO TaskSetManager: Starting task 1.0 in stage 221.0 (TID 282, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7517 bytes)
20/02/14 14:15:55 INFO TaskSetManager: Starting task 2.0 in stage 221.0 (TID 283, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7517 bytes)
20/02/14 14:15:55 INFO TaskSetManager: Starting task 3.0 in stage 221.0 (TID 284, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7517 bytes)
20/02/14 14:15:55 INFO Executor: Running task 0.0 in stage 221.0 (TID 281)
20/02/14 14:15:55 INFO Executor: Running task 1.0 in stage 221.0 (TID 282)
20/02/14 14:15:55 INFO Executor: Running task 3.0 in stage 221.0 (TID 284)
20/02/14 14:15:55 INFO Executor: Running task 2.0 in stage 221.0 (TID 283)
20/02/14 14:15:55 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:15:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:15:55 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:15:55 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:15:55 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:15:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:15:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 14:15:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:15:55 INFO CodeGenerator: Code generated in 79.3707 ms
20/02/14 14:15:55 INFO BlockManagerInfo: Removed broadcast_220_piece0 on 127.0.0.1:55441 in memory (size: 13.5 KiB, free: 413.9 MiB)
20/02/14 14:15:55 INFO BlockManagerInfo: Removed broadcast_219_piece0 on 127.0.0.1:55441 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 14:15:55 INFO CodeGenerator: Code generated in 15.7668 ms
20/02/14 14:15:55 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:15:55 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:15:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:15:55 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:15:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 14:15:55 INFO ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:15:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:15:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:15:55 INFO CodeGenerator: Code generated in 14.9915 ms
20/02/14 14:15:55 INFO CodeGenerator: Code generated in 10.2564 ms
20/02/14 14:15:55 INFO CodeGenerator: Code generated in 8.209 ms
20/02/14 14:15:55 INFO CodeGenerator: Code generated in 7.8651 ms
20/02/14 14:15:56 INFO Executor: Finished task 3.0 in stage 221.0 (TID 284). 5869 bytes result sent to driver
20/02/14 14:15:56 INFO TaskSetManager: Finished task 3.0 in stage 221.0 (TID 284) in 617 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 14:15:56 INFO Executor: Finished task 1.0 in stage 221.0 (TID 282). 5869 bytes result sent to driver
20/02/14 14:15:56 INFO TaskSetManager: Finished task 1.0 in stage 221.0 (TID 282) in 622 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 14:15:56 INFO Executor: Finished task 0.0 in stage 221.0 (TID 281). 5869 bytes result sent to driver
20/02/14 14:15:56 INFO TaskSetManager: Finished task 0.0 in stage 221.0 (TID 281) in 627 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 14:15:56 INFO Executor: Finished task 2.0 in stage 221.0 (TID 283). 5869 bytes result sent to driver
20/02/14 14:15:56 INFO TaskSetManager: Finished task 2.0 in stage 221.0 (TID 283) in 629 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 14:15:56 INFO TaskSchedulerImpl: Removed TaskSet 221.0, whose tasks have all completed, from pool 
20/02/14 14:15:56 INFO DAGScheduler: ShuffleMapStage 221 (collect at arrowconverters.scala:270) finished in 0.639 s
20/02/14 14:15:56 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:15:56 INFO DAGScheduler: running: Set()
20/02/14 14:15:56 INFO DAGScheduler: waiting: Set(ResultStage 222)
20/02/14 14:15:56 INFO DAGScheduler: failed: Set()
20/02/14 14:15:56 INFO DAGScheduler: Submitting ResultStage 222 (MapPartitionsRDD[1236] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:15:56 INFO MemoryStore: Block broadcast_222 stored as values in memory (estimated size 52.0 KiB, free 413.8 MiB)
20/02/14 14:15:56 INFO MemoryStore: Block broadcast_222_piece0 stored as bytes in memory (estimated size 21.9 KiB, free 413.8 MiB)
20/02/14 14:15:56 INFO BlockManagerInfo: Added broadcast_222_piece0 in memory on 127.0.0.1:55441 (size: 21.9 KiB, free: 413.9 MiB)
20/02/14 14:15:56 INFO SparkContext: Created broadcast 222 from broadcast at DAGScheduler.scala:1196
20/02/14 14:15:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 222 (MapPartitionsRDD[1236] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:15:56 INFO TaskSchedulerImpl: Adding task set 222.0 with 1 tasks
20/02/14 14:15:56 INFO TaskSetManager: Starting task 0.0 in stage 222.0 (TID 285, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:15:56 INFO Executor: Running task 0.0 in stage 222.0 (TID 285)
20/02/14 14:15:56 INFO ShuffleBlockFetcherIterator: Getting 4 (597.0 B) non-empty blocks including 4 (597.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:15:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:15:56 INFO Executor: Finished task 0.0 in stage 222.0 (TID 285). 6469 bytes result sent to driver
20/02/14 14:15:56 INFO TaskSetManager: Finished task 0.0 in stage 222.0 (TID 285) in 23 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:15:56 INFO TaskSchedulerImpl: Removed TaskSet 222.0, whose tasks have all completed, from pool 
20/02/14 14:15:56 INFO DAGScheduler: ResultStage 222 (collect at arrowconverters.scala:270) finished in 0.034 s
20/02/14 14:15:56 INFO DAGScheduler: Job 124 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:15:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 222: Stage finished
20/02/14 14:15:56 INFO DAGScheduler: Job 124 finished: collect at arrowconverters.scala:270, took 0.791072 s
20/02/14 14:16:00 INFO BlockManagerInfo: Removed broadcast_222_piece0 on 127.0.0.1:55441 in memory (size: 21.9 KiB, free: 413.9 MiB)
20/02/14 14:16:00 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 14:16:00 INFO DAGScheduler: Got job 125 (collect at utils.scala:41) with 4 output partitions
20/02/14 14:16:00 INFO DAGScheduler: Final stage: ResultStage 223 (collect at utils.scala:41)
20/02/14 14:16:00 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:16:00 INFO DAGScheduler: Missing parents: List()
20/02/14 14:16:00 INFO DAGScheduler: Submitting ResultStage 223 (MapPartitionsRDD[1242] at map at utils.scala:41), which has no missing parents
20/02/14 14:16:00 INFO MemoryStore: Block broadcast_223 stored as values in memory (estimated size 8.8 KiB, free 413.8 MiB)
20/02/14 14:16:00 INFO MemoryStore: Block broadcast_223_piece0 stored as bytes in memory (estimated size 4.7 KiB, free 413.8 MiB)
20/02/14 14:16:00 INFO BlockManagerInfo: Added broadcast_223_piece0 in memory on 127.0.0.1:55441 (size: 4.7 KiB, free: 413.9 MiB)
20/02/14 14:16:00 INFO SparkContext: Created broadcast 223 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:00 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 223 (MapPartitionsRDD[1242] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 14:16:00 INFO TaskSchedulerImpl: Adding task set 223.0 with 4 tasks
20/02/14 14:16:00 INFO TaskSetManager: Starting task 0.0 in stage 223.0 (TID 286, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7728 bytes)
20/02/14 14:16:00 INFO TaskSetManager: Starting task 1.0 in stage 223.0 (TID 287, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7752 bytes)
20/02/14 14:16:00 INFO TaskSetManager: Starting task 2.0 in stage 223.0 (TID 288, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7736 bytes)
20/02/14 14:16:00 INFO TaskSetManager: Starting task 3.0 in stage 223.0 (TID 289, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7744 bytes)
20/02/14 14:16:00 INFO Executor: Running task 0.0 in stage 223.0 (TID 286)
20/02/14 14:16:00 INFO Executor: Running task 2.0 in stage 223.0 (TID 288)
20/02/14 14:16:00 INFO Executor: Running task 3.0 in stage 223.0 (TID 289)
20/02/14 14:16:00 INFO Executor: Running task 1.0 in stage 223.0 (TID 287)
20/02/14 14:16:00 INFO Executor: Finished task 2.0 in stage 223.0 (TID 288). 1127 bytes result sent to driver
20/02/14 14:16:00 INFO Executor: Finished task 0.0 in stage 223.0 (TID 286). 1110 bytes result sent to driver
20/02/14 14:16:00 INFO TaskSetManager: Finished task 2.0 in stage 223.0 (TID 288) in 10 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 14:16:00 INFO Executor: Finished task 3.0 in stage 223.0 (TID 289). 1128 bytes result sent to driver
20/02/14 14:16:00 INFO Executor: Finished task 1.0 in stage 223.0 (TID 287). 1129 bytes result sent to driver
20/02/14 14:16:00 INFO TaskSetManager: Finished task 0.0 in stage 223.0 (TID 286) in 11 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 14:16:00 INFO TaskSetManager: Finished task 3.0 in stage 223.0 (TID 289) in 11 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 14:16:00 INFO TaskSetManager: Finished task 1.0 in stage 223.0 (TID 287) in 12 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 14:16:00 INFO TaskSchedulerImpl: Removed TaskSet 223.0, whose tasks have all completed, from pool 
20/02/14 14:16:00 INFO DAGScheduler: ResultStage 223 (collect at utils.scala:41) finished in 0.017 s
20/02/14 14:16:00 INFO DAGScheduler: Job 125 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 223: Stage finished
20/02/14 14:16:00 INFO DAGScheduler: Job 125 finished: collect at utils.scala:41, took 0.020900 s
20/02/14 14:16:00 INFO BlockManagerInfo: Removed broadcast_223_piece0 on 127.0.0.1:55441 in memory (size: 4.7 KiB, free: 413.9 MiB)
20/02/14 14:16:00 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/14 14:16:00 INFO DAGScheduler: Registering RDD 1251 (sql at <unknown>:0) as input to shuffle 98
20/02/14 14:16:00 INFO DAGScheduler: Got job 126 (sql at <unknown>:0) with 1 output partitions
20/02/14 14:16:00 INFO DAGScheduler: Final stage: ResultStage 225 (sql at <unknown>:0)
20/02/14 14:16:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 224)
20/02/14 14:16:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 224)
20/02/14 14:16:00 INFO DAGScheduler: Submitting ShuffleMapStage 224 (MapPartitionsRDD[1251] at sql at <unknown>:0), which has no missing parents
20/02/14 14:16:00 INFO MemoryStore: Block broadcast_224 stored as values in memory (estimated size 18.9 KiB, free 413.8 MiB)
20/02/14 14:16:00 INFO MemoryStore: Block broadcast_224_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.8 MiB)
20/02/14 14:16:00 INFO BlockManagerInfo: Added broadcast_224_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:00 INFO SparkContext: Created broadcast 224 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 224 (MapPartitionsRDD[1251] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:00 INFO TaskSchedulerImpl: Adding task set 224.0 with 1 tasks
20/02/14 14:16:00 INFO TaskSetManager: Starting task 0.0 in stage 224.0 (TID 290, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:16:00 INFO Executor: Running task 0.0 in stage 224.0 (TID 290)
20/02/14 14:16:00 INFO MemoryStore: Block rdd_1246_0 stored as values in memory (estimated size 312.0 B, free 413.8 MiB)
20/02/14 14:16:00 INFO BlockManagerInfo: Added rdd_1246_0 in memory on 127.0.0.1:55441 (size: 312.0 B, free: 413.9 MiB)
20/02/14 14:16:00 INFO Executor: Finished task 0.0 in stage 224.0 (TID 290). 2283 bytes result sent to driver
20/02/14 14:16:00 INFO TaskSetManager: Finished task 0.0 in stage 224.0 (TID 290) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:00 INFO TaskSchedulerImpl: Removed TaskSet 224.0, whose tasks have all completed, from pool 
20/02/14 14:16:00 INFO DAGScheduler: ShuffleMapStage 224 (sql at <unknown>:0) finished in 0.024 s
20/02/14 14:16:00 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:00 INFO DAGScheduler: running: Set()
20/02/14 14:16:00 INFO DAGScheduler: waiting: Set(ResultStage 225)
20/02/14 14:16:00 INFO DAGScheduler: failed: Set()
20/02/14 14:16:00 INFO DAGScheduler: Submitting ResultStage 225 (MapPartitionsRDD[1254] at sql at <unknown>:0), which has no missing parents
20/02/14 14:16:00 INFO MemoryStore: Block broadcast_225 stored as values in memory (estimated size 10.2 KiB, free 413.8 MiB)
20/02/14 14:16:00 INFO MemoryStore: Block broadcast_225_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
20/02/14 14:16:00 INFO BlockManagerInfo: Added broadcast_225_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:16:00 INFO SparkContext: Created broadcast 225 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 225 (MapPartitionsRDD[1254] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:00 INFO TaskSchedulerImpl: Adding task set 225.0 with 1 tasks
20/02/14 14:16:00 INFO TaskSetManager: Starting task 0.0 in stage 225.0 (TID 291, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:16:00 INFO Executor: Running task 0.0 in stage 225.0 (TID 291)
20/02/14 14:16:00 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:00 INFO Executor: Finished task 0.0 in stage 225.0 (TID 291). 2760 bytes result sent to driver
20/02/14 14:16:00 INFO TaskSetManager: Finished task 0.0 in stage 225.0 (TID 291) in 6 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:00 INFO TaskSchedulerImpl: Removed TaskSet 225.0, whose tasks have all completed, from pool 
20/02/14 14:16:00 INFO DAGScheduler: ResultStage 225 (sql at <unknown>:0) finished in 0.012 s
20/02/14 14:16:00 INFO DAGScheduler: Job 126 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 225: Stage finished
20/02/14 14:16:00 INFO DAGScheduler: Job 126 finished: sql at <unknown>:0, took 0.041374 s
20/02/14 14:16:00 INFO BlockManagerInfo: Removed broadcast_225_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:16:00 INFO BlockManagerInfo: Removed broadcast_224_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:01 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 14:16:01 INFO DAGScheduler: Registering RDD 1259 (collect at arrowconverters.scala:270) as input to shuffle 99
20/02/14 14:16:01 INFO DAGScheduler: Got job 127 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 14:16:01 INFO DAGScheduler: Final stage: ResultStage 227 (collect at arrowconverters.scala:270)
20/02/14 14:16:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 226)
20/02/14 14:16:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 226)
20/02/14 14:16:01 INFO DAGScheduler: Submitting ShuffleMapStage 226 (MapPartitionsRDD[1259] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:01 INFO MemoryStore: Block broadcast_226 stored as values in memory (estimated size 18.9 KiB, free 413.8 MiB)
20/02/14 14:16:01 INFO MemoryStore: Block broadcast_226_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.8 MiB)
20/02/14 14:16:01 INFO BlockManagerInfo: Added broadcast_226_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:01 INFO SparkContext: Created broadcast 226 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 226 (MapPartitionsRDD[1259] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:01 INFO TaskSchedulerImpl: Adding task set 226.0 with 1 tasks
20/02/14 14:16:01 INFO TaskSetManager: Starting task 0.0 in stage 226.0 (TID 292, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:16:01 INFO Executor: Running task 0.0 in stage 226.0 (TID 292)
20/02/14 14:16:01 INFO BlockManager: Found block rdd_1246_0 locally
20/02/14 14:16:01 INFO Executor: Finished task 0.0 in stage 226.0 (TID 292). 2369 bytes result sent to driver
20/02/14 14:16:01 INFO TaskSetManager: Finished task 0.0 in stage 226.0 (TID 292) in 12 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:01 INFO TaskSchedulerImpl: Removed TaskSet 226.0, whose tasks have all completed, from pool 
20/02/14 14:16:01 INFO DAGScheduler: ShuffleMapStage 226 (collect at arrowconverters.scala:270) finished in 0.017 s
20/02/14 14:16:01 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:01 INFO DAGScheduler: running: Set()
20/02/14 14:16:01 INFO DAGScheduler: waiting: Set(ResultStage 227)
20/02/14 14:16:01 INFO DAGScheduler: failed: Set()
20/02/14 14:16:01 INFO DAGScheduler: Submitting ResultStage 227 (MapPartitionsRDD[1265] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:01 INFO MemoryStore: Block broadcast_227 stored as values in memory (estimated size 28.9 KiB, free 413.8 MiB)
20/02/14 14:16:01 INFO MemoryStore: Block broadcast_227_piece0 stored as bytes in memory (estimated size 12.0 KiB, free 413.8 MiB)
20/02/14 14:16:01 INFO BlockManagerInfo: Added broadcast_227_piece0 in memory on 127.0.0.1:55441 (size: 12.0 KiB, free: 413.9 MiB)
20/02/14 14:16:01 INFO SparkContext: Created broadcast 227 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 227 (MapPartitionsRDD[1265] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:01 INFO TaskSchedulerImpl: Adding task set 227.0 with 1 tasks
20/02/14 14:16:01 INFO TaskSetManager: Starting task 0.0 in stage 227.0 (TID 293, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:16:01 INFO Executor: Running task 0.0 in stage 227.0 (TID 293)
20/02/14 14:16:01 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:01 INFO Executor: Finished task 0.0 in stage 227.0 (TID 293). 4285 bytes result sent to driver
20/02/14 14:16:01 INFO TaskSetManager: Finished task 0.0 in stage 227.0 (TID 293) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:01 INFO TaskSchedulerImpl: Removed TaskSet 227.0, whose tasks have all completed, from pool 
20/02/14 14:16:01 INFO DAGScheduler: ResultStage 227 (collect at arrowconverters.scala:270) finished in 0.027 s
20/02/14 14:16:01 INFO DAGScheduler: Job 127 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 227: Stage finished
20/02/14 14:16:01 INFO DAGScheduler: Job 127 finished: collect at arrowconverters.scala:270, took 0.050738 s
20/02/14 14:16:01 INFO Instrumentation: [8ab03b7c] training finished
20/02/14 14:16:01 INFO Instrumentation: [8a3676df] training finished
20/02/14 14:16:01 INFO BlockManagerInfo: Removed broadcast_227_piece0 on 127.0.0.1:55441 in memory (size: 12.0 KiB, free: 413.9 MiB)
20/02/14 14:16:01 INFO BlockManagerInfo: Removed broadcast_226_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:01 INFO CodeGenerator: Code generated in 6.5425 ms
20/02/14 14:16:01 INFO CodeGenerator: Code generated in 8.8377 ms
20/02/14 14:16:01 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 14:16:01 INFO DAGScheduler: Registering RDD 1277 (collect at arrowconverters.scala:270) as input to shuffle 101
20/02/14 14:16:01 INFO DAGScheduler: Registering RDD 1270 (collect at arrowconverters.scala:270) as input to shuffle 100
20/02/14 14:16:01 INFO DAGScheduler: Got job 128 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/14 14:16:01 INFO DAGScheduler: Final stage: ResultStage 230 (collect at arrowconverters.scala:270)
20/02/14 14:16:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 228, ShuffleMapStage 229)
20/02/14 14:16:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 228, ShuffleMapStage 229)
20/02/14 14:16:01 INFO DAGScheduler: Submitting ShuffleMapStage 228 (MapPartitionsRDD[1277] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:01 INFO MemoryStore: Block broadcast_228 stored as values in memory (estimated size 27.4 KiB, free 413.8 MiB)
20/02/14 14:16:01 INFO MemoryStore: Block broadcast_228_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 413.8 MiB)
20/02/14 14:16:01 INFO BlockManagerInfo: Added broadcast_228_piece0 in memory on 127.0.0.1:55441 (size: 10.9 KiB, free: 413.9 MiB)
20/02/14 14:16:01 INFO SparkContext: Created broadcast 228 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 228 (MapPartitionsRDD[1277] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:01 INFO TaskSchedulerImpl: Adding task set 228.0 with 1 tasks
20/02/14 14:16:01 INFO DAGScheduler: Submitting ShuffleMapStage 229 (MapPartitionsRDD[1270] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:01 INFO TaskSetManager: Starting task 0.0 in stage 228.0 (TID 294, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 14:16:01 INFO Executor: Running task 0.0 in stage 228.0 (TID 294)
20/02/14 14:16:01 INFO MemoryStore: Block broadcast_229 stored as values in memory (estimated size 32.1 KiB, free 413.8 MiB)
20/02/14 14:16:01 INFO MemoryStore: Block broadcast_229_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 413.8 MiB)
20/02/14 14:16:01 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:16:01 INFO BlockManagerInfo: Added broadcast_229_piece0 in memory on 127.0.0.1:55441 (size: 13.5 KiB, free: 413.9 MiB)
20/02/14 14:16:01 INFO SparkContext: Created broadcast 229 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 229 (MapPartitionsRDD[1270] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:01 INFO TaskSchedulerImpl: Adding task set 229.0 with 1 tasks
20/02/14 14:16:01 INFO TaskSetManager: Starting task 0.0 in stage 229.0 (TID 295, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:16:01 INFO Executor: Running task 0.0 in stage 229.0 (TID 295)
20/02/14 14:16:01 INFO BlockManager: Found block rdd_1246_0 locally
20/02/14 14:16:01 INFO Executor: Finished task 0.0 in stage 228.0 (TID 294). 2160 bytes result sent to driver
20/02/14 14:16:01 INFO TaskSetManager: Finished task 0.0 in stage 228.0 (TID 294) in 27 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:01 INFO TaskSchedulerImpl: Removed TaskSet 228.0, whose tasks have all completed, from pool 
20/02/14 14:16:01 INFO DAGScheduler: ShuffleMapStage 228 (collect at arrowconverters.scala:270) finished in 0.032 s
20/02/14 14:16:01 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:01 INFO DAGScheduler: running: Set(ShuffleMapStage 229)
20/02/14 14:16:01 INFO DAGScheduler: waiting: Set(ResultStage 230)
20/02/14 14:16:01 INFO DAGScheduler: failed: Set()
20/02/14 14:16:01 INFO Executor: Finished task 0.0 in stage 229.0 (TID 295). 2203 bytes result sent to driver
20/02/14 14:16:01 INFO TaskSetManager: Finished task 0.0 in stage 229.0 (TID 295) in 36 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:01 INFO TaskSchedulerImpl: Removed TaskSet 229.0, whose tasks have all completed, from pool 
20/02/14 14:16:01 INFO DAGScheduler: ShuffleMapStage 229 (collect at arrowconverters.scala:270) finished in 0.043 s
20/02/14 14:16:01 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:01 INFO DAGScheduler: running: Set()
20/02/14 14:16:01 INFO DAGScheduler: waiting: Set(ResultStage 230)
20/02/14 14:16:01 INFO DAGScheduler: failed: Set()
20/02/14 14:16:01 INFO DAGScheduler: Submitting ResultStage 230 (MapPartitionsRDD[1285] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:01 INFO MemoryStore: Block broadcast_230 stored as values in memory (estimated size 56.3 KiB, free 413.7 MiB)
20/02/14 14:16:01 INFO MemoryStore: Block broadcast_230_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 413.7 MiB)
20/02/14 14:16:01 INFO BlockManagerInfo: Added broadcast_230_piece0 in memory on 127.0.0.1:55441 (size: 23.0 KiB, free: 413.9 MiB)
20/02/14 14:16:01 INFO SparkContext: Created broadcast 230 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:01 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 230 (MapPartitionsRDD[1285] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 14:16:01 INFO TaskSchedulerImpl: Adding task set 230.0 with 4 tasks
20/02/14 14:16:01 INFO TaskSetManager: Starting task 0.0 in stage 230.0 (TID 296, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:01 INFO TaskSetManager: Starting task 1.0 in stage 230.0 (TID 297, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:01 INFO TaskSetManager: Starting task 2.0 in stage 230.0 (TID 298, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:01 INFO TaskSetManager: Starting task 3.0 in stage 230.0 (TID 299, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:01 INFO Executor: Running task 0.0 in stage 230.0 (TID 296)
20/02/14 14:16:01 INFO Executor: Running task 1.0 in stage 230.0 (TID 297)
20/02/14 14:16:01 INFO Executor: Running task 3.0 in stage 230.0 (TID 299)
20/02/14 14:16:01 INFO Executor: Running task 2.0 in stage 230.0 (TID 298)
20/02/14 14:16:01 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:01 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:01 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:01 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:01 INFO ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:01 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:02 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:02 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:02 INFO BlockManagerInfo: Removed broadcast_228_piece0 on 127.0.0.1:55441 in memory (size: 10.9 KiB, free: 413.9 MiB)
20/02/14 14:16:02 INFO BlockManagerInfo: Removed broadcast_229_piece0 on 127.0.0.1:55441 in memory (size: 13.5 KiB, free: 413.9 MiB)
20/02/14 14:16:02 INFO Executor: Finished task 1.0 in stage 230.0 (TID 297). 5790 bytes result sent to driver
20/02/14 14:16:02 INFO Executor: Finished task 2.0 in stage 230.0 (TID 298). 5909 bytes result sent to driver
20/02/14 14:16:02 INFO Executor: Finished task 0.0 in stage 230.0 (TID 296). 5814 bytes result sent to driver
20/02/14 14:16:02 INFO TaskSetManager: Finished task 1.0 in stage 230.0 (TID 297) in 73 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 14:16:02 INFO TaskSetManager: Finished task 0.0 in stage 230.0 (TID 296) in 74 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 14:16:02 INFO TaskSetManager: Finished task 2.0 in stage 230.0 (TID 298) in 74 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 14:16:02 INFO Executor: Finished task 3.0 in stage 230.0 (TID 299). 5807 bytes result sent to driver
20/02/14 14:16:02 INFO TaskSetManager: Finished task 3.0 in stage 230.0 (TID 299) in 77 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 14:16:02 INFO TaskSchedulerImpl: Removed TaskSet 230.0, whose tasks have all completed, from pool 
20/02/14 14:16:02 INFO DAGScheduler: ResultStage 230 (collect at arrowconverters.scala:270) finished in 0.086 s
20/02/14 14:16:02 INFO DAGScheduler: Job 128 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 230: Stage finished
20/02/14 14:16:02 INFO DAGScheduler: Job 128 finished: collect at arrowconverters.scala:270, took 0.142493 s
20/02/14 14:16:05 INFO BlockManagerInfo: Removed broadcast_230_piece0 on 127.0.0.1:55441 in memory (size: 23.0 KiB, free: 413.9 MiB)
20/02/14 14:16:05 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 14:16:05 INFO DAGScheduler: Got job 129 (collect at utils.scala:41) with 4 output partitions
20/02/14 14:16:05 INFO DAGScheduler: Final stage: ResultStage 231 (collect at utils.scala:41)
20/02/14 14:16:05 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:16:05 INFO DAGScheduler: Missing parents: List()
20/02/14 14:16:05 INFO DAGScheduler: Submitting ResultStage 231 (MapPartitionsRDD[1291] at map at utils.scala:41), which has no missing parents
20/02/14 14:16:05 INFO MemoryStore: Block broadcast_231 stored as values in memory (estimated size 8.8 KiB, free 413.8 MiB)
20/02/14 14:16:05 INFO MemoryStore: Block broadcast_231_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.8 MiB)
20/02/14 14:16:05 INFO BlockManagerInfo: Added broadcast_231_piece0 in memory on 127.0.0.1:55441 (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 14:16:05 INFO SparkContext: Created broadcast 231 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:05 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 231 (MapPartitionsRDD[1291] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 14:16:05 INFO TaskSchedulerImpl: Adding task set 231.0 with 4 tasks
20/02/14 14:16:05 INFO TaskSetManager: Starting task 0.0 in stage 231.0 (TID 300, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7728 bytes)
20/02/14 14:16:05 INFO TaskSetManager: Starting task 1.0 in stage 231.0 (TID 301, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7809 bytes)
20/02/14 14:16:05 INFO TaskSetManager: Starting task 2.0 in stage 231.0 (TID 302, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7736 bytes)
20/02/14 14:16:05 INFO TaskSetManager: Starting task 3.0 in stage 231.0 (TID 303, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7809 bytes)
20/02/14 14:16:05 INFO Executor: Running task 0.0 in stage 231.0 (TID 300)
20/02/14 14:16:05 INFO Executor: Running task 1.0 in stage 231.0 (TID 301)
20/02/14 14:16:05 INFO Executor: Running task 3.0 in stage 231.0 (TID 303)
20/02/14 14:16:05 INFO Executor: Running task 2.0 in stage 231.0 (TID 302)
20/02/14 14:16:05 INFO Executor: Finished task 2.0 in stage 231.0 (TID 302). 1169 bytes result sent to driver
20/02/14 14:16:05 INFO Executor: Finished task 3.0 in stage 231.0 (TID 303). 1199 bytes result sent to driver
20/02/14 14:16:05 INFO Executor: Finished task 0.0 in stage 231.0 (TID 300). 1153 bytes result sent to driver
20/02/14 14:16:05 INFO Executor: Finished task 1.0 in stage 231.0 (TID 301). 1199 bytes result sent to driver
20/02/14 14:16:05 INFO TaskSetManager: Finished task 2.0 in stage 231.0 (TID 302) in 6 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 14:16:05 INFO TaskSetManager: Finished task 3.0 in stage 231.0 (TID 303) in 7 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 14:16:05 INFO TaskSetManager: Finished task 0.0 in stage 231.0 (TID 300) in 8 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 14:16:05 INFO TaskSetManager: Finished task 1.0 in stage 231.0 (TID 301) in 9 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 14:16:05 INFO TaskSchedulerImpl: Removed TaskSet 231.0, whose tasks have all completed, from pool 
20/02/14 14:16:05 INFO DAGScheduler: ResultStage 231 (collect at utils.scala:41) finished in 0.014 s
20/02/14 14:16:05 INFO DAGScheduler: Job 129 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 231: Stage finished
20/02/14 14:16:05 INFO DAGScheduler: Job 129 finished: collect at utils.scala:41, took 0.017447 s
20/02/14 14:16:06 INFO BlockManagerInfo: Removed broadcast_231_piece0 on 127.0.0.1:55441 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 14:16:06 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/14 14:16:06 INFO DAGScheduler: Registering RDD 1300 (sql at <unknown>:0) as input to shuffle 102
20/02/14 14:16:06 INFO DAGScheduler: Got job 130 (sql at <unknown>:0) with 1 output partitions
20/02/14 14:16:06 INFO DAGScheduler: Final stage: ResultStage 233 (sql at <unknown>:0)
20/02/14 14:16:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 232)
20/02/14 14:16:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 232)
20/02/14 14:16:06 INFO DAGScheduler: Submitting ShuffleMapStage 232 (MapPartitionsRDD[1300] at sql at <unknown>:0), which has no missing parents
20/02/14 14:16:06 INFO MemoryStore: Block broadcast_232 stored as values in memory (estimated size 18.9 KiB, free 413.8 MiB)
20/02/14 14:16:06 INFO MemoryStore: Block broadcast_232_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.8 MiB)
20/02/14 14:16:06 INFO BlockManagerInfo: Added broadcast_232_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:06 INFO SparkContext: Created broadcast 232 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 232 (MapPartitionsRDD[1300] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:06 INFO TaskSchedulerImpl: Adding task set 232.0 with 1 tasks
20/02/14 14:16:06 INFO TaskSetManager: Starting task 0.0 in stage 232.0 (TID 304, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:16:06 INFO Executor: Running task 0.0 in stage 232.0 (TID 304)
20/02/14 14:16:06 INFO MemoryStore: Block rdd_1295_0 stored as values in memory (estimated size 312.0 B, free 413.8 MiB)
20/02/14 14:16:06 INFO BlockManagerInfo: Added rdd_1295_0 in memory on 127.0.0.1:55441 (size: 312.0 B, free: 413.9 MiB)
20/02/14 14:16:06 INFO Executor: Finished task 0.0 in stage 232.0 (TID 304). 2283 bytes result sent to driver
20/02/14 14:16:06 INFO TaskSetManager: Finished task 0.0 in stage 232.0 (TID 304) in 14 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:06 INFO TaskSchedulerImpl: Removed TaskSet 232.0, whose tasks have all completed, from pool 
20/02/14 14:16:06 INFO DAGScheduler: ShuffleMapStage 232 (sql at <unknown>:0) finished in 0.019 s
20/02/14 14:16:06 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:06 INFO DAGScheduler: running: Set()
20/02/14 14:16:06 INFO DAGScheduler: waiting: Set(ResultStage 233)
20/02/14 14:16:06 INFO DAGScheduler: failed: Set()
20/02/14 14:16:06 INFO DAGScheduler: Submitting ResultStage 233 (MapPartitionsRDD[1303] at sql at <unknown>:0), which has no missing parents
20/02/14 14:16:06 INFO MemoryStore: Block broadcast_233 stored as values in memory (estimated size 10.2 KiB, free 413.8 MiB)
20/02/14 14:16:06 INFO MemoryStore: Block broadcast_233_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
20/02/14 14:16:06 INFO BlockManagerInfo: Added broadcast_233_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:16:06 INFO SparkContext: Created broadcast 233 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 233 (MapPartitionsRDD[1303] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:06 INFO TaskSchedulerImpl: Adding task set 233.0 with 1 tasks
20/02/14 14:16:06 INFO TaskSetManager: Starting task 0.0 in stage 233.0 (TID 305, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:16:06 INFO Executor: Running task 0.0 in stage 233.0 (TID 305)
20/02/14 14:16:06 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:06 INFO Executor: Finished task 0.0 in stage 233.0 (TID 305). 2760 bytes result sent to driver
20/02/14 14:16:06 INFO TaskSetManager: Finished task 0.0 in stage 233.0 (TID 305) in 5 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:06 INFO TaskSchedulerImpl: Removed TaskSet 233.0, whose tasks have all completed, from pool 
20/02/14 14:16:06 INFO DAGScheduler: ResultStage 233 (sql at <unknown>:0) finished in 0.009 s
20/02/14 14:16:06 INFO DAGScheduler: Job 130 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 233: Stage finished
20/02/14 14:16:06 INFO DAGScheduler: Job 130 finished: sql at <unknown>:0, took 0.033721 s
20/02/14 14:16:06 INFO BlockManagerInfo: Removed broadcast_233_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:16:06 INFO BlockManagerInfo: Removed broadcast_232_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:06 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 14:16:06 INFO DAGScheduler: Registering RDD 1308 (collect at arrowconverters.scala:270) as input to shuffle 103
20/02/14 14:16:06 INFO DAGScheduler: Got job 131 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 14:16:06 INFO DAGScheduler: Final stage: ResultStage 235 (collect at arrowconverters.scala:270)
20/02/14 14:16:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 234)
20/02/14 14:16:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 234)
20/02/14 14:16:06 INFO DAGScheduler: Submitting ShuffleMapStage 234 (MapPartitionsRDD[1308] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:06 INFO MemoryStore: Block broadcast_234 stored as values in memory (estimated size 18.9 KiB, free 413.8 MiB)
20/02/14 14:16:06 INFO MemoryStore: Block broadcast_234_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.8 MiB)
20/02/14 14:16:06 INFO BlockManagerInfo: Added broadcast_234_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:06 INFO SparkContext: Created broadcast 234 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 234 (MapPartitionsRDD[1308] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:06 INFO TaskSchedulerImpl: Adding task set 234.0 with 1 tasks
20/02/14 14:16:06 INFO TaskSetManager: Starting task 0.0 in stage 234.0 (TID 306, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:16:06 INFO Executor: Running task 0.0 in stage 234.0 (TID 306)
20/02/14 14:16:06 INFO BlockManager: Found block rdd_1295_0 locally
20/02/14 14:16:06 INFO Executor: Finished task 0.0 in stage 234.0 (TID 306). 2369 bytes result sent to driver
20/02/14 14:16:06 INFO TaskSetManager: Finished task 0.0 in stage 234.0 (TID 306) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:06 INFO TaskSchedulerImpl: Removed TaskSet 234.0, whose tasks have all completed, from pool 
20/02/14 14:16:06 INFO DAGScheduler: ShuffleMapStage 234 (collect at arrowconverters.scala:270) finished in 0.022 s
20/02/14 14:16:06 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:06 INFO DAGScheduler: running: Set()
20/02/14 14:16:06 INFO DAGScheduler: waiting: Set(ResultStage 235)
20/02/14 14:16:06 INFO DAGScheduler: failed: Set()
20/02/14 14:16:06 INFO DAGScheduler: Submitting ResultStage 235 (MapPartitionsRDD[1314] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:06 INFO MemoryStore: Block broadcast_235 stored as values in memory (estimated size 28.9 KiB, free 413.8 MiB)
20/02/14 14:16:06 INFO MemoryStore: Block broadcast_235_piece0 stored as bytes in memory (estimated size 12.0 KiB, free 413.8 MiB)
20/02/14 14:16:06 INFO BlockManagerInfo: Added broadcast_235_piece0 in memory on 127.0.0.1:55441 (size: 12.0 KiB, free: 413.9 MiB)
20/02/14 14:16:06 INFO SparkContext: Created broadcast 235 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 235 (MapPartitionsRDD[1314] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:06 INFO TaskSchedulerImpl: Adding task set 235.0 with 1 tasks
20/02/14 14:16:06 INFO TaskSetManager: Starting task 0.0 in stage 235.0 (TID 307, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:16:06 INFO Executor: Running task 0.0 in stage 235.0 (TID 307)
20/02/14 14:16:06 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:06 INFO Executor: Finished task 0.0 in stage 235.0 (TID 307). 4285 bytes result sent to driver
20/02/14 14:16:06 INFO TaskSetManager: Finished task 0.0 in stage 235.0 (TID 307) in 18 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:06 INFO TaskSchedulerImpl: Removed TaskSet 235.0, whose tasks have all completed, from pool 
20/02/14 14:16:06 INFO DAGScheduler: ResultStage 235 (collect at arrowconverters.scala:270) finished in 0.030 s
20/02/14 14:16:06 INFO DAGScheduler: Job 131 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 235: Stage finished
20/02/14 14:16:06 INFO DAGScheduler: Job 131 finished: collect at arrowconverters.scala:270, took 0.056960 s
20/02/14 14:16:06 INFO Instrumentation: [23aa2323] training finished
20/02/14 14:16:06 INFO Instrumentation: [372a8cc4] training finished
20/02/14 14:16:07 INFO BlockManagerInfo: Removed broadcast_235_piece0 on 127.0.0.1:55441 in memory (size: 12.0 KiB, free: 413.9 MiB)
20/02/14 14:16:07 INFO BlockManagerInfo: Removed broadcast_234_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:07 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 14:16:07 INFO DAGScheduler: Registering RDD 1326 (collect at arrowconverters.scala:270) as input to shuffle 105
20/02/14 14:16:07 INFO DAGScheduler: Registering RDD 1319 (collect at arrowconverters.scala:270) as input to shuffle 104
20/02/14 14:16:07 INFO DAGScheduler: Got job 132 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/14 14:16:07 INFO DAGScheduler: Final stage: ResultStage 238 (collect at arrowconverters.scala:270)
20/02/14 14:16:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 237, ShuffleMapStage 236)
20/02/14 14:16:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 237, ShuffleMapStage 236)
20/02/14 14:16:07 INFO DAGScheduler: Submitting ShuffleMapStage 236 (MapPartitionsRDD[1326] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:07 INFO MemoryStore: Block broadcast_236 stored as values in memory (estimated size 27.4 KiB, free 413.8 MiB)
20/02/14 14:16:07 INFO MemoryStore: Block broadcast_236_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.8 MiB)
20/02/14 14:16:07 INFO BlockManagerInfo: Added broadcast_236_piece0 in memory on 127.0.0.1:55441 (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 14:16:07 INFO SparkContext: Created broadcast 236 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 236 (MapPartitionsRDD[1326] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:07 INFO TaskSchedulerImpl: Adding task set 236.0 with 1 tasks
20/02/14 14:16:07 INFO DAGScheduler: Submitting ShuffleMapStage 237 (MapPartitionsRDD[1319] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:07 INFO TaskSetManager: Starting task 0.0 in stage 236.0 (TID 308, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 14:16:07 INFO Executor: Running task 0.0 in stage 236.0 (TID 308)
20/02/14 14:16:07 INFO MemoryStore: Block broadcast_237 stored as values in memory (estimated size 32.1 KiB, free 413.8 MiB)
20/02/14 14:16:07 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:16:07 INFO MemoryStore: Block broadcast_237_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 413.8 MiB)
20/02/14 14:16:07 INFO BlockManagerInfo: Added broadcast_237_piece0 in memory on 127.0.0.1:55441 (size: 13.5 KiB, free: 413.9 MiB)
20/02/14 14:16:07 INFO SparkContext: Created broadcast 237 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 237 (MapPartitionsRDD[1319] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:07 INFO TaskSchedulerImpl: Adding task set 237.0 with 1 tasks
20/02/14 14:16:07 INFO TaskSetManager: Starting task 0.0 in stage 237.0 (TID 309, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:16:07 INFO Executor: Running task 0.0 in stage 237.0 (TID 309)
20/02/14 14:16:07 INFO BlockManager: Found block rdd_1295_0 locally
20/02/14 14:16:07 INFO Executor: Finished task 0.0 in stage 236.0 (TID 308). 2203 bytes result sent to driver
20/02/14 14:16:07 INFO TaskSetManager: Finished task 0.0 in stage 236.0 (TID 308) in 23 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:07 INFO TaskSchedulerImpl: Removed TaskSet 236.0, whose tasks have all completed, from pool 
20/02/14 14:16:07 INFO DAGScheduler: ShuffleMapStage 236 (collect at arrowconverters.scala:270) finished in 0.028 s
20/02/14 14:16:07 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:07 INFO DAGScheduler: running: Set(ShuffleMapStage 237)
20/02/14 14:16:07 INFO DAGScheduler: waiting: Set(ResultStage 238)
20/02/14 14:16:07 INFO DAGScheduler: failed: Set()
20/02/14 14:16:07 INFO Executor: Finished task 0.0 in stage 237.0 (TID 309). 2203 bytes result sent to driver
20/02/14 14:16:07 INFO TaskSetManager: Finished task 0.0 in stage 237.0 (TID 309) in 32 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:07 INFO TaskSchedulerImpl: Removed TaskSet 237.0, whose tasks have all completed, from pool 
20/02/14 14:16:07 INFO DAGScheduler: ShuffleMapStage 237 (collect at arrowconverters.scala:270) finished in 0.037 s
20/02/14 14:16:07 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:07 INFO DAGScheduler: running: Set()
20/02/14 14:16:07 INFO DAGScheduler: waiting: Set(ResultStage 238)
20/02/14 14:16:07 INFO DAGScheduler: failed: Set()
20/02/14 14:16:07 INFO DAGScheduler: Submitting ResultStage 238 (MapPartitionsRDD[1334] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:07 INFO MemoryStore: Block broadcast_238 stored as values in memory (estimated size 56.3 KiB, free 413.7 MiB)
20/02/14 14:16:07 INFO MemoryStore: Block broadcast_238_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 413.7 MiB)
20/02/14 14:16:07 INFO BlockManagerInfo: Added broadcast_238_piece0 in memory on 127.0.0.1:55441 (size: 23.0 KiB, free: 413.9 MiB)
20/02/14 14:16:07 INFO SparkContext: Created broadcast 238 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:07 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 238 (MapPartitionsRDD[1334] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 14:16:07 INFO TaskSchedulerImpl: Adding task set 238.0 with 4 tasks
20/02/14 14:16:07 INFO TaskSetManager: Starting task 0.0 in stage 238.0 (TID 310, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:07 INFO TaskSetManager: Starting task 1.0 in stage 238.0 (TID 311, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:07 INFO TaskSetManager: Starting task 2.0 in stage 238.0 (TID 312, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:07 INFO TaskSetManager: Starting task 3.0 in stage 238.0 (TID 313, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:07 INFO Executor: Running task 0.0 in stage 238.0 (TID 310)
20/02/14 14:16:07 INFO Executor: Running task 1.0 in stage 238.0 (TID 311)
20/02/14 14:16:07 INFO Executor: Running task 3.0 in stage 238.0 (TID 313)
20/02/14 14:16:07 INFO Executor: Running task 2.0 in stage 238.0 (TID 312)
20/02/14 14:16:07 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:07 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:07 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:07 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:07 INFO ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:07 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:07 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
20/02/14 14:16:07 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:07 INFO BlockManagerInfo: Removed broadcast_236_piece0 on 127.0.0.1:55441 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 14:16:07 INFO Executor: Finished task 1.0 in stage 238.0 (TID 311). 5790 bytes result sent to driver
20/02/14 14:16:07 INFO Executor: Finished task 0.0 in stage 238.0 (TID 310). 5814 bytes result sent to driver
20/02/14 14:16:07 INFO TaskSetManager: Finished task 1.0 in stage 238.0 (TID 311) in 55 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 14:16:07 INFO TaskSetManager: Finished task 0.0 in stage 238.0 (TID 310) in 56 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 14:16:07 INFO BlockManagerInfo: Removed broadcast_237_piece0 on 127.0.0.1:55441 in memory (size: 13.5 KiB, free: 413.9 MiB)
20/02/14 14:16:07 INFO Executor: Finished task 3.0 in stage 238.0 (TID 313). 5850 bytes result sent to driver
20/02/14 14:16:07 INFO TaskSetManager: Finished task 3.0 in stage 238.0 (TID 313) in 62 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 14:16:07 INFO Executor: Finished task 2.0 in stage 238.0 (TID 312). 5909 bytes result sent to driver
20/02/14 14:16:07 INFO TaskSetManager: Finished task 2.0 in stage 238.0 (TID 312) in 64 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 14:16:07 INFO TaskSchedulerImpl: Removed TaskSet 238.0, whose tasks have all completed, from pool 
20/02/14 14:16:07 INFO DAGScheduler: ResultStage 238 (collect at arrowconverters.scala:270) finished in 0.072 s
20/02/14 14:16:07 INFO DAGScheduler: Job 132 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 238: Stage finished
20/02/14 14:16:07 INFO DAGScheduler: Job 132 finished: collect at arrowconverters.scala:270, took 0.120797 s
20/02/14 14:16:37 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 14:16:37 INFO BlockManagerInfo: Removed broadcast_238_piece0 on 127.0.0.1:55441 in memory (size: 23.0 KiB, free: 413.9 MiB)
20/02/14 14:16:37 INFO DAGScheduler: Got job 133 (collect at utils.scala:41) with 4 output partitions
20/02/14 14:16:37 INFO DAGScheduler: Final stage: ResultStage 239 (collect at utils.scala:41)
20/02/14 14:16:37 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:16:37 INFO DAGScheduler: Missing parents: List()
20/02/14 14:16:37 INFO DAGScheduler: Submitting ResultStage 239 (MapPartitionsRDD[1340] at map at utils.scala:41), which has no missing parents
20/02/14 14:16:37 INFO MemoryStore: Block broadcast_239 stored as values in memory (estimated size 8.8 KiB, free 413.8 MiB)
20/02/14 14:16:37 INFO MemoryStore: Block broadcast_239_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.8 MiB)
20/02/14 14:16:37 INFO BlockManagerInfo: Added broadcast_239_piece0 in memory on 127.0.0.1:55441 (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 14:16:37 INFO SparkContext: Created broadcast 239 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 239 (MapPartitionsRDD[1340] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 14:16:37 INFO TaskSchedulerImpl: Adding task set 239.0 with 4 tasks
20/02/14 14:16:37 INFO TaskSetManager: Starting task 0.0 in stage 239.0 (TID 314, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7793 bytes)
20/02/14 14:16:37 INFO TaskSetManager: Starting task 1.0 in stage 239.0 (TID 315, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7809 bytes)
20/02/14 14:16:37 INFO TaskSetManager: Starting task 2.0 in stage 239.0 (TID 316, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7801 bytes)
20/02/14 14:16:37 INFO TaskSetManager: Starting task 3.0 in stage 239.0 (TID 317, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7809 bytes)
20/02/14 14:16:37 INFO Executor: Running task 0.0 in stage 239.0 (TID 314)
20/02/14 14:16:37 INFO Executor: Running task 1.0 in stage 239.0 (TID 315)
20/02/14 14:16:37 INFO Executor: Running task 3.0 in stage 239.0 (TID 317)
20/02/14 14:16:37 INFO Executor: Running task 2.0 in stage 239.0 (TID 316)
20/02/14 14:16:37 INFO Executor: Finished task 3.0 in stage 239.0 (TID 317). 1156 bytes result sent to driver
20/02/14 14:16:37 INFO Executor: Finished task 2.0 in stage 239.0 (TID 316). 1154 bytes result sent to driver
20/02/14 14:16:37 INFO Executor: Finished task 0.0 in stage 239.0 (TID 314). 1138 bytes result sent to driver
20/02/14 14:16:37 INFO Executor: Finished task 1.0 in stage 239.0 (TID 315). 1156 bytes result sent to driver
20/02/14 14:16:37 INFO TaskSetManager: Finished task 3.0 in stage 239.0 (TID 317) in 7 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 14:16:37 INFO TaskSetManager: Finished task 0.0 in stage 239.0 (TID 314) in 9 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 14:16:37 INFO TaskSetManager: Finished task 2.0 in stage 239.0 (TID 316) in 8 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 14:16:37 INFO TaskSetManager: Finished task 1.0 in stage 239.0 (TID 315) in 8 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 14:16:37 INFO TaskSchedulerImpl: Removed TaskSet 239.0, whose tasks have all completed, from pool 
20/02/14 14:16:37 INFO DAGScheduler: ResultStage 239 (collect at utils.scala:41) finished in 0.013 s
20/02/14 14:16:37 INFO DAGScheduler: Job 133 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 239: Stage finished
20/02/14 14:16:37 INFO DAGScheduler: Job 133 finished: collect at utils.scala:41, took 0.016929 s
20/02/14 14:16:37 INFO BlockManagerInfo: Removed broadcast_239_piece0 on 127.0.0.1:55441 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 14:16:37 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/14 14:16:37 INFO DAGScheduler: Registering RDD 1349 (sql at <unknown>:0) as input to shuffle 106
20/02/14 14:16:37 INFO DAGScheduler: Got job 134 (sql at <unknown>:0) with 1 output partitions
20/02/14 14:16:37 INFO DAGScheduler: Final stage: ResultStage 241 (sql at <unknown>:0)
20/02/14 14:16:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 240)
20/02/14 14:16:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 240)
20/02/14 14:16:37 INFO DAGScheduler: Submitting ShuffleMapStage 240 (MapPartitionsRDD[1349] at sql at <unknown>:0), which has no missing parents
20/02/14 14:16:37 INFO MemoryStore: Block broadcast_240 stored as values in memory (estimated size 18.9 KiB, free 413.8 MiB)
20/02/14 14:16:37 INFO MemoryStore: Block broadcast_240_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.8 MiB)
20/02/14 14:16:37 INFO BlockManagerInfo: Added broadcast_240_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:37 INFO SparkContext: Created broadcast 240 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 240 (MapPartitionsRDD[1349] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:37 INFO TaskSchedulerImpl: Adding task set 240.0 with 1 tasks
20/02/14 14:16:37 INFO TaskSetManager: Starting task 0.0 in stage 240.0 (TID 318, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:16:37 INFO Executor: Running task 0.0 in stage 240.0 (TID 318)
20/02/14 14:16:37 INFO MemoryStore: Block rdd_1344_0 stored as values in memory (estimated size 312.0 B, free 413.8 MiB)
20/02/14 14:16:37 INFO BlockManagerInfo: Added rdd_1344_0 in memory on 127.0.0.1:55441 (size: 312.0 B, free: 413.9 MiB)
20/02/14 14:16:37 INFO Executor: Finished task 0.0 in stage 240.0 (TID 318). 2283 bytes result sent to driver
20/02/14 14:16:37 INFO TaskSetManager: Finished task 0.0 in stage 240.0 (TID 318) in 14 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:37 INFO TaskSchedulerImpl: Removed TaskSet 240.0, whose tasks have all completed, from pool 
20/02/14 14:16:37 INFO DAGScheduler: ShuffleMapStage 240 (sql at <unknown>:0) finished in 0.018 s
20/02/14 14:16:37 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:37 INFO DAGScheduler: running: Set()
20/02/14 14:16:37 INFO DAGScheduler: waiting: Set(ResultStage 241)
20/02/14 14:16:37 INFO DAGScheduler: failed: Set()
20/02/14 14:16:37 INFO DAGScheduler: Submitting ResultStage 241 (MapPartitionsRDD[1352] at sql at <unknown>:0), which has no missing parents
20/02/14 14:16:37 INFO MemoryStore: Block broadcast_241 stored as values in memory (estimated size 10.2 KiB, free 413.8 MiB)
20/02/14 14:16:37 INFO MemoryStore: Block broadcast_241_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
20/02/14 14:16:37 INFO BlockManagerInfo: Added broadcast_241_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:16:37 INFO SparkContext: Created broadcast 241 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 241 (MapPartitionsRDD[1352] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:37 INFO TaskSchedulerImpl: Adding task set 241.0 with 1 tasks
20/02/14 14:16:37 INFO TaskSetManager: Starting task 0.0 in stage 241.0 (TID 319, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:16:37 INFO Executor: Running task 0.0 in stage 241.0 (TID 319)
20/02/14 14:16:37 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:37 INFO Executor: Finished task 0.0 in stage 241.0 (TID 319). 2760 bytes result sent to driver
20/02/14 14:16:37 INFO TaskSetManager: Finished task 0.0 in stage 241.0 (TID 319) in 5 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:37 INFO TaskSchedulerImpl: Removed TaskSet 241.0, whose tasks have all completed, from pool 
20/02/14 14:16:37 INFO DAGScheduler: ResultStage 241 (sql at <unknown>:0) finished in 0.009 s
20/02/14 14:16:37 INFO DAGScheduler: Job 134 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 241: Stage finished
20/02/14 14:16:37 INFO DAGScheduler: Job 134 finished: sql at <unknown>:0, took 0.032072 s
20/02/14 14:16:37 INFO BlockManagerInfo: Removed broadcast_241_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:16:37 INFO BlockManagerInfo: Removed broadcast_240_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:37 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 14:16:37 INFO DAGScheduler: Registering RDD 1357 (collect at arrowconverters.scala:270) as input to shuffle 107
20/02/14 14:16:37 INFO DAGScheduler: Got job 135 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 14:16:37 INFO DAGScheduler: Final stage: ResultStage 243 (collect at arrowconverters.scala:270)
20/02/14 14:16:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 242)
20/02/14 14:16:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 242)
20/02/14 14:16:37 INFO DAGScheduler: Submitting ShuffleMapStage 242 (MapPartitionsRDD[1357] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:37 INFO MemoryStore: Block broadcast_242 stored as values in memory (estimated size 18.9 KiB, free 413.8 MiB)
20/02/14 14:16:37 INFO MemoryStore: Block broadcast_242_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.8 MiB)
20/02/14 14:16:37 INFO BlockManagerInfo: Added broadcast_242_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:37 INFO SparkContext: Created broadcast 242 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 242 (MapPartitionsRDD[1357] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:37 INFO TaskSchedulerImpl: Adding task set 242.0 with 1 tasks
20/02/14 14:16:37 INFO TaskSetManager: Starting task 0.0 in stage 242.0 (TID 320, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:16:37 INFO Executor: Running task 0.0 in stage 242.0 (TID 320)
20/02/14 14:16:37 INFO BlockManager: Found block rdd_1344_0 locally
20/02/14 14:16:37 INFO Executor: Finished task 0.0 in stage 242.0 (TID 320). 2369 bytes result sent to driver
20/02/14 14:16:37 INFO TaskSetManager: Finished task 0.0 in stage 242.0 (TID 320) in 13 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:37 INFO TaskSchedulerImpl: Removed TaskSet 242.0, whose tasks have all completed, from pool 
20/02/14 14:16:37 INFO DAGScheduler: ShuffleMapStage 242 (collect at arrowconverters.scala:270) finished in 0.020 s
20/02/14 14:16:37 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:37 INFO DAGScheduler: running: Set()
20/02/14 14:16:37 INFO DAGScheduler: waiting: Set(ResultStage 243)
20/02/14 14:16:37 INFO DAGScheduler: failed: Set()
20/02/14 14:16:37 INFO DAGScheduler: Submitting ResultStage 243 (MapPartitionsRDD[1363] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:37 INFO MemoryStore: Block broadcast_243 stored as values in memory (estimated size 28.9 KiB, free 413.8 MiB)
20/02/14 14:16:37 INFO MemoryStore: Block broadcast_243_piece0 stored as bytes in memory (estimated size 12.0 KiB, free 413.8 MiB)
20/02/14 14:16:37 INFO BlockManagerInfo: Added broadcast_243_piece0 in memory on 127.0.0.1:55441 (size: 12.0 KiB, free: 413.9 MiB)
20/02/14 14:16:37 INFO SparkContext: Created broadcast 243 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 243 (MapPartitionsRDD[1363] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:37 INFO TaskSchedulerImpl: Adding task set 243.0 with 1 tasks
20/02/14 14:16:37 INFO TaskSetManager: Starting task 0.0 in stage 243.0 (TID 321, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:16:37 INFO Executor: Running task 0.0 in stage 243.0 (TID 321)
20/02/14 14:16:37 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:37 INFO Executor: Finished task 0.0 in stage 243.0 (TID 321). 4242 bytes result sent to driver
20/02/14 14:16:37 INFO TaskSetManager: Finished task 0.0 in stage 243.0 (TID 321) in 9 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:37 INFO TaskSchedulerImpl: Removed TaskSet 243.0, whose tasks have all completed, from pool 
20/02/14 14:16:37 INFO DAGScheduler: ResultStage 243 (collect at arrowconverters.scala:270) finished in 0.019 s
20/02/14 14:16:37 INFO DAGScheduler: Job 135 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 243: Stage finished
20/02/14 14:16:37 INFO DAGScheduler: Job 135 finished: collect at arrowconverters.scala:270, took 0.044702 s
20/02/14 14:16:37 INFO Instrumentation: [84455c00] training finished
20/02/14 14:16:37 INFO Instrumentation: [934d3217] training finished
20/02/14 14:16:38 INFO BlockManagerInfo: Removed broadcast_242_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:38 INFO BlockManagerInfo: Removed broadcast_243_piece0 on 127.0.0.1:55441 in memory (size: 12.0 KiB, free: 413.9 MiB)
20/02/14 14:16:38 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 14:16:38 INFO DAGScheduler: Registering RDD 1368 (collect at arrowconverters.scala:270) as input to shuffle 108
20/02/14 14:16:38 INFO DAGScheduler: Registering RDD 1375 (collect at arrowconverters.scala:270) as input to shuffle 109
20/02/14 14:16:38 INFO DAGScheduler: Got job 136 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/14 14:16:38 INFO DAGScheduler: Final stage: ResultStage 246 (collect at arrowconverters.scala:270)
20/02/14 14:16:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 245, ShuffleMapStage 244)
20/02/14 14:16:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 245, ShuffleMapStage 244)
20/02/14 14:16:38 INFO DAGScheduler: Submitting ShuffleMapStage 244 (MapPartitionsRDD[1368] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:38 INFO MemoryStore: Block broadcast_244 stored as values in memory (estimated size 32.1 KiB, free 413.8 MiB)
20/02/14 14:16:38 INFO MemoryStore: Block broadcast_244_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 413.8 MiB)
20/02/14 14:16:38 INFO BlockManagerInfo: Added broadcast_244_piece0 in memory on 127.0.0.1:55441 (size: 13.5 KiB, free: 413.9 MiB)
20/02/14 14:16:38 INFO SparkContext: Created broadcast 244 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 244 (MapPartitionsRDD[1368] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:38 INFO TaskSchedulerImpl: Adding task set 244.0 with 1 tasks
20/02/14 14:16:38 INFO TaskSetManager: Starting task 0.0 in stage 244.0 (TID 322, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:16:38 INFO DAGScheduler: Submitting ShuffleMapStage 245 (MapPartitionsRDD[1375] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:38 INFO Executor: Running task 0.0 in stage 244.0 (TID 322)
20/02/14 14:16:38 INFO MemoryStore: Block broadcast_245 stored as values in memory (estimated size 27.4 KiB, free 413.8 MiB)
20/02/14 14:16:38 INFO MemoryStore: Block broadcast_245_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 413.8 MiB)
20/02/14 14:16:38 INFO BlockManagerInfo: Added broadcast_245_piece0 in memory on 127.0.0.1:55441 (size: 10.9 KiB, free: 413.9 MiB)
20/02/14 14:16:38 INFO SparkContext: Created broadcast 245 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:38 INFO BlockManager: Found block rdd_1344_0 locally
20/02/14 14:16:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 245 (MapPartitionsRDD[1375] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:38 INFO TaskSchedulerImpl: Adding task set 245.0 with 1 tasks
20/02/14 14:16:38 INFO TaskSetManager: Starting task 0.0 in stage 245.0 (TID 323, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 14:16:38 INFO Executor: Running task 0.0 in stage 245.0 (TID 323)
20/02/14 14:16:38 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:16:38 INFO Executor: Finished task 0.0 in stage 245.0 (TID 323). 2203 bytes result sent to driver
20/02/14 14:16:38 INFO TaskSetManager: Finished task 0.0 in stage 245.0 (TID 323) in 24 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:38 INFO TaskSchedulerImpl: Removed TaskSet 245.0, whose tasks have all completed, from pool 
20/02/14 14:16:38 INFO DAGScheduler: ShuffleMapStage 245 (collect at arrowconverters.scala:270) finished in 0.029 s
20/02/14 14:16:38 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:38 INFO DAGScheduler: running: Set(ShuffleMapStage 244)
20/02/14 14:16:38 INFO DAGScheduler: waiting: Set(ResultStage 246)
20/02/14 14:16:38 INFO DAGScheduler: failed: Set()
20/02/14 14:16:38 INFO Executor: Finished task 0.0 in stage 244.0 (TID 322). 2160 bytes result sent to driver
20/02/14 14:16:38 INFO TaskSetManager: Finished task 0.0 in stage 244.0 (TID 322) in 33 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:38 INFO TaskSchedulerImpl: Removed TaskSet 244.0, whose tasks have all completed, from pool 
20/02/14 14:16:38 INFO DAGScheduler: ShuffleMapStage 244 (collect at arrowconverters.scala:270) finished in 0.039 s
20/02/14 14:16:38 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:38 INFO DAGScheduler: running: Set()
20/02/14 14:16:38 INFO DAGScheduler: waiting: Set(ResultStage 246)
20/02/14 14:16:38 INFO DAGScheduler: failed: Set()
20/02/14 14:16:38 INFO DAGScheduler: Submitting ResultStage 246 (MapPartitionsRDD[1383] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:38 INFO MemoryStore: Block broadcast_246 stored as values in memory (estimated size 56.3 KiB, free 413.7 MiB)
20/02/14 14:16:38 INFO MemoryStore: Block broadcast_246_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 413.7 MiB)
20/02/14 14:16:38 INFO BlockManagerInfo: Added broadcast_246_piece0 in memory on 127.0.0.1:55441 (size: 23.0 KiB, free: 413.9 MiB)
20/02/14 14:16:38 INFO SparkContext: Created broadcast 246 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:38 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 246 (MapPartitionsRDD[1383] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 14:16:38 INFO TaskSchedulerImpl: Adding task set 246.0 with 4 tasks
20/02/14 14:16:38 INFO TaskSetManager: Starting task 0.0 in stage 246.0 (TID 324, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:38 INFO TaskSetManager: Starting task 1.0 in stage 246.0 (TID 325, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:38 INFO TaskSetManager: Starting task 2.0 in stage 246.0 (TID 326, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:38 INFO TaskSetManager: Starting task 3.0 in stage 246.0 (TID 327, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:38 INFO Executor: Running task 0.0 in stage 246.0 (TID 324)
20/02/14 14:16:38 INFO Executor: Running task 3.0 in stage 246.0 (TID 327)
20/02/14 14:16:38 INFO Executor: Running task 2.0 in stage 246.0 (TID 326)
20/02/14 14:16:38 INFO Executor: Running task 1.0 in stage 246.0 (TID 325)
20/02/14 14:16:38 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:38 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:38 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:38 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:38 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:38 INFO ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:38 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:38 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
20/02/14 14:16:38 INFO BlockManagerInfo: Removed broadcast_244_piece0 on 127.0.0.1:55441 in memory (size: 13.5 KiB, free: 413.9 MiB)
20/02/14 14:16:38 INFO Executor: Finished task 0.0 in stage 246.0 (TID 324). 5814 bytes result sent to driver
20/02/14 14:16:38 INFO Executor: Finished task 1.0 in stage 246.0 (TID 325). 5833 bytes result sent to driver
20/02/14 14:16:38 INFO Executor: Finished task 3.0 in stage 246.0 (TID 327). 5807 bytes result sent to driver
20/02/14 14:16:38 INFO TaskSetManager: Finished task 0.0 in stage 246.0 (TID 324) in 58 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 14:16:38 INFO TaskSetManager: Finished task 1.0 in stage 246.0 (TID 325) in 58 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 14:16:38 INFO TaskSetManager: Finished task 3.0 in stage 246.0 (TID 327) in 58 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 14:16:38 INFO BlockManagerInfo: Removed broadcast_245_piece0 on 127.0.0.1:55441 in memory (size: 10.9 KiB, free: 413.9 MiB)
20/02/14 14:16:38 INFO Executor: Finished task 2.0 in stage 246.0 (TID 326). 5952 bytes result sent to driver
20/02/14 14:16:38 INFO TaskSetManager: Finished task 2.0 in stage 246.0 (TID 326) in 70 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 14:16:38 INFO TaskSchedulerImpl: Removed TaskSet 246.0, whose tasks have all completed, from pool 
20/02/14 14:16:38 INFO DAGScheduler: ResultStage 246 (collect at arrowconverters.scala:270) finished in 0.077 s
20/02/14 14:16:38 INFO DAGScheduler: Job 136 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 246: Stage finished
20/02/14 14:16:38 INFO DAGScheduler: Job 136 finished: collect at arrowconverters.scala:270, took 0.121379 s
20/02/14 14:16:46 INFO BlockManagerInfo: Removed broadcast_246_piece0 on 127.0.0.1:55441 in memory (size: 23.0 KiB, free: 413.9 MiB)
20/02/14 14:16:46 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 14:16:46 INFO DAGScheduler: Got job 137 (collect at utils.scala:41) with 4 output partitions
20/02/14 14:16:46 INFO DAGScheduler: Final stage: ResultStage 247 (collect at utils.scala:41)
20/02/14 14:16:46 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:16:46 INFO DAGScheduler: Missing parents: List()
20/02/14 14:16:46 INFO DAGScheduler: Submitting ResultStage 247 (MapPartitionsRDD[1389] at map at utils.scala:41), which has no missing parents
20/02/14 14:16:46 INFO MemoryStore: Block broadcast_247 stored as values in memory (estimated size 8.8 KiB, free 413.8 MiB)
20/02/14 14:16:46 INFO MemoryStore: Block broadcast_247_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.8 MiB)
20/02/14 14:16:46 INFO BlockManagerInfo: Added broadcast_247_piece0 in memory on 127.0.0.1:55441 (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 14:16:46 INFO SparkContext: Created broadcast 247 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:46 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 247 (MapPartitionsRDD[1389] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 14:16:46 INFO TaskSchedulerImpl: Adding task set 247.0 with 4 tasks
20/02/14 14:16:46 INFO TaskSetManager: Starting task 0.0 in stage 247.0 (TID 328, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7793 bytes)
20/02/14 14:16:46 INFO TaskSetManager: Starting task 1.0 in stage 247.0 (TID 329, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7866 bytes)
20/02/14 14:16:46 INFO TaskSetManager: Starting task 2.0 in stage 247.0 (TID 330, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7809 bytes)
20/02/14 14:16:46 INFO TaskSetManager: Starting task 3.0 in stage 247.0 (TID 331, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7866 bytes)
20/02/14 14:16:46 INFO Executor: Running task 0.0 in stage 247.0 (TID 328)
20/02/14 14:16:46 INFO Executor: Running task 1.0 in stage 247.0 (TID 329)
20/02/14 14:16:46 INFO Executor: Running task 3.0 in stage 247.0 (TID 331)
20/02/14 14:16:46 INFO Executor: Running task 2.0 in stage 247.0 (TID 330)
20/02/14 14:16:46 INFO Executor: Finished task 1.0 in stage 247.0 (TID 329). 1225 bytes result sent to driver
20/02/14 14:16:46 INFO Executor: Finished task 0.0 in stage 247.0 (TID 328). 1181 bytes result sent to driver
20/02/14 14:16:46 INFO Executor: Finished task 2.0 in stage 247.0 (TID 330). 1156 bytes result sent to driver
20/02/14 14:16:46 INFO TaskSetManager: Finished task 1.0 in stage 247.0 (TID 329) in 10 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 14:16:46 INFO TaskSetManager: Finished task 2.0 in stage 247.0 (TID 330) in 10 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 14:16:46 INFO TaskSetManager: Finished task 0.0 in stage 247.0 (TID 328) in 11 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 14:16:46 INFO Executor: Finished task 3.0 in stage 247.0 (TID 331). 1182 bytes result sent to driver
20/02/14 14:16:46 INFO TaskSetManager: Finished task 3.0 in stage 247.0 (TID 331) in 12 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 14:16:46 INFO TaskSchedulerImpl: Removed TaskSet 247.0, whose tasks have all completed, from pool 
20/02/14 14:16:46 INFO DAGScheduler: ResultStage 247 (collect at utils.scala:41) finished in 0.017 s
20/02/14 14:16:46 INFO DAGScheduler: Job 137 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 247: Stage finished
20/02/14 14:16:46 INFO DAGScheduler: Job 137 finished: collect at utils.scala:41, took 0.019897 s
20/02/14 14:16:47 INFO BlockManagerInfo: Removed broadcast_247_piece0 on 127.0.0.1:55441 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 14:16:47 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/14 14:16:47 INFO DAGScheduler: Registering RDD 1398 (sql at <unknown>:0) as input to shuffle 110
20/02/14 14:16:47 INFO DAGScheduler: Got job 138 (sql at <unknown>:0) with 1 output partitions
20/02/14 14:16:47 INFO DAGScheduler: Final stage: ResultStage 249 (sql at <unknown>:0)
20/02/14 14:16:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 248)
20/02/14 14:16:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 248)
20/02/14 14:16:47 INFO DAGScheduler: Submitting ShuffleMapStage 248 (MapPartitionsRDD[1398] at sql at <unknown>:0), which has no missing parents
20/02/14 14:16:47 INFO MemoryStore: Block broadcast_248 stored as values in memory (estimated size 18.9 KiB, free 413.8 MiB)
20/02/14 14:16:47 INFO MemoryStore: Block broadcast_248_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.8 MiB)
20/02/14 14:16:47 INFO BlockManagerInfo: Added broadcast_248_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:47 INFO SparkContext: Created broadcast 248 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 248 (MapPartitionsRDD[1398] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:47 INFO TaskSchedulerImpl: Adding task set 248.0 with 1 tasks
20/02/14 14:16:47 INFO TaskSetManager: Starting task 0.0 in stage 248.0 (TID 332, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:16:47 INFO Executor: Running task 0.0 in stage 248.0 (TID 332)
20/02/14 14:16:47 INFO MemoryStore: Block rdd_1393_0 stored as values in memory (estimated size 312.0 B, free 413.8 MiB)
20/02/14 14:16:47 INFO BlockManagerInfo: Added rdd_1393_0 in memory on 127.0.0.1:55441 (size: 312.0 B, free: 413.9 MiB)
20/02/14 14:16:47 INFO Executor: Finished task 0.0 in stage 248.0 (TID 332). 2240 bytes result sent to driver
20/02/14 14:16:47 INFO TaskSetManager: Finished task 0.0 in stage 248.0 (TID 332) in 13 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:47 INFO TaskSchedulerImpl: Removed TaskSet 248.0, whose tasks have all completed, from pool 
20/02/14 14:16:47 INFO DAGScheduler: ShuffleMapStage 248 (sql at <unknown>:0) finished in 0.018 s
20/02/14 14:16:47 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:47 INFO DAGScheduler: running: Set()
20/02/14 14:16:47 INFO DAGScheduler: waiting: Set(ResultStage 249)
20/02/14 14:16:47 INFO DAGScheduler: failed: Set()
20/02/14 14:16:47 INFO DAGScheduler: Submitting ResultStage 249 (MapPartitionsRDD[1401] at sql at <unknown>:0), which has no missing parents
20/02/14 14:16:47 INFO MemoryStore: Block broadcast_249 stored as values in memory (estimated size 10.2 KiB, free 413.8 MiB)
20/02/14 14:16:47 INFO MemoryStore: Block broadcast_249_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
20/02/14 14:16:47 INFO BlockManagerInfo: Added broadcast_249_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:16:47 INFO SparkContext: Created broadcast 249 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 249 (MapPartitionsRDD[1401] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:47 INFO TaskSchedulerImpl: Adding task set 249.0 with 1 tasks
20/02/14 14:16:47 INFO TaskSetManager: Starting task 0.0 in stage 249.0 (TID 333, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:16:47 INFO Executor: Running task 0.0 in stage 249.0 (TID 333)
20/02/14 14:16:47 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:47 INFO Executor: Finished task 0.0 in stage 249.0 (TID 333). 2760 bytes result sent to driver
20/02/14 14:16:47 INFO TaskSetManager: Finished task 0.0 in stage 249.0 (TID 333) in 5 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:47 INFO TaskSchedulerImpl: Removed TaskSet 249.0, whose tasks have all completed, from pool 
20/02/14 14:16:47 INFO DAGScheduler: ResultStage 249 (sql at <unknown>:0) finished in 0.008 s
20/02/14 14:16:47 INFO DAGScheduler: Job 138 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 249: Stage finished
20/02/14 14:16:47 INFO DAGScheduler: Job 138 finished: sql at <unknown>:0, took 0.030905 s
20/02/14 14:16:47 INFO BlockManagerInfo: Removed broadcast_249_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:16:47 INFO BlockManagerInfo: Removed broadcast_248_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:47 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 14:16:47 INFO DAGScheduler: Registering RDD 1406 (collect at arrowconverters.scala:270) as input to shuffle 111
20/02/14 14:16:47 INFO DAGScheduler: Got job 139 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 14:16:47 INFO DAGScheduler: Final stage: ResultStage 251 (collect at arrowconverters.scala:270)
20/02/14 14:16:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 250)
20/02/14 14:16:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 250)
20/02/14 14:16:47 INFO DAGScheduler: Submitting ShuffleMapStage 250 (MapPartitionsRDD[1406] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:47 INFO MemoryStore: Block broadcast_250 stored as values in memory (estimated size 18.9 KiB, free 413.8 MiB)
20/02/14 14:16:47 INFO MemoryStore: Block broadcast_250_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.8 MiB)
20/02/14 14:16:47 INFO BlockManagerInfo: Added broadcast_250_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:47 INFO SparkContext: Created broadcast 250 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 250 (MapPartitionsRDD[1406] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:47 INFO TaskSchedulerImpl: Adding task set 250.0 with 1 tasks
20/02/14 14:16:47 INFO TaskSetManager: Starting task 0.0 in stage 250.0 (TID 334, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:16:47 INFO Executor: Running task 0.0 in stage 250.0 (TID 334)
20/02/14 14:16:47 INFO BlockManager: Found block rdd_1393_0 locally
20/02/14 14:16:47 INFO Executor: Finished task 0.0 in stage 250.0 (TID 334). 2369 bytes result sent to driver
20/02/14 14:16:47 INFO TaskSetManager: Finished task 0.0 in stage 250.0 (TID 334) in 11 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:47 INFO TaskSchedulerImpl: Removed TaskSet 250.0, whose tasks have all completed, from pool 
20/02/14 14:16:47 INFO DAGScheduler: ShuffleMapStage 250 (collect at arrowconverters.scala:270) finished in 0.015 s
20/02/14 14:16:47 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:47 INFO DAGScheduler: running: Set()
20/02/14 14:16:47 INFO DAGScheduler: waiting: Set(ResultStage 251)
20/02/14 14:16:47 INFO DAGScheduler: failed: Set()
20/02/14 14:16:47 INFO DAGScheduler: Submitting ResultStage 251 (MapPartitionsRDD[1412] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:47 INFO MemoryStore: Block broadcast_251 stored as values in memory (estimated size 28.9 KiB, free 413.8 MiB)
20/02/14 14:16:47 INFO MemoryStore: Block broadcast_251_piece0 stored as bytes in memory (estimated size 12.0 KiB, free 413.8 MiB)
20/02/14 14:16:47 INFO BlockManagerInfo: Added broadcast_251_piece0 in memory on 127.0.0.1:55441 (size: 12.0 KiB, free: 413.9 MiB)
20/02/14 14:16:47 INFO SparkContext: Created broadcast 251 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 251 (MapPartitionsRDD[1412] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:47 INFO TaskSchedulerImpl: Adding task set 251.0 with 1 tasks
20/02/14 14:16:47 INFO TaskSetManager: Starting task 0.0 in stage 251.0 (TID 335, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:16:47 INFO Executor: Running task 0.0 in stage 251.0 (TID 335)
20/02/14 14:16:47 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:47 INFO Executor: Finished task 0.0 in stage 251.0 (TID 335). 4242 bytes result sent to driver
20/02/14 14:16:47 INFO TaskSetManager: Finished task 0.0 in stage 251.0 (TID 335) in 9 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:47 INFO TaskSchedulerImpl: Removed TaskSet 251.0, whose tasks have all completed, from pool 
20/02/14 14:16:47 INFO DAGScheduler: ResultStage 251 (collect at arrowconverters.scala:270) finished in 0.019 s
20/02/14 14:16:47 INFO DAGScheduler: Job 139 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 251: Stage finished
20/02/14 14:16:47 INFO DAGScheduler: Job 139 finished: collect at arrowconverters.scala:270, took 0.038326 s
20/02/14 14:16:47 INFO Instrumentation: [53166abc] training finished
20/02/14 14:16:47 INFO Instrumentation: [e8d70fcd] training finished
20/02/14 14:16:48 INFO BlockManagerInfo: Removed broadcast_251_piece0 on 127.0.0.1:55441 in memory (size: 12.0 KiB, free: 413.9 MiB)
20/02/14 14:16:48 INFO BlockManagerInfo: Removed broadcast_250_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:48 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 14:16:48 INFO DAGScheduler: Registering RDD 1417 (collect at arrowconverters.scala:270) as input to shuffle 112
20/02/14 14:16:48 INFO DAGScheduler: Registering RDD 1424 (collect at arrowconverters.scala:270) as input to shuffle 113
20/02/14 14:16:48 INFO DAGScheduler: Got job 140 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/14 14:16:48 INFO DAGScheduler: Final stage: ResultStage 254 (collect at arrowconverters.scala:270)
20/02/14 14:16:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 252, ShuffleMapStage 253)
20/02/14 14:16:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 252, ShuffleMapStage 253)
20/02/14 14:16:48 INFO DAGScheduler: Submitting ShuffleMapStage 252 (MapPartitionsRDD[1417] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:48 INFO MemoryStore: Block broadcast_252 stored as values in memory (estimated size 32.1 KiB, free 413.8 MiB)
20/02/14 14:16:48 INFO MemoryStore: Block broadcast_252_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 413.8 MiB)
20/02/14 14:16:48 INFO BlockManagerInfo: Added broadcast_252_piece0 in memory on 127.0.0.1:55441 (size: 13.5 KiB, free: 413.9 MiB)
20/02/14 14:16:48 INFO SparkContext: Created broadcast 252 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 252 (MapPartitionsRDD[1417] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:48 INFO TaskSchedulerImpl: Adding task set 252.0 with 1 tasks
20/02/14 14:16:48 INFO DAGScheduler: Submitting ShuffleMapStage 253 (MapPartitionsRDD[1424] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:48 INFO TaskSetManager: Starting task 0.0 in stage 252.0 (TID 336, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:16:48 INFO Executor: Running task 0.0 in stage 252.0 (TID 336)
20/02/14 14:16:48 INFO MemoryStore: Block broadcast_253 stored as values in memory (estimated size 27.4 KiB, free 413.8 MiB)
20/02/14 14:16:48 INFO MemoryStore: Block broadcast_253_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.8 MiB)
20/02/14 14:16:48 INFO BlockManagerInfo: Added broadcast_253_piece0 in memory on 127.0.0.1:55441 (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 14:16:48 INFO SparkContext: Created broadcast 253 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:48 INFO BlockManager: Found block rdd_1393_0 locally
20/02/14 14:16:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 253 (MapPartitionsRDD[1424] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:48 INFO TaskSchedulerImpl: Adding task set 253.0 with 1 tasks
20/02/14 14:16:48 INFO TaskSetManager: Starting task 0.0 in stage 253.0 (TID 337, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 14:16:48 INFO Executor: Running task 0.0 in stage 253.0 (TID 337)
20/02/14 14:16:48 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:16:48 INFO Executor: Finished task 0.0 in stage 253.0 (TID 337). 2160 bytes result sent to driver
20/02/14 14:16:48 INFO TaskSetManager: Finished task 0.0 in stage 253.0 (TID 337) in 29 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:48 INFO TaskSchedulerImpl: Removed TaskSet 253.0, whose tasks have all completed, from pool 
20/02/14 14:16:48 INFO DAGScheduler: ShuffleMapStage 253 (collect at arrowconverters.scala:270) finished in 0.035 s
20/02/14 14:16:48 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:48 INFO DAGScheduler: running: Set(ShuffleMapStage 252)
20/02/14 14:16:48 INFO DAGScheduler: waiting: Set(ResultStage 254)
20/02/14 14:16:48 INFO DAGScheduler: failed: Set()
20/02/14 14:16:48 INFO Executor: Finished task 0.0 in stage 252.0 (TID 336). 2203 bytes result sent to driver
20/02/14 14:16:48 INFO TaskSetManager: Finished task 0.0 in stage 252.0 (TID 336) in 42 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:48 INFO TaskSchedulerImpl: Removed TaskSet 252.0, whose tasks have all completed, from pool 
20/02/14 14:16:48 INFO DAGScheduler: ShuffleMapStage 252 (collect at arrowconverters.scala:270) finished in 0.049 s
20/02/14 14:16:48 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:48 INFO DAGScheduler: running: Set()
20/02/14 14:16:48 INFO DAGScheduler: waiting: Set(ResultStage 254)
20/02/14 14:16:48 INFO DAGScheduler: failed: Set()
20/02/14 14:16:48 INFO DAGScheduler: Submitting ResultStage 254 (MapPartitionsRDD[1432] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:48 INFO MemoryStore: Block broadcast_254 stored as values in memory (estimated size 56.3 KiB, free 413.7 MiB)
20/02/14 14:16:48 INFO MemoryStore: Block broadcast_254_piece0 stored as bytes in memory (estimated size 23.1 KiB, free 413.7 MiB)
20/02/14 14:16:48 INFO BlockManagerInfo: Added broadcast_254_piece0 in memory on 127.0.0.1:55441 (size: 23.1 KiB, free: 413.9 MiB)
20/02/14 14:16:48 INFO SparkContext: Created broadcast 254 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:48 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 254 (MapPartitionsRDD[1432] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 14:16:48 INFO TaskSchedulerImpl: Adding task set 254.0 with 4 tasks
20/02/14 14:16:48 INFO TaskSetManager: Starting task 0.0 in stage 254.0 (TID 338, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:48 INFO TaskSetManager: Starting task 1.0 in stage 254.0 (TID 339, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:48 INFO TaskSetManager: Starting task 2.0 in stage 254.0 (TID 340, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:48 INFO TaskSetManager: Starting task 3.0 in stage 254.0 (TID 341, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:48 INFO Executor: Running task 0.0 in stage 254.0 (TID 338)
20/02/14 14:16:48 INFO Executor: Running task 3.0 in stage 254.0 (TID 341)
20/02/14 14:16:48 INFO Executor: Running task 2.0 in stage 254.0 (TID 340)
20/02/14 14:16:48 INFO Executor: Running task 1.0 in stage 254.0 (TID 339)
20/02/14 14:16:48 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:48 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:48 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:48 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:48 INFO ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:48 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:48 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:48 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:48 INFO Executor: Finished task 0.0 in stage 254.0 (TID 338). 5857 bytes result sent to driver
20/02/14 14:16:48 INFO BlockManagerInfo: Removed broadcast_253_piece0 on 127.0.0.1:55441 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 14:16:48 INFO Executor: Finished task 1.0 in stage 254.0 (TID 339). 5833 bytes result sent to driver
20/02/14 14:16:48 INFO TaskSetManager: Finished task 0.0 in stage 254.0 (TID 338) in 49 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 14:16:48 INFO TaskSetManager: Finished task 1.0 in stage 254.0 (TID 339) in 49 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 14:16:48 INFO BlockManagerInfo: Removed broadcast_252_piece0 on 127.0.0.1:55441 in memory (size: 13.5 KiB, free: 413.9 MiB)
20/02/14 14:16:48 INFO Executor: Finished task 2.0 in stage 254.0 (TID 340). 5952 bytes result sent to driver
20/02/14 14:16:48 INFO TaskSetManager: Finished task 2.0 in stage 254.0 (TID 340) in 52 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 14:16:48 INFO Executor: Finished task 3.0 in stage 254.0 (TID 341). 5850 bytes result sent to driver
20/02/14 14:16:48 INFO TaskSetManager: Finished task 3.0 in stage 254.0 (TID 341) in 54 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 14:16:48 INFO DAGScheduler: ResultStage 254 (collect at arrowconverters.scala:270) finished in 0.061 s
20/02/14 14:16:48 INFO DAGScheduler: Job 140 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:48 INFO TaskSchedulerImpl: Removed TaskSet 254.0, whose tasks have all completed, from pool 
20/02/14 14:16:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 254: Stage finished
20/02/14 14:16:48 INFO DAGScheduler: Job 140 finished: collect at arrowconverters.scala:270, took 0.115450 s
20/02/14 14:16:54 INFO BlockManagerInfo: Removed broadcast_254_piece0 on 127.0.0.1:55441 in memory (size: 23.1 KiB, free: 413.9 MiB)
20/02/14 14:16:54 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 14:16:54 INFO DAGScheduler: Got job 141 (collect at utils.scala:41) with 4 output partitions
20/02/14 14:16:54 INFO DAGScheduler: Final stage: ResultStage 255 (collect at utils.scala:41)
20/02/14 14:16:54 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:16:54 INFO DAGScheduler: Missing parents: List()
20/02/14 14:16:54 INFO DAGScheduler: Submitting ResultStage 255 (MapPartitionsRDD[1438] at map at utils.scala:41), which has no missing parents
20/02/14 14:16:54 INFO MemoryStore: Block broadcast_255 stored as values in memory (estimated size 8.8 KiB, free 413.8 MiB)
20/02/14 14:16:54 INFO MemoryStore: Block broadcast_255_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.8 MiB)
20/02/14 14:16:54 INFO BlockManagerInfo: Added broadcast_255_piece0 in memory on 127.0.0.1:55441 (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 14:16:54 INFO SparkContext: Created broadcast 255 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:54 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 255 (MapPartitionsRDD[1438] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 14:16:54 INFO TaskSchedulerImpl: Adding task set 255.0 with 4 tasks
20/02/14 14:16:54 INFO TaskSetManager: Starting task 0.0 in stage 255.0 (TID 342, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7858 bytes)
20/02/14 14:16:54 INFO TaskSetManager: Starting task 1.0 in stage 255.0 (TID 343, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7866 bytes)
20/02/14 14:16:54 INFO TaskSetManager: Starting task 2.0 in stage 255.0 (TID 344, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7874 bytes)
20/02/14 14:16:54 INFO TaskSetManager: Starting task 3.0 in stage 255.0 (TID 345, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7866 bytes)
20/02/14 14:16:54 INFO Executor: Running task 0.0 in stage 255.0 (TID 342)
20/02/14 14:16:54 INFO Executor: Running task 1.0 in stage 255.0 (TID 343)
20/02/14 14:16:54 INFO Executor: Running task 3.0 in stage 255.0 (TID 345)
20/02/14 14:16:54 INFO Executor: Running task 2.0 in stage 255.0 (TID 344)
20/02/14 14:16:54 INFO Executor: Finished task 2.0 in stage 255.0 (TID 344). 1227 bytes result sent to driver
20/02/14 14:16:54 INFO Executor: Finished task 1.0 in stage 255.0 (TID 343). 1225 bytes result sent to driver
20/02/14 14:16:54 INFO Executor: Finished task 3.0 in stage 255.0 (TID 345). 1225 bytes result sent to driver
20/02/14 14:16:54 INFO TaskSetManager: Finished task 3.0 in stage 255.0 (TID 345) in 7 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 14:16:54 INFO TaskSetManager: Finished task 1.0 in stage 255.0 (TID 343) in 8 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 14:16:54 INFO TaskSetManager: Finished task 2.0 in stage 255.0 (TID 344) in 7 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 14:16:54 INFO Executor: Finished task 0.0 in stage 255.0 (TID 342). 1166 bytes result sent to driver
20/02/14 14:16:54 INFO TaskSetManager: Finished task 0.0 in stage 255.0 (TID 342) in 10 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 14:16:54 INFO TaskSchedulerImpl: Removed TaskSet 255.0, whose tasks have all completed, from pool 
20/02/14 14:16:54 INFO DAGScheduler: ResultStage 255 (collect at utils.scala:41) finished in 0.014 s
20/02/14 14:16:54 INFO DAGScheduler: Job 141 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 255: Stage finished
20/02/14 14:16:54 INFO DAGScheduler: Job 141 finished: collect at utils.scala:41, took 0.017526 s
20/02/14 14:16:54 INFO BlockManagerInfo: Removed broadcast_255_piece0 on 127.0.0.1:55441 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 14:16:54 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/14 14:16:54 INFO DAGScheduler: Registering RDD 1447 (sql at <unknown>:0) as input to shuffle 114
20/02/14 14:16:54 INFO DAGScheduler: Got job 142 (sql at <unknown>:0) with 1 output partitions
20/02/14 14:16:54 INFO DAGScheduler: Final stage: ResultStage 257 (sql at <unknown>:0)
20/02/14 14:16:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 256)
20/02/14 14:16:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 256)
20/02/14 14:16:54 INFO DAGScheduler: Submitting ShuffleMapStage 256 (MapPartitionsRDD[1447] at sql at <unknown>:0), which has no missing parents
20/02/14 14:16:54 INFO MemoryStore: Block broadcast_256 stored as values in memory (estimated size 18.9 KiB, free 413.8 MiB)
20/02/14 14:16:54 INFO MemoryStore: Block broadcast_256_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.8 MiB)
20/02/14 14:16:54 INFO BlockManagerInfo: Added broadcast_256_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:54 INFO SparkContext: Created broadcast 256 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 256 (MapPartitionsRDD[1447] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:54 INFO TaskSchedulerImpl: Adding task set 256.0 with 1 tasks
20/02/14 14:16:54 INFO TaskSetManager: Starting task 0.0 in stage 256.0 (TID 346, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:16:54 INFO Executor: Running task 0.0 in stage 256.0 (TID 346)
20/02/14 14:16:54 INFO MemoryStore: Block rdd_1442_0 stored as values in memory (estimated size 312.0 B, free 413.8 MiB)
20/02/14 14:16:54 INFO BlockManagerInfo: Added rdd_1442_0 in memory on 127.0.0.1:55441 (size: 312.0 B, free: 413.9 MiB)
20/02/14 14:16:54 INFO Executor: Finished task 0.0 in stage 256.0 (TID 346). 2240 bytes result sent to driver
20/02/14 14:16:54 INFO TaskSetManager: Finished task 0.0 in stage 256.0 (TID 346) in 13 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:54 INFO TaskSchedulerImpl: Removed TaskSet 256.0, whose tasks have all completed, from pool 
20/02/14 14:16:54 INFO DAGScheduler: ShuffleMapStage 256 (sql at <unknown>:0) finished in 0.017 s
20/02/14 14:16:54 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:54 INFO DAGScheduler: running: Set()
20/02/14 14:16:54 INFO DAGScheduler: waiting: Set(ResultStage 257)
20/02/14 14:16:54 INFO DAGScheduler: failed: Set()
20/02/14 14:16:54 INFO DAGScheduler: Submitting ResultStage 257 (MapPartitionsRDD[1450] at sql at <unknown>:0), which has no missing parents
20/02/14 14:16:54 INFO MemoryStore: Block broadcast_257 stored as values in memory (estimated size 10.2 KiB, free 413.8 MiB)
20/02/14 14:16:54 INFO MemoryStore: Block broadcast_257_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
20/02/14 14:16:54 INFO BlockManagerInfo: Added broadcast_257_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:16:54 INFO SparkContext: Created broadcast 257 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 257 (MapPartitionsRDD[1450] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:54 INFO TaskSchedulerImpl: Adding task set 257.0 with 1 tasks
20/02/14 14:16:54 INFO TaskSetManager: Starting task 0.0 in stage 257.0 (TID 347, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:16:54 INFO Executor: Running task 0.0 in stage 257.0 (TID 347)
20/02/14 14:16:54 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:54 INFO Executor: Finished task 0.0 in stage 257.0 (TID 347). 2760 bytes result sent to driver
20/02/14 14:16:54 INFO TaskSetManager: Finished task 0.0 in stage 257.0 (TID 347) in 4 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:54 INFO TaskSchedulerImpl: Removed TaskSet 257.0, whose tasks have all completed, from pool 
20/02/14 14:16:54 INFO DAGScheduler: ResultStage 257 (sql at <unknown>:0) finished in 0.009 s
20/02/14 14:16:54 INFO DAGScheduler: Job 142 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 257: Stage finished
20/02/14 14:16:54 INFO DAGScheduler: Job 142 finished: sql at <unknown>:0, took 0.029933 s
20/02/14 14:16:54 INFO BlockManagerInfo: Removed broadcast_256_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:54 INFO BlockManagerInfo: Removed broadcast_257_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:16:54 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 14:16:54 INFO DAGScheduler: Registering RDD 1455 (collect at arrowconverters.scala:270) as input to shuffle 115
20/02/14 14:16:54 INFO DAGScheduler: Got job 143 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 14:16:54 INFO DAGScheduler: Final stage: ResultStage 259 (collect at arrowconverters.scala:270)
20/02/14 14:16:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 258)
20/02/14 14:16:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 258)
20/02/14 14:16:54 INFO DAGScheduler: Submitting ShuffleMapStage 258 (MapPartitionsRDD[1455] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:54 INFO MemoryStore: Block broadcast_258 stored as values in memory (estimated size 18.9 KiB, free 413.8 MiB)
20/02/14 14:16:54 INFO MemoryStore: Block broadcast_258_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.8 MiB)
20/02/14 14:16:54 INFO BlockManagerInfo: Added broadcast_258_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:54 INFO SparkContext: Created broadcast 258 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 258 (MapPartitionsRDD[1455] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:54 INFO TaskSchedulerImpl: Adding task set 258.0 with 1 tasks
20/02/14 14:16:54 INFO TaskSetManager: Starting task 0.0 in stage 258.0 (TID 348, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:16:54 INFO Executor: Running task 0.0 in stage 258.0 (TID 348)
20/02/14 14:16:54 INFO BlockManager: Found block rdd_1442_0 locally
20/02/14 14:16:54 INFO Executor: Finished task 0.0 in stage 258.0 (TID 348). 2369 bytes result sent to driver
20/02/14 14:16:54 INFO TaskSetManager: Finished task 0.0 in stage 258.0 (TID 348) in 12 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:54 INFO TaskSchedulerImpl: Removed TaskSet 258.0, whose tasks have all completed, from pool 
20/02/14 14:16:54 INFO DAGScheduler: ShuffleMapStage 258 (collect at arrowconverters.scala:270) finished in 0.019 s
20/02/14 14:16:54 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:54 INFO DAGScheduler: running: Set()
20/02/14 14:16:54 INFO DAGScheduler: waiting: Set(ResultStage 259)
20/02/14 14:16:54 INFO DAGScheduler: failed: Set()
20/02/14 14:16:54 INFO DAGScheduler: Submitting ResultStage 259 (MapPartitionsRDD[1461] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:54 INFO MemoryStore: Block broadcast_259 stored as values in memory (estimated size 28.9 KiB, free 413.8 MiB)
20/02/14 14:16:54 INFO MemoryStore: Block broadcast_259_piece0 stored as bytes in memory (estimated size 12.0 KiB, free 413.8 MiB)
20/02/14 14:16:54 INFO BlockManagerInfo: Added broadcast_259_piece0 in memory on 127.0.0.1:55441 (size: 12.0 KiB, free: 413.9 MiB)
20/02/14 14:16:54 INFO SparkContext: Created broadcast 259 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 259 (MapPartitionsRDD[1461] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:54 INFO TaskSchedulerImpl: Adding task set 259.0 with 1 tasks
20/02/14 14:16:54 INFO TaskSetManager: Starting task 0.0 in stage 259.0 (TID 349, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:16:54 INFO Executor: Running task 0.0 in stage 259.0 (TID 349)
20/02/14 14:16:54 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:54 INFO Executor: Finished task 0.0 in stage 259.0 (TID 349). 4242 bytes result sent to driver
20/02/14 14:16:54 INFO TaskSetManager: Finished task 0.0 in stage 259.0 (TID 349) in 11 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:54 INFO TaskSchedulerImpl: Removed TaskSet 259.0, whose tasks have all completed, from pool 
20/02/14 14:16:54 INFO DAGScheduler: ResultStage 259 (collect at arrowconverters.scala:270) finished in 0.024 s
20/02/14 14:16:54 INFO DAGScheduler: Job 143 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 259: Stage finished
20/02/14 14:16:54 INFO DAGScheduler: Job 143 finished: collect at arrowconverters.scala:270, took 0.048275 s
20/02/14 14:16:54 INFO Instrumentation: [25f22529] training finished
20/02/14 14:16:54 INFO Instrumentation: [cb2a3a22] training finished
20/02/14 14:16:55 INFO BlockManagerInfo: Removed broadcast_259_piece0 on 127.0.0.1:55441 in memory (size: 12.0 KiB, free: 413.9 MiB)
20/02/14 14:16:55 INFO BlockManagerInfo: Removed broadcast_258_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:16:55 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 14:16:55 INFO DAGScheduler: Registering RDD 1473 (collect at arrowconverters.scala:270) as input to shuffle 117
20/02/14 14:16:55 INFO DAGScheduler: Registering RDD 1466 (collect at arrowconverters.scala:270) as input to shuffle 116
20/02/14 14:16:55 INFO DAGScheduler: Got job 144 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/14 14:16:55 INFO DAGScheduler: Final stage: ResultStage 262 (collect at arrowconverters.scala:270)
20/02/14 14:16:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 260, ShuffleMapStage 261)
20/02/14 14:16:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 260, ShuffleMapStage 261)
20/02/14 14:16:55 INFO DAGScheduler: Submitting ShuffleMapStage 260 (MapPartitionsRDD[1473] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:55 INFO MemoryStore: Block broadcast_260 stored as values in memory (estimated size 27.4 KiB, free 413.8 MiB)
20/02/14 14:16:55 INFO MemoryStore: Block broadcast_260_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 413.8 MiB)
20/02/14 14:16:55 INFO BlockManagerInfo: Added broadcast_260_piece0 in memory on 127.0.0.1:55441 (size: 10.9 KiB, free: 413.9 MiB)
20/02/14 14:16:55 INFO SparkContext: Created broadcast 260 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 260 (MapPartitionsRDD[1473] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:55 INFO TaskSchedulerImpl: Adding task set 260.0 with 1 tasks
20/02/14 14:16:55 INFO DAGScheduler: Submitting ShuffleMapStage 261 (MapPartitionsRDD[1466] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:55 INFO TaskSetManager: Starting task 0.0 in stage 260.0 (TID 350, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 14:16:55 INFO Executor: Running task 0.0 in stage 260.0 (TID 350)
20/02/14 14:16:55 INFO MemoryStore: Block broadcast_261 stored as values in memory (estimated size 32.1 KiB, free 413.8 MiB)
20/02/14 14:16:55 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:16:55 INFO MemoryStore: Block broadcast_261_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 413.8 MiB)
20/02/14 14:16:55 INFO BlockManagerInfo: Added broadcast_261_piece0 in memory on 127.0.0.1:55441 (size: 13.5 KiB, free: 413.9 MiB)
20/02/14 14:16:55 INFO SparkContext: Created broadcast 261 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 261 (MapPartitionsRDD[1466] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:16:55 INFO TaskSchedulerImpl: Adding task set 261.0 with 1 tasks
20/02/14 14:16:55 INFO TaskSetManager: Starting task 0.0 in stage 261.0 (TID 351, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:16:55 INFO Executor: Running task 0.0 in stage 261.0 (TID 351)
20/02/14 14:16:55 INFO BlockManager: Found block rdd_1442_0 locally
20/02/14 14:16:55 INFO Executor: Finished task 0.0 in stage 260.0 (TID 350). 2203 bytes result sent to driver
20/02/14 14:16:55 INFO TaskSetManager: Finished task 0.0 in stage 260.0 (TID 350) in 26 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:55 INFO TaskSchedulerImpl: Removed TaskSet 260.0, whose tasks have all completed, from pool 
20/02/14 14:16:55 INFO DAGScheduler: ShuffleMapStage 260 (collect at arrowconverters.scala:270) finished in 0.036 s
20/02/14 14:16:55 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:55 INFO DAGScheduler: running: Set(ShuffleMapStage 261)
20/02/14 14:16:55 INFO DAGScheduler: waiting: Set(ResultStage 262)
20/02/14 14:16:55 INFO DAGScheduler: failed: Set()
20/02/14 14:16:55 INFO Executor: Finished task 0.0 in stage 261.0 (TID 351). 2203 bytes result sent to driver
20/02/14 14:16:55 INFO TaskSetManager: Finished task 0.0 in stage 261.0 (TID 351) in 32 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:16:55 INFO TaskSchedulerImpl: Removed TaskSet 261.0, whose tasks have all completed, from pool 
20/02/14 14:16:55 INFO DAGScheduler: ShuffleMapStage 261 (collect at arrowconverters.scala:270) finished in 0.038 s
20/02/14 14:16:55 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:16:55 INFO DAGScheduler: running: Set()
20/02/14 14:16:55 INFO DAGScheduler: waiting: Set(ResultStage 262)
20/02/14 14:16:55 INFO DAGScheduler: failed: Set()
20/02/14 14:16:55 INFO DAGScheduler: Submitting ResultStage 262 (MapPartitionsRDD[1481] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:16:55 INFO MemoryStore: Block broadcast_262 stored as values in memory (estimated size 56.3 KiB, free 413.7 MiB)
20/02/14 14:16:55 INFO MemoryStore: Block broadcast_262_piece0 stored as bytes in memory (estimated size 23.1 KiB, free 413.7 MiB)
20/02/14 14:16:55 INFO BlockManagerInfo: Added broadcast_262_piece0 in memory on 127.0.0.1:55441 (size: 23.1 KiB, free: 413.9 MiB)
20/02/14 14:16:55 INFO SparkContext: Created broadcast 262 from broadcast at DAGScheduler.scala:1196
20/02/14 14:16:55 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 262 (MapPartitionsRDD[1481] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 14:16:55 INFO TaskSchedulerImpl: Adding task set 262.0 with 4 tasks
20/02/14 14:16:55 INFO TaskSetManager: Starting task 0.0 in stage 262.0 (TID 352, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:55 INFO TaskSetManager: Starting task 1.0 in stage 262.0 (TID 353, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:55 INFO TaskSetManager: Starting task 2.0 in stage 262.0 (TID 354, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:55 INFO TaskSetManager: Starting task 3.0 in stage 262.0 (TID 355, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7528 bytes)
20/02/14 14:16:55 INFO Executor: Running task 0.0 in stage 262.0 (TID 352)
20/02/14 14:16:55 INFO Executor: Running task 1.0 in stage 262.0 (TID 353)
20/02/14 14:16:55 INFO Executor: Running task 3.0 in stage 262.0 (TID 355)
20/02/14 14:16:55 INFO Executor: Running task 2.0 in stage 262.0 (TID 354)
20/02/14 14:16:55 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:55 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:55 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:55 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
20/02/14 14:16:55 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:55 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:55 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:55 INFO ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:16:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:16:55 INFO BlockManagerInfo: Removed broadcast_260_piece0 on 127.0.0.1:55441 in memory (size: 10.9 KiB, free: 413.9 MiB)
20/02/14 14:16:55 INFO Executor: Finished task 0.0 in stage 262.0 (TID 352). 5857 bytes result sent to driver
20/02/14 14:16:55 INFO TaskSetManager: Finished task 0.0 in stage 262.0 (TID 352) in 62 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 14:16:55 INFO Executor: Finished task 3.0 in stage 262.0 (TID 355). 5850 bytes result sent to driver
20/02/14 14:16:55 INFO TaskSetManager: Finished task 3.0 in stage 262.0 (TID 355) in 66 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 14:16:55 INFO BlockManagerInfo: Removed broadcast_261_piece0 on 127.0.0.1:55441 in memory (size: 13.5 KiB, free: 413.9 MiB)
20/02/14 14:16:55 INFO Executor: Finished task 1.0 in stage 262.0 (TID 353). 5790 bytes result sent to driver
20/02/14 14:16:55 INFO TaskSetManager: Finished task 1.0 in stage 262.0 (TID 353) in 72 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 14:16:55 INFO Executor: Finished task 2.0 in stage 262.0 (TID 354). 5952 bytes result sent to driver
20/02/14 14:16:55 INFO TaskSetManager: Finished task 2.0 in stage 262.0 (TID 354) in 75 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 14:16:55 INFO TaskSchedulerImpl: Removed TaskSet 262.0, whose tasks have all completed, from pool 
20/02/14 14:16:55 INFO DAGScheduler: ResultStage 262 (collect at arrowconverters.scala:270) finished in 0.081 s
20/02/14 14:16:55 INFO DAGScheduler: Job 144 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:16:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 262: Stage finished
20/02/14 14:16:55 INFO DAGScheduler: Job 144 finished: collect at arrowconverters.scala:270, took 0.137296 s
20/02/14 14:17:03 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 14:17:03 INFO DAGScheduler: Got job 145 (collect at utils.scala:41) with 4 output partitions
20/02/14 14:17:03 INFO DAGScheduler: Final stage: ResultStage 263 (collect at utils.scala:41)
20/02/14 14:17:03 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:17:03 INFO DAGScheduler: Missing parents: List()
20/02/14 14:17:03 INFO DAGScheduler: Submitting ResultStage 263 (MapPartitionsRDD[1487] at map at utils.scala:41), which has no missing parents
20/02/14 14:17:03 INFO MemoryStore: Block broadcast_263 stored as values in memory (estimated size 8.8 KiB, free 413.8 MiB)
20/02/14 14:17:03 INFO MemoryStore: Block broadcast_263_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.8 MiB)
20/02/14 14:17:03 INFO BlockManagerInfo: Added broadcast_263_piece0 in memory on 127.0.0.1:55441 (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 14:17:03 INFO SparkContext: Created broadcast 263 from broadcast at DAGScheduler.scala:1196
20/02/14 14:17:03 INFO BlockManagerInfo: Removed broadcast_262_piece0 on 127.0.0.1:55441 in memory (size: 23.1 KiB, free: 413.9 MiB)
20/02/14 14:17:03 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 263 (MapPartitionsRDD[1487] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 14:17:03 INFO TaskSchedulerImpl: Adding task set 263.0 with 4 tasks
20/02/14 14:17:03 INFO TaskSetManager: Starting task 0.0 in stage 263.0 (TID 356, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7858 bytes)
20/02/14 14:17:03 INFO TaskSetManager: Starting task 1.0 in stage 263.0 (TID 357, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7931 bytes)
20/02/14 14:17:03 INFO TaskSetManager: Starting task 2.0 in stage 263.0 (TID 358, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7874 bytes)
20/02/14 14:17:03 INFO TaskSetManager: Starting task 3.0 in stage 263.0 (TID 359, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7931 bytes)
20/02/14 14:17:03 INFO Executor: Running task 0.0 in stage 263.0 (TID 356)
20/02/14 14:17:03 INFO Executor: Running task 3.0 in stage 263.0 (TID 359)
20/02/14 14:17:03 INFO Executor: Running task 2.0 in stage 263.0 (TID 358)
20/02/14 14:17:03 INFO Executor: Running task 1.0 in stage 263.0 (TID 357)
20/02/14 14:17:03 INFO Executor: Finished task 2.0 in stage 263.0 (TID 358). 1227 bytes result sent to driver
20/02/14 14:17:03 INFO Executor: Finished task 1.0 in stage 263.0 (TID 357). 1253 bytes result sent to driver
20/02/14 14:17:03 INFO Executor: Finished task 3.0 in stage 263.0 (TID 359). 1253 bytes result sent to driver
20/02/14 14:17:03 INFO TaskSetManager: Finished task 2.0 in stage 263.0 (TID 358) in 8 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 14:17:03 INFO TaskSetManager: Finished task 1.0 in stage 263.0 (TID 357) in 9 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 14:17:03 INFO TaskSetManager: Finished task 3.0 in stage 263.0 (TID 359) in 8 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 14:17:03 INFO Executor: Finished task 0.0 in stage 263.0 (TID 356). 1166 bytes result sent to driver
20/02/14 14:17:03 INFO TaskSetManager: Finished task 0.0 in stage 263.0 (TID 356) in 12 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 14:17:03 INFO TaskSchedulerImpl: Removed TaskSet 263.0, whose tasks have all completed, from pool 
20/02/14 14:17:03 INFO DAGScheduler: ResultStage 263 (collect at utils.scala:41) finished in 0.022 s
20/02/14 14:17:03 INFO DAGScheduler: Job 145 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:17:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 263: Stage finished
20/02/14 14:17:03 INFO DAGScheduler: Job 145 finished: collect at utils.scala:41, took 0.025200 s
20/02/14 14:17:03 INFO BlockManagerInfo: Removed broadcast_263_piece0 on 127.0.0.1:55441 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 14:17:03 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/14 14:17:03 INFO DAGScheduler: Registering RDD 1496 (sql at <unknown>:0) as input to shuffle 118
20/02/14 14:17:03 INFO DAGScheduler: Got job 146 (sql at <unknown>:0) with 1 output partitions
20/02/14 14:17:03 INFO DAGScheduler: Final stage: ResultStage 265 (sql at <unknown>:0)
20/02/14 14:17:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 264)
20/02/14 14:17:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 264)
20/02/14 14:17:03 INFO DAGScheduler: Submitting ShuffleMapStage 264 (MapPartitionsRDD[1496] at sql at <unknown>:0), which has no missing parents
20/02/14 14:17:03 INFO MemoryStore: Block broadcast_264 stored as values in memory (estimated size 18.9 KiB, free 413.8 MiB)
20/02/14 14:17:03 INFO MemoryStore: Block broadcast_264_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.8 MiB)
20/02/14 14:17:03 INFO BlockManagerInfo: Added broadcast_264_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:17:03 INFO SparkContext: Created broadcast 264 from broadcast at DAGScheduler.scala:1196
20/02/14 14:17:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 264 (MapPartitionsRDD[1496] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:17:03 INFO TaskSchedulerImpl: Adding task set 264.0 with 1 tasks
20/02/14 14:17:03 INFO TaskSetManager: Starting task 0.0 in stage 264.0 (TID 360, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:17:03 INFO Executor: Running task 0.0 in stage 264.0 (TID 360)
20/02/14 14:17:03 INFO MemoryStore: Block rdd_1491_0 stored as values in memory (estimated size 312.0 B, free 413.8 MiB)
20/02/14 14:17:03 INFO BlockManagerInfo: Added rdd_1491_0 in memory on 127.0.0.1:55441 (size: 312.0 B, free: 413.9 MiB)
20/02/14 14:17:03 INFO Executor: Finished task 0.0 in stage 264.0 (TID 360). 2283 bytes result sent to driver
20/02/14 14:17:03 INFO TaskSetManager: Finished task 0.0 in stage 264.0 (TID 360) in 14 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:17:03 INFO TaskSchedulerImpl: Removed TaskSet 264.0, whose tasks have all completed, from pool 
20/02/14 14:17:03 INFO DAGScheduler: ShuffleMapStage 264 (sql at <unknown>:0) finished in 0.019 s
20/02/14 14:17:03 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:17:03 INFO DAGScheduler: running: Set()
20/02/14 14:17:03 INFO DAGScheduler: waiting: Set(ResultStage 265)
20/02/14 14:17:03 INFO DAGScheduler: failed: Set()
20/02/14 14:17:03 INFO DAGScheduler: Submitting ResultStage 265 (MapPartitionsRDD[1499] at sql at <unknown>:0), which has no missing parents
20/02/14 14:17:03 INFO MemoryStore: Block broadcast_265 stored as values in memory (estimated size 10.2 KiB, free 413.8 MiB)
20/02/14 14:17:03 INFO MemoryStore: Block broadcast_265_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
20/02/14 14:17:03 INFO BlockManagerInfo: Added broadcast_265_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:17:03 INFO SparkContext: Created broadcast 265 from broadcast at DAGScheduler.scala:1196
20/02/14 14:17:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 265 (MapPartitionsRDD[1499] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:17:03 INFO TaskSchedulerImpl: Adding task set 265.0 with 1 tasks
20/02/14 14:17:03 INFO TaskSetManager: Starting task 0.0 in stage 265.0 (TID 361, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:17:03 INFO Executor: Running task 0.0 in stage 265.0 (TID 361)
20/02/14 14:17:03 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:17:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:17:03 INFO Executor: Finished task 0.0 in stage 265.0 (TID 361). 2803 bytes result sent to driver
20/02/14 14:17:03 INFO TaskSetManager: Finished task 0.0 in stage 265.0 (TID 361) in 4 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:17:03 INFO TaskSchedulerImpl: Removed TaskSet 265.0, whose tasks have all completed, from pool 
20/02/14 14:17:03 INFO DAGScheduler: ResultStage 265 (sql at <unknown>:0) finished in 0.009 s
20/02/14 14:17:03 INFO DAGScheduler: Job 146 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:17:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 265: Stage finished
20/02/14 14:17:03 INFO DAGScheduler: Job 146 finished: sql at <unknown>:0, took 0.032125 s
20/02/14 14:17:03 INFO BlockManagerInfo: Removed broadcast_265_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 14:17:03 INFO BlockManagerInfo: Removed broadcast_264_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:17:03 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 14:17:03 INFO DAGScheduler: Registering RDD 1504 (collect at arrowconverters.scala:270) as input to shuffle 119
20/02/14 14:17:03 INFO DAGScheduler: Got job 147 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 14:17:03 INFO DAGScheduler: Final stage: ResultStage 267 (collect at arrowconverters.scala:270)
20/02/14 14:17:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 266)
20/02/14 14:17:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 266)
20/02/14 14:17:03 INFO DAGScheduler: Submitting ShuffleMapStage 266 (MapPartitionsRDD[1504] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:17:03 INFO MemoryStore: Block broadcast_266 stored as values in memory (estimated size 18.9 KiB, free 413.8 MiB)
20/02/14 14:17:03 INFO MemoryStore: Block broadcast_266_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.8 MiB)
20/02/14 14:17:03 INFO BlockManagerInfo: Added broadcast_266_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:17:03 INFO SparkContext: Created broadcast 266 from broadcast at DAGScheduler.scala:1196
20/02/14 14:17:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 266 (MapPartitionsRDD[1504] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:17:03 INFO TaskSchedulerImpl: Adding task set 266.0 with 1 tasks
20/02/14 14:17:03 INFO TaskSetManager: Starting task 0.0 in stage 266.0 (TID 362, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:17:03 INFO Executor: Running task 0.0 in stage 266.0 (TID 362)
20/02/14 14:17:03 INFO BlockManager: Found block rdd_1491_0 locally
20/02/14 14:17:03 INFO Executor: Finished task 0.0 in stage 266.0 (TID 362). 2369 bytes result sent to driver
20/02/14 14:17:03 INFO TaskSetManager: Finished task 0.0 in stage 266.0 (TID 362) in 11 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:17:03 INFO TaskSchedulerImpl: Removed TaskSet 266.0, whose tasks have all completed, from pool 
20/02/14 14:17:03 INFO DAGScheduler: ShuffleMapStage 266 (collect at arrowconverters.scala:270) finished in 0.015 s
20/02/14 14:17:03 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:17:03 INFO DAGScheduler: running: Set()
20/02/14 14:17:03 INFO DAGScheduler: waiting: Set(ResultStage 267)
20/02/14 14:17:03 INFO DAGScheduler: failed: Set()
20/02/14 14:17:03 INFO DAGScheduler: Submitting ResultStage 267 (MapPartitionsRDD[1510] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:17:03 INFO MemoryStore: Block broadcast_267 stored as values in memory (estimated size 28.9 KiB, free 413.8 MiB)
20/02/14 14:17:03 INFO MemoryStore: Block broadcast_267_piece0 stored as bytes in memory (estimated size 12.1 KiB, free 413.8 MiB)
20/02/14 14:17:03 INFO BlockManagerInfo: Added broadcast_267_piece0 in memory on 127.0.0.1:55441 (size: 12.1 KiB, free: 413.9 MiB)
20/02/14 14:17:03 INFO SparkContext: Created broadcast 267 from broadcast at DAGScheduler.scala:1196
20/02/14 14:17:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 267 (MapPartitionsRDD[1510] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:17:03 INFO TaskSchedulerImpl: Adding task set 267.0 with 1 tasks
20/02/14 14:17:03 INFO TaskSetManager: Starting task 0.0 in stage 267.0 (TID 363, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 14:17:03 INFO Executor: Running task 0.0 in stage 267.0 (TID 363)
20/02/14 14:17:03 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:17:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:17:03 INFO Executor: Finished task 0.0 in stage 267.0 (TID 363). 4242 bytes result sent to driver
20/02/14 14:17:03 INFO TaskSetManager: Finished task 0.0 in stage 267.0 (TID 363) in 9 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:17:03 INFO TaskSchedulerImpl: Removed TaskSet 267.0, whose tasks have all completed, from pool 
20/02/14 14:17:03 INFO DAGScheduler: ResultStage 267 (collect at arrowconverters.scala:270) finished in 0.020 s
20/02/14 14:17:03 INFO DAGScheduler: Job 147 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:17:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 267: Stage finished
20/02/14 14:17:03 INFO DAGScheduler: Job 147 finished: collect at arrowconverters.scala:270, took 0.040077 s
20/02/14 14:17:03 INFO Instrumentation: [5b5b0c52] training finished
20/02/14 14:17:03 INFO Instrumentation: [1aef4762] training finished
20/02/14 14:17:04 INFO BlockManagerInfo: Removed broadcast_266_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 14:17:04 INFO BlockManagerInfo: Removed broadcast_267_piece0 on 127.0.0.1:55441 in memory (size: 12.1 KiB, free: 413.9 MiB)
20/02/14 14:17:04 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 14:17:04 INFO DAGScheduler: Registering RDD 1522 (collect at arrowconverters.scala:270) as input to shuffle 121
20/02/14 14:17:04 INFO DAGScheduler: Registering RDD 1515 (collect at arrowconverters.scala:270) as input to shuffle 120
20/02/14 14:17:04 INFO DAGScheduler: Got job 148 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/14 14:17:04 INFO DAGScheduler: Final stage: ResultStage 270 (collect at arrowconverters.scala:270)
20/02/14 14:17:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 269, ShuffleMapStage 268)
20/02/14 14:17:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 269, ShuffleMapStage 268)
20/02/14 14:17:04 INFO DAGScheduler: Submitting ShuffleMapStage 268 (MapPartitionsRDD[1522] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:17:04 INFO MemoryStore: Block broadcast_268 stored as values in memory (estimated size 27.4 KiB, free 413.8 MiB)
20/02/14 14:17:04 INFO MemoryStore: Block broadcast_268_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.8 MiB)
20/02/14 14:17:04 INFO BlockManagerInfo: Added broadcast_268_piece0 in memory on 127.0.0.1:55441 (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 14:17:04 INFO SparkContext: Created broadcast 268 from broadcast at DAGScheduler.scala:1196
20/02/14 14:17:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 268 (MapPartitionsRDD[1522] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:17:04 INFO TaskSchedulerImpl: Adding task set 268.0 with 1 tasks
20/02/14 14:17:04 INFO DAGScheduler: Submitting ShuffleMapStage 269 (MapPartitionsRDD[1515] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:17:04 INFO TaskSetManager: Starting task 0.0 in stage 268.0 (TID 364, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 14:17:04 INFO Executor: Running task 0.0 in stage 268.0 (TID 364)
20/02/14 14:17:04 INFO MemoryStore: Block broadcast_269 stored as values in memory (estimated size 32.1 KiB, free 413.8 MiB)
20/02/14 14:17:04 INFO MemoryStore: Block broadcast_269_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 413.8 MiB)
20/02/14 14:17:04 INFO BlockManagerInfo: Added broadcast_269_piece0 in memory on 127.0.0.1:55441 (size: 13.5 KiB, free: 413.9 MiB)
20/02/14 14:17:04 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:17:04 INFO SparkContext: Created broadcast 269 from broadcast at DAGScheduler.scala:1196
20/02/14 14:17:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 269 (MapPartitionsRDD[1515] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 14:17:04 INFO TaskSchedulerImpl: Adding task set 269.0 with 1 tasks
20/02/14 14:17:04 INFO TaskSetManager: Starting task 0.0 in stage 269.0 (TID 365, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 14:17:04 INFO Executor: Running task 0.0 in stage 269.0 (TID 365)
20/02/14 14:17:04 INFO BlockManager: Found block rdd_1491_0 locally
20/02/14 14:17:04 INFO Executor: Finished task 0.0 in stage 268.0 (TID 364). 2160 bytes result sent to driver
20/02/14 14:17:04 INFO TaskSetManager: Finished task 0.0 in stage 268.0 (TID 364) in 26 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:17:04 INFO TaskSchedulerImpl: Removed TaskSet 268.0, whose tasks have all completed, from pool 
20/02/14 14:17:04 INFO DAGScheduler: ShuffleMapStage 268 (collect at arrowconverters.scala:270) finished in 0.031 s
20/02/14 14:17:04 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:17:04 INFO DAGScheduler: running: Set(ShuffleMapStage 269)
20/02/14 14:17:04 INFO DAGScheduler: waiting: Set(ResultStage 270)
20/02/14 14:17:04 INFO DAGScheduler: failed: Set()
20/02/14 14:17:04 INFO Executor: Finished task 0.0 in stage 269.0 (TID 365). 2203 bytes result sent to driver
20/02/14 14:17:04 INFO TaskSetManager: Finished task 0.0 in stage 269.0 (TID 365) in 49 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 14:17:04 INFO TaskSchedulerImpl: Removed TaskSet 269.0, whose tasks have all completed, from pool 
20/02/14 14:17:04 INFO DAGScheduler: ShuffleMapStage 269 (collect at arrowconverters.scala:270) finished in 0.055 s
20/02/14 14:17:04 INFO DAGScheduler: looking for newly runnable stages
20/02/14 14:17:04 INFO DAGScheduler: running: Set()
20/02/14 14:17:04 INFO DAGScheduler: waiting: Set(ResultStage 270)
20/02/14 14:17:04 INFO DAGScheduler: failed: Set()
20/02/14 14:17:04 INFO DAGScheduler: Submitting ResultStage 270 (MapPartitionsRDD[1530] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 14:17:04 INFO MemoryStore: Block broadcast_270 stored as values in memory (estimated size 56.3 KiB, free 413.7 MiB)
20/02/14 14:17:04 INFO MemoryStore: Block broadcast_270_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 413.7 MiB)
20/02/14 14:17:04 INFO BlockManagerInfo: Added broadcast_270_piece0 in memory on 127.0.0.1:55441 (size: 23.0 KiB, free: 413.9 MiB)
20/02/14 14:17:04 INFO SparkContext: Created broadcast 270 from broadcast at DAGScheduler.scala:1196
20/02/14 14:17:04 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 270 (MapPartitionsRDD[1530] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 14:17:04 INFO TaskSchedulerImpl: Adding task set 270.0 with 4 tasks
20/02/14 14:17:04 INFO TaskSetManager: Starting task 0.0 in stage 270.0 (TID 366, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7528 bytes)
20/02/14 14:17:04 INFO TaskSetManager: Starting task 1.0 in stage 270.0 (TID 367, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7528 bytes)
20/02/14 14:17:04 INFO TaskSetManager: Starting task 2.0 in stage 270.0 (TID 368, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7528 bytes)
20/02/14 14:17:04 INFO TaskSetManager: Starting task 3.0 in stage 270.0 (TID 369, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7528 bytes)
20/02/14 14:17:04 INFO Executor: Running task 2.0 in stage 270.0 (TID 368)
20/02/14 14:17:04 INFO Executor: Running task 3.0 in stage 270.0 (TID 369)
20/02/14 14:17:04 INFO Executor: Running task 1.0 in stage 270.0 (TID 367)
20/02/14 14:17:04 INFO Executor: Running task 0.0 in stage 270.0 (TID 366)
20/02/14 14:17:04 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:17:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:17:04 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:17:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:17:04 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:17:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 14:17:04 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:17:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:17:04 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:17:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:17:04 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:17:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:17:04 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:17:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:17:04 INFO ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 14:17:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 14:17:04 INFO BlockManagerInfo: Removed broadcast_269_piece0 on 127.0.0.1:55441 in memory (size: 13.5 KiB, free: 413.9 MiB)
20/02/14 14:17:04 INFO Executor: Finished task 0.0 in stage 270.0 (TID 366). 5857 bytes result sent to driver
20/02/14 14:17:04 INFO TaskSetManager: Finished task 0.0 in stage 270.0 (TID 366) in 55 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 14:17:04 INFO Executor: Finished task 1.0 in stage 270.0 (TID 367). 5833 bytes result sent to driver
20/02/14 14:17:04 INFO TaskSetManager: Finished task 1.0 in stage 270.0 (TID 367) in 55 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 14:17:04 INFO BlockManagerInfo: Removed broadcast_268_piece0 on 127.0.0.1:55441 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 14:17:04 INFO Executor: Finished task 2.0 in stage 270.0 (TID 368). 5909 bytes result sent to driver
20/02/14 14:17:04 INFO TaskSetManager: Finished task 2.0 in stage 270.0 (TID 368) in 57 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 14:17:04 INFO Executor: Finished task 3.0 in stage 270.0 (TID 369). 5807 bytes result sent to driver
20/02/14 14:17:04 INFO TaskSetManager: Finished task 3.0 in stage 270.0 (TID 369) in 61 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 14:17:04 INFO TaskSchedulerImpl: Removed TaskSet 270.0, whose tasks have all completed, from pool 
20/02/14 14:17:04 INFO DAGScheduler: ResultStage 270 (collect at arrowconverters.scala:270) finished in 0.068 s
20/02/14 14:17:04 INFO DAGScheduler: Job 148 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 14:17:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 270: Stage finished
20/02/14 14:17:04 INFO DAGScheduler: Job 148 finished: collect at arrowconverters.scala:270, took 0.133827 s
20/02/14 14:32:57 INFO BlockManagerInfo: Removed broadcast_270_piece0 on 127.0.0.1:55441 in memory (size: 23.0 KiB, free: 413.9 MiB)
20/02/14 14:32:57 INFO BlockManagerInfo: Removed broadcast_221_piece0 on 127.0.0.1:55441 in memory (size: 22.1 KiB, free: 413.9 MiB)
20/02/14 14:43:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
20/02/14 14:43:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/02/14 14:43:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
20/02/14 14:43:46 INFO CodeGenerator: Code generated in 33.8705 ms
20/02/14 14:43:46 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/14 14:43:46 INFO DAGScheduler: Got job 149 (csv at <unknown>:0) with 1 output partitions
20/02/14 14:43:46 INFO DAGScheduler: Final stage: ResultStage 271 (csv at <unknown>:0)
20/02/14 14:43:46 INFO DAGScheduler: Parents of final stage: List()
20/02/14 14:43:46 INFO DAGScheduler: Missing parents: List()
20/02/14 14:43:46 INFO DAGScheduler: Submitting ResultStage 271 (MapPartitionsRDD[1534] at csv at <unknown>:0), which has no missing parents
20/02/14 14:43:46 INFO MemoryStore: Block broadcast_271 stored as values in memory (estimated size 196.6 KiB, free 413.7 MiB)
20/02/14 14:43:46 INFO MemoryStore: Block broadcast_271_piece0 stored as bytes in memory (estimated size 68.8 KiB, free 413.7 MiB)
20/02/14 14:43:46 INFO BlockManagerInfo: Added broadcast_271_piece0 in memory on 127.0.0.1:55441 (size: 68.8 KiB, free: 413.9 MiB)
20/02/14 14:43:46 INFO SparkContext: Created broadcast 271 from broadcast at DAGScheduler.scala:1196
20/02/14 14:43:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 271 (MapPartitionsRDD[1534] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 14:43:46 INFO TaskSchedulerImpl: Adding task set 271.0 with 1 tasks
20/02/14 14:43:46 INFO TaskSetManager: Starting task 0.0 in stage 271.0 (TID 370, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 14:43:46 INFO Executor: Running task 0.0 in stage 271.0 (TID 370)
20/02/14 14:43:46 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 14:43:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
20/02/14 14:43:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/02/14 14:43:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
20/02/14 14:43:47 ERROR Utils: Aborting task
java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
20/02/14 14:43:47 ERROR FileFormatWriter: Job job_20200214144346_0271 aborted.
20/02/14 14:43:47 ERROR Executor: Exception in task 0.0 in stage 271.0 (TID 370)
org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more
20/02/14 14:43:47 WARN TaskSetManager: Lost task 0.0 in stage 271.0 (TID 370, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more

20/02/14 14:43:47 ERROR TaskSetManager: Task 0 in stage 271.0 failed 1 times; aborting job
20/02/14 14:43:47 INFO TaskSchedulerImpl: Removed TaskSet 271.0, whose tasks have all completed, from pool 
20/02/14 14:43:47 INFO TaskSchedulerImpl: Cancelling stage 271
20/02/14 14:43:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 271: Stage cancelled
20/02/14 14:43:47 INFO DAGScheduler: ResultStage 271 (csv at <unknown>:0) failed in 0.810 s due to Job aborted due to stage failure: Task 0 in stage 271.0 failed 1 times, most recent failure: Lost task 0.0 in stage 271.0 (TID 370, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more

Driver stacktrace:
20/02/14 14:43:47 INFO DAGScheduler: Job 149 failed: csv at <unknown>:0, took 0.814354 s
20/02/14 14:43:47 ERROR FileFormatWriter: Aborting job a88951d8-8da0-4b0f-977a-99e3f25642ca.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 271.0 failed 1 times, most recent failure: Lost task 0.0 in stage 271.0 (TID 370, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:1979)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1967)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1966)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1966)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:946)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:946)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:946)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2196)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2145)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2134)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:748)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2095)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:195)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:175)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:105)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:103)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:124)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:189)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:227)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:224)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:185)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:110)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:109)
	at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:829)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$4(SQLExecution.scala:100)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:87)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:829)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:309)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:236)
	at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:819)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at sparklyr.Invoke.invoke(invoke.scala:147)
	at sparklyr.StreamHandler.handleMethodCall(stream.scala:122)
	at sparklyr.StreamHandler.read(stream.scala:65)
	at sparklyr.BackendHandler.channelRead0(handler.scala:53)
	at sparklyr.BackendHandler.channelRead0(handler.scala:12)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:328)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:302)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1422)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:931)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:700)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:635)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:552)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:514)
	at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1044)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	... 1 more
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more
20/02/14 14:44:12 INFO BlockManagerInfo: Removed broadcast_271_piece0 on 127.0.0.1:55441 in memory (size: 68.8 KiB, free: 413.9 MiB)
20/02/14 15:05:15 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 15:05:15 INFO DAGScheduler: Got job 150 (collect at utils.scala:41) with 4 output partitions
20/02/14 15:05:15 INFO DAGScheduler: Final stage: ResultStage 272 (collect at utils.scala:41)
20/02/14 15:05:15 INFO DAGScheduler: Parents of final stage: List()
20/02/14 15:05:15 INFO DAGScheduler: Missing parents: List()
20/02/14 15:05:15 INFO DAGScheduler: Submitting ResultStage 272 (MapPartitionsRDD[1540] at map at utils.scala:41), which has no missing parents
20/02/14 15:05:15 INFO MemoryStore: Block broadcast_272 stored as values in memory (estimated size 8.8 KiB, free 413.9 MiB)
20/02/14 15:05:15 INFO MemoryStore: Block broadcast_272_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.9 MiB)
20/02/14 15:05:15 INFO BlockManagerInfo: Added broadcast_272_piece0 in memory on 127.0.0.1:55441 (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 15:05:15 INFO SparkContext: Created broadcast 272 from broadcast at DAGScheduler.scala:1196
20/02/14 15:05:15 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 272 (MapPartitionsRDD[1540] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 15:05:15 INFO TaskSchedulerImpl: Adding task set 272.0 with 4 tasks
20/02/14 15:05:15 INFO TaskSetManager: Starting task 0.0 in stage 272.0 (TID 371, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7923 bytes)
20/02/14 15:05:15 INFO TaskSetManager: Starting task 1.0 in stage 272.0 (TID 372, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7931 bytes)
20/02/14 15:05:15 INFO TaskSetManager: Starting task 2.0 in stage 272.0 (TID 373, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7939 bytes)
20/02/14 15:05:15 INFO TaskSetManager: Starting task 3.0 in stage 272.0 (TID 374, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7923 bytes)
20/02/14 15:05:15 INFO Executor: Running task 2.0 in stage 272.0 (TID 373)
20/02/14 15:05:15 INFO Executor: Running task 0.0 in stage 272.0 (TID 371)
20/02/14 15:05:15 INFO Executor: Running task 1.0 in stage 272.0 (TID 372)
20/02/14 15:05:15 INFO Executor: Running task 3.0 in stage 272.0 (TID 374)
20/02/14 15:05:15 INFO Executor: Finished task 1.0 in stage 272.0 (TID 372). 1253 bytes result sent to driver
20/02/14 15:05:15 INFO Executor: Finished task 2.0 in stage 272.0 (TID 373). 1255 bytes result sent to driver
20/02/14 15:05:15 INFO Executor: Finished task 3.0 in stage 272.0 (TID 374). 1209 bytes result sent to driver
20/02/14 15:05:15 INFO Executor: Finished task 0.0 in stage 272.0 (TID 371). 1237 bytes result sent to driver
20/02/14 15:05:15 INFO TaskSetManager: Finished task 1.0 in stage 272.0 (TID 372) in 14 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 15:05:15 INFO TaskSetManager: Finished task 3.0 in stage 272.0 (TID 374) in 14 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 15:05:15 INFO TaskSetManager: Finished task 2.0 in stage 272.0 (TID 373) in 15 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 15:05:15 INFO TaskSetManager: Finished task 0.0 in stage 272.0 (TID 371) in 17 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 15:05:15 INFO TaskSchedulerImpl: Removed TaskSet 272.0, whose tasks have all completed, from pool 
20/02/14 15:05:15 INFO DAGScheduler: ResultStage 272 (collect at utils.scala:41) finished in 0.025 s
20/02/14 15:05:15 INFO DAGScheduler: Job 150 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 15:05:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 272: Stage finished
20/02/14 15:05:15 INFO DAGScheduler: Job 150 finished: collect at utils.scala:41, took 0.029383 s
20/02/14 15:05:15 INFO BlockManagerInfo: Removed broadcast_272_piece0 on 127.0.0.1:55441 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 15:05:15 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/14 15:05:15 INFO DAGScheduler: Registering RDD 1549 (sql at <unknown>:0) as input to shuffle 122
20/02/14 15:05:15 INFO DAGScheduler: Got job 151 (sql at <unknown>:0) with 1 output partitions
20/02/14 15:05:15 INFO DAGScheduler: Final stage: ResultStage 274 (sql at <unknown>:0)
20/02/14 15:05:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 273)
20/02/14 15:05:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 273)
20/02/14 15:05:15 INFO DAGScheduler: Submitting ShuffleMapStage 273 (MapPartitionsRDD[1549] at sql at <unknown>:0), which has no missing parents
20/02/14 15:05:15 INFO MemoryStore: Block broadcast_273 stored as values in memory (estimated size 18.9 KiB, free 413.9 MiB)
20/02/14 15:05:15 INFO MemoryStore: Block broadcast_273_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.9 MiB)
20/02/14 15:05:15 INFO BlockManagerInfo: Added broadcast_273_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 15:05:15 INFO SparkContext: Created broadcast 273 from broadcast at DAGScheduler.scala:1196
20/02/14 15:05:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 273 (MapPartitionsRDD[1549] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 15:05:15 INFO TaskSchedulerImpl: Adding task set 273.0 with 1 tasks
20/02/14 15:05:15 INFO TaskSetManager: Starting task 0.0 in stage 273.0 (TID 375, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 15:05:15 INFO Executor: Running task 0.0 in stage 273.0 (TID 375)
20/02/14 15:05:15 INFO MemoryStore: Block rdd_1544_0 stored as values in memory (estimated size 312.0 B, free 413.9 MiB)
20/02/14 15:05:15 INFO BlockManagerInfo: Added rdd_1544_0 in memory on 127.0.0.1:55441 (size: 312.0 B, free: 413.9 MiB)
20/02/14 15:05:15 INFO Executor: Finished task 0.0 in stage 273.0 (TID 375). 2283 bytes result sent to driver
20/02/14 15:05:15 INFO TaskSetManager: Finished task 0.0 in stage 273.0 (TID 375) in 23 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 15:05:15 INFO TaskSchedulerImpl: Removed TaskSet 273.0, whose tasks have all completed, from pool 
20/02/14 15:05:15 INFO DAGScheduler: ShuffleMapStage 273 (sql at <unknown>:0) finished in 0.031 s
20/02/14 15:05:15 INFO DAGScheduler: looking for newly runnable stages
20/02/14 15:05:15 INFO DAGScheduler: running: Set()
20/02/14 15:05:15 INFO DAGScheduler: waiting: Set(ResultStage 274)
20/02/14 15:05:15 INFO DAGScheduler: failed: Set()
20/02/14 15:05:15 INFO DAGScheduler: Submitting ResultStage 274 (MapPartitionsRDD[1552] at sql at <unknown>:0), which has no missing parents
20/02/14 15:05:15 INFO MemoryStore: Block broadcast_274 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/14 15:05:15 INFO MemoryStore: Block broadcast_274_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
20/02/14 15:05:15 INFO BlockManagerInfo: Added broadcast_274_piece0 in memory on 127.0.0.1:55441 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 15:05:15 INFO SparkContext: Created broadcast 274 from broadcast at DAGScheduler.scala:1196
20/02/14 15:05:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 274 (MapPartitionsRDD[1552] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 15:05:15 INFO TaskSchedulerImpl: Adding task set 274.0 with 1 tasks
20/02/14 15:05:15 INFO TaskSetManager: Starting task 0.0 in stage 274.0 (TID 376, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 15:05:15 INFO Executor: Running task 0.0 in stage 274.0 (TID 376)
20/02/14 15:05:15 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 15:05:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 15:05:15 INFO Executor: Finished task 0.0 in stage 274.0 (TID 376). 2760 bytes result sent to driver
20/02/14 15:05:15 INFO TaskSetManager: Finished task 0.0 in stage 274.0 (TID 376) in 7 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 15:05:15 INFO TaskSchedulerImpl: Removed TaskSet 274.0, whose tasks have all completed, from pool 
20/02/14 15:05:15 INFO DAGScheduler: ResultStage 274 (sql at <unknown>:0) finished in 0.014 s
20/02/14 15:05:15 INFO DAGScheduler: Job 151 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 15:05:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 274: Stage finished
20/02/14 15:05:15 INFO DAGScheduler: Job 151 finished: sql at <unknown>:0, took 0.052223 s
20/02/14 15:05:15 INFO BlockManagerInfo: Removed broadcast_274_piece0 on 127.0.0.1:55441 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 15:05:15 INFO BlockManagerInfo: Removed broadcast_273_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 15:05:15 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 15:05:15 INFO DAGScheduler: Registering RDD 1557 (collect at arrowconverters.scala:270) as input to shuffle 123
20/02/14 15:05:15 INFO DAGScheduler: Got job 152 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 15:05:15 INFO DAGScheduler: Final stage: ResultStage 276 (collect at arrowconverters.scala:270)
20/02/14 15:05:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 275)
20/02/14 15:05:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 275)
20/02/14 15:05:15 INFO DAGScheduler: Submitting ShuffleMapStage 275 (MapPartitionsRDD[1557] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 15:05:15 INFO MemoryStore: Block broadcast_275 stored as values in memory (estimated size 18.9 KiB, free 413.9 MiB)
20/02/14 15:05:15 INFO MemoryStore: Block broadcast_275_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.9 MiB)
20/02/14 15:05:15 INFO BlockManagerInfo: Added broadcast_275_piece0 in memory on 127.0.0.1:55441 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 15:05:15 INFO SparkContext: Created broadcast 275 from broadcast at DAGScheduler.scala:1196
20/02/14 15:05:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 275 (MapPartitionsRDD[1557] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 15:05:15 INFO TaskSchedulerImpl: Adding task set 275.0 with 1 tasks
20/02/14 15:05:15 INFO TaskSetManager: Starting task 0.0 in stage 275.0 (TID 377, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 15:05:15 INFO Executor: Running task 0.0 in stage 275.0 (TID 377)
20/02/14 15:05:15 INFO BlockManager: Found block rdd_1544_0 locally
20/02/14 15:05:15 INFO Executor: Finished task 0.0 in stage 275.0 (TID 377). 2369 bytes result sent to driver
20/02/14 15:05:15 INFO TaskSetManager: Finished task 0.0 in stage 275.0 (TID 377) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 15:05:15 INFO TaskSchedulerImpl: Removed TaskSet 275.0, whose tasks have all completed, from pool 
20/02/14 15:05:15 INFO DAGScheduler: ShuffleMapStage 275 (collect at arrowconverters.scala:270) finished in 0.026 s
20/02/14 15:05:15 INFO DAGScheduler: looking for newly runnable stages
20/02/14 15:05:15 INFO DAGScheduler: running: Set()
20/02/14 15:05:15 INFO DAGScheduler: waiting: Set(ResultStage 276)
20/02/14 15:05:15 INFO DAGScheduler: failed: Set()
20/02/14 15:05:15 INFO DAGScheduler: Submitting ResultStage 276 (MapPartitionsRDD[1563] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 15:05:15 INFO MemoryStore: Block broadcast_276 stored as values in memory (estimated size 28.9 KiB, free 413.9 MiB)
20/02/14 15:05:15 INFO MemoryStore: Block broadcast_276_piece0 stored as bytes in memory (estimated size 12.1 KiB, free 413.9 MiB)
20/02/14 15:05:15 INFO BlockManagerInfo: Added broadcast_276_piece0 in memory on 127.0.0.1:55441 (size: 12.1 KiB, free: 413.9 MiB)
20/02/14 15:05:15 INFO SparkContext: Created broadcast 276 from broadcast at DAGScheduler.scala:1196
20/02/14 15:05:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 276 (MapPartitionsRDD[1563] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 15:05:15 INFO TaskSchedulerImpl: Adding task set 276.0 with 1 tasks
20/02/14 15:05:15 INFO TaskSetManager: Starting task 0.0 in stage 276.0 (TID 378, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 15:05:15 INFO Executor: Running task 0.0 in stage 276.0 (TID 378)
20/02/14 15:05:15 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 15:05:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 15:05:16 INFO BlockManagerInfo: Removed broadcast_275_piece0 on 127.0.0.1:55441 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 15:05:16 INFO Executor: Finished task 0.0 in stage 276.0 (TID 378). 4328 bytes result sent to driver
20/02/14 15:05:16 INFO TaskSetManager: Finished task 0.0 in stage 276.0 (TID 378) in 43 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 15:05:16 INFO TaskSchedulerImpl: Removed TaskSet 276.0, whose tasks have all completed, from pool 
20/02/14 15:05:16 INFO DAGScheduler: ResultStage 276 (collect at arrowconverters.scala:270) finished in 0.050 s
20/02/14 15:05:16 INFO DAGScheduler: Job 152 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 15:05:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 276: Stage finished
20/02/14 15:05:16 INFO DAGScheduler: Job 152 finished: collect at arrowconverters.scala:270, took 0.084993 s
20/02/14 15:05:16 INFO Instrumentation: [b73f7619] training finished
20/02/14 15:05:16 INFO Instrumentation: [1338b772] training finished
20/02/14 15:05:17 INFO BlockManagerInfo: Removed broadcast_276_piece0 on 127.0.0.1:55441 in memory (size: 12.1 KiB, free: 413.9 MiB)
20/02/14 15:05:17 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 15:05:17 INFO DAGScheduler: Registering RDD 1568 (collect at arrowconverters.scala:270) as input to shuffle 124
20/02/14 15:05:17 INFO DAGScheduler: Registering RDD 1575 (collect at arrowconverters.scala:270) as input to shuffle 125
20/02/14 15:05:17 INFO DAGScheduler: Got job 153 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/14 15:05:17 INFO DAGScheduler: Final stage: ResultStage 279 (collect at arrowconverters.scala:270)
20/02/14 15:05:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 277, ShuffleMapStage 278)
20/02/14 15:05:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 277, ShuffleMapStage 278)
20/02/14 15:05:17 INFO DAGScheduler: Submitting ShuffleMapStage 277 (MapPartitionsRDD[1568] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 15:05:17 INFO MemoryStore: Block broadcast_277 stored as values in memory (estimated size 32.1 KiB, free 413.9 MiB)
20/02/14 15:05:17 INFO MemoryStore: Block broadcast_277_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 413.9 MiB)
20/02/14 15:05:17 INFO BlockManagerInfo: Added broadcast_277_piece0 in memory on 127.0.0.1:55441 (size: 13.5 KiB, free: 413.9 MiB)
20/02/14 15:05:17 INFO SparkContext: Created broadcast 277 from broadcast at DAGScheduler.scala:1196
20/02/14 15:05:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 277 (MapPartitionsRDD[1568] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 15:05:17 INFO TaskSchedulerImpl: Adding task set 277.0 with 1 tasks
20/02/14 15:05:17 INFO DAGScheduler: Submitting ShuffleMapStage 278 (MapPartitionsRDD[1575] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 15:05:17 INFO TaskSetManager: Starting task 0.0 in stage 277.0 (TID 379, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 15:05:17 INFO MemoryStore: Block broadcast_278 stored as values in memory (estimated size 27.4 KiB, free 413.8 MiB)
20/02/14 15:05:17 INFO Executor: Running task 0.0 in stage 277.0 (TID 379)
20/02/14 15:05:17 INFO MemoryStore: Block broadcast_278_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.8 MiB)
20/02/14 15:05:17 INFO BlockManagerInfo: Added broadcast_278_piece0 in memory on 127.0.0.1:55441 (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 15:05:17 INFO SparkContext: Created broadcast 278 from broadcast at DAGScheduler.scala:1196
20/02/14 15:05:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 278 (MapPartitionsRDD[1575] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 15:05:17 INFO TaskSchedulerImpl: Adding task set 278.0 with 1 tasks
20/02/14 15:05:17 INFO TaskSetManager: Starting task 0.0 in stage 278.0 (TID 380, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 15:05:17 INFO Executor: Running task 0.0 in stage 278.0 (TID 380)
20/02/14 15:05:17 INFO BlockManager: Found block rdd_1544_0 locally
20/02/14 15:05:17 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 15:05:17 INFO Executor: Finished task 0.0 in stage 277.0 (TID 379). 2203 bytes result sent to driver
20/02/14 15:05:17 INFO TaskSetManager: Finished task 0.0 in stage 277.0 (TID 379) in 80 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 15:05:17 INFO TaskSchedulerImpl: Removed TaskSet 277.0, whose tasks have all completed, from pool 
20/02/14 15:05:17 INFO DAGScheduler: ShuffleMapStage 277 (collect at arrowconverters.scala:270) finished in 0.080 s
20/02/14 15:05:17 INFO DAGScheduler: looking for newly runnable stages
20/02/14 15:05:17 INFO DAGScheduler: running: Set(ShuffleMapStage 278)
20/02/14 15:05:17 INFO DAGScheduler: waiting: Set(ResultStage 279)
20/02/14 15:05:17 INFO DAGScheduler: failed: Set()
20/02/14 15:05:17 INFO Executor: Finished task 0.0 in stage 278.0 (TID 380). 2203 bytes result sent to driver
20/02/14 15:05:17 INFO TaskSetManager: Finished task 0.0 in stage 278.0 (TID 380) in 62 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 15:05:17 INFO TaskSchedulerImpl: Removed TaskSet 278.0, whose tasks have all completed, from pool 
20/02/14 15:05:17 INFO DAGScheduler: ShuffleMapStage 278 (collect at arrowconverters.scala:270) finished in 0.078 s
20/02/14 15:05:17 INFO DAGScheduler: looking for newly runnable stages
20/02/14 15:05:17 INFO DAGScheduler: running: Set()
20/02/14 15:05:17 INFO DAGScheduler: waiting: Set(ResultStage 279)
20/02/14 15:05:17 INFO DAGScheduler: failed: Set()
20/02/14 15:05:17 INFO DAGScheduler: Submitting ResultStage 279 (MapPartitionsRDD[1583] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 15:05:17 INFO MemoryStore: Block broadcast_279 stored as values in memory (estimated size 56.3 KiB, free 413.8 MiB)
20/02/14 15:05:17 INFO MemoryStore: Block broadcast_279_piece0 stored as bytes in memory (estimated size 23.1 KiB, free 413.8 MiB)
20/02/14 15:05:17 INFO BlockManagerInfo: Added broadcast_279_piece0 in memory on 127.0.0.1:55441 (size: 23.1 KiB, free: 413.9 MiB)
20/02/14 15:05:17 INFO SparkContext: Created broadcast 279 from broadcast at DAGScheduler.scala:1196
20/02/14 15:05:17 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 279 (MapPartitionsRDD[1583] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 15:05:17 INFO TaskSchedulerImpl: Adding task set 279.0 with 4 tasks
20/02/14 15:05:17 INFO TaskSetManager: Starting task 0.0 in stage 279.0 (TID 381, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7528 bytes)
20/02/14 15:05:17 INFO TaskSetManager: Starting task 1.0 in stage 279.0 (TID 382, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7528 bytes)
20/02/14 15:05:17 INFO TaskSetManager: Starting task 2.0 in stage 279.0 (TID 383, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7528 bytes)
20/02/14 15:05:17 INFO TaskSetManager: Starting task 3.0 in stage 279.0 (TID 384, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7528 bytes)
20/02/14 15:05:17 INFO Executor: Running task 1.0 in stage 279.0 (TID 382)
20/02/14 15:05:17 INFO Executor: Running task 2.0 in stage 279.0 (TID 383)
20/02/14 15:05:17 INFO Executor: Running task 3.0 in stage 279.0 (TID 384)
20/02/14 15:05:17 INFO Executor: Running task 0.0 in stage 279.0 (TID 381)
20/02/14 15:05:17 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 15:05:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 15:05:17 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 15:05:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 15:05:17 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 15:05:17 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 15:05:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 15:05:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 15:05:17 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 15:05:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 15:05:17 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 15:05:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 15:05:17 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 15:05:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 15:05:17 INFO ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 15:05:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 15:05:17 INFO Executor: Finished task 2.0 in stage 279.0 (TID 383). 5952 bytes result sent to driver
20/02/14 15:05:17 INFO TaskSetManager: Finished task 2.0 in stage 279.0 (TID 383) in 69 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 15:05:17 INFO Executor: Finished task 3.0 in stage 279.0 (TID 384). 5807 bytes result sent to driver
20/02/14 15:05:17 INFO TaskSetManager: Finished task 3.0 in stage 279.0 (TID 384) in 69 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 15:05:17 INFO BlockManagerInfo: Removed broadcast_277_piece0 on 127.0.0.1:55441 in memory (size: 13.5 KiB, free: 413.9 MiB)
20/02/14 15:05:17 INFO Executor: Finished task 0.0 in stage 279.0 (TID 381). 5814 bytes result sent to driver
20/02/14 15:05:17 INFO TaskSetManager: Finished task 0.0 in stage 279.0 (TID 381) in 69 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 15:05:17 INFO BlockManagerInfo: Removed broadcast_278_piece0 on 127.0.0.1:55441 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 15:05:17 INFO Executor: Finished task 1.0 in stage 279.0 (TID 382). 5833 bytes result sent to driver
20/02/14 15:05:17 INFO TaskSetManager: Finished task 1.0 in stage 279.0 (TID 382) in 84 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 15:05:17 INFO TaskSchedulerImpl: Removed TaskSet 279.0, whose tasks have all completed, from pool 
20/02/14 15:05:17 INFO DAGScheduler: ResultStage 279 (collect at arrowconverters.scala:270) finished in 0.100 s
20/02/14 15:05:17 INFO DAGScheduler: Job 153 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 15:05:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 279: Stage finished
20/02/14 15:05:17 INFO DAGScheduler: Job 153 finished: collect at arrowconverters.scala:270, took 0.205353 s
20/02/14 15:32:57 INFO BlockManagerInfo: Removed broadcast_279_piece0 on 127.0.0.1:55441 in memory (size: 23.1 KiB, free: 413.9 MiB)
20/02/14 16:30:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
20/02/14 16:30:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/02/14 16:30:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
20/02/14 16:30:07 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/14 16:30:07 INFO DAGScheduler: Got job 154 (csv at <unknown>:0) with 1 output partitions
20/02/14 16:30:07 INFO DAGScheduler: Final stage: ResultStage 280 (csv at <unknown>:0)
20/02/14 16:30:07 INFO DAGScheduler: Parents of final stage: List()
20/02/14 16:30:07 INFO DAGScheduler: Missing parents: List()
20/02/14 16:30:07 INFO DAGScheduler: Submitting ResultStage 280 (MapPartitionsRDD[1587] at csv at <unknown>:0), which has no missing parents
20/02/14 16:30:07 INFO MemoryStore: Block broadcast_280 stored as values in memory (estimated size 196.6 KiB, free 413.7 MiB)
20/02/14 16:30:07 INFO MemoryStore: Block broadcast_280_piece0 stored as bytes in memory (estimated size 68.8 KiB, free 413.7 MiB)
20/02/14 16:30:07 INFO BlockManagerInfo: Added broadcast_280_piece0 in memory on 127.0.0.1:55441 (size: 68.8 KiB, free: 413.9 MiB)
20/02/14 16:30:07 INFO SparkContext: Created broadcast 280 from broadcast at DAGScheduler.scala:1196
20/02/14 16:30:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 280 (MapPartitionsRDD[1587] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 16:30:07 INFO TaskSchedulerImpl: Adding task set 280.0 with 1 tasks
20/02/14 16:30:07 INFO TaskSetManager: Starting task 0.0 in stage 280.0 (TID 385, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 16:30:07 INFO Executor: Running task 0.0 in stage 280.0 (TID 385)
20/02/14 16:30:07 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 16:30:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
20/02/14 16:30:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/02/14 16:30:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
20/02/14 16:30:07 ERROR Utils: Aborting task
java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
20/02/14 16:30:07 ERROR FileFormatWriter: Job job_20200214163007_0280 aborted.
20/02/14 16:30:07 ERROR Executor: Exception in task 0.0 in stage 280.0 (TID 385)
org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more
20/02/14 16:30:07 WARN TaskSetManager: Lost task 0.0 in stage 280.0 (TID 385, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more

20/02/14 16:30:07 ERROR TaskSetManager: Task 0 in stage 280.0 failed 1 times; aborting job
20/02/14 16:30:07 INFO TaskSchedulerImpl: Removed TaskSet 280.0, whose tasks have all completed, from pool 
20/02/14 16:30:07 INFO TaskSchedulerImpl: Cancelling stage 280
20/02/14 16:30:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 280: Stage cancelled
20/02/14 16:30:07 INFO DAGScheduler: ResultStage 280 (csv at <unknown>:0) failed in 0.358 s due to Job aborted due to stage failure: Task 0 in stage 280.0 failed 1 times, most recent failure: Lost task 0.0 in stage 280.0 (TID 385, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more

Driver stacktrace:
20/02/14 16:30:07 INFO DAGScheduler: Job 154 failed: csv at <unknown>:0, took 0.363156 s
20/02/14 16:30:07 ERROR FileFormatWriter: Aborting job 51cecd50-ae82-458d-9ff3-5f0197b270d3.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 280.0 failed 1 times, most recent failure: Lost task 0.0 in stage 280.0 (TID 385, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:1979)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1967)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1966)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1966)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:946)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:946)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:946)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2196)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2145)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2134)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:748)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2095)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:195)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:175)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:105)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:103)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:124)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:189)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:227)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:224)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:185)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:110)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:109)
	at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:829)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$4(SQLExecution.scala:100)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:87)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:829)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:309)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:236)
	at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:819)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at sparklyr.Invoke.invoke(invoke.scala:147)
	at sparklyr.StreamHandler.handleMethodCall(stream.scala:122)
	at sparklyr.StreamHandler.read(stream.scala:65)
	at sparklyr.BackendHandler.channelRead0(handler.scala:53)
	at sparklyr.BackendHandler.channelRead0(handler.scala:12)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:328)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:302)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1422)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:931)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:700)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:635)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:552)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:514)
	at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1044)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	... 1 more
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more
20/02/14 16:30:07 INFO BlockManagerInfo: Removed broadcast_280_piece0 on 127.0.0.1:55441 in memory (size: 68.8 KiB, free: 413.9 MiB)
20/02/14 16:31:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
20/02/14 16:31:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/02/14 16:31:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
20/02/14 16:31:13 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/14 16:31:13 INFO DAGScheduler: Got job 155 (csv at <unknown>:0) with 1 output partitions
20/02/14 16:31:13 INFO DAGScheduler: Final stage: ResultStage 281 (csv at <unknown>:0)
20/02/14 16:31:13 INFO DAGScheduler: Parents of final stage: List()
20/02/14 16:31:13 INFO DAGScheduler: Missing parents: List()
20/02/14 16:31:13 INFO DAGScheduler: Submitting ResultStage 281 (MapPartitionsRDD[1591] at csv at <unknown>:0), which has no missing parents
20/02/14 16:31:13 INFO MemoryStore: Block broadcast_281 stored as values in memory (estimated size 196.6 KiB, free 413.7 MiB)
20/02/14 16:31:13 INFO MemoryStore: Block broadcast_281_piece0 stored as bytes in memory (estimated size 68.9 KiB, free 413.7 MiB)
20/02/14 16:31:13 INFO BlockManagerInfo: Added broadcast_281_piece0 in memory on 127.0.0.1:55441 (size: 68.9 KiB, free: 413.9 MiB)
20/02/14 16:31:13 INFO SparkContext: Created broadcast 281 from broadcast at DAGScheduler.scala:1196
20/02/14 16:31:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 281 (MapPartitionsRDD[1591] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 16:31:13 INFO TaskSchedulerImpl: Adding task set 281.0 with 1 tasks
20/02/14 16:31:13 INFO TaskSetManager: Starting task 0.0 in stage 281.0 (TID 386, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 16:31:13 INFO Executor: Running task 0.0 in stage 281.0 (TID 386)
20/02/14 16:31:13 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 16:31:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
20/02/14 16:31:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/02/14 16:31:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
20/02/14 16:31:13 ERROR Utils: Aborting task
java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
20/02/14 16:31:13 ERROR FileFormatWriter: Job job_20200214163113_0281 aborted.
20/02/14 16:31:13 ERROR Executor: Exception in task 0.0 in stage 281.0 (TID 386)
org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more
20/02/14 16:31:13 WARN TaskSetManager: Lost task 0.0 in stage 281.0 (TID 386, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more

20/02/14 16:31:13 ERROR TaskSetManager: Task 0 in stage 281.0 failed 1 times; aborting job
20/02/14 16:31:13 INFO TaskSchedulerImpl: Removed TaskSet 281.0, whose tasks have all completed, from pool 
20/02/14 16:31:13 INFO TaskSchedulerImpl: Cancelling stage 281
20/02/14 16:31:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 281: Stage cancelled
20/02/14 16:31:13 INFO DAGScheduler: ResultStage 281 (csv at <unknown>:0) failed in 0.228 s due to Job aborted due to stage failure: Task 0 in stage 281.0 failed 1 times, most recent failure: Lost task 0.0 in stage 281.0 (TID 386, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more

Driver stacktrace:
20/02/14 16:31:13 INFO DAGScheduler: Job 155 failed: csv at <unknown>:0, took 0.230911 s
20/02/14 16:31:13 ERROR FileFormatWriter: Aborting job bf7af72a-8661-413e-a361-1818ce74b81a.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 281.0 failed 1 times, most recent failure: Lost task 0.0 in stage 281.0 (TID 386, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:1979)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1967)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1966)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1966)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:946)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:946)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:946)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2196)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2145)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2134)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:748)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2095)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:195)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:175)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:105)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:103)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:124)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:189)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:227)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:224)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:185)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:110)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:109)
	at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:829)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$4(SQLExecution.scala:100)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:87)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:829)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:309)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:236)
	at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:819)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at sparklyr.Invoke.invoke(invoke.scala:147)
	at sparklyr.StreamHandler.handleMethodCall(stream.scala:122)
	at sparklyr.StreamHandler.read(stream.scala:65)
	at sparklyr.BackendHandler.channelRead0(handler.scala:53)
	at sparklyr.BackendHandler.channelRead0(handler.scala:12)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:328)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:302)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1422)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:931)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:700)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:635)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:552)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:514)
	at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1044)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	... 1 more
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more
20/02/14 16:31:26 INFO BlockManagerInfo: Removed broadcast_281_piece0 on 127.0.0.1:55441 in memory (size: 68.9 KiB, free: 413.9 MiB)
20/02/14 16:31:26 INFO CodeGenerator: Code generated in 16.374 ms
20/02/14 16:31:26 INFO CodeGenerator: Code generated in 19.7248 ms
20/02/14 16:31:26 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 16:31:26 INFO DAGScheduler: Registering RDD 1596 (collect at arrowconverters.scala:270) as input to shuffle 126
20/02/14 16:31:26 INFO DAGScheduler: Got job 156 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 16:31:26 INFO DAGScheduler: Final stage: ResultStage 283 (collect at arrowconverters.scala:270)
20/02/14 16:31:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 282)
20/02/14 16:31:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 282)
20/02/14 16:31:26 INFO DAGScheduler: Submitting ShuffleMapStage 282 (MapPartitionsRDD[1596] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 16:31:26 INFO MemoryStore: Block broadcast_282 stored as values in memory (estimated size 32.1 KiB, free 413.9 MiB)
20/02/14 16:31:26 INFO MemoryStore: Block broadcast_282_piece0 stored as bytes in memory (estimated size 11.4 KiB, free 413.9 MiB)
20/02/14 16:31:26 INFO BlockManagerInfo: Added broadcast_282_piece0 in memory on 127.0.0.1:55441 (size: 11.4 KiB, free: 413.9 MiB)
20/02/14 16:31:26 INFO SparkContext: Created broadcast 282 from broadcast at DAGScheduler.scala:1196
20/02/14 16:31:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 282 (MapPartitionsRDD[1596] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 16:31:26 INFO TaskSchedulerImpl: Adding task set 282.0 with 1 tasks
20/02/14 16:31:26 INFO TaskSetManager: Starting task 0.0 in stage 282.0 (TID 387, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 16:31:26 INFO Executor: Running task 0.0 in stage 282.0 (TID 387)
20/02/14 16:31:26 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 16:31:26 INFO Executor: 1 block locks were not released by TID = 387:
[rdd_901_0]
20/02/14 16:31:26 INFO Executor: Finished task 0.0 in stage 282.0 (TID 387). 2243 bytes result sent to driver
20/02/14 16:31:26 INFO TaskSetManager: Finished task 0.0 in stage 282.0 (TID 387) in 22 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 16:31:26 INFO TaskSchedulerImpl: Removed TaskSet 282.0, whose tasks have all completed, from pool 
20/02/14 16:31:26 INFO DAGScheduler: ShuffleMapStage 282 (collect at arrowconverters.scala:270) finished in 0.030 s
20/02/14 16:31:26 INFO DAGScheduler: looking for newly runnable stages
20/02/14 16:31:26 INFO DAGScheduler: running: Set()
20/02/14 16:31:26 INFO DAGScheduler: waiting: Set(ResultStage 283)
20/02/14 16:31:26 INFO DAGScheduler: failed: Set()
20/02/14 16:31:26 INFO DAGScheduler: Submitting ResultStage 283 (MapPartitionsRDD[1602] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 16:31:26 INFO MemoryStore: Block broadcast_283 stored as values in memory (estimated size 35.6 KiB, free 413.8 MiB)
20/02/14 16:31:26 INFO MemoryStore: Block broadcast_283_piece0 stored as bytes in memory (estimated size 14.1 KiB, free 413.8 MiB)
20/02/14 16:31:26 INFO BlockManagerInfo: Added broadcast_283_piece0 in memory on 127.0.0.1:55441 (size: 14.1 KiB, free: 413.9 MiB)
20/02/14 16:31:26 INFO SparkContext: Created broadcast 283 from broadcast at DAGScheduler.scala:1196
20/02/14 16:31:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 283 (MapPartitionsRDD[1602] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 16:31:26 INFO TaskSchedulerImpl: Adding task set 283.0 with 1 tasks
20/02/14 16:31:26 INFO TaskSetManager: Starting task 0.0 in stage 283.0 (TID 388, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 16:31:26 INFO Executor: Running task 0.0 in stage 283.0 (TID 388)
20/02/14 16:31:26 INFO ShuffleBlockFetcherIterator: Getting 1 (539.0 B) non-empty blocks including 1 (539.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 16:31:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 16:31:26 INFO CodeGenerator: Code generated in 19.1649 ms
20/02/14 16:31:26 INFO BlockManagerInfo: Removed broadcast_282_piece0 on 127.0.0.1:55441 in memory (size: 11.4 KiB, free: 413.9 MiB)
20/02/14 16:31:26 INFO CodeGenerator: Code generated in 56.717 ms
20/02/14 16:31:26 INFO Executor: Finished task 0.0 in stage 283.0 (TID 388). 3741 bytes result sent to driver
20/02/14 16:31:26 INFO TaskSetManager: Finished task 0.0 in stage 283.0 (TID 388) in 149 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 16:31:26 INFO TaskSchedulerImpl: Removed TaskSet 283.0, whose tasks have all completed, from pool 
20/02/14 16:31:26 INFO DAGScheduler: ResultStage 283 (collect at arrowconverters.scala:270) finished in 0.156 s
20/02/14 16:31:26 INFO DAGScheduler: Job 156 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 16:31:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 283: Stage finished
20/02/14 16:31:26 INFO DAGScheduler: Job 156 finished: collect at arrowconverters.scala:270, took 0.193628 s
20/02/14 16:31:45 INFO BlockManagerInfo: Removed broadcast_283_piece0 on 127.0.0.1:55441 in memory (size: 14.1 KiB, free: 413.9 MiB)
20/02/14 16:31:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
20/02/14 16:31:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/02/14 16:31:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
20/02/14 16:31:45 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/14 16:31:45 INFO DAGScheduler: Got job 157 (csv at <unknown>:0) with 1 output partitions
20/02/14 16:31:45 INFO DAGScheduler: Final stage: ResultStage 284 (csv at <unknown>:0)
20/02/14 16:31:45 INFO DAGScheduler: Parents of final stage: List()
20/02/14 16:31:45 INFO DAGScheduler: Missing parents: List()
20/02/14 16:31:45 INFO DAGScheduler: Submitting ResultStage 284 (MapPartitionsRDD[1606] at csv at <unknown>:0), which has no missing parents
20/02/14 16:31:45 INFO MemoryStore: Block broadcast_284 stored as values in memory (estimated size 196.6 KiB, free 413.7 MiB)
20/02/14 16:31:45 INFO MemoryStore: Block broadcast_284_piece0 stored as bytes in memory (estimated size 68.8 KiB, free 413.7 MiB)
20/02/14 16:31:45 INFO BlockManagerInfo: Added broadcast_284_piece0 in memory on 127.0.0.1:55441 (size: 68.8 KiB, free: 413.9 MiB)
20/02/14 16:31:45 INFO SparkContext: Created broadcast 284 from broadcast at DAGScheduler.scala:1196
20/02/14 16:31:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 284 (MapPartitionsRDD[1606] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 16:31:45 INFO TaskSchedulerImpl: Adding task set 284.0 with 1 tasks
20/02/14 16:31:45 INFO TaskSetManager: Starting task 0.0 in stage 284.0 (TID 389, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 16:31:45 INFO Executor: Running task 0.0 in stage 284.0 (TID 389)
20/02/14 16:31:46 INFO BlockManager: Found block rdd_901_0 locally
20/02/14 16:31:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
20/02/14 16:31:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/02/14 16:31:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
20/02/14 16:31:46 ERROR Utils: Aborting task
java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
20/02/14 16:31:46 ERROR FileFormatWriter: Job job_20200214163145_0284 aborted.
20/02/14 16:31:46 ERROR Executor: Exception in task 0.0 in stage 284.0 (TID 389)
org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more
20/02/14 16:31:46 WARN TaskSetManager: Lost task 0.0 in stage 284.0 (TID 389, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more

20/02/14 16:31:46 ERROR TaskSetManager: Task 0 in stage 284.0 failed 1 times; aborting job
20/02/14 16:31:46 INFO TaskSchedulerImpl: Removed TaskSet 284.0, whose tasks have all completed, from pool 
20/02/14 16:31:46 INFO TaskSchedulerImpl: Cancelling stage 284
20/02/14 16:31:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 284: Stage cancelled
20/02/14 16:31:46 INFO DAGScheduler: ResultStage 284 (csv at <unknown>:0) failed in 0.212 s due to Job aborted due to stage failure: Task 0 in stage 284.0 failed 1 times, most recent failure: Lost task 0.0 in stage 284.0 (TID 389, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more

Driver stacktrace:
20/02/14 16:31:46 INFO DAGScheduler: Job 157 failed: csv at <unknown>:0, took 0.216750 s
20/02/14 16:31:46 ERROR FileFormatWriter: Aborting job 15c420b4-6af8-4cb0-a0c9-8019ba052cdd.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 284.0 failed 1 times, most recent failure: Lost task 0.0 in stage 284.0 (TID 389, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:1979)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1967)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1966)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1966)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:946)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:946)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:946)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2196)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2145)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2134)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:748)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2095)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:195)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:175)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:105)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:103)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:124)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:189)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:227)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:224)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:185)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:110)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:109)
	at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:829)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$4(SQLExecution.scala:100)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:87)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:829)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:309)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:236)
	at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:819)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at sparklyr.Invoke.invoke(invoke.scala:147)
	at sparklyr.StreamHandler.handleMethodCall(stream.scala:122)
	at sparklyr.StreamHandler.read(stream.scala:65)
	at sparklyr.BackendHandler.channelRead0(handler.scala:53)
	at sparklyr.BackendHandler.channelRead0(handler.scala:12)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:328)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:302)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1422)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:931)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:700)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:635)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:552)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:514)
	at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1044)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	... 1 more
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more
20/02/14 16:32:57 INFO BlockManagerInfo: Removed broadcast_284_piece0 on 127.0.0.1:55441 in memory (size: 68.8 KiB, free: 413.9 MiB)
20/02/14 17:00:52 INFO SparkContext: Invoking stop() from shutdown hook
20/02/14 17:00:52 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
20/02/14 17:00:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/02/14 17:00:52 INFO MemoryStore: MemoryStore cleared
20/02/14 17:00:52 INFO BlockManager: BlockManager stopped
20/02/14 17:00:52 INFO BlockManagerMaster: BlockManagerMaster stopped
20/02/14 17:00:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/02/14 17:00:52 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-d59c381c-16f7-4df2-8f81-75bfc5d31040\userFiles-b5b0dfb7-308c-4a5d-a331-75486d6d5f97
java.io.IOException: Failed to delete: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-d59c381c-16f7-4df2-8f81-75bfc5d31040\userFiles-b5b0dfb7-308c-4a5d-a331-75486d6d5f97\sparklyr-3.0.0-preview-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext.$anonfun$stop$21(SparkContext.scala:2008)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2008)
	at org.apache.spark.SparkContext.$anonfun$new$33(SparkContext.scala:632)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1960)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
20/02/14 17:00:52 INFO SparkContext: Successfully stopped SparkContext
20/02/14 17:00:52 INFO ShutdownHookManager: Shutdown hook called
20/02/14 17:00:52 INFO ShutdownHookManager: Deleting directory C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-d59c381c-16f7-4df2-8f81-75bfc5d31040\userFiles-b5b0dfb7-308c-4a5d-a331-75486d6d5f97
20/02/14 17:00:52 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-d59c381c-16f7-4df2-8f81-75bfc5d31040\userFiles-b5b0dfb7-308c-4a5d-a331-75486d6d5f97
java.io.IOException: Failed to delete: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-d59c381c-16f7-4df2-8f81-75bfc5d31040\userFiles-b5b0dfb7-308c-4a5d-a331-75486d6d5f97\sparklyr-3.0.0-preview-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1960)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
20/02/14 17:00:52 INFO ShutdownHookManager: Deleting directory C:\Users\Gigabyte\AppData\Local\Temp\spark-faf7098d-ccaf-4925-96a2-6b6436915b65
20/02/14 17:00:52 INFO ShutdownHookManager: Deleting directory C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-d59c381c-16f7-4df2-8f81-75bfc5d31040
20/02/14 17:00:52 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-d59c381c-16f7-4df2-8f81-75bfc5d31040
java.io.IOException: Failed to delete: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-d59c381c-16f7-4df2-8f81-75bfc5d31040\userFiles-b5b0dfb7-308c-4a5d-a331-75486d6d5f97\sparklyr-3.0.0-preview-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1960)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
20/02/14 18:35:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/14 18:35:06 INFO SecurityManager: Changing view acls to: Gigabyte
20/02/14 18:35:06 INFO SecurityManager: Changing modify acls to: Gigabyte
20/02/14 18:35:06 INFO SecurityManager: Changing view acls groups to: 
20/02/14 18:35:06 INFO SecurityManager: Changing modify acls groups to: 
20/02/14 18:35:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Gigabyte); groups with view permissions: Set(); users  with modify permissions: Set(Gigabyte); groups with modify permissions: Set()
20/02/14 18:35:08 INFO SparkContext: Running Spark version 3.0.0-preview
20/02/14 18:35:08 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
20/02/14 18:35:08 INFO ResourceUtils: ==============================================================
20/02/14 18:35:08 INFO ResourceUtils: Resources for spark.driver:

20/02/14 18:35:08 INFO ResourceUtils: ==============================================================
20/02/14 18:35:08 INFO SparkContext: Submitted application: sparklyr
20/02/14 18:35:08 INFO SecurityManager: Changing view acls to: Gigabyte
20/02/14 18:35:08 INFO SecurityManager: Changing modify acls to: Gigabyte
20/02/14 18:35:08 INFO SecurityManager: Changing view acls groups to: 
20/02/14 18:35:08 INFO SecurityManager: Changing modify acls groups to: 
20/02/14 18:35:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Gigabyte); groups with view permissions: Set(); users  with modify permissions: Set(Gigabyte); groups with modify permissions: Set()
20/02/14 18:35:08 INFO Utils: Successfully started service 'sparkDriver' on port 64161.
20/02/14 18:35:09 INFO SparkEnv: Registering MapOutputTracker
20/02/14 18:35:09 INFO SparkEnv: Registering BlockManagerMaster
20/02/14 18:35:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/14 18:35:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/14 18:35:09 INFO DiskBlockManager: Created local directory at C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\blockmgr-45f7c3a8-1d67-4595-b84b-85a88e4b9edb
20/02/14 18:35:09 INFO MemoryStore: MemoryStore started with capacity 413.9 MiB
20/02/14 18:35:09 INFO SparkEnv: Registering OutputCommitCoordinator
20/02/14 18:35:09 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/local]. Please check your configured local directories.
20/02/14 18:35:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/02/14 18:35:09 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
20/02/14 18:35:09 INFO SparkContext: Added JAR file:/C:/Users/Gigabyte/Documents/R/win-library/3.6/sparklyr/java/sparklyr-3.0.0-preview-2.12.jar at spark://127.0.0.1:64161/jars/sparklyr-3.0.0-preview-2.12.jar with timestamp 1581685509750
20/02/14 18:35:09 INFO Executor: Starting executor ID driver on host 127.0.0.1
20/02/14 18:35:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64190.
20/02/14 18:35:09 INFO NettyBlockTransferService: Server created on 127.0.0.1:64190
20/02/14 18:35:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/14 18:35:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64190, None)
20/02/14 18:35:09 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:64190 with 413.9 MiB RAM, BlockManagerId(driver, 127.0.0.1, 64190, None)
20/02/14 18:35:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 64190, None)
20/02/14 18:35:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 64190, None)
20/02/14 18:35:11 INFO SharedState: loading hive config file: file:/C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/conf/hive-site.xml
20/02/14 18:35:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/hive').
20/02/14 18:35:11 INFO SharedState: Warehouse path is 'C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/hive'.
20/02/14 18:35:11 WARN SharedState: Not allowing to set spark.sql.warehouse.dir or hive.metastore.warehouse.dir in SparkSession's options, it should be set statically for cross-session usages
20/02/14 18:35:16 INFO CodeGenerator: Code generated in 241.4882 ms
20/02/14 18:35:17 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:35:17 INFO DAGScheduler: Got job 0 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 18:35:17 INFO DAGScheduler: Final stage: ResultStage 0 (collect at arrowconverters.scala:270)
20/02/14 18:35:17 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:35:17 INFO DAGScheduler: Missing parents: List()
20/02/14 18:35:17 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:35:17 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
20/02/14 18:35:17 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 11.1 KiB, free 413.9 MiB)
20/02/14 18:35:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
20/02/14 18:35:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:64190 (size: 5.2 KiB, free: 413.9 MiB)
20/02/14 18:35:17 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1196
20/02/14 18:35:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:35:17 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
20/02/14 18:35:17 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7374 bytes)
20/02/14 18:35:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/02/14 18:35:17 INFO Executor: Fetching spark://127.0.0.1:64161/jars/sparklyr-3.0.0-preview-2.12.jar with timestamp 1581685509750
20/02/14 18:35:17 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:64161 after 44 ms (0 ms spent in bootstraps)
20/02/14 18:35:17 INFO Utils: Fetching spark://127.0.0.1:64161/jars/sparklyr-3.0.0-preview-2.12.jar to C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-c371b7d1-f023-45c5-bcb5-0fe7985860de\userFiles-fb471d7b-10f9-4dfb-b674-1f49d2612d05\fetchFileTemp2405588170214466827.tmp
20/02/14 18:35:17 INFO Executor: Adding file:/C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/local/spark-c371b7d1-f023-45c5-bcb5-0fe7985860de/userFiles-fb471d7b-10f9-4dfb-b674-1f49d2612d05/sparklyr-3.0.0-preview-2.12.jar to class loader
20/02/14 18:35:17 INFO CodeGenerator: Code generated in 17.2566 ms
20/02/14 18:35:18 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1451 bytes result sent to driver
20/02/14 18:35:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 881 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:35:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/02/14 18:35:18 INFO DAGScheduler: ResultStage 0 (collect at arrowconverters.scala:270) finished in 1.137 s
20/02/14 18:35:18 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:35:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
20/02/14 18:35:18 INFO DAGScheduler: Job 0 finished: collect at arrowconverters.scala:270, took 1.205738 s
20/02/14 18:35:18 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:35:18 INFO DAGScheduler: Got job 1 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 18:35:18 INFO DAGScheduler: Final stage: ResultStage 1 (collect at arrowconverters.scala:270)
20/02/14 18:35:18 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:35:18 INFO DAGScheduler: Missing parents: List()
20/02/14 18:35:18 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[11] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:35:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.1 KiB, free 413.9 MiB)
20/02/14 18:35:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
20/02/14 18:35:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:64190 (size: 5.2 KiB, free: 413.9 MiB)
20/02/14 18:35:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1196
20/02/14 18:35:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:35:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
20/02/14 18:35:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7374 bytes)
20/02/14 18:35:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
20/02/14 18:35:18 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1365 bytes result sent to driver
20/02/14 18:35:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 22 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:35:18 INFO DAGScheduler: ResultStage 1 (collect at arrowconverters.scala:270) finished in 0.032 s
20/02/14 18:35:18 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:35:18 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/02/14 18:35:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
20/02/14 18:35:18 INFO DAGScheduler: Job 1 finished: collect at arrowconverters.scala:270, took 0.038747 s
20/02/14 18:35:20 WARN ProcfsMetricsGetter: Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
20/02/14 18:35:20 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:64190 in memory (size: 5.2 KiB, free: 413.9 MiB)
20/02/14 18:35:28 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:35:28 INFO DAGScheduler: Got job 2 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 18:35:28 INFO DAGScheduler: Final stage: ResultStage 2 (collect at arrowconverters.scala:270)
20/02/14 18:35:28 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:35:28 INFO DAGScheduler: Missing parents: List()
20/02/14 18:35:28 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:35:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 11.1 KiB, free 413.9 MiB)
20/02/14 18:35:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
20/02/14 18:35:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:64190 (size: 5.2 KiB, free: 413.9 MiB)
20/02/14 18:35:28 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1196
20/02/14 18:35:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:35:28 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
20/02/14 18:35:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7374 bytes)
20/02/14 18:35:28 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
20/02/14 18:35:28 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1365 bytes result sent to driver
20/02/14 18:35:28 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 25 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:35:28 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/02/14 18:35:28 INFO DAGScheduler: ResultStage 2 (collect at arrowconverters.scala:270) finished in 0.035 s
20/02/14 18:35:28 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:35:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
20/02/14 18:35:28 INFO DAGScheduler: Job 2 finished: collect at arrowconverters.scala:270, took 0.040515 s
20/02/14 18:35:28 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:64190 in memory (size: 5.2 KiB, free: 413.9 MiB)
20/02/14 18:35:29 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:35:29 INFO DAGScheduler: Got job 3 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 18:35:29 INFO DAGScheduler: Final stage: ResultStage 3 (collect at arrowconverters.scala:270)
20/02/14 18:35:29 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:35:29 INFO DAGScheduler: Missing parents: List()
20/02/14 18:35:29 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[23] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:35:29 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.1 KiB, free 413.9 MiB)
20/02/14 18:35:29 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
20/02/14 18:35:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:64190 (size: 5.2 KiB, free: 413.9 MiB)
20/02/14 18:35:29 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1196
20/02/14 18:35:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[23] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:35:29 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
20/02/14 18:35:29 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7374 bytes)
20/02/14 18:35:29 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
20/02/14 18:35:29 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1365 bytes result sent to driver
20/02/14 18:35:29 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 14 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:35:29 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
20/02/14 18:35:29 INFO DAGScheduler: ResultStage 3 (collect at arrowconverters.scala:270) finished in 0.022 s
20/02/14 18:35:29 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:35:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
20/02/14 18:35:29 INFO DAGScheduler: Job 3 finished: collect at arrowconverters.scala:270, took 0.027265 s
20/02/14 18:35:29 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:64190 in memory (size: 5.2 KiB, free: 413.9 MiB)
20/02/14 18:35:29 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:35:29 INFO DAGScheduler: Got job 4 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 18:35:29 INFO DAGScheduler: Final stage: ResultStage 4 (collect at arrowconverters.scala:270)
20/02/14 18:35:29 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:35:29 INFO DAGScheduler: Missing parents: List()
20/02/14 18:35:29 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[29] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:35:29 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 11.1 KiB, free 413.9 MiB)
20/02/14 18:35:29 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
20/02/14 18:35:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:64190 (size: 5.2 KiB, free: 413.9 MiB)
20/02/14 18:35:29 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1196
20/02/14 18:35:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[29] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:35:29 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
20/02/14 18:35:29 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7374 bytes)
20/02/14 18:35:29 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
20/02/14 18:35:29 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1322 bytes result sent to driver
20/02/14 18:35:29 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 12 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:35:29 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
20/02/14 18:35:29 INFO DAGScheduler: ResultStage 4 (collect at arrowconverters.scala:270) finished in 0.021 s
20/02/14 18:35:29 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:35:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
20/02/14 18:35:29 INFO DAGScheduler: Job 4 finished: collect at arrowconverters.scala:270, took 0.025900 s
20/02/14 18:35:29 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:64190 in memory (size: 5.2 KiB, free: 413.9 MiB)
20/02/14 18:35:29 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:35:29 INFO DAGScheduler: Got job 5 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 18:35:29 INFO DAGScheduler: Final stage: ResultStage 5 (collect at arrowconverters.scala:270)
20/02/14 18:35:29 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:35:29 INFO DAGScheduler: Missing parents: List()
20/02/14 18:35:29 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[35] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:35:29 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.1 KiB, free 413.9 MiB)
20/02/14 18:35:29 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
20/02/14 18:35:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:64190 (size: 5.2 KiB, free: 413.9 MiB)
20/02/14 18:35:29 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1196
20/02/14 18:35:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[35] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:35:29 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
20/02/14 18:35:29 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7374 bytes)
20/02/14 18:35:29 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
20/02/14 18:35:29 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1322 bytes result sent to driver
20/02/14 18:35:29 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 12 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:35:29 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
20/02/14 18:35:29 INFO DAGScheduler: ResultStage 5 (collect at arrowconverters.scala:270) finished in 0.018 s
20/02/14 18:35:29 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:35:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
20/02/14 18:35:29 INFO DAGScheduler: Job 5 finished: collect at arrowconverters.scala:270, took 0.022077 s
20/02/14 18:35:30 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:64190 in memory (size: 5.2 KiB, free: 413.9 MiB)
20/02/14 18:35:43 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 18:35:43 INFO DAGScheduler: Got job 6 (collect at utils.scala:41) with 1 output partitions
20/02/14 18:35:43 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:41)
20/02/14 18:35:43 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:35:43 INFO DAGScheduler: Missing parents: List()
20/02/14 18:35:43 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[41] at map at utils.scala:41), which has no missing parents
20/02/14 18:35:43 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.8 KiB, free 413.9 MiB)
20/02/14 18:35:43 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.9 MiB)
20/02/14 18:35:43 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:64190 (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 18:35:43 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1196
20/02/14 18:35:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[41] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
20/02/14 18:35:43 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
20/02/14 18:35:43 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7374 bytes)
20/02/14 18:35:43 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
20/02/14 18:35:43 INFO CodeGenerator: Code generated in 8.843 ms
20/02/14 18:35:43 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1103 bytes result sent to driver
20/02/14 18:35:43 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 77 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:35:43 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
20/02/14 18:35:43 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:41) finished in 0.083 s
20/02/14 18:35:43 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:35:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
20/02/14 18:35:43 INFO DAGScheduler: Job 6 finished: collect at utils.scala:41, took 0.086274 s
20/02/14 18:35:44 INFO CodeGenerator: Code generated in 12.7264 ms
20/02/14 18:35:44 INFO CodeGenerator: Code generated in 23.8179 ms
20/02/14 18:35:44 INFO CodeGenerator: Code generated in 14.836 ms
20/02/14 18:35:44 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/14 18:35:44 INFO DAGScheduler: Registering RDD 50 (sql at <unknown>:0) as input to shuffle 0
20/02/14 18:35:44 INFO DAGScheduler: Got job 7 (sql at <unknown>:0) with 1 output partitions
20/02/14 18:35:44 INFO DAGScheduler: Final stage: ResultStage 8 (sql at <unknown>:0)
20/02/14 18:35:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
20/02/14 18:35:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
20/02/14 18:35:44 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[50] at sql at <unknown>:0), which has no missing parents
20/02/14 18:35:44 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 26.8 KiB, free 413.9 MiB)
20/02/14 18:35:44 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.9 MiB)
20/02/14 18:35:44 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:64190 (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 18:35:44 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1196
20/02/14 18:35:44 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:64190 in memory (size: 5.2 KiB, free: 413.9 MiB)
20/02/14 18:35:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[50] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 18:35:44 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
20/02/14 18:35:44 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:64190 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 18:35:44 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 18:35:44 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
20/02/14 18:35:44 INFO MemoryStore: Block rdd_45_0 stored as values in memory (estimated size 3.9 KiB, free 413.9 MiB)
20/02/14 18:35:44 INFO BlockManagerInfo: Added rdd_45_0 in memory on 127.0.0.1:64190 (size: 3.9 KiB, free: 413.9 MiB)
20/02/14 18:35:44 INFO CodeGenerator: Code generated in 3.8813 ms
20/02/14 18:35:44 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2412 bytes result sent to driver
20/02/14 18:35:44 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 271 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:35:44 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
20/02/14 18:35:44 INFO DAGScheduler: ShuffleMapStage 7 (sql at <unknown>:0) finished in 0.365 s
20/02/14 18:35:44 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:35:44 INFO DAGScheduler: running: Set()
20/02/14 18:35:44 INFO DAGScheduler: waiting: Set(ResultStage 8)
20/02/14 18:35:44 INFO DAGScheduler: failed: Set()
20/02/14 18:35:44 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[53] at sql at <unknown>:0), which has no missing parents
20/02/14 18:35:44 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/14 18:35:44 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
20/02/14 18:35:44 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:64190 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 18:35:44 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1196
20/02/14 18:35:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[53] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 18:35:44 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
20/02/14 18:35:44 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 18:35:44 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
20/02/14 18:35:44 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:35:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
20/02/14 18:35:45 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2803 bytes result sent to driver
20/02/14 18:35:45 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 78 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:35:45 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
20/02/14 18:35:45 INFO DAGScheduler: ResultStage 8 (sql at <unknown>:0) finished in 0.091 s
20/02/14 18:35:45 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:35:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
20/02/14 18:35:45 INFO DAGScheduler: Job 7 finished: sql at <unknown>:0, took 0.490556 s
20/02/14 18:35:45 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:64190 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 18:35:45 INFO CodeGenerator: Code generated in 6.1227 ms
20/02/14 18:35:45 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:35:45 INFO DAGScheduler: Registering RDD 58 (collect at arrowconverters.scala:270) as input to shuffle 1
20/02/14 18:35:45 INFO DAGScheduler: Got job 8 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 18:35:45 INFO DAGScheduler: Final stage: ResultStage 10 (collect at arrowconverters.scala:270)
20/02/14 18:35:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
20/02/14 18:35:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
20/02/14 18:35:45 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[58] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:35:45 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 26.8 KiB, free 413.9 MiB)
20/02/14 18:35:45 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.8 MiB)
20/02/14 18:35:45 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:64190 (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 18:35:45 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1196
20/02/14 18:35:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[58] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:35:45 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
20/02/14 18:35:45 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 18:35:45 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
20/02/14 18:35:45 INFO BlockManager: Found block rdd_45_0 locally
20/02/14 18:35:45 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2326 bytes result sent to driver
20/02/14 18:35:45 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 14 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:35:45 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
20/02/14 18:35:45 INFO DAGScheduler: ShuffleMapStage 9 (collect at arrowconverters.scala:270) finished in 0.022 s
20/02/14 18:35:45 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:35:45 INFO DAGScheduler: running: Set()
20/02/14 18:35:45 INFO DAGScheduler: waiting: Set(ResultStage 10)
20/02/14 18:35:45 INFO DAGScheduler: failed: Set()
20/02/14 18:35:45 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[64] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:35:45 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 36.7 KiB, free 413.8 MiB)
20/02/14 18:35:45 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 413.8 MiB)
20/02/14 18:35:45 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:64190 (size: 15.5 KiB, free: 413.9 MiB)
20/02/14 18:35:45 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1196
20/02/14 18:35:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[64] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:35:45 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
20/02/14 18:35:45 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 18:35:45 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
20/02/14 18:35:45 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:35:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:35:45 INFO CodeGenerator: Code generated in 4.9517 ms
20/02/14 18:35:45 INFO CodeGenerator: Code generated in 16.8487 ms
20/02/14 18:35:45 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 4286 bytes result sent to driver
20/02/14 18:35:45 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 47 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:35:45 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
20/02/14 18:35:45 INFO DAGScheduler: ResultStage 10 (collect at arrowconverters.scala:270) finished in 0.055 s
20/02/14 18:35:45 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:35:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
20/02/14 18:35:45 INFO DAGScheduler: Job 8 finished: collect at arrowconverters.scala:270, took 0.082890 s
20/02/14 18:35:45 INFO CodeGenerator: Code generated in 5.0184 ms
20/02/14 18:35:45 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:64190 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 18:35:45 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:64190 in memory (size: 15.5 KiB, free: 413.9 MiB)
20/02/14 18:35:45 INFO CodeGenerator: Code generated in 5.8593 ms
20/02/14 18:35:45 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:35:45 INFO DAGScheduler: Got job 9 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 18:35:45 INFO DAGScheduler: Final stage: ResultStage 11 (collect at arrowconverters.scala:270)
20/02/14 18:35:45 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:35:45 INFO DAGScheduler: Missing parents: List()
20/02/14 18:35:45 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[70] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:35:45 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 11.1 KiB, free 413.9 MiB)
20/02/14 18:35:45 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
20/02/14 18:35:45 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:64190 (size: 5.2 KiB, free: 413.9 MiB)
20/02/14 18:35:45 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1196
20/02/14 18:35:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[70] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:35:45 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
20/02/14 18:35:46 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7549 bytes)
20/02/14 18:35:46 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
20/02/14 18:35:46 INFO CodeGenerator: Code generated in 19.0983 ms
20/02/14 18:35:46 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1543 bytes result sent to driver
20/02/14 18:35:46 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 46 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:35:46 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
20/02/14 18:35:46 INFO DAGScheduler: ResultStage 11 (collect at arrowconverters.scala:270) finished in 0.056 s
20/02/14 18:35:46 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:35:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
20/02/14 18:35:46 INFO DAGScheduler: Job 9 finished: collect at arrowconverters.scala:270, took 0.060000 s
20/02/14 18:35:55 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:64190 in memory (size: 5.2 KiB, free: 413.9 MiB)
20/02/14 18:35:55 INFO CodeGenerator: Code generated in 33.3983 ms
20/02/14 18:35:55 INFO CodeGenerator: Code generated in 74.449 ms
20/02/14 18:35:55 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:35:55 INFO DAGScheduler: Registering RDD 75 (collect at arrowconverters.scala:270) as input to shuffle 2
20/02/14 18:35:55 INFO DAGScheduler: Got job 10 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/14 18:35:55 INFO DAGScheduler: Final stage: ResultStage 13 (collect at arrowconverters.scala:270)
20/02/14 18:35:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
20/02/14 18:35:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
20/02/14 18:35:55 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[75] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:35:55 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 45.3 KiB, free 413.8 MiB)
20/02/14 18:35:55 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 18.3 KiB, free 413.8 MiB)
20/02/14 18:35:55 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:64190 (size: 18.3 KiB, free: 413.9 MiB)
20/02/14 18:35:55 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1196
20/02/14 18:35:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[75] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:35:55 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
20/02/14 18:35:55 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 18:35:55 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
20/02/14 18:35:55 INFO BlockManager: Found block rdd_45_0 locally
20/02/14 18:35:55 INFO CodeGenerator: Code generated in 5.5073 ms
20/02/14 18:35:55 INFO CodeGenerator: Code generated in 4.7734 ms
20/02/14 18:35:55 INFO CodeGenerator: Code generated in 6.1667 ms
20/02/14 18:35:55 INFO CodeGenerator: Code generated in 10.4383 ms
20/02/14 18:35:55 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2756 bytes result sent to driver
20/02/14 18:35:55 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 160 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:35:55 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
20/02/14 18:35:55 INFO DAGScheduler: ShuffleMapStage 12 (collect at arrowconverters.scala:270) finished in 0.167 s
20/02/14 18:35:55 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:35:55 INFO DAGScheduler: running: Set()
20/02/14 18:35:55 INFO DAGScheduler: waiting: Set(ResultStage 13)
20/02/14 18:35:55 INFO DAGScheduler: failed: Set()
20/02/14 18:35:55 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[81] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:35:55 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 42.4 KiB, free 413.8 MiB)
20/02/14 18:35:55 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 413.8 MiB)
20/02/14 18:35:55 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:64190 (size: 17.6 KiB, free: 413.9 MiB)
20/02/14 18:35:55 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1196
20/02/14 18:35:55 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 13 (MapPartitionsRDD[81] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 18:35:55 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
20/02/14 18:35:55 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 18:35:55 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 14, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7248 bytes)
20/02/14 18:35:55 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 15, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7248 bytes)
20/02/14 18:35:55 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 16, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7248 bytes)
20/02/14 18:35:55 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
20/02/14 18:35:55 INFO Executor: Running task 1.0 in stage 13.0 (TID 14)
20/02/14 18:35:55 INFO Executor: Running task 2.0 in stage 13.0 (TID 15)
20/02/14 18:35:55 INFO Executor: Running task 3.0 in stage 13.0 (TID 16)
20/02/14 18:35:55 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:35:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 18:35:55 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:35:55 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:35:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 18:35:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 18:35:55 INFO ShuffleBlockFetcherIterator: Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:35:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 18:35:55 INFO CodeGenerator: Code generated in 7.432 ms
20/02/14 18:35:55 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:64190 in memory (size: 18.3 KiB, free: 413.9 MiB)
20/02/14 18:35:55 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:64190 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 18:35:56 INFO CodeGenerator: Code generated in 110.963 ms
20/02/14 18:35:56 INFO Executor: Finished task 3.0 in stage 13.0 (TID 16). 4458 bytes result sent to driver
20/02/14 18:35:56 INFO Executor: Finished task 2.0 in stage 13.0 (TID 15). 4547 bytes result sent to driver
20/02/14 18:35:56 INFO Executor: Finished task 1.0 in stage 13.0 (TID 14). 4498 bytes result sent to driver
20/02/14 18:35:56 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 4483 bytes result sent to driver
20/02/14 18:35:56 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 16) in 191 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 18:35:56 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 192 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 18:35:56 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 15) in 193 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 18:35:56 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 14) in 193 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 18:35:56 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
20/02/14 18:35:56 INFO DAGScheduler: ResultStage 13 (collect at arrowconverters.scala:270) finished in 0.207 s
20/02/14 18:35:56 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:35:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
20/02/14 18:35:56 INFO DAGScheduler: Job 10 finished: collect at arrowconverters.scala:270, took 0.383481 s
20/02/14 18:36:00 INFO CodeGenerator: Code generated in 10.1928 ms
20/02/14 18:36:00 INFO CodeGenerator: Code generated in 9.9399 ms
20/02/14 18:36:00 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:36:00 INFO DAGScheduler: Got job 11 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 18:36:00 INFO DAGScheduler: Final stage: ResultStage 14 (collect at arrowconverters.scala:270)
20/02/14 18:36:00 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:36:00 INFO DAGScheduler: Missing parents: List()
20/02/14 18:36:00 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[89] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:36:00 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 29.9 KiB, free 413.8 MiB)
20/02/14 18:36:00 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 413.8 MiB)
20/02/14 18:36:00 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:64190 (size: 11.2 KiB, free: 413.9 MiB)
20/02/14 18:36:00 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1196
20/02/14 18:36:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[89] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:36:00 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
20/02/14 18:36:00 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 17, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 18:36:00 INFO Executor: Running task 0.0 in stage 14.0 (TID 17)
20/02/14 18:36:00 INFO BlockManager: Found block rdd_45_0 locally
20/02/14 18:36:00 INFO CodeGenerator: Code generated in 6.9782 ms
20/02/14 18:36:00 INFO CodeGenerator: Code generated in 9.7422 ms
20/02/14 18:36:00 INFO Executor: Finished task 0.0 in stage 14.0 (TID 17). 2342 bytes result sent to driver
20/02/14 18:36:00 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 17) in 37 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:36:00 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
20/02/14 18:36:00 INFO DAGScheduler: ResultStage 14 (collect at arrowconverters.scala:270) finished in 0.043 s
20/02/14 18:36:00 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:36:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
20/02/14 18:36:00 INFO DAGScheduler: Job 11 finished: collect at arrowconverters.scala:270, took 0.047982 s
20/02/14 18:36:05 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:64190 in memory (size: 11.2 KiB, free: 413.9 MiB)
20/02/14 18:36:06 INFO Instrumentation: [9e711732] training finished
20/02/14 18:36:06 INFO Instrumentation: [a531ca91] training finished
20/02/14 18:36:06 INFO CodeGenerator: Code generated in 20.6999 ms
20/02/14 18:36:06 INFO SparkContext: Starting job: first at LinearRegression.scala:321
20/02/14 18:36:06 INFO DAGScheduler: Got job 12 (first at LinearRegression.scala:321) with 1 output partitions
20/02/14 18:36:06 INFO DAGScheduler: Final stage: ResultStage 15 (first at LinearRegression.scala:321)
20/02/14 18:36:06 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:36:06 INFO DAGScheduler: Missing parents: List()
20/02/14 18:36:06 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[94] at first at LinearRegression.scala:321), which has no missing parents
20/02/14 18:36:06 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 36.0 KiB, free 413.8 MiB)
20/02/14 18:36:06 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 413.8 MiB)
20/02/14 18:36:06 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:64190 (size: 13.4 KiB, free: 413.9 MiB)
20/02/14 18:36:06 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1196
20/02/14 18:36:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[94] at first at LinearRegression.scala:321) (first 15 tasks are for partitions Vector(0))
20/02/14 18:36:06 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
20/02/14 18:36:06 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 18, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 18:36:06 INFO Executor: Running task 0.0 in stage 15.0 (TID 18)
20/02/14 18:36:06 INFO BlockManager: Found block rdd_45_0 locally
20/02/14 18:36:06 INFO Executor: 1 block locks were not released by TID = 18:
[rdd_45_0]
20/02/14 18:36:06 INFO Executor: Finished task 0.0 in stage 15.0 (TID 18). 1881 bytes result sent to driver
20/02/14 18:36:06 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 18) in 69 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:36:06 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
20/02/14 18:36:06 INFO DAGScheduler: ResultStage 15 (first at LinearRegression.scala:321) finished in 0.076 s
20/02/14 18:36:06 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:36:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
20/02/14 18:36:06 INFO DAGScheduler: Job 12 finished: first at LinearRegression.scala:321, took 0.078987 s
20/02/14 18:36:06 INFO CodeGenerator: Code generated in 5.2654 ms
20/02/14 18:36:06 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:64190 in memory (size: 13.4 KiB, free: 413.9 MiB)
20/02/14 18:36:06 INFO CodeGenerator: Code generated in 22.1102 ms
20/02/14 18:36:06 INFO Instrumentation: [d280b995] Stage class: LinearRegression
20/02/14 18:36:06 INFO Instrumentation: [d280b995] Stage uid: linear_regression_13870ea6276
20/02/14 18:36:06 INFO CodeGenerator: Code generated in 17.5311 ms
20/02/14 18:36:06 INFO Instrumentation: [d280b995] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
20/02/14 18:36:06 INFO Instrumentation: [d280b995] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
20/02/14 18:36:06 INFO Instrumentation: [d280b995] {"numFeatures":1}
20/02/14 18:36:06 WARN Instrumentation: [d280b995] regParam is zero, which might cause numerical instability and overfitting.
20/02/14 18:36:06 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:105
20/02/14 18:36:06 INFO DAGScheduler: Got job 13 (treeAggregate at WeightedLeastSquares.scala:105) with 1 output partitions
20/02/14 18:36:06 INFO DAGScheduler: Final stage: ResultStage 16 (treeAggregate at WeightedLeastSquares.scala:105)
20/02/14 18:36:06 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:36:06 INFO DAGScheduler: Missing parents: List()
20/02/14 18:36:06 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[110] at treeAggregate at WeightedLeastSquares.scala:105), which has no missing parents
20/02/14 18:36:06 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 44.5 KiB, free 413.8 MiB)
20/02/14 18:36:06 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 413.8 MiB)
20/02/14 18:36:06 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:64190 (size: 17.3 KiB, free: 413.9 MiB)
20/02/14 18:36:06 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1196
20/02/14 18:36:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[110] at treeAggregate at WeightedLeastSquares.scala:105) (first 15 tasks are for partitions Vector(0))
20/02/14 18:36:06 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
20/02/14 18:36:06 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 19, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 18:36:06 INFO Executor: Running task 0.0 in stage 16.0 (TID 19)
20/02/14 18:36:07 INFO BlockManager: Found block rdd_45_0 locally
20/02/14 18:36:07 INFO CodeGenerator: Code generated in 6.184 ms
20/02/14 18:36:07 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
20/02/14 18:36:07 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
20/02/14 18:36:07 INFO Executor: Finished task 0.0 in stage 16.0 (TID 19). 2039 bytes result sent to driver
20/02/14 18:36:07 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 19) in 63 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:36:07 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
20/02/14 18:36:07 INFO DAGScheduler: ResultStage 16 (treeAggregate at WeightedLeastSquares.scala:105) finished in 0.092 s
20/02/14 18:36:07 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:36:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
20/02/14 18:36:07 INFO DAGScheduler: Job 13 finished: treeAggregate at WeightedLeastSquares.scala:105, took 0.096356 s
20/02/14 18:36:07 INFO Instrumentation: [d280b995] Number of instances: 32.
20/02/14 18:36:07 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
20/02/14 18:36:07 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
20/02/14 18:36:07 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:64190 in memory (size: 17.3 KiB, free: 413.9 MiB)
20/02/14 18:36:07 INFO CodeGenerator: Code generated in 11.6074 ms
20/02/14 18:36:07 INFO SparkContext: Starting job: treeAggregate at RegressionMetrics.scala:68
20/02/14 18:36:07 INFO DAGScheduler: Got job 14 (treeAggregate at RegressionMetrics.scala:68) with 1 output partitions
20/02/14 18:36:07 INFO DAGScheduler: Final stage: ResultStage 17 (treeAggregate at RegressionMetrics.scala:68)
20/02/14 18:36:07 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:36:07 INFO DAGScheduler: Missing parents: List()
20/02/14 18:36:07 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[120] at treeAggregate at RegressionMetrics.scala:68), which has no missing parents
20/02/14 18:36:07 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 46.2 KiB, free 413.8 MiB)
20/02/14 18:36:07 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 413.8 MiB)
20/02/14 18:36:07 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:64190 (size: 18.8 KiB, free: 413.9 MiB)
20/02/14 18:36:07 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1196
20/02/14 18:36:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[120] at treeAggregate at RegressionMetrics.scala:68) (first 15 tasks are for partitions Vector(0))
20/02/14 18:36:07 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
20/02/14 18:36:07 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 20, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 18:36:07 INFO Executor: Running task 0.0 in stage 17.0 (TID 20)
20/02/14 18:36:07 INFO BlockManager: Found block rdd_45_0 locally
20/02/14 18:36:07 INFO CodeGenerator: Code generated in 4.9731 ms
20/02/14 18:36:07 INFO Executor: Finished task 0.0 in stage 17.0 (TID 20). 2199 bytes result sent to driver
20/02/14 18:36:07 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 20) in 39 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:36:07 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
20/02/14 18:36:07 INFO DAGScheduler: ResultStage 17 (treeAggregate at RegressionMetrics.scala:68) finished in 0.049 s
20/02/14 18:36:07 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:36:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
20/02/14 18:36:07 INFO DAGScheduler: Job 14 finished: treeAggregate at RegressionMetrics.scala:68, took 0.053306 s
20/02/14 18:36:07 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:64190 in memory (size: 18.8 KiB, free: 413.9 MiB)
20/02/14 18:36:07 INFO SparkContext: Starting job: count at LinearRegression.scala:930
20/02/14 18:36:07 INFO DAGScheduler: Registering RDD 125 (count at LinearRegression.scala:930) as input to shuffle 3
20/02/14 18:36:07 INFO DAGScheduler: Got job 15 (count at LinearRegression.scala:930) with 1 output partitions
20/02/14 18:36:07 INFO DAGScheduler: Final stage: ResultStage 19 (count at LinearRegression.scala:930)
20/02/14 18:36:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
20/02/14 18:36:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
20/02/14 18:36:07 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[125] at count at LinearRegression.scala:930), which has no missing parents
20/02/14 18:36:07 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 26.9 KiB, free 413.8 MiB)
20/02/14 18:36:07 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 413.8 MiB)
20/02/14 18:36:07 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:64190 (size: 10.9 KiB, free: 413.9 MiB)
20/02/14 18:36:07 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1196
20/02/14 18:36:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[125] at count at LinearRegression.scala:930) (first 15 tasks are for partitions Vector(0))
20/02/14 18:36:07 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
20/02/14 18:36:07 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 21, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 18:36:07 INFO Executor: Running task 0.0 in stage 18.0 (TID 21)
20/02/14 18:36:07 INFO BlockManager: Found block rdd_45_0 locally
20/02/14 18:36:07 INFO Executor: Finished task 0.0 in stage 18.0 (TID 21). 2369 bytes result sent to driver
20/02/14 18:36:07 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 21) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:36:07 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
20/02/14 18:36:07 INFO DAGScheduler: ShuffleMapStage 18 (count at LinearRegression.scala:930) finished in 0.021 s
20/02/14 18:36:07 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:36:07 INFO DAGScheduler: running: Set()
20/02/14 18:36:07 INFO DAGScheduler: waiting: Set(ResultStage 19)
20/02/14 18:36:07 INFO DAGScheduler: failed: Set()
20/02/14 18:36:07 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[128] at count at LinearRegression.scala:930), which has no missing parents
20/02/14 18:36:07 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 10.2 KiB, free 413.8 MiB)
20/02/14 18:36:07 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
20/02/14 18:36:07 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:64190 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 18:36:07 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1196
20/02/14 18:36:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[128] at count at LinearRegression.scala:930) (first 15 tasks are for partitions Vector(0))
20/02/14 18:36:07 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
20/02/14 18:36:07 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 22, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 18:36:07 INFO Executor: Running task 0.0 in stage 19.0 (TID 22)
20/02/14 18:36:07 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:36:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:36:07 INFO Executor: Finished task 0.0 in stage 19.0 (TID 22). 2760 bytes result sent to driver
20/02/14 18:36:07 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 22) in 4 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:36:07 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
20/02/14 18:36:07 INFO DAGScheduler: ResultStage 19 (count at LinearRegression.scala:930) finished in 0.012 s
20/02/14 18:36:07 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:36:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
20/02/14 18:36:07 INFO DAGScheduler: Job 15 finished: count at LinearRegression.scala:930, took 0.038604 s
20/02/14 18:36:07 INFO Instrumentation: [4c23d02c] training finished
20/02/14 18:36:07 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:64190 in memory (size: 10.9 KiB, free: 413.9 MiB)
20/02/14 18:36:07 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:64190 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 18:36:07 INFO Instrumentation: [22705c4e] training finished
20/02/14 18:36:10 INFO SparkContext: Starting job: count at <unknown>:0
20/02/14 18:36:10 INFO DAGScheduler: Registering RDD 133 (count at <unknown>:0) as input to shuffle 4
20/02/14 18:36:10 INFO DAGScheduler: Got job 16 (count at <unknown>:0) with 1 output partitions
20/02/14 18:36:10 INFO DAGScheduler: Final stage: ResultStage 21 (count at <unknown>:0)
20/02/14 18:36:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
20/02/14 18:36:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
20/02/14 18:36:10 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[133] at count at <unknown>:0), which has no missing parents
20/02/14 18:36:10 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 26.8 KiB, free 413.8 MiB)
20/02/14 18:36:10 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.8 MiB)
20/02/14 18:36:10 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:64190 (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 18:36:10 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1196
20/02/14 18:36:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[133] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 18:36:10 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
20/02/14 18:36:10 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 23, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 18:36:10 INFO Executor: Running task 0.0 in stage 20.0 (TID 23)
20/02/14 18:36:10 INFO BlockManager: Found block rdd_45_0 locally
20/02/14 18:36:10 INFO Executor: Finished task 0.0 in stage 20.0 (TID 23). 2326 bytes result sent to driver
20/02/14 18:36:10 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 23) in 12 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:36:10 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
20/02/14 18:36:10 INFO DAGScheduler: ShuffleMapStage 20 (count at <unknown>:0) finished in 0.021 s
20/02/14 18:36:10 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:36:10 INFO DAGScheduler: running: Set()
20/02/14 18:36:10 INFO DAGScheduler: waiting: Set(ResultStage 21)
20/02/14 18:36:10 INFO DAGScheduler: failed: Set()
20/02/14 18:36:10 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[136] at count at <unknown>:0), which has no missing parents
20/02/14 18:36:10 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 10.2 KiB, free 413.8 MiB)
20/02/14 18:36:10 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
20/02/14 18:36:10 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:64190 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 18:36:10 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1196
20/02/14 18:36:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[136] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 18:36:10 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
20/02/14 18:36:10 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 24, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 18:36:10 INFO Executor: Running task 0.0 in stage 21.0 (TID 24)
20/02/14 18:36:10 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:36:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:36:10 INFO Executor: Finished task 0.0 in stage 21.0 (TID 24). 2760 bytes result sent to driver
20/02/14 18:36:10 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 24) in 4 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:36:10 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
20/02/14 18:36:10 INFO DAGScheduler: ResultStage 21 (count at <unknown>:0) finished in 0.010 s
20/02/14 18:36:10 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:36:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
20/02/14 18:36:10 INFO DAGScheduler: Job 16 finished: count at <unknown>:0, took 0.035866 s
20/02/14 18:36:10 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:64190 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 18:36:10 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:64190 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/14 18:36:10 INFO CodeGenerator: Code generated in 13.7573 ms
20/02/14 18:36:10 INFO SparkContext: Starting job: collect at utils.scala:34
20/02/14 18:36:10 INFO DAGScheduler: Got job 17 (collect at utils.scala:34) with 1 output partitions
20/02/14 18:36:10 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:34)
20/02/14 18:36:10 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:36:10 INFO DAGScheduler: Missing parents: List()
20/02/14 18:36:10 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[144] at map at utils.scala:34), which has no missing parents
20/02/14 18:36:10 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 46.8 KiB, free 413.8 MiB)
20/02/14 18:36:10 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 413.8 MiB)
20/02/14 18:36:10 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:64190 (size: 19.2 KiB, free: 413.9 MiB)
20/02/14 18:36:10 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1196
20/02/14 18:36:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[144] at map at utils.scala:34) (first 15 tasks are for partitions Vector(0))
20/02/14 18:36:10 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
20/02/14 18:36:10 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 25, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 18:36:10 INFO Executor: Running task 0.0 in stage 22.0 (TID 25)
20/02/14 18:36:10 INFO BlockManager: Found block rdd_45_0 locally
20/02/14 18:36:10 INFO CodeGenerator: Code generated in 4.6582 ms
20/02/14 18:36:10 INFO Executor: Finished task 0.0 in stage 22.0 (TID 25). 1865 bytes result sent to driver
20/02/14 18:36:10 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 25) in 22 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:36:10 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
20/02/14 18:36:10 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:34) finished in 0.028 s
20/02/14 18:36:10 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:36:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
20/02/14 18:36:10 INFO DAGScheduler: Job 17 finished: collect at utils.scala:34, took 0.032045 s
20/02/14 18:36:14 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:64190 in memory (size: 19.2 KiB, free: 413.9 MiB)
20/02/14 18:36:14 INFO CodeGenerator: Code generated in 4.0452 ms
20/02/14 18:36:14 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 18:36:14 INFO DAGScheduler: Got job 18 (collect at utils.scala:41) with 4 output partitions
20/02/14 18:36:14 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:41)
20/02/14 18:36:14 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:36:14 INFO DAGScheduler: Missing parents: List()
20/02/14 18:36:14 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[150] at map at utils.scala:41), which has no missing parents
20/02/14 18:36:14 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 8.8 KiB, free 413.9 MiB)
20/02/14 18:36:14 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.8 MiB)
20/02/14 18:36:14 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:64190 (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 18:36:14 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1196
20/02/14 18:36:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 23 (MapPartitionsRDD[150] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 18:36:14 INFO TaskSchedulerImpl: Adding task set 23.0 with 4 tasks
20/02/14 18:36:14 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 26, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7533 bytes)
20/02/14 18:36:14 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 27, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7549 bytes)
20/02/14 18:36:14 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 28, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7549 bytes)
20/02/14 18:36:14 INFO TaskSetManager: Starting task 3.0 in stage 23.0 (TID 29, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7606 bytes)
20/02/14 18:36:14 INFO Executor: Running task 1.0 in stage 23.0 (TID 27)
20/02/14 18:36:14 INFO Executor: Running task 0.0 in stage 23.0 (TID 26)
20/02/14 18:36:14 INFO Executor: Running task 3.0 in stage 23.0 (TID 29)
20/02/14 18:36:14 INFO Executor: Running task 2.0 in stage 23.0 (TID 28)
20/02/14 18:36:14 INFO Executor: Finished task 3.0 in stage 23.0 (TID 29). 1070 bytes result sent to driver
20/02/14 18:36:14 INFO Executor: Finished task 0.0 in stage 23.0 (TID 26). 1026 bytes result sent to driver
20/02/14 18:36:14 INFO Executor: Finished task 1.0 in stage 23.0 (TID 27). 1044 bytes result sent to driver
20/02/14 18:36:14 INFO TaskSetManager: Finished task 3.0 in stage 23.0 (TID 29) in 11 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 18:36:14 INFO Executor: Finished task 2.0 in stage 23.0 (TID 28). 1043 bytes result sent to driver
20/02/14 18:36:14 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 26) in 12 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 18:36:14 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 28) in 11 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 18:36:14 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 27) in 11 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 18:36:14 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
20/02/14 18:36:14 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:41) finished in 0.020 s
20/02/14 18:36:14 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:36:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
20/02/14 18:36:14 INFO DAGScheduler: Job 18 finished: collect at utils.scala:41, took 0.023546 s
20/02/14 18:36:14 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:64190 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/14 18:36:14 INFO CodeGenerator: Code generated in 5.9522 ms
20/02/14 18:36:14 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/14 18:36:14 INFO DAGScheduler: Registering RDD 159 (sql at <unknown>:0) as input to shuffle 5
20/02/14 18:36:14 INFO DAGScheduler: Got job 19 (sql at <unknown>:0) with 1 output partitions
20/02/14 18:36:14 INFO DAGScheduler: Final stage: ResultStage 25 (sql at <unknown>:0)
20/02/14 18:36:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
20/02/14 18:36:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 24)
20/02/14 18:36:14 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[159] at sql at <unknown>:0), which has no missing parents
20/02/14 18:36:14 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 18.9 KiB, free 413.8 MiB)
20/02/14 18:36:14 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.8 MiB)
20/02/14 18:36:14 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:64190 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 18:36:14 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1196
20/02/14 18:36:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[159] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 18:36:14 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
20/02/14 18:36:14 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 30, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 18:36:14 INFO Executor: Running task 0.0 in stage 24.0 (TID 30)
20/02/14 18:36:14 INFO MemoryStore: Block rdd_154_0 stored as values in memory (estimated size 312.0 B, free 413.8 MiB)
20/02/14 18:36:14 INFO BlockManagerInfo: Added rdd_154_0 in memory on 127.0.0.1:64190 (size: 312.0 B, free: 413.9 MiB)
20/02/14 18:36:14 INFO Executor: Finished task 0.0 in stage 24.0 (TID 30). 2283 bytes result sent to driver
20/02/14 18:36:14 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 30) in 21 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:36:14 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
20/02/14 18:36:14 INFO DAGScheduler: ShuffleMapStage 24 (sql at <unknown>:0) finished in 0.028 s
20/02/14 18:36:14 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:36:14 INFO DAGScheduler: running: Set()
20/02/14 18:36:14 INFO DAGScheduler: waiting: Set(ResultStage 25)
20/02/14 18:36:14 INFO DAGScheduler: failed: Set()
20/02/14 18:36:14 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[162] at sql at <unknown>:0), which has no missing parents
20/02/14 18:36:14 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 10.2 KiB, free 413.8 MiB)
20/02/14 18:36:14 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
20/02/14 18:36:14 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:64190 (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 18:36:14 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1196
20/02/14 18:36:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[162] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 18:36:14 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
20/02/14 18:36:14 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 31, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 18:36:14 INFO Executor: Running task 0.0 in stage 25.0 (TID 31)
20/02/14 18:36:14 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:36:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:36:14 INFO Executor: Finished task 0.0 in stage 25.0 (TID 31). 2803 bytes result sent to driver
20/02/14 18:36:14 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 31) in 12 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:36:14 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
20/02/14 18:36:14 INFO DAGScheduler: ResultStage 25 (sql at <unknown>:0) finished in 0.050 s
20/02/14 18:36:14 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:36:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
20/02/14 18:36:14 INFO DAGScheduler: Job 19 finished: sql at <unknown>:0, took 0.083137 s
20/02/14 18:36:14 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:64190 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 18:36:14 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:64190 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/14 18:36:14 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:36:14 INFO DAGScheduler: Registering RDD 167 (collect at arrowconverters.scala:270) as input to shuffle 6
20/02/14 18:36:14 INFO DAGScheduler: Got job 20 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 18:36:14 INFO DAGScheduler: Final stage: ResultStage 27 (collect at arrowconverters.scala:270)
20/02/14 18:36:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
20/02/14 18:36:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
20/02/14 18:36:14 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[167] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:36:14 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 18.9 KiB, free 413.8 MiB)
20/02/14 18:36:14 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.8 MiB)
20/02/14 18:36:14 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:64190 (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 18:36:14 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1196
20/02/14 18:36:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[167] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:36:14 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
20/02/14 18:36:14 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 32, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 18:36:14 INFO Executor: Running task 0.0 in stage 26.0 (TID 32)
20/02/14 18:36:14 INFO BlockManager: Found block rdd_154_0 locally
20/02/14 18:36:14 INFO Executor: Finished task 0.0 in stage 26.0 (TID 32). 2326 bytes result sent to driver
20/02/14 18:36:14 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 32) in 18 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:36:14 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
20/02/14 18:36:14 INFO DAGScheduler: ShuffleMapStage 26 (collect at arrowconverters.scala:270) finished in 0.024 s
20/02/14 18:36:14 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:36:14 INFO DAGScheduler: running: Set()
20/02/14 18:36:14 INFO DAGScheduler: waiting: Set(ResultStage 27)
20/02/14 18:36:14 INFO DAGScheduler: failed: Set()
20/02/14 18:36:14 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[173] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:36:14 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 28.9 KiB, free 413.8 MiB)
20/02/14 18:36:14 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 12.0 KiB, free 413.8 MiB)
20/02/14 18:36:14 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:64190 (size: 12.0 KiB, free: 413.9 MiB)
20/02/14 18:36:14 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1196
20/02/14 18:36:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[173] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:36:14 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
20/02/14 18:36:14 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 33, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 18:36:14 INFO Executor: Running task 0.0 in stage 27.0 (TID 33)
20/02/14 18:36:14 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:36:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:36:14 INFO Executor: Finished task 0.0 in stage 27.0 (TID 33). 4285 bytes result sent to driver
20/02/14 18:36:14 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 33) in 19 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:36:14 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
20/02/14 18:36:14 INFO DAGScheduler: ResultStage 27 (collect at arrowconverters.scala:270) finished in 0.030 s
20/02/14 18:36:14 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:36:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
20/02/14 18:36:14 INFO DAGScheduler: Job 20 finished: collect at arrowconverters.scala:270, took 0.060958 s
20/02/14 18:36:15 INFO Instrumentation: [6299fc2b] training finished
20/02/14 18:36:15 INFO Instrumentation: [816dae53] training finished
20/02/14 18:36:15 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:64190 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/14 18:36:15 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:64190 in memory (size: 12.0 KiB, free: 413.9 MiB)
20/02/14 18:36:15 INFO CodeGenerator: Code generated in 5.5595 ms
20/02/14 18:36:15 INFO CodeGenerator: Code generated in 7.2475 ms
20/02/14 18:36:15 INFO CodeGenerator: Code generated in 23.6779 ms
20/02/14 18:36:15 INFO CodeGenerator: Code generated in 13.7255 ms
20/02/14 18:36:15 INFO CodeGenerator: Code generated in 9.1345 ms
20/02/14 18:36:15 INFO CodeGenerator: Code generated in 6.8228 ms
20/02/14 18:36:15 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:36:15 INFO DAGScheduler: Registering RDD 178 (collect at arrowconverters.scala:270) as input to shuffle 7
20/02/14 18:36:15 INFO DAGScheduler: Registering RDD 185 (collect at arrowconverters.scala:270) as input to shuffle 8
20/02/14 18:36:15 INFO DAGScheduler: Got job 21 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/14 18:36:15 INFO DAGScheduler: Final stage: ResultStage 30 (collect at arrowconverters.scala:270)
20/02/14 18:36:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28, ShuffleMapStage 29)
20/02/14 18:36:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28, ShuffleMapStage 29)
20/02/14 18:36:15 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[178] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:36:15 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 32.1 KiB, free 413.8 MiB)
20/02/14 18:36:15 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 413.8 MiB)
20/02/14 18:36:15 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:64190 (size: 13.4 KiB, free: 413.9 MiB)
20/02/14 18:36:15 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1196
20/02/14 18:36:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[178] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:36:15 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
20/02/14 18:36:15 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 34, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 18:36:15 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[185] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:36:15 INFO Executor: Running task 0.0 in stage 28.0 (TID 34)
20/02/14 18:36:15 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 27.4 KiB, free 413.8 MiB)
20/02/14 18:36:15 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 413.8 MiB)
20/02/14 18:36:15 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:64190 (size: 10.9 KiB, free: 413.9 MiB)
20/02/14 18:36:15 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1196
20/02/14 18:36:15 INFO BlockManager: Found block rdd_154_0 locally
20/02/14 18:36:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[185] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:36:15 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
20/02/14 18:36:15 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 35, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 18:36:15 INFO Executor: Running task 0.0 in stage 29.0 (TID 35)
20/02/14 18:36:15 INFO BlockManager: Found block rdd_45_0 locally
20/02/14 18:36:15 INFO CodeGenerator: Code generated in 12.0933 ms
20/02/14 18:36:15 INFO CodeGenerator: Code generated in 12.1485 ms
20/02/14 18:36:15 INFO Executor: Finished task 0.0 in stage 28.0 (TID 34). 2246 bytes result sent to driver
20/02/14 18:36:15 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 34) in 90 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:36:15 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
20/02/14 18:36:15 INFO DAGScheduler: ShuffleMapStage 28 (collect at arrowconverters.scala:270) finished in 0.097 s
20/02/14 18:36:15 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:36:15 INFO DAGScheduler: running: Set(ShuffleMapStage 29)
20/02/14 18:36:15 INFO DAGScheduler: waiting: Set(ResultStage 30)
20/02/14 18:36:15 INFO DAGScheduler: failed: Set()
20/02/14 18:36:15 INFO Executor: Finished task 0.0 in stage 29.0 (TID 35). 2203 bytes result sent to driver
20/02/14 18:36:15 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 35) in 89 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:36:15 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
20/02/14 18:36:15 INFO DAGScheduler: ShuffleMapStage 29 (collect at arrowconverters.scala:270) finished in 0.097 s
20/02/14 18:36:15 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:36:15 INFO DAGScheduler: running: Set()
20/02/14 18:36:15 INFO DAGScheduler: waiting: Set(ResultStage 30)
20/02/14 18:36:15 INFO DAGScheduler: failed: Set()
20/02/14 18:36:15 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[193] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:36:15 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 56.3 KiB, free 413.7 MiB)
20/02/14 18:36:15 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 22.9 KiB, free 413.7 MiB)
20/02/14 18:36:15 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:64190 (size: 22.9 KiB, free: 413.9 MiB)
20/02/14 18:36:15 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1196
20/02/14 18:36:15 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[193] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 18:36:15 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
20/02/14 18:36:15 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 36, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7528 bytes)
20/02/14 18:36:15 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 37, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7528 bytes)
20/02/14 18:36:15 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 38, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7528 bytes)
20/02/14 18:36:15 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 39, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7528 bytes)
20/02/14 18:36:15 INFO Executor: Running task 1.0 in stage 30.0 (TID 37)
20/02/14 18:36:15 INFO Executor: Running task 3.0 in stage 30.0 (TID 39)
20/02/14 18:36:15 INFO Executor: Running task 0.0 in stage 30.0 (TID 36)
20/02/14 18:36:15 INFO Executor: Running task 2.0 in stage 30.0 (TID 38)
20/02/14 18:36:16 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:64190 in memory (size: 10.9 KiB, free: 413.9 MiB)
20/02/14 18:36:16 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:36:16 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:36:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:36:16 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:36:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:36:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:36:16 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:36:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
20/02/14 18:36:16 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:64190 in memory (size: 13.4 KiB, free: 413.9 MiB)
20/02/14 18:36:16 INFO CodeGenerator: Code generated in 19.6511 ms
20/02/14 18:36:16 INFO CodeGenerator: Code generated in 9.5504 ms
20/02/14 18:36:16 INFO ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:36:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:36:16 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:36:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:36:16 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:36:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 18:36:16 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:36:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:36:16 INFO CodeGenerator: Code generated in 10.2628 ms
20/02/14 18:36:16 INFO CodeGenerator: Code generated in 8.2142 ms
20/02/14 18:36:16 INFO CodeGenerator: Code generated in 6.9694 ms
20/02/14 18:36:16 INFO CodeGenerator: Code generated in 6.9854 ms
20/02/14 18:36:16 INFO Executor: Finished task 3.0 in stage 30.0 (TID 39). 5850 bytes result sent to driver
20/02/14 18:36:16 INFO Executor: Finished task 1.0 in stage 30.0 (TID 37). 5833 bytes result sent to driver
20/02/14 18:36:16 INFO Executor: Finished task 2.0 in stage 30.0 (TID 38). 5952 bytes result sent to driver
20/02/14 18:36:16 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 39) in 252 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 18:36:16 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 37) in 254 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 18:36:16 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 38) in 253 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 18:36:16 INFO Executor: Finished task 0.0 in stage 30.0 (TID 36). 5814 bytes result sent to driver
20/02/14 18:36:16 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 36) in 259 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 18:36:16 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
20/02/14 18:36:16 INFO DAGScheduler: ResultStage 30 (collect at arrowconverters.scala:270) finished in 0.266 s
20/02/14 18:36:16 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:36:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
20/02/14 18:36:16 INFO DAGScheduler: Job 21 finished: collect at arrowconverters.scala:270, took 0.377256 s
20/02/14 18:36:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
20/02/14 18:36:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/02/14 18:36:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
20/02/14 18:36:39 INFO CodeGenerator: Code generated in 10.9643 ms
20/02/14 18:36:39 INFO SparkContext: Starting job: csv at <unknown>:0
20/02/14 18:36:39 INFO DAGScheduler: Got job 22 (csv at <unknown>:0) with 1 output partitions
20/02/14 18:36:39 INFO DAGScheduler: Final stage: ResultStage 31 (csv at <unknown>:0)
20/02/14 18:36:39 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:36:39 INFO DAGScheduler: Missing parents: List()
20/02/14 18:36:39 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[197] at csv at <unknown>:0), which has no missing parents
20/02/14 18:36:39 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 196.6 KiB, free 413.6 MiB)
20/02/14 18:36:39 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 68.8 KiB, free 413.5 MiB)
20/02/14 18:36:39 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:64190 (size: 68.8 KiB, free: 413.8 MiB)
20/02/14 18:36:39 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1196
20/02/14 18:36:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[197] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 18:36:39 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
20/02/14 18:36:39 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 40, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 18:36:39 INFO Executor: Running task 0.0 in stage 31.0 (TID 40)
20/02/14 18:36:39 INFO BlockManager: Found block rdd_45_0 locally
20/02/14 18:36:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
20/02/14 18:36:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/02/14 18:36:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
20/02/14 18:36:39 ERROR Utils: Aborting task
java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
20/02/14 18:36:39 ERROR FileFormatWriter: Job job_20200214183639_0031 aborted.
20/02/14 18:36:39 ERROR Executor: Exception in task 0.0 in stage 31.0 (TID 40)
org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more
20/02/14 18:36:39 WARN TaskSetManager: Lost task 0.0 in stage 31.0 (TID 40, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more

20/02/14 18:36:39 ERROR TaskSetManager: Task 0 in stage 31.0 failed 1 times; aborting job
20/02/14 18:36:39 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
20/02/14 18:36:39 INFO TaskSchedulerImpl: Cancelling stage 31
20/02/14 18:36:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage cancelled
20/02/14 18:36:40 INFO DAGScheduler: ResultStage 31 (csv at <unknown>:0) failed in 0.591 s due to Job aborted due to stage failure: Task 0 in stage 31.0 failed 1 times, most recent failure: Lost task 0.0 in stage 31.0 (TID 40, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more

Driver stacktrace:
20/02/14 18:36:40 INFO DAGScheduler: Job 22 failed: csv at <unknown>:0, took 0.595770 s
20/02/14 18:36:40 ERROR FileFormatWriter: Aborting job a3e9e34c-368a-45e7-9e19-d5e530a80269.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 31.0 failed 1 times, most recent failure: Lost task 0.0 in stage 31.0 (TID 40, 127.0.0.1, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:1979)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1967)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1966)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1966)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:946)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:946)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:946)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2196)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2145)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2134)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:748)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2095)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:195)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:175)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:105)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:103)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:124)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:189)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:227)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:224)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:185)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:110)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:109)
	at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:829)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$4(SQLExecution.scala:100)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:87)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:829)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:309)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:236)
	at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:819)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at sparklyr.Invoke.invoke(invoke.scala:147)
	at sparklyr.StreamHandler.handleMethodCall(stream.scala:122)
	at sparklyr.StreamHandler.read(stream.scala:65)
	at sparklyr.BackendHandler.channelRead0(handler.scala:53)
	at sparklyr.BackendHandler.channelRead0(handler.scala:12)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:328)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:302)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:352)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1422)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:374)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:360)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:931)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:163)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:700)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:635)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:552)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:514)
	at io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1044)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:285)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:205)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:455)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:458)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	... 1 more
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:645)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:1230)
	at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1435)
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:493)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1868)
	at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1910)
	at org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:678)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:484)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
	at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:79)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:275)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1411)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:270)
	... 9 more
20/02/14 18:41:40 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 18:41:40 INFO DAGScheduler: Got job 23 (collect at utils.scala:41) with 4 output partitions
20/02/14 18:41:40 INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:41)
20/02/14 18:41:40 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:41:40 INFO DAGScheduler: Missing parents: List()
20/02/14 18:41:40 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[203] at map at utils.scala:41), which has no missing parents
20/02/14 18:41:40 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 8.8 KiB, free 413.5 MiB)
20/02/14 18:41:40 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.5 MiB)
20/02/14 18:41:40 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:64190 (size: 4.6 KiB, free: 413.8 MiB)
20/02/14 18:41:40 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:40 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 32 (MapPartitionsRDD[203] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 18:41:40 INFO TaskSchedulerImpl: Adding task set 32.0 with 4 tasks
20/02/14 18:41:40 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 41, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7533 bytes)
20/02/14 18:41:40 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 42, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7606 bytes)
20/02/14 18:41:40 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 43, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7606 bytes)
20/02/14 18:41:40 INFO TaskSetManager: Starting task 3.0 in stage 32.0 (TID 44, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7606 bytes)
20/02/14 18:41:40 INFO Executor: Running task 0.0 in stage 32.0 (TID 41)
20/02/14 18:41:40 INFO Executor: Running task 2.0 in stage 32.0 (TID 43)
20/02/14 18:41:40 INFO Executor: Running task 1.0 in stage 32.0 (TID 42)
20/02/14 18:41:40 INFO Executor: Running task 3.0 in stage 32.0 (TID 44)
20/02/14 18:41:40 INFO Executor: Finished task 2.0 in stage 32.0 (TID 43). 1070 bytes result sent to driver
20/02/14 18:41:40 INFO Executor: Finished task 1.0 in stage 32.0 (TID 42). 1071 bytes result sent to driver
20/02/14 18:41:40 INFO Executor: Finished task 0.0 in stage 32.0 (TID 41). 1026 bytes result sent to driver
20/02/14 18:41:40 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 43) in 10 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 18:41:40 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 42) in 11 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 18:41:40 INFO Executor: Finished task 3.0 in stage 32.0 (TID 44). 1070 bytes result sent to driver
20/02/14 18:41:40 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 41) in 12 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 18:41:40 INFO TaskSetManager: Finished task 3.0 in stage 32.0 (TID 44) in 11 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 18:41:40 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
20/02/14 18:41:40 INFO DAGScheduler: ResultStage 32 (collect at utils.scala:41) finished in 0.019 s
20/02/14 18:41:40 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:41:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
20/02/14 18:41:40 INFO DAGScheduler: Job 23 finished: collect at utils.scala:41, took 0.023302 s
20/02/14 18:41:40 INFO MapPartitionsRDD: Removing RDD 45 from persistence list
20/02/14 18:41:40 INFO BlockManager: Removing RDD 45
20/02/14 18:41:40 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:64190 in memory (size: 4.6 KiB, free: 413.8 MiB)
20/02/14 18:41:41 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/14 18:41:41 INFO DAGScheduler: Registering RDD 212 (sql at <unknown>:0) as input to shuffle 9
20/02/14 18:41:41 INFO DAGScheduler: Got job 24 (sql at <unknown>:0) with 1 output partitions
20/02/14 18:41:41 INFO DAGScheduler: Final stage: ResultStage 34 (sql at <unknown>:0)
20/02/14 18:41:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
20/02/14 18:41:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
20/02/14 18:41:41 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[212] at sql at <unknown>:0), which has no missing parents
20/02/14 18:41:41 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 26.8 KiB, free 413.5 MiB)
20/02/14 18:41:41 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.5 MiB)
20/02/14 18:41:41 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:64190 (size: 10.8 KiB, free: 413.8 MiB)
20/02/14 18:41:41 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[212] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:41 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
20/02/14 18:41:41 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 45, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 18:41:41 INFO Executor: Running task 0.0 in stage 33.0 (TID 45)
20/02/14 18:41:41 INFO MemoryStore: Block rdd_207_0 stored as values in memory (estimated size 3.9 KiB, free 413.5 MiB)
20/02/14 18:41:41 INFO BlockManagerInfo: Added rdd_207_0 in memory on 127.0.0.1:64190 (size: 3.9 KiB, free: 413.8 MiB)
20/02/14 18:41:41 INFO Executor: Finished task 0.0 in stage 33.0 (TID 45). 2283 bytes result sent to driver
20/02/14 18:41:41 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 45) in 52 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:41 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
20/02/14 18:41:41 INFO DAGScheduler: ShuffleMapStage 33 (sql at <unknown>:0) finished in 0.059 s
20/02/14 18:41:41 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:41:41 INFO DAGScheduler: running: Set()
20/02/14 18:41:41 INFO DAGScheduler: waiting: Set(ResultStage 34)
20/02/14 18:41:41 INFO DAGScheduler: failed: Set()
20/02/14 18:41:41 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[215] at sql at <unknown>:0), which has no missing parents
20/02/14 18:41:41 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 10.2 KiB, free 413.5 MiB)
20/02/14 18:41:41 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.5 MiB)
20/02/14 18:41:41 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:64190 (size: 5.0 KiB, free: 413.8 MiB)
20/02/14 18:41:41 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[215] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:41 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
20/02/14 18:41:41 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 46, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 18:41:41 INFO Executor: Running task 0.0 in stage 34.0 (TID 46)
20/02/14 18:41:41 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:41:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:41:41 INFO Executor: Finished task 0.0 in stage 34.0 (TID 46). 2803 bytes result sent to driver
20/02/14 18:41:41 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 46) in 5 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:41 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
20/02/14 18:41:41 INFO DAGScheduler: ResultStage 34 (sql at <unknown>:0) finished in 0.011 s
20/02/14 18:41:41 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:41:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
20/02/14 18:41:41 INFO DAGScheduler: Job 24 finished: sql at <unknown>:0, took 0.075970 s
20/02/14 18:41:41 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:64190 in memory (size: 10.8 KiB, free: 413.8 MiB)
20/02/14 18:41:41 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:64190 in memory (size: 5.0 KiB, free: 413.8 MiB)
20/02/14 18:41:41 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:41:41 INFO DAGScheduler: Registering RDD 220 (collect at arrowconverters.scala:270) as input to shuffle 10
20/02/14 18:41:41 INFO DAGScheduler: Got job 25 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 18:41:41 INFO DAGScheduler: Final stage: ResultStage 36 (collect at arrowconverters.scala:270)
20/02/14 18:41:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
20/02/14 18:41:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
20/02/14 18:41:41 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[220] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:41:41 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 26.8 KiB, free 413.5 MiB)
20/02/14 18:41:41 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.5 MiB)
20/02/14 18:41:41 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:64190 (size: 10.8 KiB, free: 413.8 MiB)
20/02/14 18:41:41 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[220] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:41 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
20/02/14 18:41:41 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 47, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 18:41:41 INFO Executor: Running task 0.0 in stage 35.0 (TID 47)
20/02/14 18:41:41 INFO BlockManager: Found block rdd_207_0 locally
20/02/14 18:41:41 INFO Executor: Finished task 0.0 in stage 35.0 (TID 47). 2369 bytes result sent to driver
20/02/14 18:41:41 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 47) in 17 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:41 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
20/02/14 18:41:41 INFO DAGScheduler: ShuffleMapStage 35 (collect at arrowconverters.scala:270) finished in 0.025 s
20/02/14 18:41:41 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:41:41 INFO DAGScheduler: running: Set()
20/02/14 18:41:41 INFO DAGScheduler: waiting: Set(ResultStage 36)
20/02/14 18:41:41 INFO DAGScheduler: failed: Set()
20/02/14 18:41:41 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[226] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:41:41 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 36.7 KiB, free 413.5 MiB)
20/02/14 18:41:41 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 15.5 KiB, free 413.4 MiB)
20/02/14 18:41:41 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:64190 (size: 15.5 KiB, free: 413.8 MiB)
20/02/14 18:41:41 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[226] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:41 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
20/02/14 18:41:41 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 48, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 18:41:41 INFO Executor: Running task 0.0 in stage 36.0 (TID 48)
20/02/14 18:41:41 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:41:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:41:41 INFO Executor: Finished task 0.0 in stage 36.0 (TID 48). 4286 bytes result sent to driver
20/02/14 18:41:41 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 48) in 13 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:41 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
20/02/14 18:41:41 INFO DAGScheduler: ResultStage 36 (collect at arrowconverters.scala:270) finished in 0.021 s
20/02/14 18:41:41 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:41:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
20/02/14 18:41:41 INFO DAGScheduler: Job 25 finished: collect at arrowconverters.scala:270, took 0.057361 s
20/02/14 18:41:41 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:64190 in memory (size: 10.8 KiB, free: 413.8 MiB)
20/02/14 18:41:41 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:64190 in memory (size: 15.5 KiB, free: 413.8 MiB)
20/02/14 18:41:41 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:41:41 INFO DAGScheduler: Registering RDD 231 (collect at arrowconverters.scala:270) as input to shuffle 11
20/02/14 18:41:41 INFO DAGScheduler: Got job 26 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/14 18:41:41 INFO DAGScheduler: Final stage: ResultStage 38 (collect at arrowconverters.scala:270)
20/02/14 18:41:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
20/02/14 18:41:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 37)
20/02/14 18:41:41 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[231] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:41:41 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 45.3 KiB, free 413.5 MiB)
20/02/14 18:41:41 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 18.3 KiB, free 413.5 MiB)
20/02/14 18:41:41 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:64190 (size: 18.3 KiB, free: 413.8 MiB)
20/02/14 18:41:41 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[231] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:41 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
20/02/14 18:41:41 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 49, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 18:41:41 INFO Executor: Running task 0.0 in stage 37.0 (TID 49)
20/02/14 18:41:41 INFO BlockManager: Found block rdd_207_0 locally
20/02/14 18:41:41 INFO Executor: Finished task 0.0 in stage 37.0 (TID 49). 2713 bytes result sent to driver
20/02/14 18:41:41 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 49) in 38 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:41 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
20/02/14 18:41:41 INFO DAGScheduler: ShuffleMapStage 37 (collect at arrowconverters.scala:270) finished in 0.050 s
20/02/14 18:41:41 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:41:41 INFO DAGScheduler: running: Set()
20/02/14 18:41:41 INFO DAGScheduler: waiting: Set(ResultStage 38)
20/02/14 18:41:41 INFO DAGScheduler: failed: Set()
20/02/14 18:41:41 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[237] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:41:41 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 42.4 KiB, free 413.4 MiB)
20/02/14 18:41:41 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 17.5 KiB, free 413.4 MiB)
20/02/14 18:41:41 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:64190 (size: 17.5 KiB, free: 413.8 MiB)
20/02/14 18:41:41 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:41 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 38 (MapPartitionsRDD[237] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 18:41:41 INFO TaskSchedulerImpl: Adding task set 38.0 with 4 tasks
20/02/14 18:41:41 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 50, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 18:41:41 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 51, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7248 bytes)
20/02/14 18:41:41 INFO TaskSetManager: Starting task 2.0 in stage 38.0 (TID 52, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7248 bytes)
20/02/14 18:41:41 INFO TaskSetManager: Starting task 3.0 in stage 38.0 (TID 53, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7248 bytes)
20/02/14 18:41:41 INFO Executor: Running task 0.0 in stage 38.0 (TID 50)
20/02/14 18:41:41 INFO Executor: Running task 1.0 in stage 38.0 (TID 51)
20/02/14 18:41:41 INFO Executor: Running task 3.0 in stage 38.0 (TID 53)
20/02/14 18:41:41 INFO Executor: Running task 2.0 in stage 38.0 (TID 52)
20/02/14 18:41:41 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:41:41 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:41:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:41:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:41:41 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:41:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:41:41 INFO ShuffleBlockFetcherIterator: Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:41:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 18:41:41 INFO Executor: Finished task 1.0 in stage 38.0 (TID 51). 4455 bytes result sent to driver
20/02/14 18:41:41 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 51) in 47 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 18:41:41 INFO Executor: Finished task 2.0 in stage 38.0 (TID 52). 4504 bytes result sent to driver
20/02/14 18:41:41 INFO TaskSetManager: Finished task 2.0 in stage 38.0 (TID 52) in 49 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 18:41:41 INFO Executor: Finished task 3.0 in stage 38.0 (TID 53). 4415 bytes result sent to driver
20/02/14 18:41:41 INFO TaskSetManager: Finished task 3.0 in stage 38.0 (TID 53) in 52 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 18:41:41 INFO Executor: Finished task 0.0 in stage 38.0 (TID 50). 4440 bytes result sent to driver
20/02/14 18:41:41 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 50) in 65 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 18:41:41 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
20/02/14 18:41:41 INFO DAGScheduler: ResultStage 38 (collect at arrowconverters.scala:270) finished in 0.074 s
20/02/14 18:41:41 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:41:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished
20/02/14 18:41:41 INFO DAGScheduler: Job 26 finished: collect at arrowconverters.scala:270, took 0.131475 s
20/02/14 18:41:42 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:64190 in memory (size: 18.3 KiB, free: 413.8 MiB)
20/02/14 18:41:42 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:64190 in memory (size: 17.5 KiB, free: 413.8 MiB)
20/02/14 18:41:42 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:41:42 INFO DAGScheduler: Got job 27 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 18:41:42 INFO DAGScheduler: Final stage: ResultStage 39 (collect at arrowconverters.scala:270)
20/02/14 18:41:42 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:41:42 INFO DAGScheduler: Missing parents: List()
20/02/14 18:41:42 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[245] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:41:42 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 29.9 KiB, free 413.5 MiB)
20/02/14 18:41:42 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 413.5 MiB)
20/02/14 18:41:42 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:64190 (size: 11.2 KiB, free: 413.8 MiB)
20/02/14 18:41:42 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[245] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:42 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
20/02/14 18:41:42 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 54, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 18:41:42 INFO Executor: Running task 0.0 in stage 39.0 (TID 54)
20/02/14 18:41:42 INFO BlockManager: Found block rdd_207_0 locally
20/02/14 18:41:42 INFO Executor: Finished task 0.0 in stage 39.0 (TID 54). 2299 bytes result sent to driver
20/02/14 18:41:42 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 54) in 12 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:42 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
20/02/14 18:41:42 INFO DAGScheduler: ResultStage 39 (collect at arrowconverters.scala:270) finished in 0.019 s
20/02/14 18:41:42 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:41:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
20/02/14 18:41:42 INFO DAGScheduler: Job 27 finished: collect at arrowconverters.scala:270, took 0.022256 s
20/02/14 18:41:43 INFO Instrumentation: [b3802928] training finished
20/02/14 18:41:43 INFO Instrumentation: [3974b869] training finished
20/02/14 18:41:43 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:64190 in memory (size: 11.2 KiB, free: 413.8 MiB)
20/02/14 18:41:43 INFO SparkContext: Starting job: first at LinearRegression.scala:321
20/02/14 18:41:43 INFO DAGScheduler: Got job 28 (first at LinearRegression.scala:321) with 1 output partitions
20/02/14 18:41:43 INFO DAGScheduler: Final stage: ResultStage 40 (first at LinearRegression.scala:321)
20/02/14 18:41:43 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:41:43 INFO DAGScheduler: Missing parents: List()
20/02/14 18:41:43 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[250] at first at LinearRegression.scala:321), which has no missing parents
20/02/14 18:41:43 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 36.0 KiB, free 413.5 MiB)
20/02/14 18:41:43 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 413.5 MiB)
20/02/14 18:41:43 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:64190 (size: 13.4 KiB, free: 413.8 MiB)
20/02/14 18:41:43 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[250] at first at LinearRegression.scala:321) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:43 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
20/02/14 18:41:43 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 55, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 18:41:43 INFO Executor: Running task 0.0 in stage 40.0 (TID 55)
20/02/14 18:41:43 INFO BlockManager: Found block rdd_207_0 locally
20/02/14 18:41:43 INFO Executor: 1 block locks were not released by TID = 55:
[rdd_207_0]
20/02/14 18:41:43 INFO Executor: Finished task 0.0 in stage 40.0 (TID 55). 1795 bytes result sent to driver
20/02/14 18:41:43 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 55) in 7 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:43 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
20/02/14 18:41:43 INFO DAGScheduler: ResultStage 40 (first at LinearRegression.scala:321) finished in 0.013 s
20/02/14 18:41:43 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:41:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
20/02/14 18:41:43 INFO DAGScheduler: Job 28 finished: first at LinearRegression.scala:321, took 0.016180 s
20/02/14 18:41:43 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:64190 in memory (size: 13.4 KiB, free: 413.8 MiB)
20/02/14 18:41:43 INFO Instrumentation: [0e0b1101] Stage class: LinearRegression
20/02/14 18:41:43 INFO Instrumentation: [0e0b1101] Stage uid: linear_regression_13842186a10
20/02/14 18:41:43 INFO Instrumentation: [0e0b1101] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
20/02/14 18:41:43 INFO Instrumentation: [0e0b1101] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
20/02/14 18:41:43 INFO Instrumentation: [0e0b1101] {"numFeatures":1}
20/02/14 18:41:43 WARN Instrumentation: [0e0b1101] regParam is zero, which might cause numerical instability and overfitting.
20/02/14 18:41:43 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:105
20/02/14 18:41:43 INFO DAGScheduler: Got job 29 (treeAggregate at WeightedLeastSquares.scala:105) with 1 output partitions
20/02/14 18:41:43 INFO DAGScheduler: Final stage: ResultStage 41 (treeAggregate at WeightedLeastSquares.scala:105)
20/02/14 18:41:43 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:41:43 INFO DAGScheduler: Missing parents: List()
20/02/14 18:41:43 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[266] at treeAggregate at WeightedLeastSquares.scala:105), which has no missing parents
20/02/14 18:41:43 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 44.5 KiB, free 413.5 MiB)
20/02/14 18:41:43 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 413.5 MiB)
20/02/14 18:41:43 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:64190 (size: 17.3 KiB, free: 413.8 MiB)
20/02/14 18:41:43 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[266] at treeAggregate at WeightedLeastSquares.scala:105) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:43 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
20/02/14 18:41:43 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 56, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 18:41:43 INFO Executor: Running task 0.0 in stage 41.0 (TID 56)
20/02/14 18:41:43 INFO BlockManager: Found block rdd_207_0 locally
20/02/14 18:41:43 INFO Executor: Finished task 0.0 in stage 41.0 (TID 56). 1996 bytes result sent to driver
20/02/14 18:41:43 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 56) in 12 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:43 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
20/02/14 18:41:43 INFO DAGScheduler: ResultStage 41 (treeAggregate at WeightedLeastSquares.scala:105) finished in 0.024 s
20/02/14 18:41:43 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:41:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished
20/02/14 18:41:43 INFO DAGScheduler: Job 29 finished: treeAggregate at WeightedLeastSquares.scala:105, took 0.027684 s
20/02/14 18:41:43 INFO Instrumentation: [0e0b1101] Number of instances: 32.
20/02/14 18:41:43 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:64190 in memory (size: 17.3 KiB, free: 413.8 MiB)
20/02/14 18:41:44 INFO SparkContext: Starting job: treeAggregate at RegressionMetrics.scala:68
20/02/14 18:41:44 INFO DAGScheduler: Got job 30 (treeAggregate at RegressionMetrics.scala:68) with 1 output partitions
20/02/14 18:41:44 INFO DAGScheduler: Final stage: ResultStage 42 (treeAggregate at RegressionMetrics.scala:68)
20/02/14 18:41:44 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:41:44 INFO DAGScheduler: Missing parents: List()
20/02/14 18:41:44 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[276] at treeAggregate at RegressionMetrics.scala:68), which has no missing parents
20/02/14 18:41:44 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 46.2 KiB, free 413.5 MiB)
20/02/14 18:41:44 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 413.5 MiB)
20/02/14 18:41:44 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:64190 (size: 18.9 KiB, free: 413.8 MiB)
20/02/14 18:41:44 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[276] at treeAggregate at RegressionMetrics.scala:68) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:44 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
20/02/14 18:41:44 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 57, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 18:41:44 INFO Executor: Running task 0.0 in stage 42.0 (TID 57)
20/02/14 18:41:44 INFO BlockManager: Found block rdd_207_0 locally
20/02/14 18:41:44 INFO Executor: Finished task 0.0 in stage 42.0 (TID 57). 2113 bytes result sent to driver
20/02/14 18:41:44 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 57) in 12 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:44 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
20/02/14 18:41:44 INFO DAGScheduler: ResultStage 42 (treeAggregate at RegressionMetrics.scala:68) finished in 0.020 s
20/02/14 18:41:44 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:41:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
20/02/14 18:41:44 INFO DAGScheduler: Job 30 finished: treeAggregate at RegressionMetrics.scala:68, took 0.024108 s
20/02/14 18:41:44 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:64190 in memory (size: 18.9 KiB, free: 413.8 MiB)
20/02/14 18:41:44 INFO SparkContext: Starting job: count at LinearRegression.scala:930
20/02/14 18:41:44 INFO DAGScheduler: Registering RDD 281 (count at LinearRegression.scala:930) as input to shuffle 12
20/02/14 18:41:44 INFO DAGScheduler: Got job 31 (count at LinearRegression.scala:930) with 1 output partitions
20/02/14 18:41:44 INFO DAGScheduler: Final stage: ResultStage 44 (count at LinearRegression.scala:930)
20/02/14 18:41:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
20/02/14 18:41:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 43)
20/02/14 18:41:44 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[281] at count at LinearRegression.scala:930), which has no missing parents
20/02/14 18:41:44 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 26.9 KiB, free 413.5 MiB)
20/02/14 18:41:44 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 413.5 MiB)
20/02/14 18:41:44 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:64190 (size: 10.9 KiB, free: 413.8 MiB)
20/02/14 18:41:44 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[281] at count at LinearRegression.scala:930) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:44 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
20/02/14 18:41:44 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 58, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 18:41:44 INFO Executor: Running task 0.0 in stage 43.0 (TID 58)
20/02/14 18:41:44 INFO BlockManager: Found block rdd_207_0 locally
20/02/14 18:41:44 INFO Executor: Finished task 0.0 in stage 43.0 (TID 58). 2326 bytes result sent to driver
20/02/14 18:41:44 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 58) in 12 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:44 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
20/02/14 18:41:44 INFO DAGScheduler: ShuffleMapStage 43 (count at LinearRegression.scala:930) finished in 0.018 s
20/02/14 18:41:44 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:41:44 INFO DAGScheduler: running: Set()
20/02/14 18:41:44 INFO DAGScheduler: waiting: Set(ResultStage 44)
20/02/14 18:41:44 INFO DAGScheduler: failed: Set()
20/02/14 18:41:44 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[284] at count at LinearRegression.scala:930), which has no missing parents
20/02/14 18:41:44 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 10.2 KiB, free 413.5 MiB)
20/02/14 18:41:44 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.5 MiB)
20/02/14 18:41:44 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:64190 (size: 5.0 KiB, free: 413.8 MiB)
20/02/14 18:41:44 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[284] at count at LinearRegression.scala:930) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:44 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
20/02/14 18:41:44 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 59, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 18:41:44 INFO Executor: Running task 0.0 in stage 44.0 (TID 59)
20/02/14 18:41:44 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:41:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:41:44 INFO Executor: Finished task 0.0 in stage 44.0 (TID 59). 2760 bytes result sent to driver
20/02/14 18:41:44 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 59) in 5 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:44 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
20/02/14 18:41:44 INFO DAGScheduler: ResultStage 44 (count at LinearRegression.scala:930) finished in 0.015 s
20/02/14 18:41:44 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:41:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
20/02/14 18:41:44 INFO DAGScheduler: Job 31 finished: count at LinearRegression.scala:930, took 0.037958 s
20/02/14 18:41:44 INFO Instrumentation: [119e8b37] training finished
20/02/14 18:41:44 INFO Instrumentation: [4de8dbb1] training finished
20/02/14 18:41:45 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:64190 in memory (size: 10.9 KiB, free: 413.8 MiB)
20/02/14 18:41:45 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:64190 in memory (size: 5.0 KiB, free: 413.8 MiB)
20/02/14 18:41:45 INFO SparkContext: Starting job: count at <unknown>:0
20/02/14 18:41:45 INFO DAGScheduler: Registering RDD 289 (count at <unknown>:0) as input to shuffle 13
20/02/14 18:41:45 INFO DAGScheduler: Got job 32 (count at <unknown>:0) with 1 output partitions
20/02/14 18:41:45 INFO DAGScheduler: Final stage: ResultStage 46 (count at <unknown>:0)
20/02/14 18:41:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)
20/02/14 18:41:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 45)
20/02/14 18:41:45 INFO DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[289] at count at <unknown>:0), which has no missing parents
20/02/14 18:41:45 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 26.8 KiB, free 413.5 MiB)
20/02/14 18:41:45 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 413.5 MiB)
20/02/14 18:41:45 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:64190 (size: 10.9 KiB, free: 413.8 MiB)
20/02/14 18:41:45 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[289] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:45 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
20/02/14 18:41:45 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 60, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 18:41:45 INFO Executor: Running task 0.0 in stage 45.0 (TID 60)
20/02/14 18:41:45 INFO BlockManager: Found block rdd_207_0 locally
20/02/14 18:41:45 INFO Executor: Finished task 0.0 in stage 45.0 (TID 60). 2369 bytes result sent to driver
20/02/14 18:41:45 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 60) in 12 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:45 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
20/02/14 18:41:45 INFO DAGScheduler: ShuffleMapStage 45 (count at <unknown>:0) finished in 0.017 s
20/02/14 18:41:45 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:41:45 INFO DAGScheduler: running: Set()
20/02/14 18:41:45 INFO DAGScheduler: waiting: Set(ResultStage 46)
20/02/14 18:41:45 INFO DAGScheduler: failed: Set()
20/02/14 18:41:45 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[292] at count at <unknown>:0), which has no missing parents
20/02/14 18:41:45 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 10.2 KiB, free 413.5 MiB)
20/02/14 18:41:45 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.5 MiB)
20/02/14 18:41:45 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:64190 (size: 5.0 KiB, free: 413.8 MiB)
20/02/14 18:41:45 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[292] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:45 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
20/02/14 18:41:45 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 61, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 18:41:45 INFO Executor: Running task 0.0 in stage 46.0 (TID 61)
20/02/14 18:41:45 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:41:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:41:45 INFO Executor: Finished task 0.0 in stage 46.0 (TID 61). 2760 bytes result sent to driver
20/02/14 18:41:45 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 61) in 5 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:45 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
20/02/14 18:41:45 INFO DAGScheduler: ResultStage 46 (count at <unknown>:0) finished in 0.014 s
20/02/14 18:41:45 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:41:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
20/02/14 18:41:45 INFO DAGScheduler: Job 32 finished: count at <unknown>:0, took 0.036436 s
20/02/14 18:41:45 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:64190 in memory (size: 5.0 KiB, free: 413.8 MiB)
20/02/14 18:41:45 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:64190 in memory (size: 10.9 KiB, free: 413.8 MiB)
20/02/14 18:41:45 INFO SparkContext: Starting job: collect at utils.scala:34
20/02/14 18:41:45 INFO DAGScheduler: Got job 33 (collect at utils.scala:34) with 1 output partitions
20/02/14 18:41:45 INFO DAGScheduler: Final stage: ResultStage 47 (collect at utils.scala:34)
20/02/14 18:41:45 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:41:45 INFO DAGScheduler: Missing parents: List()
20/02/14 18:41:45 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[300] at map at utils.scala:34), which has no missing parents
20/02/14 18:41:45 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 46.8 KiB, free 413.5 MiB)
20/02/14 18:41:45 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 413.5 MiB)
20/02/14 18:41:45 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:64190 (size: 19.2 KiB, free: 413.8 MiB)
20/02/14 18:41:45 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[300] at map at utils.scala:34) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:45 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
20/02/14 18:41:45 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 62, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/14 18:41:45 INFO Executor: Running task 0.0 in stage 47.0 (TID 62)
20/02/14 18:41:45 INFO BlockManager: Found block rdd_207_0 locally
20/02/14 18:41:45 INFO Executor: Finished task 0.0 in stage 47.0 (TID 62). 1822 bytes result sent to driver
20/02/14 18:41:45 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 62) in 9 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:45 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
20/02/14 18:41:45 INFO DAGScheduler: ResultStage 47 (collect at utils.scala:34) finished in 0.015 s
20/02/14 18:41:45 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:41:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
20/02/14 18:41:45 INFO DAGScheduler: Job 33 finished: collect at utils.scala:34, took 0.017668 s
20/02/14 18:41:45 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:64190 in memory (size: 19.2 KiB, free: 413.8 MiB)
20/02/14 18:41:46 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 18:41:46 INFO DAGScheduler: Got job 34 (collect at utils.scala:41) with 4 output partitions
20/02/14 18:41:46 INFO DAGScheduler: Final stage: ResultStage 48 (collect at utils.scala:41)
20/02/14 18:41:46 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:41:46 INFO DAGScheduler: Missing parents: List()
20/02/14 18:41:46 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[306] at map at utils.scala:41), which has no missing parents
20/02/14 18:41:46 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 8.8 KiB, free 413.5 MiB)
20/02/14 18:41:46 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.5 MiB)
20/02/14 18:41:46 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:64190 (size: 4.6 KiB, free: 413.8 MiB)
20/02/14 18:41:46 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:46 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 48 (MapPartitionsRDD[306] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 18:41:46 INFO TaskSchedulerImpl: Adding task set 48.0 with 4 tasks
20/02/14 18:41:46 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 63, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7590 bytes)
20/02/14 18:41:46 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 64, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7663 bytes)
20/02/14 18:41:46 INFO TaskSetManager: Starting task 2.0 in stage 48.0 (TID 65, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7663 bytes)
20/02/14 18:41:46 INFO TaskSetManager: Starting task 3.0 in stage 48.0 (TID 66, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7663 bytes)
20/02/14 18:41:46 INFO Executor: Running task 2.0 in stage 48.0 (TID 65)
20/02/14 18:41:46 INFO Executor: Running task 1.0 in stage 48.0 (TID 64)
20/02/14 18:41:46 INFO Executor: Running task 3.0 in stage 48.0 (TID 66)
20/02/14 18:41:46 INFO Executor: Running task 0.0 in stage 48.0 (TID 63)
20/02/14 18:41:46 INFO Executor: Finished task 2.0 in stage 48.0 (TID 65). 1141 bytes result sent to driver
20/02/14 18:41:46 INFO Executor: Finished task 0.0 in stage 48.0 (TID 63). 1053 bytes result sent to driver
20/02/14 18:41:46 INFO Executor: Finished task 1.0 in stage 48.0 (TID 64). 1140 bytes result sent to driver
20/02/14 18:41:46 INFO TaskSetManager: Finished task 2.0 in stage 48.0 (TID 65) in 14 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 18:41:46 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 63) in 15 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 18:41:46 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 64) in 15 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 18:41:46 INFO Executor: Finished task 3.0 in stage 48.0 (TID 66). 1183 bytes result sent to driver
20/02/14 18:41:46 INFO TaskSetManager: Finished task 3.0 in stage 48.0 (TID 66) in 17 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 18:41:46 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
20/02/14 18:41:46 INFO DAGScheduler: ResultStage 48 (collect at utils.scala:41) finished in 0.022 s
20/02/14 18:41:46 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:41:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
20/02/14 18:41:46 INFO DAGScheduler: Job 34 finished: collect at utils.scala:41, took 0.024370 s
20/02/14 18:41:46 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:64190 in memory (size: 4.6 KiB, free: 413.8 MiB)
20/02/14 18:41:46 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/14 18:41:46 INFO DAGScheduler: Registering RDD 315 (sql at <unknown>:0) as input to shuffle 14
20/02/14 18:41:46 INFO DAGScheduler: Got job 35 (sql at <unknown>:0) with 1 output partitions
20/02/14 18:41:46 INFO DAGScheduler: Final stage: ResultStage 50 (sql at <unknown>:0)
20/02/14 18:41:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 49)
20/02/14 18:41:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 49)
20/02/14 18:41:46 INFO DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[315] at sql at <unknown>:0), which has no missing parents
20/02/14 18:41:46 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 18.9 KiB, free 413.5 MiB)
20/02/14 18:41:46 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.5 MiB)
20/02/14 18:41:46 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:64190 (size: 8.2 KiB, free: 413.8 MiB)
20/02/14 18:41:46 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[315] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:46 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
20/02/14 18:41:46 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 67, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 18:41:46 INFO Executor: Running task 0.0 in stage 49.0 (TID 67)
20/02/14 18:41:46 INFO MemoryStore: Block rdd_310_0 stored as values in memory (estimated size 312.0 B, free 413.5 MiB)
20/02/14 18:41:46 INFO BlockManagerInfo: Added rdd_310_0 in memory on 127.0.0.1:64190 (size: 312.0 B, free: 413.8 MiB)
20/02/14 18:41:46 INFO Executor: Finished task 0.0 in stage 49.0 (TID 67). 2283 bytes result sent to driver
20/02/14 18:41:46 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 67) in 18 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:46 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
20/02/14 18:41:46 INFO DAGScheduler: ShuffleMapStage 49 (sql at <unknown>:0) finished in 0.025 s
20/02/14 18:41:46 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:41:46 INFO DAGScheduler: running: Set()
20/02/14 18:41:46 INFO DAGScheduler: waiting: Set(ResultStage 50)
20/02/14 18:41:46 INFO DAGScheduler: failed: Set()
20/02/14 18:41:46 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[318] at sql at <unknown>:0), which has no missing parents
20/02/14 18:41:46 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 10.2 KiB, free 413.5 MiB)
20/02/14 18:41:46 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.5 MiB)
20/02/14 18:41:46 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:64190 (size: 5.0 KiB, free: 413.8 MiB)
20/02/14 18:41:46 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[318] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:46 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
20/02/14 18:41:46 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 68, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 18:41:46 INFO Executor: Running task 0.0 in stage 50.0 (TID 68)
20/02/14 18:41:46 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:41:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:41:46 INFO Executor: Finished task 0.0 in stage 50.0 (TID 68). 2803 bytes result sent to driver
20/02/14 18:41:46 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:64190 in memory (size: 8.2 KiB, free: 413.8 MiB)
20/02/14 18:41:46 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 68) in 12 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:46 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
20/02/14 18:41:46 INFO DAGScheduler: ResultStage 50 (sql at <unknown>:0) finished in 0.017 s
20/02/14 18:41:46 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:41:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished
20/02/14 18:41:46 INFO DAGScheduler: Job 35 finished: sql at <unknown>:0, took 0.048994 s
20/02/14 18:41:46 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:64190 in memory (size: 5.0 KiB, free: 413.8 MiB)
20/02/14 18:41:46 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:41:46 INFO DAGScheduler: Registering RDD 323 (collect at arrowconverters.scala:270) as input to shuffle 15
20/02/14 18:41:46 INFO DAGScheduler: Got job 36 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 18:41:46 INFO DAGScheduler: Final stage: ResultStage 52 (collect at arrowconverters.scala:270)
20/02/14 18:41:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51)
20/02/14 18:41:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 51)
20/02/14 18:41:46 INFO DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[323] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:41:46 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 18.9 KiB, free 413.5 MiB)
20/02/14 18:41:46 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.5 MiB)
20/02/14 18:41:46 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:64190 (size: 8.2 KiB, free: 413.8 MiB)
20/02/14 18:41:46 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[323] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:46 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
20/02/14 18:41:46 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 69, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 18:41:46 INFO Executor: Running task 0.0 in stage 51.0 (TID 69)
20/02/14 18:41:46 INFO BlockManager: Found block rdd_310_0 locally
20/02/14 18:41:46 INFO Executor: Finished task 0.0 in stage 51.0 (TID 69). 2326 bytes result sent to driver
20/02/14 18:41:46 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 69) in 12 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:46 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
20/02/14 18:41:46 INFO DAGScheduler: ShuffleMapStage 51 (collect at arrowconverters.scala:270) finished in 0.018 s
20/02/14 18:41:46 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:41:46 INFO DAGScheduler: running: Set()
20/02/14 18:41:46 INFO DAGScheduler: waiting: Set(ResultStage 52)
20/02/14 18:41:46 INFO DAGScheduler: failed: Set()
20/02/14 18:41:46 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[329] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:41:46 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 28.9 KiB, free 413.5 MiB)
20/02/14 18:41:46 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 12.0 KiB, free 413.5 MiB)
20/02/14 18:41:46 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:64190 (size: 12.0 KiB, free: 413.8 MiB)
20/02/14 18:41:46 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[329] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:46 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
20/02/14 18:41:46 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 70, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 18:41:46 INFO Executor: Running task 0.0 in stage 52.0 (TID 70)
20/02/14 18:41:46 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:41:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:41:46 INFO Executor: Finished task 0.0 in stage 52.0 (TID 70). 4242 bytes result sent to driver
20/02/14 18:41:46 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 70) in 11 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:46 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
20/02/14 18:41:46 INFO DAGScheduler: ResultStage 52 (collect at arrowconverters.scala:270) finished in 0.016 s
20/02/14 18:41:46 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:41:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished
20/02/14 18:41:46 INFO DAGScheduler: Job 36 finished: collect at arrowconverters.scala:270, took 0.042669 s
20/02/14 18:41:46 INFO Instrumentation: [0e76bd61] training finished
20/02/14 18:41:46 INFO Instrumentation: [b1d7a4f2] training finished
20/02/14 18:41:46 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:64190 in memory (size: 8.2 KiB, free: 413.8 MiB)
20/02/14 18:41:46 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:64190 in memory (size: 12.0 KiB, free: 413.8 MiB)
20/02/14 18:41:47 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:41:47 INFO DAGScheduler: Registering RDD 334 (collect at arrowconverters.scala:270) as input to shuffle 16
20/02/14 18:41:47 INFO DAGScheduler: Registering RDD 341 (collect at arrowconverters.scala:270) as input to shuffle 17
20/02/14 18:41:47 INFO DAGScheduler: Got job 37 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/14 18:41:47 INFO DAGScheduler: Final stage: ResultStage 55 (collect at arrowconverters.scala:270)
20/02/14 18:41:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53, ShuffleMapStage 54)
20/02/14 18:41:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 53, ShuffleMapStage 54)
20/02/14 18:41:47 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[334] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:41:47 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 32.1 KiB, free 413.5 MiB)
20/02/14 18:41:47 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 413.5 MiB)
20/02/14 18:41:47 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:64190 (size: 13.4 KiB, free: 413.8 MiB)
20/02/14 18:41:47 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[334] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:47 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
20/02/14 18:41:47 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 71, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 18:41:47 INFO DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[341] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:41:47 INFO Executor: Running task 0.0 in stage 53.0 (TID 71)
20/02/14 18:41:47 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 27.4 KiB, free 413.5 MiB)
20/02/14 18:41:47 INFO BlockManager: Found block rdd_310_0 locally
20/02/14 18:41:47 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.4 MiB)
20/02/14 18:41:47 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:64190 (size: 10.8 KiB, free: 413.8 MiB)
20/02/14 18:41:47 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[341] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:41:47 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
20/02/14 18:41:47 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 72, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 18:41:47 INFO Executor: Running task 0.0 in stage 54.0 (TID 72)
20/02/14 18:41:47 INFO BlockManager: Found block rdd_207_0 locally
20/02/14 18:41:47 INFO Executor: Finished task 0.0 in stage 53.0 (TID 71). 2203 bytes result sent to driver
20/02/14 18:41:47 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 71) in 52 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:47 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
20/02/14 18:41:47 INFO DAGScheduler: ShuffleMapStage 53 (collect at arrowconverters.scala:270) finished in 0.061 s
20/02/14 18:41:47 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:41:47 INFO DAGScheduler: running: Set(ShuffleMapStage 54)
20/02/14 18:41:47 INFO DAGScheduler: waiting: Set(ResultStage 55)
20/02/14 18:41:47 INFO DAGScheduler: failed: Set()
20/02/14 18:41:47 INFO Executor: Finished task 0.0 in stage 54.0 (TID 72). 2246 bytes result sent to driver
20/02/14 18:41:47 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 72) in 50 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:41:47 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
20/02/14 18:41:47 INFO DAGScheduler: ShuffleMapStage 54 (collect at arrowconverters.scala:270) finished in 0.056 s
20/02/14 18:41:47 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:41:47 INFO DAGScheduler: running: Set()
20/02/14 18:41:47 INFO DAGScheduler: waiting: Set(ResultStage 55)
20/02/14 18:41:47 INFO DAGScheduler: failed: Set()
20/02/14 18:41:47 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[349] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:41:47 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 56.3 KiB, free 413.4 MiB)
20/02/14 18:41:47 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 413.4 MiB)
20/02/14 18:41:47 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:64190 (size: 23.0 KiB, free: 413.8 MiB)
20/02/14 18:41:47 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:47 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:64190 in memory (size: 13.4 KiB, free: 413.8 MiB)
20/02/14 18:41:47 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 55 (MapPartitionsRDD[349] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 18:41:47 INFO TaskSchedulerImpl: Adding task set 55.0 with 4 tasks
20/02/14 18:41:47 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 73, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7528 bytes)
20/02/14 18:41:47 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 74, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7528 bytes)
20/02/14 18:41:47 INFO TaskSetManager: Starting task 2.0 in stage 55.0 (TID 75, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7528 bytes)
20/02/14 18:41:47 INFO TaskSetManager: Starting task 3.0 in stage 55.0 (TID 76, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7528 bytes)
20/02/14 18:41:47 INFO Executor: Running task 1.0 in stage 55.0 (TID 74)
20/02/14 18:41:47 INFO Executor: Running task 3.0 in stage 55.0 (TID 76)
20/02/14 18:41:47 INFO Executor: Running task 2.0 in stage 55.0 (TID 75)
20/02/14 18:41:47 INFO Executor: Running task 0.0 in stage 55.0 (TID 73)
20/02/14 18:41:47 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:41:47 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:41:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:41:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:41:47 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:41:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:41:47 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:41:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:41:47 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:41:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:41:47 INFO ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:41:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:41:47 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:41:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
20/02/14 18:41:47 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:41:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
20/02/14 18:41:47 INFO Executor: Finished task 1.0 in stage 55.0 (TID 74). 5790 bytes result sent to driver
20/02/14 18:41:47 INFO Executor: Finished task 2.0 in stage 55.0 (TID 75). 5909 bytes result sent to driver
20/02/14 18:41:47 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 74) in 57 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 18:41:47 INFO TaskSetManager: Finished task 2.0 in stage 55.0 (TID 75) in 57 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 18:41:47 INFO Executor: Finished task 3.0 in stage 55.0 (TID 76). 5807 bytes result sent to driver
20/02/14 18:41:47 INFO TaskSetManager: Finished task 3.0 in stage 55.0 (TID 76) in 59 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 18:41:47 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:64190 in memory (size: 10.8 KiB, free: 413.8 MiB)
20/02/14 18:41:47 INFO Executor: Finished task 0.0 in stage 55.0 (TID 73). 5814 bytes result sent to driver
20/02/14 18:41:47 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 73) in 67 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 18:41:47 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
20/02/14 18:41:47 INFO DAGScheduler: ResultStage 55 (collect at arrowconverters.scala:270) finished in 0.081 s
20/02/14 18:41:47 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:41:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
20/02/14 18:41:47 INFO DAGScheduler: Job 37 finished: collect at arrowconverters.scala:270, took 0.152404 s
20/02/14 18:41:48 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:64190 in memory (size: 23.0 KiB, free: 413.8 MiB)
20/02/14 18:41:48 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:41:48 INFO DAGScheduler: Got job 38 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/14 18:41:48 INFO DAGScheduler: Final stage: ResultStage 56 (collect at arrowconverters.scala:270)
20/02/14 18:41:48 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:41:48 INFO DAGScheduler: Missing parents: List()
20/02/14 18:41:48 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[355] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:41:48 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 11.1 KiB, free 413.5 MiB)
20/02/14 18:41:48 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 413.5 MiB)
20/02/14 18:41:48 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:64190 (size: 5.3 KiB, free: 413.8 MiB)
20/02/14 18:41:48 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1196
20/02/14 18:41:48 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 56 (MapPartitionsRDD[355] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 18:41:48 INFO TaskSchedulerImpl: Adding task set 56.0 with 4 tasks
20/02/14 18:41:48 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 77, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7695 bytes)
20/02/14 18:41:48 INFO TaskSetManager: Starting task 1.0 in stage 56.0 (TID 78, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7711 bytes)
20/02/14 18:41:48 INFO TaskSetManager: Starting task 2.0 in stage 56.0 (TID 79, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7711 bytes)
20/02/14 18:41:48 INFO TaskSetManager: Starting task 3.0 in stage 56.0 (TID 80, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7784 bytes)
20/02/14 18:41:48 INFO Executor: Running task 0.0 in stage 56.0 (TID 77)
20/02/14 18:41:48 INFO Executor: Running task 2.0 in stage 56.0 (TID 79)
20/02/14 18:41:48 INFO Executor: Running task 3.0 in stage 56.0 (TID 80)
20/02/14 18:41:48 INFO Executor: Running task 1.0 in stage 56.0 (TID 78)
20/02/14 18:41:48 INFO Executor: Finished task 1.0 in stage 56.0 (TID 78). 1595 bytes result sent to driver
20/02/14 18:41:48 INFO Executor: Finished task 3.0 in stage 56.0 (TID 80). 1608 bytes result sent to driver
20/02/14 18:41:48 INFO TaskSetManager: Finished task 1.0 in stage 56.0 (TID 78) in 27 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 18:41:48 INFO TaskSetManager: Finished task 3.0 in stage 56.0 (TID 80) in 28 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 18:41:48 INFO Executor: Finished task 2.0 in stage 56.0 (TID 79). 1598 bytes result sent to driver
20/02/14 18:41:48 INFO TaskSetManager: Finished task 2.0 in stage 56.0 (TID 79) in 29 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 18:41:48 INFO Executor: Finished task 0.0 in stage 56.0 (TID 77). 1632 bytes result sent to driver
20/02/14 18:41:48 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 77) in 32 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 18:41:48 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
20/02/14 18:41:48 INFO DAGScheduler: ResultStage 56 (collect at arrowconverters.scala:270) finished in 0.039 s
20/02/14 18:41:48 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:41:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
20/02/14 18:41:48 INFO DAGScheduler: Job 38 finished: collect at arrowconverters.scala:270, took 0.041313 s
20/02/14 18:43:21 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:64190 in memory (size: 5.3 KiB, free: 413.8 MiB)
20/02/14 18:43:21 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/14 18:43:21 INFO DAGScheduler: Got job 39 (collect at utils.scala:41) with 4 output partitions
20/02/14 18:43:21 INFO DAGScheduler: Final stage: ResultStage 57 (collect at utils.scala:41)
20/02/14 18:43:21 INFO DAGScheduler: Parents of final stage: List()
20/02/14 18:43:21 INFO DAGScheduler: Missing parents: List()
20/02/14 18:43:21 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[361] at map at utils.scala:41), which has no missing parents
20/02/14 18:43:21 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 8.8 KiB, free 413.5 MiB)
20/02/14 18:43:21 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.5 MiB)
20/02/14 18:43:21 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:64190 (size: 4.6 KiB, free: 413.8 MiB)
20/02/14 18:43:21 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1196
20/02/14 18:43:21 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 57 (MapPartitionsRDD[361] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 18:43:21 INFO TaskSchedulerImpl: Adding task set 57.0 with 4 tasks
20/02/14 18:43:21 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 81, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7647 bytes)
20/02/14 18:43:21 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 82, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7663 bytes)
20/02/14 18:43:21 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 83, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7663 bytes)
20/02/14 18:43:21 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 84, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7720 bytes)
20/02/14 18:43:21 INFO Executor: Running task 0.0 in stage 57.0 (TID 81)
20/02/14 18:43:21 INFO Executor: Running task 2.0 in stage 57.0 (TID 83)
20/02/14 18:43:21 INFO Executor: Running task 1.0 in stage 57.0 (TID 82)
20/02/14 18:43:21 INFO Executor: Finished task 2.0 in stage 57.0 (TID 83). 1098 bytes result sent to driver
20/02/14 18:43:21 INFO Executor: Finished task 0.0 in stage 57.0 (TID 81). 1080 bytes result sent to driver
20/02/14 18:43:21 INFO Executor: Finished task 1.0 in stage 57.0 (TID 82). 1097 bytes result sent to driver
20/02/14 18:43:21 INFO TaskSetManager: Finished task 2.0 in stage 57.0 (TID 83) in 9 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 18:43:21 INFO Executor: Running task 3.0 in stage 57.0 (TID 84)
20/02/14 18:43:21 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 82) in 10 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 18:43:21 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 81) in 11 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 18:43:21 INFO Executor: Finished task 3.0 in stage 57.0 (TID 84). 1124 bytes result sent to driver
20/02/14 18:43:21 INFO TaskSetManager: Finished task 3.0 in stage 57.0 (TID 84) in 16 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 18:43:21 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
20/02/14 18:43:21 INFO DAGScheduler: ResultStage 57 (collect at utils.scala:41) finished in 0.023 s
20/02/14 18:43:21 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:43:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
20/02/14 18:43:21 INFO DAGScheduler: Job 39 finished: collect at utils.scala:41, took 0.027402 s
20/02/14 18:43:21 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:64190 in memory (size: 4.6 KiB, free: 413.8 MiB)
20/02/14 18:43:21 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/14 18:43:21 INFO DAGScheduler: Registering RDD 370 (sql at <unknown>:0) as input to shuffle 18
20/02/14 18:43:21 INFO DAGScheduler: Got job 40 (sql at <unknown>:0) with 1 output partitions
20/02/14 18:43:21 INFO DAGScheduler: Final stage: ResultStage 59 (sql at <unknown>:0)
20/02/14 18:43:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)
20/02/14 18:43:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 58)
20/02/14 18:43:21 INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[370] at sql at <unknown>:0), which has no missing parents
20/02/14 18:43:21 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 18.9 KiB, free 413.5 MiB)
20/02/14 18:43:21 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.5 MiB)
20/02/14 18:43:21 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:64190 (size: 8.2 KiB, free: 413.8 MiB)
20/02/14 18:43:21 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1196
20/02/14 18:43:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[370] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 18:43:21 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
20/02/14 18:43:21 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 85, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 18:43:21 INFO Executor: Running task 0.0 in stage 58.0 (TID 85)
20/02/14 18:43:21 INFO MemoryStore: Block rdd_365_0 stored as values in memory (estimated size 312.0 B, free 413.5 MiB)
20/02/14 18:43:21 INFO BlockManagerInfo: Added rdd_365_0 in memory on 127.0.0.1:64190 (size: 312.0 B, free: 413.8 MiB)
20/02/14 18:43:21 INFO Executor: Finished task 0.0 in stage 58.0 (TID 85). 2283 bytes result sent to driver
20/02/14 18:43:21 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 85) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:43:21 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
20/02/14 18:43:21 INFO DAGScheduler: ShuffleMapStage 58 (sql at <unknown>:0) finished in 0.027 s
20/02/14 18:43:21 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:43:21 INFO DAGScheduler: running: Set()
20/02/14 18:43:21 INFO DAGScheduler: waiting: Set(ResultStage 59)
20/02/14 18:43:21 INFO DAGScheduler: failed: Set()
20/02/14 18:43:21 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[373] at sql at <unknown>:0), which has no missing parents
20/02/14 18:43:21 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 10.2 KiB, free 413.5 MiB)
20/02/14 18:43:21 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.5 MiB)
20/02/14 18:43:21 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:64190 (size: 5.0 KiB, free: 413.8 MiB)
20/02/14 18:43:21 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1196
20/02/14 18:43:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[373] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/14 18:43:21 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
20/02/14 18:43:21 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 86, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 18:43:21 INFO Executor: Running task 0.0 in stage 59.0 (TID 86)
20/02/14 18:43:21 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:43:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:43:21 INFO Executor: Finished task 0.0 in stage 59.0 (TID 86). 2760 bytes result sent to driver
20/02/14 18:43:21 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 86) in 5 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:43:21 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
20/02/14 18:43:21 INFO DAGScheduler: ResultStage 59 (sql at <unknown>:0) finished in 0.010 s
20/02/14 18:43:21 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:43:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished
20/02/14 18:43:21 INFO DAGScheduler: Job 40 finished: sql at <unknown>:0, took 0.041433 s
20/02/14 18:43:21 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:64190 in memory (size: 8.2 KiB, free: 413.8 MiB)
20/02/14 18:43:21 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:64190 in memory (size: 5.0 KiB, free: 413.8 MiB)
20/02/14 18:43:21 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:43:21 INFO DAGScheduler: Registering RDD 378 (collect at arrowconverters.scala:270) as input to shuffle 19
20/02/14 18:43:21 INFO DAGScheduler: Got job 41 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/14 18:43:21 INFO DAGScheduler: Final stage: ResultStage 61 (collect at arrowconverters.scala:270)
20/02/14 18:43:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 60)
20/02/14 18:43:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 60)
20/02/14 18:43:21 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[378] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:43:21 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 18.9 KiB, free 413.5 MiB)
20/02/14 18:43:21 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.5 MiB)
20/02/14 18:43:21 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:64190 (size: 8.2 KiB, free: 413.8 MiB)
20/02/14 18:43:21 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1196
20/02/14 18:43:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[378] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:43:21 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
20/02/14 18:43:21 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 87, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 18:43:21 INFO Executor: Running task 0.0 in stage 60.0 (TID 87)
20/02/14 18:43:21 INFO BlockManager: Found block rdd_365_0 locally
20/02/14 18:43:21 INFO Executor: Finished task 0.0 in stage 60.0 (TID 87). 2326 bytes result sent to driver
20/02/14 18:43:21 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 87) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:43:21 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
20/02/14 18:43:21 INFO DAGScheduler: ShuffleMapStage 60 (collect at arrowconverters.scala:270) finished in 0.024 s
20/02/14 18:43:21 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:43:21 INFO DAGScheduler: running: Set()
20/02/14 18:43:21 INFO DAGScheduler: waiting: Set(ResultStage 61)
20/02/14 18:43:21 INFO DAGScheduler: failed: Set()
20/02/14 18:43:21 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[384] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:43:21 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 28.9 KiB, free 413.5 MiB)
20/02/14 18:43:21 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 12.0 KiB, free 413.5 MiB)
20/02/14 18:43:21 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:64190 (size: 12.0 KiB, free: 413.8 MiB)
20/02/14 18:43:21 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1196
20/02/14 18:43:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[384] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:43:21 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
20/02/14 18:43:21 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 88, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/14 18:43:21 INFO Executor: Running task 0.0 in stage 61.0 (TID 88)
20/02/14 18:43:21 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:43:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:43:21 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:64190 in memory (size: 8.2 KiB, free: 413.8 MiB)
20/02/14 18:43:21 INFO Executor: Finished task 0.0 in stage 61.0 (TID 88). 4328 bytes result sent to driver
20/02/14 18:43:21 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 88) in 31 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:43:21 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
20/02/14 18:43:21 INFO DAGScheduler: ResultStage 61 (collect at arrowconverters.scala:270) finished in 0.039 s
20/02/14 18:43:21 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:43:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
20/02/14 18:43:21 INFO DAGScheduler: Job 41 finished: collect at arrowconverters.scala:270, took 0.070602 s
20/02/14 18:43:21 INFO Instrumentation: [426736ea] training finished
20/02/14 18:43:22 INFO Instrumentation: [d9882bf4] training finished
20/02/14 18:43:22 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:64190 in memory (size: 12.0 KiB, free: 413.8 MiB)
20/02/14 18:43:22 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/14 18:43:22 INFO DAGScheduler: Registering RDD 396 (collect at arrowconverters.scala:270) as input to shuffle 21
20/02/14 18:43:22 INFO DAGScheduler: Registering RDD 389 (collect at arrowconverters.scala:270) as input to shuffle 20
20/02/14 18:43:22 INFO DAGScheduler: Got job 42 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/14 18:43:22 INFO DAGScheduler: Final stage: ResultStage 64 (collect at arrowconverters.scala:270)
20/02/14 18:43:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63, ShuffleMapStage 62)
20/02/14 18:43:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 63, ShuffleMapStage 62)
20/02/14 18:43:22 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[396] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:43:22 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 27.4 KiB, free 413.5 MiB)
20/02/14 18:43:22 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.5 MiB)
20/02/14 18:43:22 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:64190 (size: 10.8 KiB, free: 413.8 MiB)
20/02/14 18:43:22 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1196
20/02/14 18:43:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[396] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:43:22 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
20/02/14 18:43:22 INFO DAGScheduler: Submitting ShuffleMapStage 63 (MapPartitionsRDD[389] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:43:22 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 89, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/14 18:43:22 INFO Executor: Running task 0.0 in stage 62.0 (TID 89)
20/02/14 18:43:22 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 32.1 KiB, free 413.5 MiB)
20/02/14 18:43:22 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 413.4 MiB)
20/02/14 18:43:22 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:64190 (size: 13.4 KiB, free: 413.8 MiB)
20/02/14 18:43:22 INFO BlockManager: Found block rdd_207_0 locally
20/02/14 18:43:22 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1196
20/02/14 18:43:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 63 (MapPartitionsRDD[389] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/14 18:43:22 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
20/02/14 18:43:22 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 90, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/14 18:43:22 INFO Executor: Running task 0.0 in stage 63.0 (TID 90)
20/02/14 18:43:22 INFO BlockManager: Found block rdd_365_0 locally
20/02/14 18:43:22 INFO Executor: Finished task 0.0 in stage 62.0 (TID 89). 2289 bytes result sent to driver
20/02/14 18:43:22 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 89) in 46 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:43:22 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
20/02/14 18:43:22 INFO DAGScheduler: ShuffleMapStage 62 (collect at arrowconverters.scala:270) finished in 0.052 s
20/02/14 18:43:22 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:43:22 INFO DAGScheduler: running: Set(ShuffleMapStage 63)
20/02/14 18:43:22 INFO DAGScheduler: waiting: Set(ResultStage 64)
20/02/14 18:43:22 INFO DAGScheduler: failed: Set()
20/02/14 18:43:22 INFO Executor: Finished task 0.0 in stage 63.0 (TID 90). 2160 bytes result sent to driver
20/02/14 18:43:22 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 90) in 43 ms on 127.0.0.1 (executor driver) (1/1)
20/02/14 18:43:22 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
20/02/14 18:43:22 INFO DAGScheduler: ShuffleMapStage 63 (collect at arrowconverters.scala:270) finished in 0.056 s
20/02/14 18:43:22 INFO DAGScheduler: looking for newly runnable stages
20/02/14 18:43:22 INFO DAGScheduler: running: Set()
20/02/14 18:43:22 INFO DAGScheduler: waiting: Set(ResultStage 64)
20/02/14 18:43:22 INFO DAGScheduler: failed: Set()
20/02/14 18:43:22 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[404] at collect at arrowconverters.scala:270), which has no missing parents
20/02/14 18:43:22 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 56.3 KiB, free 413.4 MiB)
20/02/14 18:43:22 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 413.4 MiB)
20/02/14 18:43:22 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:64190 (size: 23.0 KiB, free: 413.8 MiB)
20/02/14 18:43:22 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1196
20/02/14 18:43:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 64 (MapPartitionsRDD[404] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/14 18:43:22 INFO TaskSchedulerImpl: Adding task set 64.0 with 4 tasks
20/02/14 18:43:22 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 91, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7528 bytes)
20/02/14 18:43:22 INFO TaskSetManager: Starting task 1.0 in stage 64.0 (TID 92, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7528 bytes)
20/02/14 18:43:22 INFO TaskSetManager: Starting task 2.0 in stage 64.0 (TID 93, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7528 bytes)
20/02/14 18:43:22 INFO TaskSetManager: Starting task 3.0 in stage 64.0 (TID 94, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7528 bytes)
20/02/14 18:43:22 INFO Executor: Running task 1.0 in stage 64.0 (TID 92)
20/02/14 18:43:22 INFO Executor: Running task 2.0 in stage 64.0 (TID 93)
20/02/14 18:43:22 INFO Executor: Running task 3.0 in stage 64.0 (TID 94)
20/02/14 18:43:22 INFO Executor: Running task 0.0 in stage 64.0 (TID 91)
20/02/14 18:43:22 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:43:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:43:22 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:43:22 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:43:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:43:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/14 18:43:22 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:43:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:43:22 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:43:22 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:43:22 INFO ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:43:22 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/14 18:43:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:43:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:43:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:43:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/14 18:43:22 INFO Executor: Finished task 0.0 in stage 64.0 (TID 91). 5857 bytes result sent to driver
20/02/14 18:43:22 INFO Executor: Finished task 2.0 in stage 64.0 (TID 93). 5909 bytes result sent to driver
20/02/14 18:43:22 INFO Executor: Finished task 3.0 in stage 64.0 (TID 94). 5850 bytes result sent to driver
20/02/14 18:43:22 INFO Executor: Finished task 1.0 in stage 64.0 (TID 92). 5833 bytes result sent to driver
20/02/14 18:43:22 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 91) in 58 ms on 127.0.0.1 (executor driver) (1/4)
20/02/14 18:43:22 INFO TaskSetManager: Finished task 2.0 in stage 64.0 (TID 93) in 58 ms on 127.0.0.1 (executor driver) (2/4)
20/02/14 18:43:22 INFO TaskSetManager: Finished task 3.0 in stage 64.0 (TID 94) in 58 ms on 127.0.0.1 (executor driver) (3/4)
20/02/14 18:43:22 INFO TaskSetManager: Finished task 1.0 in stage 64.0 (TID 92) in 59 ms on 127.0.0.1 (executor driver) (4/4)
20/02/14 18:43:22 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
20/02/14 18:43:22 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:64190 in memory (size: 13.4 KiB, free: 413.8 MiB)
20/02/14 18:43:22 INFO DAGScheduler: ResultStage 64 (collect at arrowconverters.scala:270) finished in 0.066 s
20/02/14 18:43:22 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/14 18:43:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished
20/02/14 18:43:22 INFO DAGScheduler: Job 42 finished: collect at arrowconverters.scala:270, took 0.134039 s
20/02/14 18:43:22 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:64190 in memory (size: 10.8 KiB, free: 413.8 MiB)
20/02/14 19:05:10 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:64190 in memory (size: 22.9 KiB, free: 413.8 MiB)
20/02/14 19:05:10 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:64190 in memory (size: 23.0 KiB, free: 413.8 MiB)
20/02/14 19:05:10 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:64190 in memory (size: 17.6 KiB, free: 413.9 MiB)
20/02/14 19:05:10 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:64190 in memory (size: 68.8 KiB, free: 413.9 MiB)

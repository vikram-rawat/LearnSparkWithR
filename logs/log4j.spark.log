20/02/17 10:12:32 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:922)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:211)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1960)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:219)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
20/02/17 10:12:50 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:38)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)
	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:922)
	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:211)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1960)
	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.runAndReset(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(Unknown Source)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:219)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 more
20/02/17 10:12:54 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
20/02/17 10:12:55 WARN NettyRpcEnv: Ignored message: HeartbeatResponse(false)
20/02/17 10:38:43 INFO CodeGenerator: Code generated in 35.6584 ms
20/02/17 10:38:43 INFO CodeGenerator: Code generated in 31.3649 ms
20/02/17 10:38:43 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/17 10:38:43 INFO DAGScheduler: Registering RDD 409 (collect at arrowconverters.scala:270) as input to shuffle 22
20/02/17 10:38:43 INFO DAGScheduler: Got job 43 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/17 10:38:43 INFO DAGScheduler: Final stage: ResultStage 66 (collect at arrowconverters.scala:270)
20/02/17 10:38:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
20/02/17 10:38:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 65)
20/02/17 10:38:43 INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[409] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 10:38:43 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 32.1 KiB, free 413.9 MiB)
20/02/17 10:38:43 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 11.4 KiB, free 413.9 MiB)
20/02/17 10:38:43 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:64190 (size: 11.4 KiB, free: 413.9 MiB)
20/02/17 10:38:43 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1196
20/02/17 10:38:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[409] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 10:38:44 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
20/02/17 10:38:44 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 95, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/17 10:38:44 INFO Executor: Running task 0.0 in stage 65.0 (TID 95)
20/02/17 10:38:44 INFO BlockManager: Found block rdd_207_0 locally
20/02/17 10:38:44 INFO Executor: Finished task 0.0 in stage 65.0 (TID 95). 2243 bytes result sent to driver
20/02/17 10:38:44 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 95) in 90 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 10:38:44 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
20/02/17 10:38:44 INFO DAGScheduler: ShuffleMapStage 65 (collect at arrowconverters.scala:270) finished in 0.150 s
20/02/17 10:38:44 INFO DAGScheduler: looking for newly runnable stages
20/02/17 10:38:44 INFO DAGScheduler: running: Set()
20/02/17 10:38:44 INFO DAGScheduler: waiting: Set(ResultStage 66)
20/02/17 10:38:44 INFO DAGScheduler: failed: Set()
20/02/17 10:38:44 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[415] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 10:38:44 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 35.6 KiB, free 413.8 MiB)
20/02/17 10:38:44 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 14.2 KiB, free 413.8 MiB)
20/02/17 10:38:44 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:64190 (size: 14.2 KiB, free: 413.9 MiB)
20/02/17 10:38:44 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1196
20/02/17 10:38:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[415] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 10:38:44 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
20/02/17 10:38:44 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 96, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/17 10:38:44 INFO Executor: Running task 0.0 in stage 66.0 (TID 96)
20/02/17 10:38:44 INFO ShuffleBlockFetcherIterator: Getting 1 (1399.0 B) non-empty blocks including 1 (1399.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 10:38:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 10:38:44 INFO CodeGenerator: Code generated in 21.3321 ms
20/02/17 10:38:44 INFO CodeGenerator: Code generated in 53.9098 ms
20/02/17 10:38:44 INFO Executor: Finished task 0.0 in stage 66.0 (TID 96). 4705 bytes result sent to driver
20/02/17 10:38:44 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 96) in 209 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 10:38:44 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
20/02/17 10:38:44 INFO DAGScheduler: ResultStage 66 (collect at arrowconverters.scala:270) finished in 0.221 s
20/02/17 10:38:44 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 10:38:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished
20/02/17 10:38:44 INFO DAGScheduler: Job 43 finished: collect at arrowconverters.scala:270, took 0.383371 s
20/02/17 11:03:10 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:64190 in memory (size: 14.2 KiB, free: 413.9 MiB)
20/02/17 11:03:10 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:64190 in memory (size: 11.4 KiB, free: 413.9 MiB)
20/02/17 11:21:07 INFO SparkContext: Invoking stop() from shutdown hook
20/02/17 11:21:07 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
20/02/17 11:21:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/02/17 11:21:07 INFO MemoryStore: MemoryStore cleared
20/02/17 11:21:07 INFO BlockManager: BlockManager stopped
20/02/17 11:21:07 INFO BlockManagerMaster: BlockManagerMaster stopped
20/02/17 11:21:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/02/17 11:21:07 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-c371b7d1-f023-45c5-bcb5-0fe7985860de\userFiles-fb471d7b-10f9-4dfb-b674-1f49d2612d05
java.io.IOException: Failed to delete: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-c371b7d1-f023-45c5-bcb5-0fe7985860de\userFiles-fb471d7b-10f9-4dfb-b674-1f49d2612d05\sparklyr-3.0.0-preview-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext.$anonfun$stop$21(SparkContext.scala:2008)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2008)
	at org.apache.spark.SparkContext.$anonfun$new$33(SparkContext.scala:632)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1960)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
20/02/17 11:21:07 INFO SparkContext: Successfully stopped SparkContext
20/02/17 11:21:07 INFO ShutdownHookManager: Shutdown hook called
20/02/17 11:21:07 INFO ShutdownHookManager: Deleting directory C:\Users\Gigabyte\AppData\Local\Temp\spark-225ad4db-79dc-47f9-a572-1424e0793596
20/02/17 11:21:07 INFO ShutdownHookManager: Deleting directory C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-c371b7d1-f023-45c5-bcb5-0fe7985860de
20/02/17 11:21:07 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-c371b7d1-f023-45c5-bcb5-0fe7985860de
java.io.IOException: Failed to delete: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-c371b7d1-f023-45c5-bcb5-0fe7985860de\userFiles-fb471d7b-10f9-4dfb-b674-1f49d2612d05\sparklyr-3.0.0-preview-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1960)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
20/02/17 11:21:07 INFO ShutdownHookManager: Deleting directory C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-c371b7d1-f023-45c5-bcb5-0fe7985860de\userFiles-fb471d7b-10f9-4dfb-b674-1f49d2612d05
20/02/17 11:21:07 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-c371b7d1-f023-45c5-bcb5-0fe7985860de\userFiles-fb471d7b-10f9-4dfb-b674-1f49d2612d05
java.io.IOException: Failed to delete: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-c371b7d1-f023-45c5-bcb5-0fe7985860de\userFiles-fb471d7b-10f9-4dfb-b674-1f49d2612d05\sparklyr-3.0.0-preview-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1960)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
20/02/17 14:53:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/17 14:53:06 INFO SecurityManager: Changing view acls to: Gigabyte
20/02/17 14:53:06 INFO SecurityManager: Changing modify acls to: Gigabyte
20/02/17 14:53:06 INFO SecurityManager: Changing view acls groups to: 
20/02/17 14:53:06 INFO SecurityManager: Changing modify acls groups to: 
20/02/17 14:53:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Gigabyte); groups with view permissions: Set(); users  with modify permissions: Set(Gigabyte); groups with modify permissions: Set()
20/02/17 14:53:07 INFO SparkContext: Running Spark version 3.0.0-preview
20/02/17 14:53:07 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
20/02/17 14:53:08 INFO ResourceUtils: ==============================================================
20/02/17 14:53:08 INFO ResourceUtils: Resources for spark.driver:

20/02/17 14:53:08 INFO ResourceUtils: ==============================================================
20/02/17 14:53:08 INFO SparkContext: Submitted application: sparklyr
20/02/17 14:53:08 INFO SecurityManager: Changing view acls to: Gigabyte
20/02/17 14:53:08 INFO SecurityManager: Changing modify acls to: Gigabyte
20/02/17 14:53:08 INFO SecurityManager: Changing view acls groups to: 
20/02/17 14:53:08 INFO SecurityManager: Changing modify acls groups to: 
20/02/17 14:53:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Gigabyte); groups with view permissions: Set(); users  with modify permissions: Set(Gigabyte); groups with modify permissions: Set()
20/02/17 14:53:08 INFO Utils: Successfully started service 'sparkDriver' on port 54038.
20/02/17 14:53:08 INFO SparkEnv: Registering MapOutputTracker
20/02/17 14:53:08 INFO SparkEnv: Registering BlockManagerMaster
20/02/17 14:53:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/17 14:53:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/17 14:53:08 INFO DiskBlockManager: Created local directory at C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\blockmgr-af9b56e0-0dab-4bb6-8d51-ed1cfe91214b
20/02/17 14:53:08 INFO MemoryStore: MemoryStore started with capacity 413.9 MiB
20/02/17 14:53:08 INFO SparkEnv: Registering OutputCommitCoordinator
20/02/17 14:53:08 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/local]. Please check your configured local directories.
20/02/17 14:53:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/02/17 14:53:08 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
20/02/17 14:53:08 INFO SparkContext: Added JAR file:/C:/Users/Gigabyte/Documents/R/win-library/3.6/sparklyr/java/sparklyr-3.0.0-preview-2.12.jar at spark://127.0.0.1:54038/jars/sparklyr-3.0.0-preview-2.12.jar with timestamp 1581931388936
20/02/17 14:53:09 INFO Executor: Starting executor ID driver on host 127.0.0.1
20/02/17 14:53:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54067.
20/02/17 14:53:09 INFO NettyBlockTransferService: Server created on 127.0.0.1:54067
20/02/17 14:53:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/17 14:53:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 54067, None)
20/02/17 14:53:09 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:54067 with 413.9 MiB RAM, BlockManagerId(driver, 127.0.0.1, 54067, None)
20/02/17 14:53:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 54067, None)
20/02/17 14:53:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 54067, None)
20/02/17 14:53:10 INFO SharedState: loading hive config file: file:/C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/conf/hive-site.xml
20/02/17 14:53:10 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/hive').
20/02/17 14:53:10 INFO SharedState: Warehouse path is 'C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/hive'.
20/02/17 14:53:10 WARN SharedState: Not allowing to set spark.sql.warehouse.dir or hive.metastore.warehouse.dir in SparkSession's options, it should be set statically for cross-session usages
20/02/17 14:53:14 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/17 14:53:14 INFO DAGScheduler: Got job 0 (collect at utils.scala:41) with 1 output partitions
20/02/17 14:53:14 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:41)
20/02/17 14:53:14 INFO DAGScheduler: Parents of final stage: List()
20/02/17 14:53:14 INFO DAGScheduler: Missing parents: List()
20/02/17 14:53:14 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:41), which has no missing parents
20/02/17 14:53:14 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
20/02/17 14:53:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.8 KiB, free 413.9 MiB)
20/02/17 14:53:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.9 MiB)
20/02/17 14:53:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:54067 (size: 4.6 KiB, free: 413.9 MiB)
20/02/17 14:53:15 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
20/02/17 14:53:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7374 bytes)
20/02/17 14:53:15 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/02/17 14:53:15 INFO Executor: Fetching spark://127.0.0.1:54038/jars/sparklyr-3.0.0-preview-2.12.jar with timestamp 1581931388936
20/02/17 14:53:15 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:54038 after 38 ms (0 ms spent in bootstraps)
20/02/17 14:53:15 INFO Utils: Fetching spark://127.0.0.1:54038/jars/sparklyr-3.0.0-preview-2.12.jar to C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-b9ea26cd-8ded-43da-b84d-8b1d8233d9ed\userFiles-23780591-f122-47a5-892e-1a46f08fde58\fetchFileTemp1840628112754489140.tmp
20/02/17 14:53:15 INFO Executor: Adding file:/C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/local/spark-b9ea26cd-8ded-43da-b84d-8b1d8233d9ed/userFiles-23780591-f122-47a5-892e-1a46f08fde58/sparklyr-3.0.0-preview-2.12.jar to class loader
20/02/17 14:53:16 INFO CodeGenerator: Code generated in 228.6154 ms
20/02/17 14:53:16 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1146 bytes result sent to driver
20/02/17 14:53:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1391 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:16 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/02/17 14:53:16 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:41) finished in 1.603 s
20/02/17 14:53:16 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 14:53:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
20/02/17 14:53:16 INFO DAGScheduler: Job 0 finished: collect at utils.scala:41, took 1.662296 s
20/02/17 14:53:17 INFO CodeGenerator: Code generated in 16.575 ms
20/02/17 14:53:17 INFO CodeGenerator: Code generated in 16.3126 ms
20/02/17 14:53:17 INFO CodeGenerator: Code generated in 30.7331 ms
20/02/17 14:53:17 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/17 14:53:17 INFO DAGScheduler: Registering RDD 14 (sql at <unknown>:0) as input to shuffle 0
20/02/17 14:53:17 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
20/02/17 14:53:17 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
20/02/17 14:53:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
20/02/17 14:53:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
20/02/17 14:53:17 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[14] at sql at <unknown>:0), which has no missing parents
20/02/17 14:53:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 26.8 KiB, free 413.9 MiB)
20/02/17 14:53:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.9 MiB)
20/02/17 14:53:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:54067 (size: 10.8 KiB, free: 413.9 MiB)
20/02/17 14:53:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[14] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:17 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
20/02/17 14:53:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/17 14:53:17 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
20/02/17 14:53:17 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 3.9 KiB, free 413.9 MiB)
20/02/17 14:53:17 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:54067 (size: 3.9 KiB, free: 413.9 MiB)
20/02/17 14:53:17 INFO CodeGenerator: Code generated in 4.167 ms
20/02/17 14:53:17 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2412 bytes result sent to driver
20/02/17 14:53:17 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 430 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:17 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/02/17 14:53:17 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.453 s
20/02/17 14:53:17 INFO DAGScheduler: looking for newly runnable stages
20/02/17 14:53:17 INFO DAGScheduler: running: Set()
20/02/17 14:53:17 INFO DAGScheduler: waiting: Set(ResultStage 2)
20/02/17 14:53:17 INFO DAGScheduler: failed: Set()
20/02/17 14:53:17 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at sql at <unknown>:0), which has no missing parents
20/02/17 14:53:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/17 14:53:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
20/02/17 14:53:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:54067 (size: 5.0 KiB, free: 413.9 MiB)
20/02/17 14:53:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:17 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
20/02/17 14:53:17 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/17 14:53:17 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
20/02/17 14:53:17 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 14:53:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
20/02/17 14:53:17 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2889 bytes result sent to driver
20/02/17 14:53:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 99 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:17 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/02/17 14:53:17 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0.113 s
20/02/17 14:53:17 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 14:53:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
20/02/17 14:53:17 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.605437 s
20/02/17 14:53:18 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:54067 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/17 14:53:18 INFO CodeGenerator: Code generated in 6.7013 ms
20/02/17 14:53:18 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/17 14:53:18 INFO DAGScheduler: Registering RDD 22 (collect at arrowconverters.scala:270) as input to shuffle 1
20/02/17 14:53:18 INFO DAGScheduler: Got job 2 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/17 14:53:18 INFO DAGScheduler: Final stage: ResultStage 4 (collect at arrowconverters.scala:270)
20/02/17 14:53:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
20/02/17 14:53:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
20/02/17 14:53:18 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[22] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 14:53:18 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 26.8 KiB, free 413.8 MiB)
20/02/17 14:53:18 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.8 MiB)
20/02/17 14:53:18 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:54067 (size: 10.8 KiB, free: 413.9 MiB)
20/02/17 14:53:18 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[22] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:18 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
20/02/17 14:53:18 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/17 14:53:18 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
20/02/17 14:53:18 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 14:53:18 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2326 bytes result sent to driver
20/02/17 14:53:18 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 19 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:18 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
20/02/17 14:53:18 INFO DAGScheduler: ShuffleMapStage 3 (collect at arrowconverters.scala:270) finished in 0.027 s
20/02/17 14:53:18 INFO DAGScheduler: looking for newly runnable stages
20/02/17 14:53:18 INFO DAGScheduler: running: Set()
20/02/17 14:53:18 INFO DAGScheduler: waiting: Set(ResultStage 4)
20/02/17 14:53:18 INFO DAGScheduler: failed: Set()
20/02/17 14:53:18 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[28] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 14:53:18 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 36.7 KiB, free 413.8 MiB)
20/02/17 14:53:18 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 413.8 MiB)
20/02/17 14:53:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:54067 (size: 15.6 KiB, free: 413.9 MiB)
20/02/17 14:53:18 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[28] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:18 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
20/02/17 14:53:18 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/17 14:53:18 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
20/02/17 14:53:18 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 14:53:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 14:53:18 INFO CodeGenerator: Code generated in 5.5713 ms
20/02/17 14:53:18 INFO CodeGenerator: Code generated in 20.1739 ms
20/02/17 14:53:18 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:54067 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/17 14:53:18 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 4372 bytes result sent to driver
20/02/17 14:53:18 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 80 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:18 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
20/02/17 14:53:18 INFO DAGScheduler: ResultStage 4 (collect at arrowconverters.scala:270) finished in 0.094 s
20/02/17 14:53:18 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 14:53:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
20/02/17 14:53:18 INFO DAGScheduler: Job 2 finished: collect at arrowconverters.scala:270, took 0.129983 s
20/02/17 14:53:18 INFO CodeGenerator: Code generated in 7.4017 ms
20/02/17 14:53:19 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:54067 in memory (size: 15.6 KiB, free: 413.9 MiB)
20/02/17 14:53:19 INFO CodeGenerator: Code generated in 31.2026 ms
20/02/17 14:53:19 INFO CodeGenerator: Code generated in 63.5535 ms
20/02/17 14:53:19 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:54067 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/17 14:53:19 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:54067 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/17 14:53:19 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/17 14:53:19 INFO DAGScheduler: Registering RDD 33 (collect at arrowconverters.scala:270) as input to shuffle 2
20/02/17 14:53:19 INFO DAGScheduler: Got job 3 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/17 14:53:19 INFO DAGScheduler: Final stage: ResultStage 6 (collect at arrowconverters.scala:270)
20/02/17 14:53:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
20/02/17 14:53:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
20/02/17 14:53:19 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[33] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 14:53:19 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 45.3 KiB, free 413.9 MiB)
20/02/17 14:53:19 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 18.3 KiB, free 413.9 MiB)
20/02/17 14:53:19 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:54067 (size: 18.3 KiB, free: 413.9 MiB)
20/02/17 14:53:19 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[33] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:19 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
20/02/17 14:53:19 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/17 14:53:19 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
20/02/17 14:53:19 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 14:53:19 INFO CodeGenerator: Code generated in 6.3386 ms
20/02/17 14:53:19 INFO CodeGenerator: Code generated in 6.0665 ms
20/02/17 14:53:19 INFO CodeGenerator: Code generated in 7.2521 ms
20/02/17 14:53:19 INFO CodeGenerator: Code generated in 10.1383 ms
20/02/17 14:53:19 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2756 bytes result sent to driver
20/02/17 14:53:19 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 149 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:19 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
20/02/17 14:53:19 INFO DAGScheduler: ShuffleMapStage 5 (collect at arrowconverters.scala:270) finished in 0.165 s
20/02/17 14:53:19 INFO DAGScheduler: looking for newly runnable stages
20/02/17 14:53:19 INFO DAGScheduler: running: Set()
20/02/17 14:53:19 INFO DAGScheduler: waiting: Set(ResultStage 6)
20/02/17 14:53:19 INFO DAGScheduler: failed: Set()
20/02/17 14:53:19 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[39] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 14:53:19 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 42.4 KiB, free 413.8 MiB)
20/02/17 14:53:19 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 413.8 MiB)
20/02/17 14:53:19 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:54067 (size: 17.6 KiB, free: 413.9 MiB)
20/02/17 14:53:19 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:19 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 6 (MapPartitionsRDD[39] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/17 14:53:19 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
20/02/17 14:53:19 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/17 14:53:19 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 7, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7248 bytes)
20/02/17 14:53:19 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 8, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7248 bytes)
20/02/17 14:53:19 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 9, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7248 bytes)
20/02/17 14:53:19 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
20/02/17 14:53:19 INFO Executor: Running task 2.0 in stage 6.0 (TID 8)
20/02/17 14:53:19 INFO Executor: Running task 3.0 in stage 6.0 (TID 9)
20/02/17 14:53:19 INFO Executor: Running task 1.0 in stage 6.0 (TID 7)
20/02/17 14:53:19 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 14:53:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 14:53:19 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 14:53:19 INFO ShuffleBlockFetcherIterator: Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 14:53:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/17 14:53:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 14:53:19 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 14:53:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 14:53:19 INFO CodeGenerator: Code generated in 10.4381 ms
20/02/17 14:53:19 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:54067 in memory (size: 18.3 KiB, free: 413.9 MiB)
20/02/17 14:53:19 INFO CodeGenerator: Code generated in 53.3947 ms
20/02/17 14:53:19 INFO Executor: Finished task 1.0 in stage 6.0 (TID 7). 4498 bytes result sent to driver
20/02/17 14:53:19 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 4483 bytes result sent to driver
20/02/17 14:53:19 INFO Executor: Finished task 2.0 in stage 6.0 (TID 8). 4547 bytes result sent to driver
20/02/17 14:53:19 INFO Executor: Finished task 3.0 in stage 6.0 (TID 9). 4458 bytes result sent to driver
20/02/17 14:53:19 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 152 ms on 127.0.0.1 (executor driver) (1/4)
20/02/17 14:53:19 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 7) in 152 ms on 127.0.0.1 (executor driver) (2/4)
20/02/17 14:53:19 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 8) in 154 ms on 127.0.0.1 (executor driver) (3/4)
20/02/17 14:53:19 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 9) in 153 ms on 127.0.0.1 (executor driver) (4/4)
20/02/17 14:53:19 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
20/02/17 14:53:19 INFO DAGScheduler: ResultStage 6 (collect at arrowconverters.scala:270) finished in 0.162 s
20/02/17 14:53:19 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 14:53:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
20/02/17 14:53:19 INFO DAGScheduler: Job 3 finished: collect at arrowconverters.scala:270, took 0.336044 s
20/02/17 14:53:20 INFO CodeGenerator: Code generated in 5.4237 ms
20/02/17 14:53:20 INFO CodeGenerator: Code generated in 7.2524 ms
20/02/17 14:53:20 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/17 14:53:20 INFO DAGScheduler: Got job 4 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/17 14:53:20 INFO DAGScheduler: Final stage: ResultStage 7 (collect at arrowconverters.scala:270)
20/02/17 14:53:20 INFO DAGScheduler: Parents of final stage: List()
20/02/17 14:53:20 INFO DAGScheduler: Missing parents: List()
20/02/17 14:53:20 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[47] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 14:53:20 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 29.9 KiB, free 413.8 MiB)
20/02/17 14:53:20 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 413.8 MiB)
20/02/17 14:53:20 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:54067 (size: 11.2 KiB, free: 413.9 MiB)
20/02/17 14:53:20 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[47] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:20 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
20/02/17 14:53:20 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/17 14:53:20 INFO Executor: Running task 0.0 in stage 7.0 (TID 10)
20/02/17 14:53:20 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 14:53:20 INFO CodeGenerator: Code generated in 7.376 ms
20/02/17 14:53:20 INFO CodeGenerator: Code generated in 10.4565 ms
20/02/17 14:53:20 INFO Executor: Finished task 0.0 in stage 7.0 (TID 10). 2342 bytes result sent to driver
20/02/17 14:53:20 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 43 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:20 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
20/02/17 14:53:20 INFO DAGScheduler: ResultStage 7 (collect at arrowconverters.scala:270) finished in 0.051 s
20/02/17 14:53:20 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 14:53:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
20/02/17 14:53:20 INFO DAGScheduler: Job 4 finished: collect at arrowconverters.scala:270, took 0.054739 s
20/02/17 14:53:20 WARN ProcfsMetricsGetter: Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
20/02/17 14:53:21 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:54067 in memory (size: 11.2 KiB, free: 413.9 MiB)
20/02/17 14:53:22 INFO Instrumentation: [83aa3e62] training finished
20/02/17 14:53:22 INFO Instrumentation: [132f3953] training finished
20/02/17 14:53:22 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:54067 in memory (size: 17.6 KiB, free: 413.9 MiB)
20/02/17 14:53:22 INFO CodeGenerator: Code generated in 18.6246 ms
20/02/17 14:53:22 INFO SparkContext: Starting job: first at LinearRegression.scala:321
20/02/17 14:53:22 INFO DAGScheduler: Got job 5 (first at LinearRegression.scala:321) with 1 output partitions
20/02/17 14:53:22 INFO DAGScheduler: Final stage: ResultStage 8 (first at LinearRegression.scala:321)
20/02/17 14:53:22 INFO DAGScheduler: Parents of final stage: List()
20/02/17 14:53:22 INFO DAGScheduler: Missing parents: List()
20/02/17 14:53:22 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[52] at first at LinearRegression.scala:321), which has no missing parents
20/02/17 14:53:22 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 36.0 KiB, free 413.9 MiB)
20/02/17 14:53:22 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 413.9 MiB)
20/02/17 14:53:22 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:54067 (size: 13.4 KiB, free: 413.9 MiB)
20/02/17 14:53:22 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[52] at first at LinearRegression.scala:321) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:22 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
20/02/17 14:53:22 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 11, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/17 14:53:22 INFO Executor: Running task 0.0 in stage 8.0 (TID 11)
20/02/17 14:53:22 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 14:53:22 INFO Executor: 1 block locks were not released by TID = 11:
[rdd_9_0]
20/02/17 14:53:22 INFO Executor: Finished task 0.0 in stage 8.0 (TID 11). 1881 bytes result sent to driver
20/02/17 14:53:22 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 11) in 70 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:22 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
20/02/17 14:53:22 INFO DAGScheduler: ResultStage 8 (first at LinearRegression.scala:321) finished in 0.080 s
20/02/17 14:53:22 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 14:53:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
20/02/17 14:53:22 INFO DAGScheduler: Job 5 finished: first at LinearRegression.scala:321, took 0.082150 s
20/02/17 14:53:22 INFO CodeGenerator: Code generated in 7.9123 ms
20/02/17 14:53:22 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:54067 in memory (size: 13.4 KiB, free: 413.9 MiB)
20/02/17 14:53:22 INFO CodeGenerator: Code generated in 15.2597 ms
20/02/17 14:53:22 INFO Instrumentation: [a870dd64] Stage class: LinearRegression
20/02/17 14:53:22 INFO Instrumentation: [a870dd64] Stage uid: linear_regression_3f0060014388
20/02/17 14:53:22 INFO CodeGenerator: Code generated in 19.4354 ms
20/02/17 14:53:23 INFO Instrumentation: [a870dd64] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
20/02/17 14:53:23 INFO Instrumentation: [a870dd64] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
20/02/17 14:53:23 INFO Instrumentation: [a870dd64] {"numFeatures":1}
20/02/17 14:53:23 WARN Instrumentation: [a870dd64] regParam is zero, which might cause numerical instability and overfitting.
20/02/17 14:53:23 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:105
20/02/17 14:53:23 INFO DAGScheduler: Got job 6 (treeAggregate at WeightedLeastSquares.scala:105) with 1 output partitions
20/02/17 14:53:23 INFO DAGScheduler: Final stage: ResultStage 9 (treeAggregate at WeightedLeastSquares.scala:105)
20/02/17 14:53:23 INFO DAGScheduler: Parents of final stage: List()
20/02/17 14:53:23 INFO DAGScheduler: Missing parents: List()
20/02/17 14:53:23 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[68] at treeAggregate at WeightedLeastSquares.scala:105), which has no missing parents
20/02/17 14:53:23 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 44.5 KiB, free 413.9 MiB)
20/02/17 14:53:23 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 17.4 KiB, free 413.9 MiB)
20/02/17 14:53:23 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:54067 (size: 17.4 KiB, free: 413.9 MiB)
20/02/17 14:53:23 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[68] at treeAggregate at WeightedLeastSquares.scala:105) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:23 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
20/02/17 14:53:23 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 12, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/17 14:53:23 INFO Executor: Running task 0.0 in stage 9.0 (TID 12)
20/02/17 14:53:23 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 14:53:23 INFO CodeGenerator: Code generated in 6.4682 ms
20/02/17 14:53:23 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
20/02/17 14:53:23 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
20/02/17 14:53:23 INFO Executor: Finished task 0.0 in stage 9.0 (TID 12). 2082 bytes result sent to driver
20/02/17 14:53:23 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 12) in 65 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:23 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
20/02/17 14:53:23 INFO DAGScheduler: ResultStage 9 (treeAggregate at WeightedLeastSquares.scala:105) finished in 0.087 s
20/02/17 14:53:23 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 14:53:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
20/02/17 14:53:23 INFO DAGScheduler: Job 6 finished: treeAggregate at WeightedLeastSquares.scala:105, took 0.092569 s
20/02/17 14:53:23 INFO Instrumentation: [a870dd64] Number of instances: 32.
20/02/17 14:53:23 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
20/02/17 14:53:23 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
20/02/17 14:53:23 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:54067 in memory (size: 17.4 KiB, free: 413.9 MiB)
20/02/17 14:53:23 INFO CodeGenerator: Code generated in 12.7349 ms
20/02/17 14:53:23 INFO SparkContext: Starting job: treeAggregate at RegressionMetrics.scala:68
20/02/17 14:53:23 INFO DAGScheduler: Got job 7 (treeAggregate at RegressionMetrics.scala:68) with 1 output partitions
20/02/17 14:53:23 INFO DAGScheduler: Final stage: ResultStage 10 (treeAggregate at RegressionMetrics.scala:68)
20/02/17 14:53:23 INFO DAGScheduler: Parents of final stage: List()
20/02/17 14:53:23 INFO DAGScheduler: Missing parents: List()
20/02/17 14:53:23 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[78] at treeAggregate at RegressionMetrics.scala:68), which has no missing parents
20/02/17 14:53:23 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 46.2 KiB, free 413.9 MiB)
20/02/17 14:53:23 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 413.9 MiB)
20/02/17 14:53:23 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:54067 (size: 18.9 KiB, free: 413.9 MiB)
20/02/17 14:53:23 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[78] at treeAggregate at RegressionMetrics.scala:68) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:23 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
20/02/17 14:53:23 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/17 14:53:23 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
20/02/17 14:53:23 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 14:53:23 INFO CodeGenerator: Code generated in 5.4066 ms
20/02/17 14:53:23 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 2199 bytes result sent to driver
20/02/17 14:53:23 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 36 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:23 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
20/02/17 14:53:23 INFO DAGScheduler: ResultStage 10 (treeAggregate at RegressionMetrics.scala:68) finished in 0.045 s
20/02/17 14:53:23 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 14:53:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
20/02/17 14:53:23 INFO DAGScheduler: Job 7 finished: treeAggregate at RegressionMetrics.scala:68, took 0.050167 s
20/02/17 14:53:23 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:54067 in memory (size: 18.9 KiB, free: 413.9 MiB)
20/02/17 14:53:23 INFO SparkContext: Starting job: count at LinearRegression.scala:930
20/02/17 14:53:23 INFO DAGScheduler: Registering RDD 83 (count at LinearRegression.scala:930) as input to shuffle 3
20/02/17 14:53:23 INFO DAGScheduler: Got job 8 (count at LinearRegression.scala:930) with 1 output partitions
20/02/17 14:53:23 INFO DAGScheduler: Final stage: ResultStage 12 (count at LinearRegression.scala:930)
20/02/17 14:53:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
20/02/17 14:53:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
20/02/17 14:53:23 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[83] at count at LinearRegression.scala:930), which has no missing parents
20/02/17 14:53:23 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 26.9 KiB, free 413.9 MiB)
20/02/17 14:53:23 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 413.9 MiB)
20/02/17 14:53:23 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:54067 (size: 10.9 KiB, free: 413.9 MiB)
20/02/17 14:53:23 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[83] at count at LinearRegression.scala:930) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:23 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
20/02/17 14:53:23 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 14, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/17 14:53:23 INFO Executor: Running task 0.0 in stage 11.0 (TID 14)
20/02/17 14:53:23 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 14:53:23 INFO Executor: Finished task 0.0 in stage 11.0 (TID 14). 2369 bytes result sent to driver
20/02/17 14:53:23 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 14) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:23 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
20/02/17 14:53:23 INFO DAGScheduler: ShuffleMapStage 11 (count at LinearRegression.scala:930) finished in 0.024 s
20/02/17 14:53:23 INFO DAGScheduler: looking for newly runnable stages
20/02/17 14:53:23 INFO DAGScheduler: running: Set()
20/02/17 14:53:23 INFO DAGScheduler: waiting: Set(ResultStage 12)
20/02/17 14:53:23 INFO DAGScheduler: failed: Set()
20/02/17 14:53:23 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[86] at count at LinearRegression.scala:930), which has no missing parents
20/02/17 14:53:23 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/17 14:53:23 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
20/02/17 14:53:23 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:54067 (size: 5.0 KiB, free: 413.9 MiB)
20/02/17 14:53:23 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[86] at count at LinearRegression.scala:930) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:23 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
20/02/17 14:53:23 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 15, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/17 14:53:23 INFO Executor: Running task 0.0 in stage 12.0 (TID 15)
20/02/17 14:53:23 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 14:53:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 14:53:23 INFO Executor: Finished task 0.0 in stage 12.0 (TID 15). 2760 bytes result sent to driver
20/02/17 14:53:23 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 15) in 9 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:23 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
20/02/17 14:53:23 INFO DAGScheduler: ResultStage 12 (count at LinearRegression.scala:930) finished in 0.014 s
20/02/17 14:53:23 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 14:53:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
20/02/17 14:53:23 INFO DAGScheduler: Job 8 finished: count at LinearRegression.scala:930, took 0.046440 s
20/02/17 14:53:23 INFO Instrumentation: [faa5e858] training finished
20/02/17 14:53:23 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:54067 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/17 14:53:23 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:54067 in memory (size: 10.9 KiB, free: 413.9 MiB)
20/02/17 14:53:24 INFO Instrumentation: [f105f033] training finished
20/02/17 14:53:25 INFO SparkContext: Starting job: count at <unknown>:0
20/02/17 14:53:25 INFO DAGScheduler: Registering RDD 91 (count at <unknown>:0) as input to shuffle 4
20/02/17 14:53:25 INFO DAGScheduler: Got job 9 (count at <unknown>:0) with 1 output partitions
20/02/17 14:53:25 INFO DAGScheduler: Final stage: ResultStage 14 (count at <unknown>:0)
20/02/17 14:53:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
20/02/17 14:53:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
20/02/17 14:53:25 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[91] at count at <unknown>:0), which has no missing parents
20/02/17 14:53:25 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 26.8 KiB, free 413.9 MiB)
20/02/17 14:53:25 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.9 MiB)
20/02/17 14:53:25 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:54067 (size: 10.8 KiB, free: 413.9 MiB)
20/02/17 14:53:25 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[91] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:25 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
20/02/17 14:53:25 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 16, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/17 14:53:25 INFO Executor: Running task 0.0 in stage 13.0 (TID 16)
20/02/17 14:53:25 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 14:53:25 INFO Executor: Finished task 0.0 in stage 13.0 (TID 16). 2369 bytes result sent to driver
20/02/17 14:53:25 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 16) in 13 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:25 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
20/02/17 14:53:25 INFO DAGScheduler: ShuffleMapStage 13 (count at <unknown>:0) finished in 0.020 s
20/02/17 14:53:25 INFO DAGScheduler: looking for newly runnable stages
20/02/17 14:53:25 INFO DAGScheduler: running: Set()
20/02/17 14:53:25 INFO DAGScheduler: waiting: Set(ResultStage 14)
20/02/17 14:53:25 INFO DAGScheduler: failed: Set()
20/02/17 14:53:25 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[94] at count at <unknown>:0), which has no missing parents
20/02/17 14:53:25 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/17 14:53:25 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
20/02/17 14:53:25 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:54067 (size: 5.0 KiB, free: 413.9 MiB)
20/02/17 14:53:25 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[94] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:25 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
20/02/17 14:53:25 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 17, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/17 14:53:25 INFO Executor: Running task 0.0 in stage 14.0 (TID 17)
20/02/17 14:53:25 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 14:53:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 14:53:25 INFO Executor: Finished task 0.0 in stage 14.0 (TID 17). 2760 bytes result sent to driver
20/02/17 14:53:25 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 17) in 6 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:25 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
20/02/17 14:53:25 INFO DAGScheduler: ResultStage 14 (count at <unknown>:0) finished in 0.016 s
20/02/17 14:53:25 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 14:53:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
20/02/17 14:53:25 INFO DAGScheduler: Job 9 finished: count at <unknown>:0, took 0.041271 s
20/02/17 14:53:25 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:54067 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/17 14:53:25 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:54067 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/17 14:53:25 INFO CodeGenerator: Code generated in 15.7508 ms
20/02/17 14:53:25 INFO SparkContext: Starting job: collect at utils.scala:34
20/02/17 14:53:25 INFO DAGScheduler: Got job 10 (collect at utils.scala:34) with 1 output partitions
20/02/17 14:53:25 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:34)
20/02/17 14:53:25 INFO DAGScheduler: Parents of final stage: List()
20/02/17 14:53:25 INFO DAGScheduler: Missing parents: List()
20/02/17 14:53:25 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[102] at map at utils.scala:34), which has no missing parents
20/02/17 14:53:25 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 46.8 KiB, free 413.9 MiB)
20/02/17 14:53:25 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 413.9 MiB)
20/02/17 14:53:25 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:54067 (size: 19.2 KiB, free: 413.9 MiB)
20/02/17 14:53:25 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[102] at map at utils.scala:34) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:25 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
20/02/17 14:53:25 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 18, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/17 14:53:25 INFO Executor: Running task 0.0 in stage 15.0 (TID 18)
20/02/17 14:53:25 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 14:53:25 INFO CodeGenerator: Code generated in 4.8022 ms
20/02/17 14:53:25 INFO Executor: Finished task 0.0 in stage 15.0 (TID 18). 1908 bytes result sent to driver
20/02/17 14:53:25 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 18) in 21 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:25 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
20/02/17 14:53:25 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:34) finished in 0.035 s
20/02/17 14:53:25 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 14:53:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
20/02/17 14:53:25 INFO DAGScheduler: Job 10 finished: collect at utils.scala:34, took 0.038684 s
20/02/17 14:53:25 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:54067 in memory (size: 19.2 KiB, free: 413.9 MiB)
20/02/17 14:53:25 INFO CodeGenerator: Code generated in 4.3709 ms
20/02/17 14:53:25 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/17 14:53:25 INFO DAGScheduler: Got job 11 (collect at utils.scala:41) with 4 output partitions
20/02/17 14:53:25 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:41)
20/02/17 14:53:25 INFO DAGScheduler: Parents of final stage: List()
20/02/17 14:53:25 INFO DAGScheduler: Missing parents: List()
20/02/17 14:53:25 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[108] at map at utils.scala:41), which has no missing parents
20/02/17 14:53:25 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 8.8 KiB, free 413.9 MiB)
20/02/17 14:53:25 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.9 MiB)
20/02/17 14:53:25 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:54067 (size: 4.6 KiB, free: 413.9 MiB)
20/02/17 14:53:25 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 16 (MapPartitionsRDD[108] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/17 14:53:25 INFO TaskSchedulerImpl: Adding task set 16.0 with 4 tasks
20/02/17 14:53:25 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 19, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7533 bytes)
20/02/17 14:53:25 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 20, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7557 bytes)
20/02/17 14:53:25 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 21, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7557 bytes)
20/02/17 14:53:25 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 22, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7614 bytes)
20/02/17 14:53:25 INFO Executor: Running task 0.0 in stage 16.0 (TID 19)
20/02/17 14:53:25 INFO Executor: Running task 2.0 in stage 16.0 (TID 21)
20/02/17 14:53:25 INFO Executor: Running task 3.0 in stage 16.0 (TID 22)
20/02/17 14:53:25 INFO Executor: Running task 1.0 in stage 16.0 (TID 20)
20/02/17 14:53:25 INFO Executor: Finished task 0.0 in stage 16.0 (TID 19). 1069 bytes result sent to driver
20/02/17 14:53:25 INFO Executor: Finished task 2.0 in stage 16.0 (TID 21). 1045 bytes result sent to driver
20/02/17 14:53:25 INFO Executor: Finished task 3.0 in stage 16.0 (TID 22). 1072 bytes result sent to driver
20/02/17 14:53:25 INFO Executor: Finished task 1.0 in stage 16.0 (TID 20). 1088 bytes result sent to driver
20/02/17 14:53:25 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 19) in 18 ms on 127.0.0.1 (executor driver) (1/4)
20/02/17 14:53:25 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 21) in 18 ms on 127.0.0.1 (executor driver) (2/4)
20/02/17 14:53:25 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 22) in 17 ms on 127.0.0.1 (executor driver) (3/4)
20/02/17 14:53:25 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 20) in 19 ms on 127.0.0.1 (executor driver) (4/4)
20/02/17 14:53:25 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
20/02/17 14:53:25 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:41) finished in 0.025 s
20/02/17 14:53:25 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 14:53:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
20/02/17 14:53:25 INFO DAGScheduler: Job 11 finished: collect at utils.scala:41, took 0.028988 s
20/02/17 14:53:25 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:54067 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/17 14:53:25 INFO CodeGenerator: Code generated in 5.1278 ms
20/02/17 14:53:25 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/17 14:53:25 INFO DAGScheduler: Registering RDD 117 (sql at <unknown>:0) as input to shuffle 5
20/02/17 14:53:25 INFO DAGScheduler: Got job 12 (sql at <unknown>:0) with 1 output partitions
20/02/17 14:53:25 INFO DAGScheduler: Final stage: ResultStage 18 (sql at <unknown>:0)
20/02/17 14:53:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
20/02/17 14:53:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
20/02/17 14:53:25 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[117] at sql at <unknown>:0), which has no missing parents
20/02/17 14:53:25 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 18.9 KiB, free 413.9 MiB)
20/02/17 14:53:25 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.9 MiB)
20/02/17 14:53:25 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:54067 (size: 8.2 KiB, free: 413.9 MiB)
20/02/17 14:53:25 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[117] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:25 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
20/02/17 14:53:25 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 23, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/17 14:53:25 INFO Executor: Running task 0.0 in stage 17.0 (TID 23)
20/02/17 14:53:26 INFO MemoryStore: Block rdd_112_0 stored as values in memory (estimated size 312.0 B, free 413.9 MiB)
20/02/17 14:53:26 INFO BlockManagerInfo: Added rdd_112_0 in memory on 127.0.0.1:54067 (size: 312.0 B, free: 413.9 MiB)
20/02/17 14:53:26 INFO Executor: Finished task 0.0 in stage 17.0 (TID 23). 2283 bytes result sent to driver
20/02/17 14:53:26 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 23) in 32 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:26 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
20/02/17 14:53:26 INFO DAGScheduler: ShuffleMapStage 17 (sql at <unknown>:0) finished in 0.037 s
20/02/17 14:53:26 INFO DAGScheduler: looking for newly runnable stages
20/02/17 14:53:26 INFO DAGScheduler: running: Set()
20/02/17 14:53:26 INFO DAGScheduler: waiting: Set(ResultStage 18)
20/02/17 14:53:26 INFO DAGScheduler: failed: Set()
20/02/17 14:53:26 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[120] at sql at <unknown>:0), which has no missing parents
20/02/17 14:53:26 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/17 14:53:26 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
20/02/17 14:53:26 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:54067 (size: 5.0 KiB, free: 413.9 MiB)
20/02/17 14:53:26 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[120] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:26 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
20/02/17 14:53:26 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 24, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/17 14:53:26 INFO Executor: Running task 0.0 in stage 18.0 (TID 24)
20/02/17 14:53:26 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 14:53:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 14:53:26 INFO Executor: Finished task 0.0 in stage 18.0 (TID 24). 2803 bytes result sent to driver
20/02/17 14:53:26 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 24) in 5 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:26 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
20/02/17 14:53:26 INFO DAGScheduler: ResultStage 18 (sql at <unknown>:0) finished in 0.010 s
20/02/17 14:53:26 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 14:53:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
20/02/17 14:53:26 INFO DAGScheduler: Job 12 finished: sql at <unknown>:0, took 0.053120 s
20/02/17 14:53:26 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:54067 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/17 14:53:26 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:54067 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/17 14:53:26 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/17 14:53:26 INFO DAGScheduler: Registering RDD 125 (collect at arrowconverters.scala:270) as input to shuffle 6
20/02/17 14:53:26 INFO DAGScheduler: Got job 13 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/17 14:53:26 INFO DAGScheduler: Final stage: ResultStage 20 (collect at arrowconverters.scala:270)
20/02/17 14:53:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
20/02/17 14:53:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
20/02/17 14:53:26 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[125] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 14:53:26 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 18.9 KiB, free 413.9 MiB)
20/02/17 14:53:26 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.9 MiB)
20/02/17 14:53:26 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:54067 (size: 8.2 KiB, free: 413.9 MiB)
20/02/17 14:53:26 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[125] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:26 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
20/02/17 14:53:26 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 25, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/17 14:53:26 INFO Executor: Running task 0.0 in stage 19.0 (TID 25)
20/02/17 14:53:26 INFO BlockManager: Found block rdd_112_0 locally
20/02/17 14:53:26 INFO Executor: Finished task 0.0 in stage 19.0 (TID 25). 2369 bytes result sent to driver
20/02/17 14:53:26 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 25) in 13 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:26 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
20/02/17 14:53:26 INFO DAGScheduler: ShuffleMapStage 19 (collect at arrowconverters.scala:270) finished in 0.021 s
20/02/17 14:53:26 INFO DAGScheduler: looking for newly runnable stages
20/02/17 14:53:26 INFO DAGScheduler: running: Set()
20/02/17 14:53:26 INFO DAGScheduler: waiting: Set(ResultStage 20)
20/02/17 14:53:26 INFO DAGScheduler: failed: Set()
20/02/17 14:53:26 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[131] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 14:53:26 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 28.9 KiB, free 413.9 MiB)
20/02/17 14:53:26 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 12.1 KiB, free 413.9 MiB)
20/02/17 14:53:26 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:54067 (size: 12.1 KiB, free: 413.9 MiB)
20/02/17 14:53:26 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[131] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:26 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
20/02/17 14:53:26 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 26, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/17 14:53:26 INFO Executor: Running task 0.0 in stage 20.0 (TID 26)
20/02/17 14:53:26 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 14:53:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 14:53:26 INFO Executor: Finished task 0.0 in stage 20.0 (TID 26). 4285 bytes result sent to driver
20/02/17 14:53:26 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 26) in 18 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:26 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
20/02/17 14:53:26 INFO DAGScheduler: ResultStage 20 (collect at arrowconverters.scala:270) finished in 0.025 s
20/02/17 14:53:26 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 14:53:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
20/02/17 14:53:26 INFO DAGScheduler: Job 13 finished: collect at arrowconverters.scala:270, took 0.051601 s
20/02/17 14:53:26 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:54067 in memory (size: 12.1 KiB, free: 413.9 MiB)
20/02/17 14:53:26 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:54067 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/17 14:53:26 INFO Instrumentation: [add09ac9] training finished
20/02/17 14:53:26 INFO Instrumentation: [fb1f6643] training finished
20/02/17 14:53:26 INFO CodeGenerator: Code generated in 7.1749 ms
20/02/17 14:53:26 INFO CodeGenerator: Code generated in 5.7264 ms
20/02/17 14:53:27 INFO CodeGenerator: Code generated in 18.1182 ms
20/02/17 14:53:27 INFO CodeGenerator: Code generated in 12.835 ms
20/02/17 14:53:27 INFO CodeGenerator: Code generated in 8.0651 ms
20/02/17 14:53:27 INFO CodeGenerator: Code generated in 5.7222 ms
20/02/17 14:53:27 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/17 14:53:27 INFO DAGScheduler: Registering RDD 143 (collect at arrowconverters.scala:270) as input to shuffle 8
20/02/17 14:53:27 INFO DAGScheduler: Registering RDD 136 (collect at arrowconverters.scala:270) as input to shuffle 7
20/02/17 14:53:27 INFO DAGScheduler: Got job 14 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/17 14:53:27 INFO DAGScheduler: Final stage: ResultStage 23 (collect at arrowconverters.scala:270)
20/02/17 14:53:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21, ShuffleMapStage 22)
20/02/17 14:53:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21, ShuffleMapStage 22)
20/02/17 14:53:27 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[143] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 14:53:27 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 27.4 KiB, free 413.9 MiB)
20/02/17 14:53:27 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 413.9 MiB)
20/02/17 14:53:27 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:54067 (size: 10.9 KiB, free: 413.9 MiB)
20/02/17 14:53:27 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[143] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:27 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
20/02/17 14:53:27 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 27, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/17 14:53:27 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[136] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 14:53:27 INFO Executor: Running task 0.0 in stage 21.0 (TID 27)
20/02/17 14:53:27 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 32.1 KiB, free 413.9 MiB)
20/02/17 14:53:27 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 14:53:27 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 413.8 MiB)
20/02/17 14:53:27 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:54067 (size: 13.4 KiB, free: 413.9 MiB)
20/02/17 14:53:27 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[136] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 14:53:27 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
20/02/17 14:53:27 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 28, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/17 14:53:27 INFO Executor: Running task 0.0 in stage 22.0 (TID 28)
20/02/17 14:53:27 INFO BlockManager: Found block rdd_112_0 locally
20/02/17 14:53:27 INFO CodeGenerator: Code generated in 14.2632 ms
20/02/17 14:53:27 INFO CodeGenerator: Code generated in 13.0868 ms
20/02/17 14:53:27 INFO Executor: Finished task 0.0 in stage 22.0 (TID 28). 2246 bytes result sent to driver
20/02/17 14:53:27 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 28) in 72 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:27 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
20/02/17 14:53:27 INFO DAGScheduler: ShuffleMapStage 22 (collect at arrowconverters.scala:270) finished in 0.080 s
20/02/17 14:53:27 INFO DAGScheduler: looking for newly runnable stages
20/02/17 14:53:27 INFO DAGScheduler: running: Set(ShuffleMapStage 21)
20/02/17 14:53:27 INFO DAGScheduler: waiting: Set(ResultStage 23)
20/02/17 14:53:27 INFO DAGScheduler: failed: Set()
20/02/17 14:53:27 INFO Executor: Finished task 0.0 in stage 21.0 (TID 27). 2203 bytes result sent to driver
20/02/17 14:53:27 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 27) in 100 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 14:53:27 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
20/02/17 14:53:27 INFO DAGScheduler: ShuffleMapStage 21 (collect at arrowconverters.scala:270) finished in 0.105 s
20/02/17 14:53:27 INFO DAGScheduler: looking for newly runnable stages
20/02/17 14:53:27 INFO DAGScheduler: running: Set()
20/02/17 14:53:27 INFO DAGScheduler: waiting: Set(ResultStage 23)
20/02/17 14:53:27 INFO DAGScheduler: failed: Set()
20/02/17 14:53:27 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[151] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 14:53:27 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 56.3 KiB, free 413.8 MiB)
20/02/17 14:53:27 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 413.8 MiB)
20/02/17 14:53:27 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:54067 (size: 23.0 KiB, free: 413.9 MiB)
20/02/17 14:53:27 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:27 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:54067 in memory (size: 13.4 KiB, free: 413.9 MiB)
20/02/17 14:53:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 23 (MapPartitionsRDD[151] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/17 14:53:27 INFO TaskSchedulerImpl: Adding task set 23.0 with 4 tasks
20/02/17 14:53:27 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 29, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7528 bytes)
20/02/17 14:53:27 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 30, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7528 bytes)
20/02/17 14:53:27 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 31, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7528 bytes)
20/02/17 14:53:27 INFO TaskSetManager: Starting task 3.0 in stage 23.0 (TID 32, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7528 bytes)
20/02/17 14:53:27 INFO Executor: Running task 0.0 in stage 23.0 (TID 29)
20/02/17 14:53:27 INFO Executor: Running task 2.0 in stage 23.0 (TID 31)
20/02/17 14:53:27 INFO Executor: Running task 1.0 in stage 23.0 (TID 30)
20/02/17 14:53:27 INFO Executor: Running task 3.0 in stage 23.0 (TID 32)
20/02/17 14:53:27 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 14:53:27 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 14:53:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/17 14:53:27 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 14:53:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 14:53:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 14:53:27 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 14:53:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
20/02/17 14:53:27 INFO CodeGenerator: Code generated in 32.8813 ms
20/02/17 14:53:27 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:54067 in memory (size: 10.9 KiB, free: 413.9 MiB)
20/02/17 14:53:27 INFO CodeGenerator: Code generated in 11.8984 ms
20/02/17 14:53:27 INFO ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 14:53:27 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 14:53:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 14:53:27 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 14:53:27 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 14:53:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 14:53:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 14:53:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 14:53:27 INFO CodeGenerator: Code generated in 14.798 ms
20/02/17 14:53:27 INFO CodeGenerator: Code generated in 10.3516 ms
20/02/17 14:53:27 INFO CodeGenerator: Code generated in 7.8043 ms
20/02/17 14:53:27 INFO CodeGenerator: Code generated in 8.6887 ms
20/02/17 14:53:27 INFO Executor: Finished task 3.0 in stage 23.0 (TID 32). 5850 bytes result sent to driver
20/02/17 14:53:27 INFO Executor: Finished task 2.0 in stage 23.0 (TID 31). 5952 bytes result sent to driver
20/02/17 14:53:27 INFO Executor: Finished task 1.0 in stage 23.0 (TID 30). 5833 bytes result sent to driver
20/02/17 14:53:27 INFO Executor: Finished task 0.0 in stage 23.0 (TID 29). 5857 bytes result sent to driver
20/02/17 14:53:27 INFO TaskSetManager: Finished task 3.0 in stage 23.0 (TID 32) in 432 ms on 127.0.0.1 (executor driver) (1/4)
20/02/17 14:53:27 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 30) in 434 ms on 127.0.0.1 (executor driver) (2/4)
20/02/17 14:53:27 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 31) in 435 ms on 127.0.0.1 (executor driver) (3/4)
20/02/17 14:53:27 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 29) in 437 ms on 127.0.0.1 (executor driver) (4/4)
20/02/17 14:53:27 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
20/02/17 14:53:27 INFO DAGScheduler: ResultStage 23 (collect at arrowconverters.scala:270) finished in 0.454 s
20/02/17 14:53:27 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 14:53:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
20/02/17 14:53:27 INFO DAGScheduler: Job 14 finished: collect at arrowconverters.scala:270, took 0.567068 s
20/02/17 14:53:28 INFO CodeGenerator: Code generated in 6.325 ms
20/02/17 14:53:28 INFO CodeGenerator: Code generated in 8.6389 ms
20/02/17 14:53:28 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/17 14:53:28 INFO DAGScheduler: Got job 15 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/17 14:53:28 INFO DAGScheduler: Final stage: ResultStage 24 (collect at arrowconverters.scala:270)
20/02/17 14:53:28 INFO DAGScheduler: Parents of final stage: List()
20/02/17 14:53:28 INFO DAGScheduler: Missing parents: List()
20/02/17 14:53:28 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[157] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 14:53:28 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 11.1 KiB, free 413.8 MiB)
20/02/17 14:53:28 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.8 MiB)
20/02/17 14:53:28 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:54067 (size: 5.2 KiB, free: 413.9 MiB)
20/02/17 14:53:28 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[157] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/17 14:53:28 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
20/02/17 14:53:28 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 33, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7549 bytes)
20/02/17 14:53:28 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 34, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7654 bytes)
20/02/17 14:53:28 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 35, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7654 bytes)
20/02/17 14:53:28 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 36, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7646 bytes)
20/02/17 14:53:28 INFO Executor: Running task 0.0 in stage 24.0 (TID 33)
20/02/17 14:53:28 INFO Executor: Running task 1.0 in stage 24.0 (TID 34)
20/02/17 14:53:28 INFO Executor: Running task 2.0 in stage 24.0 (TID 35)
20/02/17 14:53:28 INFO Executor: Running task 3.0 in stage 24.0 (TID 36)
20/02/17 14:53:28 INFO CodeGenerator: Code generated in 6.1736 ms
20/02/17 14:53:28 INFO CodeGenerator: Code generated in 20.2255 ms
20/02/17 14:53:28 INFO Executor: Finished task 3.0 in stage 24.0 (TID 36). 1628 bytes result sent to driver
20/02/17 14:53:28 INFO Executor: Finished task 0.0 in stage 24.0 (TID 33). 1586 bytes result sent to driver
20/02/17 14:53:28 INFO Executor: Finished task 1.0 in stage 24.0 (TID 34). 1672 bytes result sent to driver
20/02/17 14:53:28 INFO Executor: Finished task 2.0 in stage 24.0 (TID 35). 1628 bytes result sent to driver
20/02/17 14:53:28 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 36) in 78 ms on 127.0.0.1 (executor driver) (1/4)
20/02/17 14:53:28 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 33) in 80 ms on 127.0.0.1 (executor driver) (2/4)
20/02/17 14:53:28 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 34) in 80 ms on 127.0.0.1 (executor driver) (3/4)
20/02/17 14:53:28 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 35) in 80 ms on 127.0.0.1 (executor driver) (4/4)
20/02/17 14:53:28 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
20/02/17 14:53:28 INFO DAGScheduler: ResultStage 24 (collect at arrowconverters.scala:270) finished in 0.087 s
20/02/17 14:53:28 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 14:53:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
20/02/17 14:53:28 INFO DAGScheduler: Job 15 finished: collect at arrowconverters.scala:270, took 0.090479 s
20/02/17 14:53:29 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/17 14:53:29 INFO DAGScheduler: Got job 16 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/17 14:53:29 INFO DAGScheduler: Final stage: ResultStage 25 (collect at arrowconverters.scala:270)
20/02/17 14:53:29 INFO DAGScheduler: Parents of final stage: List()
20/02/17 14:53:29 INFO DAGScheduler: Missing parents: List()
20/02/17 14:53:29 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[163] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 14:53:29 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 11.1 KiB, free 413.8 MiB)
20/02/17 14:53:29 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:54067 in memory (size: 5.2 KiB, free: 413.9 MiB)
20/02/17 14:53:29 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 413.8 MiB)
20/02/17 14:53:29 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:54067 (size: 5.3 KiB, free: 413.9 MiB)
20/02/17 14:53:29 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1196
20/02/17 14:53:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 25 (MapPartitionsRDD[163] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/17 14:53:29 INFO TaskSchedulerImpl: Adding task set 25.0 with 4 tasks
20/02/17 14:53:29 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 37, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7549 bytes)
20/02/17 14:53:29 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 38, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7654 bytes)
20/02/17 14:53:29 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 39, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7654 bytes)
20/02/17 14:53:29 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 40, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7646 bytes)
20/02/17 14:53:29 INFO Executor: Running task 0.0 in stage 25.0 (TID 37)
20/02/17 14:53:29 INFO Executor: Running task 1.0 in stage 25.0 (TID 38)
20/02/17 14:53:29 INFO Executor: Running task 3.0 in stage 25.0 (TID 40)
20/02/17 14:53:29 INFO Executor: Running task 2.0 in stage 25.0 (TID 39)
20/02/17 14:53:29 INFO Executor: Finished task 0.0 in stage 25.0 (TID 37). 1543 bytes result sent to driver
20/02/17 14:53:29 INFO Executor: Finished task 2.0 in stage 25.0 (TID 39). 1585 bytes result sent to driver
20/02/17 14:53:29 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 37) in 20 ms on 127.0.0.1 (executor driver) (1/4)
20/02/17 14:53:29 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 39) in 19 ms on 127.0.0.1 (executor driver) (2/4)
20/02/17 14:53:29 INFO Executor: Finished task 1.0 in stage 25.0 (TID 38). 1543 bytes result sent to driver
20/02/17 14:53:29 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 38) in 22 ms on 127.0.0.1 (executor driver) (3/4)
20/02/17 14:53:29 INFO Executor: Finished task 3.0 in stage 25.0 (TID 40). 1585 bytes result sent to driver
20/02/17 14:53:29 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 40) in 24 ms on 127.0.0.1 (executor driver) (4/4)
20/02/17 14:53:29 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
20/02/17 14:53:29 INFO DAGScheduler: ResultStage 25 (collect at arrowconverters.scala:270) finished in 0.032 s
20/02/17 14:53:29 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 14:53:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
20/02/17 14:53:29 INFO DAGScheduler: Job 16 finished: collect at arrowconverters.scala:270, took 0.038946 s
20/02/17 14:53:31 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:54067 in memory (size: 5.3 KiB, free: 413.9 MiB)
20/02/17 14:55:01 INFO SparkContext: Invoking stop() from shutdown hook
20/02/17 14:55:01 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
20/02/17 14:55:01 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/02/17 14:55:01 INFO MemoryStore: MemoryStore cleared
20/02/17 14:55:01 INFO BlockManager: BlockManager stopped
20/02/17 14:55:01 INFO BlockManagerMaster: BlockManagerMaster stopped
20/02/17 14:55:01 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/02/17 14:55:01 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-b9ea26cd-8ded-43da-b84d-8b1d8233d9ed\userFiles-23780591-f122-47a5-892e-1a46f08fde58
java.io.IOException: Failed to delete: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-b9ea26cd-8ded-43da-b84d-8b1d8233d9ed\userFiles-23780591-f122-47a5-892e-1a46f08fde58\sparklyr-3.0.0-preview-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:103)
	at org.apache.spark.SparkContext.$anonfun$stop$21(SparkContext.scala:2008)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1357)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:2008)
	at org.apache.spark.SparkContext.$anonfun$new$33(SparkContext.scala:632)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1960)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
20/02/17 14:55:01 INFO SparkContext: Successfully stopped SparkContext
20/02/17 14:55:01 INFO ShutdownHookManager: Shutdown hook called
20/02/17 14:55:01 INFO ShutdownHookManager: Deleting directory C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-b9ea26cd-8ded-43da-b84d-8b1d8233d9ed
20/02/17 14:55:01 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-b9ea26cd-8ded-43da-b84d-8b1d8233d9ed
java.io.IOException: Failed to delete: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-b9ea26cd-8ded-43da-b84d-8b1d8233d9ed\userFiles-23780591-f122-47a5-892e-1a46f08fde58\sparklyr-3.0.0-preview-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1960)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
20/02/17 14:55:01 INFO ShutdownHookManager: Deleting directory C:\Users\Gigabyte\AppData\Local\Temp\spark-a9032c62-f173-44d0-8717-94dd3f5b0251
20/02/17 14:55:01 INFO ShutdownHookManager: Deleting directory C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-b9ea26cd-8ded-43da-b84d-8b1d8233d9ed\userFiles-23780591-f122-47a5-892e-1a46f08fde58
20/02/17 14:55:01 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-b9ea26cd-8ded-43da-b84d-8b1d8233d9ed\userFiles-23780591-f122-47a5-892e-1a46f08fde58
java.io.IOException: Failed to delete: C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-b9ea26cd-8ded-43da-b84d-8b1d8233d9ed\userFiles-23780591-f122-47a5-892e-1a46f08fde58\sparklyr-3.0.0-preview-2.12.jar
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:144)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursivelyUsingJavaIO(JavaUtils.java:128)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:118)
	at org.apache.spark.network.util.JavaUtils.deleteRecursively(JavaUtils.java:91)
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1079)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$4$adapted(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at org.apache.spark.util.ShutdownHookManager$.$anonfun$new$2(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$2(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1960)
	at org.apache.spark.util.SparkShutdownHookManager.$anonfun$runAll$1(ShutdownHookManager.scala:188)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.util.Try$.apply(Try.scala:213)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
20/02/17 18:08:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
20/02/17 18:08:35 INFO SecurityManager: Changing view acls to: Gigabyte
20/02/17 18:08:35 INFO SecurityManager: Changing modify acls to: Gigabyte
20/02/17 18:08:35 INFO SecurityManager: Changing view acls groups to: 
20/02/17 18:08:35 INFO SecurityManager: Changing modify acls groups to: 
20/02/17 18:08:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Gigabyte); groups with view permissions: Set(); users  with modify permissions: Set(Gigabyte); groups with modify permissions: Set()
20/02/17 18:08:36 INFO SparkContext: Running Spark version 3.0.0-preview
20/02/17 18:08:36 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
20/02/17 18:08:36 INFO ResourceUtils: ==============================================================
20/02/17 18:08:36 INFO ResourceUtils: Resources for spark.driver:

20/02/17 18:08:36 INFO ResourceUtils: ==============================================================
20/02/17 18:08:36 INFO SparkContext: Submitted application: sparklyr
20/02/17 18:08:36 INFO SecurityManager: Changing view acls to: Gigabyte
20/02/17 18:08:36 INFO SecurityManager: Changing modify acls to: Gigabyte
20/02/17 18:08:36 INFO SecurityManager: Changing view acls groups to: 
20/02/17 18:08:36 INFO SecurityManager: Changing modify acls groups to: 
20/02/17 18:08:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Gigabyte); groups with view permissions: Set(); users  with modify permissions: Set(Gigabyte); groups with modify permissions: Set()
20/02/17 18:08:36 INFO Utils: Successfully started service 'sparkDriver' on port 56073.
20/02/17 18:08:37 INFO SparkEnv: Registering MapOutputTracker
20/02/17 18:08:37 INFO SparkEnv: Registering BlockManagerMaster
20/02/17 18:08:37 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
20/02/17 18:08:37 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/02/17 18:08:37 INFO DiskBlockManager: Created local directory at C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\blockmgr-d035aab6-ac87-448f-94a1-540a5dbc0142
20/02/17 18:08:37 INFO MemoryStore: MemoryStore started with capacity 413.9 MiB
20/02/17 18:08:37 INFO SparkEnv: Registering OutputCommitCoordinator
20/02/17 18:08:37 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/local]. Please check your configured local directories.
20/02/17 18:08:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
20/02/17 18:08:37 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
20/02/17 18:08:37 INFO SparkContext: Added JAR file:/C:/Users/Gigabyte/Documents/R/win-library/3.6/sparklyr/java/sparklyr-3.0.0-preview-2.12.jar at spark://127.0.0.1:56073/jars/sparklyr-3.0.0-preview-2.12.jar with timestamp 1581943117490
20/02/17 18:08:37 INFO Executor: Starting executor ID driver on host 127.0.0.1
20/02/17 18:08:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56102.
20/02/17 18:08:37 INFO NettyBlockTransferService: Server created on 127.0.0.1:56102
20/02/17 18:08:37 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
20/02/17 18:08:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 56102, None)
20/02/17 18:08:37 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:56102 with 413.9 MiB RAM, BlockManagerId(driver, 127.0.0.1, 56102, None)
20/02/17 18:08:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 56102, None)
20/02/17 18:08:37 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 56102, None)
20/02/17 18:08:38 INFO SharedState: loading hive config file: file:/C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/conf/hive-site.xml
20/02/17 18:08:38 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/hive').
20/02/17 18:08:38 INFO SharedState: Warehouse path is 'C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/hive'.
20/02/17 18:08:38 WARN SharedState: Not allowing to set spark.sql.warehouse.dir or hive.metastore.warehouse.dir in SparkSession's options, it should be set statically for cross-session usages
20/02/17 18:08:43 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/17 18:08:43 INFO DAGScheduler: Got job 0 (collect at utils.scala:41) with 1 output partitions
20/02/17 18:08:43 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:41)
20/02/17 18:08:43 INFO DAGScheduler: Parents of final stage: List()
20/02/17 18:08:43 INFO DAGScheduler: Missing parents: List()
20/02/17 18:08:43 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:41), which has no missing parents
20/02/17 18:08:43 WARN SizeEstimator: Failed to check whether UseCompressedOops is set; assuming yes
20/02/17 18:08:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.8 KiB, free 413.9 MiB)
20/02/17 18:08:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.9 MiB)
20/02/17 18:08:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:56102 (size: 4.6 KiB, free: 413.9 MiB)
20/02/17 18:08:43 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1196
20/02/17 18:08:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
20/02/17 18:08:44 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
20/02/17 18:08:44 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7374 bytes)
20/02/17 18:08:44 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/02/17 18:08:44 INFO Executor: Fetching spark://127.0.0.1:56073/jars/sparklyr-3.0.0-preview-2.12.jar with timestamp 1581943117490
20/02/17 18:08:44 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:56073 after 39 ms (0 ms spent in bootstraps)
20/02/17 18:08:44 INFO Utils: Fetching spark://127.0.0.1:56073/jars/sparklyr-3.0.0-preview-2.12.jar to C:\Users\Gigabyte\AppData\Local\spark\spark-3.0.0-preview-bin-hadoop3.2\tmp\local\spark-8704007e-df65-4150-a3d7-cfb27fc3d884\userFiles-290e8873-9700-43c6-a631-02544d76438d\fetchFileTemp5581048733033496385.tmp
20/02/17 18:08:44 INFO Executor: Adding file:/C:/Users/Gigabyte/AppData/Local/spark/spark-3.0.0-preview-bin-hadoop3.2/tmp/local/spark-8704007e-df65-4150-a3d7-cfb27fc3d884/userFiles-290e8873-9700-43c6-a631-02544d76438d/sparklyr-3.0.0-preview-2.12.jar to class loader
20/02/17 18:08:45 INFO CodeGenerator: Code generated in 245.1945 ms
20/02/17 18:08:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1146 bytes result sent to driver
20/02/17 18:08:45 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1202 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:08:45 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/02/17 18:08:45 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:41) finished in 1.458 s
20/02/17 18:08:45 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:08:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
20/02/17 18:08:45 INFO DAGScheduler: Job 0 finished: collect at utils.scala:41, took 1.542697 s
20/02/17 18:08:45 INFO CodeGenerator: Code generated in 15.7821 ms
20/02/17 18:08:46 INFO CodeGenerator: Code generated in 13.0151 ms
20/02/17 18:08:46 INFO CodeGenerator: Code generated in 14.8406 ms
20/02/17 18:08:46 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/17 18:08:46 INFO DAGScheduler: Registering RDD 14 (sql at <unknown>:0) as input to shuffle 0
20/02/17 18:08:46 INFO DAGScheduler: Got job 1 (sql at <unknown>:0) with 1 output partitions
20/02/17 18:08:46 INFO DAGScheduler: Final stage: ResultStage 2 (sql at <unknown>:0)
20/02/17 18:08:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
20/02/17 18:08:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
20/02/17 18:08:46 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[14] at sql at <unknown>:0), which has no missing parents
20/02/17 18:08:46 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 26.8 KiB, free 413.9 MiB)
20/02/17 18:08:46 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.9 MiB)
20/02/17 18:08:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:56102 (size: 10.8 KiB, free: 413.9 MiB)
20/02/17 18:08:46 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1196
20/02/17 18:08:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[14] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/17 18:08:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
20/02/17 18:08:46 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/17 18:08:46 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
20/02/17 18:08:46 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 3.9 KiB, free 413.9 MiB)
20/02/17 18:08:46 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:56102 (size: 3.9 KiB, free: 413.9 MiB)
20/02/17 18:08:46 INFO CodeGenerator: Code generated in 4.2447 ms
20/02/17 18:08:46 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2412 bytes result sent to driver
20/02/17 18:08:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 431 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:08:46 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
20/02/17 18:08:46 INFO DAGScheduler: ShuffleMapStage 1 (sql at <unknown>:0) finished in 0.463 s
20/02/17 18:08:46 INFO DAGScheduler: looking for newly runnable stages
20/02/17 18:08:46 INFO DAGScheduler: running: Set()
20/02/17 18:08:46 INFO DAGScheduler: waiting: Set(ResultStage 2)
20/02/17 18:08:46 INFO DAGScheduler: failed: Set()
20/02/17 18:08:46 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at sql at <unknown>:0), which has no missing parents
20/02/17 18:08:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.2 KiB, free 413.9 MiB)
20/02/17 18:08:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.9 MiB)
20/02/17 18:08:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:56102 (size: 5.0 KiB, free: 413.9 MiB)
20/02/17 18:08:46 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1196
20/02/17 18:08:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/17 18:08:46 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
20/02/17 18:08:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/17 18:08:46 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
20/02/17 18:08:46 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:08:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
20/02/17 18:08:46 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2803 bytes result sent to driver
20/02/17 18:08:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 47 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:08:46 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
20/02/17 18:08:46 INFO DAGScheduler: ResultStage 2 (sql at <unknown>:0) finished in 0.062 s
20/02/17 18:08:46 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:08:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
20/02/17 18:08:46 INFO DAGScheduler: Job 1 finished: sql at <unknown>:0, took 0.582399 s
20/02/17 18:08:46 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:56102 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/17 18:08:47 INFO CodeGenerator: Code generated in 6.4875 ms
20/02/17 18:08:47 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/17 18:08:47 INFO DAGScheduler: Registering RDD 22 (collect at arrowconverters.scala:270) as input to shuffle 1
20/02/17 18:08:47 INFO DAGScheduler: Got job 2 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/17 18:08:47 INFO DAGScheduler: Final stage: ResultStage 4 (collect at arrowconverters.scala:270)
20/02/17 18:08:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
20/02/17 18:08:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
20/02/17 18:08:47 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[22] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 18:08:47 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 26.8 KiB, free 413.8 MiB)
20/02/17 18:08:47 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.8 MiB)
20/02/17 18:08:47 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:56102 (size: 10.8 KiB, free: 413.9 MiB)
20/02/17 18:08:47 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1196
20/02/17 18:08:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[22] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 18:08:47 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
20/02/17 18:08:47 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/17 18:08:47 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
20/02/17 18:08:47 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 18:08:47 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2412 bytes result sent to driver
20/02/17 18:08:47 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 38 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:08:47 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
20/02/17 18:08:47 INFO DAGScheduler: ShuffleMapStage 3 (collect at arrowconverters.scala:270) finished in 0.039 s
20/02/17 18:08:47 INFO DAGScheduler: looking for newly runnable stages
20/02/17 18:08:47 INFO DAGScheduler: running: Set()
20/02/17 18:08:47 INFO DAGScheduler: waiting: Set(ResultStage 4)
20/02/17 18:08:47 INFO DAGScheduler: failed: Set()
20/02/17 18:08:47 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[28] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 18:08:47 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 36.7 KiB, free 413.8 MiB)
20/02/17 18:08:47 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 413.8 MiB)
20/02/17 18:08:47 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:56102 (size: 15.6 KiB, free: 413.9 MiB)
20/02/17 18:08:47 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1196
20/02/17 18:08:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[28] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 18:08:47 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
20/02/17 18:08:47 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/17 18:08:47 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
20/02/17 18:08:47 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:08:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:08:47 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:56102 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/17 18:08:47 INFO CodeGenerator: Code generated in 15.8545 ms
20/02/17 18:08:47 INFO CodeGenerator: Code generated in 13.2975 ms
20/02/17 18:08:47 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 4329 bytes result sent to driver
20/02/17 18:08:47 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 93 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:08:47 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
20/02/17 18:08:47 INFO DAGScheduler: ResultStage 4 (collect at arrowconverters.scala:270) finished in 0.104 s
20/02/17 18:08:47 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:08:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
20/02/17 18:08:47 INFO DAGScheduler: Job 2 finished: collect at arrowconverters.scala:270, took 0.152596 s
20/02/17 18:08:47 INFO CodeGenerator: Code generated in 7.0347 ms
20/02/17 18:08:47 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:56102 in memory (size: 15.6 KiB, free: 413.9 MiB)
20/02/17 18:08:47 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:56102 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/17 18:08:47 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:56102 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/17 18:08:48 INFO CodeGenerator: Code generated in 7.4162 ms
20/02/17 18:08:48 INFO CodeGenerator: Code generated in 7.7127 ms
20/02/17 18:08:48 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/17 18:08:48 INFO DAGScheduler: Got job 3 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/17 18:08:48 INFO DAGScheduler: Final stage: ResultStage 5 (collect at arrowconverters.scala:270)
20/02/17 18:08:48 INFO DAGScheduler: Parents of final stage: List()
20/02/17 18:08:48 INFO DAGScheduler: Missing parents: List()
20/02/17 18:08:48 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[34] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 18:08:48 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.1 KiB, free 413.9 MiB)
20/02/17 18:08:48 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
20/02/17 18:08:48 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:56102 (size: 5.2 KiB, free: 413.9 MiB)
20/02/17 18:08:48 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1196
20/02/17 18:08:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[34] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 18:08:48 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
20/02/17 18:08:48 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7549 bytes)
20/02/17 18:08:48 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
20/02/17 18:08:48 INFO CodeGenerator: Code generated in 8.2311 ms
20/02/17 18:08:48 INFO CodeGenerator: Code generated in 17.4089 ms
20/02/17 18:08:48 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1543 bytes result sent to driver
20/02/17 18:08:48 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 63 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:08:48 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
20/02/17 18:08:48 INFO DAGScheduler: ResultStage 5 (collect at arrowconverters.scala:270) finished in 0.078 s
20/02/17 18:08:48 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:08:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
20/02/17 18:08:48 INFO DAGScheduler: Job 3 finished: collect at arrowconverters.scala:270, took 0.076613 s
20/02/17 18:08:48 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:56102 in memory (size: 5.2 KiB, free: 413.9 MiB)
20/02/17 18:08:48 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/17 18:08:48 INFO DAGScheduler: Got job 4 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/17 18:08:48 INFO DAGScheduler: Final stage: ResultStage 6 (collect at arrowconverters.scala:270)
20/02/17 18:08:48 INFO DAGScheduler: Parents of final stage: List()
20/02/17 18:08:48 INFO DAGScheduler: Missing parents: List()
20/02/17 18:08:48 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[40] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 18:08:48 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.1 KiB, free 413.9 MiB)
20/02/17 18:08:48 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 413.9 MiB)
20/02/17 18:08:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:56102 (size: 5.2 KiB, free: 413.9 MiB)
20/02/17 18:08:48 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1196
20/02/17 18:08:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[40] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 18:08:48 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
20/02/17 18:08:48 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7549 bytes)
20/02/17 18:08:48 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
20/02/17 18:08:48 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1543 bytes result sent to driver
20/02/17 18:08:48 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:08:48 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
20/02/17 18:08:48 INFO DAGScheduler: ResultStage 6 (collect at arrowconverters.scala:270) finished in 0.015 s
20/02/17 18:08:48 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:08:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
20/02/17 18:08:48 INFO DAGScheduler: Job 4 finished: collect at arrowconverters.scala:270, took 0.027039 s
20/02/17 18:08:49 WARN ProcfsMetricsGetter: Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
20/02/17 18:13:46 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:56102 in memory (size: 5.2 KiB, free: 413.9 MiB)
20/02/17 18:13:47 INFO CodeGenerator: Code generated in 50.8639 ms
20/02/17 18:13:47 INFO CodeGenerator: Code generated in 63.8084 ms
20/02/17 18:13:47 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/17 18:13:47 INFO DAGScheduler: Registering RDD 45 (collect at arrowconverters.scala:270) as input to shuffle 2
20/02/17 18:13:47 INFO DAGScheduler: Got job 5 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/17 18:13:47 INFO DAGScheduler: Final stage: ResultStage 8 (collect at arrowconverters.scala:270)
20/02/17 18:13:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
20/02/17 18:13:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
20/02/17 18:13:47 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[45] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 18:13:47 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 45.3 KiB, free 413.9 MiB)
20/02/17 18:13:47 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 18.3 KiB, free 413.9 MiB)
20/02/17 18:13:47 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:56102 (size: 18.3 KiB, free: 413.9 MiB)
20/02/17 18:13:47 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1196
20/02/17 18:13:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[45] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 18:13:47 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
20/02/17 18:13:47 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/17 18:13:47 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
20/02/17 18:13:47 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 18:13:47 INFO CodeGenerator: Code generated in 7.0642 ms
20/02/17 18:13:47 INFO CodeGenerator: Code generated in 5.963 ms
20/02/17 18:13:47 INFO CodeGenerator: Code generated in 6.929 ms
20/02/17 18:13:47 INFO CodeGenerator: Code generated in 20.4065 ms
20/02/17 18:13:47 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2799 bytes result sent to driver
20/02/17 18:13:47 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 170 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:13:47 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
20/02/17 18:13:47 INFO DAGScheduler: ShuffleMapStage 7 (collect at arrowconverters.scala:270) finished in 0.179 s
20/02/17 18:13:47 INFO DAGScheduler: looking for newly runnable stages
20/02/17 18:13:47 INFO DAGScheduler: running: Set()
20/02/17 18:13:47 INFO DAGScheduler: waiting: Set(ResultStage 8)
20/02/17 18:13:47 INFO DAGScheduler: failed: Set()
20/02/17 18:13:47 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[51] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 18:13:47 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 42.4 KiB, free 413.8 MiB)
20/02/17 18:13:47 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 17.6 KiB, free 413.8 MiB)
20/02/17 18:13:47 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:56102 (size: 17.6 KiB, free: 413.9 MiB)
20/02/17 18:13:47 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1196
20/02/17 18:13:47 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 8 (MapPartitionsRDD[51] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/17 18:13:47 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
20/02/17 18:13:47 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/17 18:13:47 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 9, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7248 bytes)
20/02/17 18:13:47 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 10, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7248 bytes)
20/02/17 18:13:47 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 11, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7248 bytes)
20/02/17 18:13:47 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
20/02/17 18:13:47 INFO Executor: Running task 1.0 in stage 8.0 (TID 9)
20/02/17 18:13:47 INFO Executor: Running task 2.0 in stage 8.0 (TID 10)
20/02/17 18:13:47 INFO Executor: Running task 3.0 in stage 8.0 (TID 11)
20/02/17 18:13:47 INFO ShuffleBlockFetcherIterator: Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:13:47 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:13:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:13:47 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:13:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:13:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:13:47 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:13:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:13:47 INFO CodeGenerator: Code generated in 7.513 ms
20/02/17 18:13:47 INFO CodeGenerator: Code generated in 29.0767 ms
20/02/17 18:13:47 INFO Executor: Finished task 1.0 in stage 8.0 (TID 9). 4541 bytes result sent to driver
20/02/17 18:13:47 INFO Executor: Finished task 2.0 in stage 8.0 (TID 10). 4590 bytes result sent to driver
20/02/17 18:13:47 INFO Executor: Finished task 3.0 in stage 8.0 (TID 11). 4458 bytes result sent to driver
20/02/17 18:13:47 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 4526 bytes result sent to driver
20/02/17 18:13:47 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 9) in 123 ms on 127.0.0.1 (executor driver) (1/4)
20/02/17 18:13:47 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 10) in 126 ms on 127.0.0.1 (executor driver) (2/4)
20/02/17 18:13:47 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 11) in 125 ms on 127.0.0.1 (executor driver) (3/4)
20/02/17 18:13:47 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 128 ms on 127.0.0.1 (executor driver) (4/4)
20/02/17 18:13:47 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
20/02/17 18:13:47 INFO DAGScheduler: ResultStage 8 (collect at arrowconverters.scala:270) finished in 0.136 s
20/02/17 18:13:47 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:13:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
20/02/17 18:13:47 INFO DAGScheduler: Job 5 finished: collect at arrowconverters.scala:270, took 0.326035 s
20/02/17 18:13:48 INFO CodeGenerator: Code generated in 4.7762 ms
20/02/17 18:13:48 INFO CodeGenerator: Code generated in 6.238 ms
20/02/17 18:13:48 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/17 18:13:48 INFO DAGScheduler: Got job 6 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/17 18:13:48 INFO DAGScheduler: Final stage: ResultStage 9 (collect at arrowconverters.scala:270)
20/02/17 18:13:48 INFO DAGScheduler: Parents of final stage: List()
20/02/17 18:13:48 INFO DAGScheduler: Missing parents: List()
20/02/17 18:13:48 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[59] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 18:13:48 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 29.9 KiB, free 413.8 MiB)
20/02/17 18:13:48 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 413.8 MiB)
20/02/17 18:13:48 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:56102 (size: 11.2 KiB, free: 413.9 MiB)
20/02/17 18:13:48 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1196
20/02/17 18:13:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[59] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 18:13:48 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
20/02/17 18:13:48 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 12, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/17 18:13:48 INFO Executor: Running task 0.0 in stage 9.0 (TID 12)
20/02/17 18:13:48 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 18:13:48 INFO CodeGenerator: Code generated in 5.5433 ms
20/02/17 18:13:48 INFO CodeGenerator: Code generated in 12.0078 ms
20/02/17 18:13:48 INFO Executor: Finished task 0.0 in stage 9.0 (TID 12). 2342 bytes result sent to driver
20/02/17 18:13:48 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 12) in 41 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:13:48 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
20/02/17 18:13:48 INFO DAGScheduler: ResultStage 9 (collect at arrowconverters.scala:270) finished in 0.052 s
20/02/17 18:13:48 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:13:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
20/02/17 18:13:48 INFO DAGScheduler: Job 6 finished: collect at arrowconverters.scala:270, took 0.056976 s
20/02/17 18:13:50 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:56102 in memory (size: 11.2 KiB, free: 413.9 MiB)
20/02/17 18:13:51 INFO Instrumentation: [b5737fde] training finished
20/02/17 18:13:51 INFO Instrumentation: [0459b8e8] training finished
20/02/17 18:13:51 INFO CodeGenerator: Code generated in 17.5684 ms
20/02/17 18:13:51 INFO SparkContext: Starting job: first at LinearRegression.scala:321
20/02/17 18:13:51 INFO DAGScheduler: Got job 7 (first at LinearRegression.scala:321) with 1 output partitions
20/02/17 18:13:51 INFO DAGScheduler: Final stage: ResultStage 10 (first at LinearRegression.scala:321)
20/02/17 18:13:51 INFO DAGScheduler: Parents of final stage: List()
20/02/17 18:13:51 INFO DAGScheduler: Missing parents: List()
20/02/17 18:13:51 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[64] at first at LinearRegression.scala:321), which has no missing parents
20/02/17 18:13:51 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 36.0 KiB, free 413.8 MiB)
20/02/17 18:13:51 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 413.8 MiB)
20/02/17 18:13:51 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:56102 (size: 13.4 KiB, free: 413.9 MiB)
20/02/17 18:13:51 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1196
20/02/17 18:13:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[64] at first at LinearRegression.scala:321) (first 15 tasks are for partitions Vector(0))
20/02/17 18:13:51 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
20/02/17 18:13:51 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/17 18:13:51 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
20/02/17 18:13:51 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 18:13:51 INFO Executor: 1 block locks were not released by TID = 13:
[rdd_9_0]
20/02/17 18:13:51 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 1838 bytes result sent to driver
20/02/17 18:13:51 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 61 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:13:51 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
20/02/17 18:13:51 INFO DAGScheduler: ResultStage 10 (first at LinearRegression.scala:321) finished in 0.069 s
20/02/17 18:13:51 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:13:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
20/02/17 18:13:51 INFO DAGScheduler: Job 7 finished: first at LinearRegression.scala:321, took 0.072834 s
20/02/17 18:13:51 INFO CodeGenerator: Code generated in 5.2331 ms
20/02/17 18:13:51 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:56102 in memory (size: 13.4 KiB, free: 413.9 MiB)
20/02/17 18:13:51 INFO CodeGenerator: Code generated in 16.2548 ms
20/02/17 18:13:51 INFO Instrumentation: [31194636] Stage class: LinearRegression
20/02/17 18:13:51 INFO Instrumentation: [31194636] Stage uid: linear_regression_3958713e4e38
20/02/17 18:13:52 INFO CodeGenerator: Code generated in 16.1505 ms
20/02/17 18:13:52 INFO Instrumentation: [31194636] training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
20/02/17 18:13:52 INFO Instrumentation: [31194636] {"elasticNetParam":0.0,"featuresCol":"features","fitIntercept":true,"solver":"auto","labelCol":"label","predictionCol":"prediction","standardization":true,"loss":"squaredError","regParam":0.0,"tol":1.0E-6,"maxIter":100}
20/02/17 18:13:52 INFO Instrumentation: [31194636] {"numFeatures":1}
20/02/17 18:13:52 WARN Instrumentation: [31194636] regParam is zero, which might cause numerical instability and overfitting.
20/02/17 18:13:52 INFO SparkContext: Starting job: treeAggregate at WeightedLeastSquares.scala:105
20/02/17 18:13:52 INFO DAGScheduler: Got job 8 (treeAggregate at WeightedLeastSquares.scala:105) with 1 output partitions
20/02/17 18:13:52 INFO DAGScheduler: Final stage: ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:105)
20/02/17 18:13:52 INFO DAGScheduler: Parents of final stage: List()
20/02/17 18:13:52 INFO DAGScheduler: Missing parents: List()
20/02/17 18:13:52 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[80] at treeAggregate at WeightedLeastSquares.scala:105), which has no missing parents
20/02/17 18:13:52 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 44.5 KiB, free 413.8 MiB)
20/02/17 18:13:52 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 413.7 MiB)
20/02/17 18:13:52 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:56102 (size: 17.3 KiB, free: 413.9 MiB)
20/02/17 18:13:52 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1196
20/02/17 18:13:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[80] at treeAggregate at WeightedLeastSquares.scala:105) (first 15 tasks are for partitions Vector(0))
20/02/17 18:13:52 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
20/02/17 18:13:52 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 14, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/17 18:13:52 INFO Executor: Running task 0.0 in stage 11.0 (TID 14)
20/02/17 18:13:52 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 18:13:52 INFO CodeGenerator: Code generated in 5.575 ms
20/02/17 18:13:52 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
20/02/17 18:13:52 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
20/02/17 18:13:52 INFO Executor: Finished task 0.0 in stage 11.0 (TID 14). 2082 bytes result sent to driver
20/02/17 18:13:52 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 14) in 78 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:13:52 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
20/02/17 18:13:52 INFO DAGScheduler: ResultStage 11 (treeAggregate at WeightedLeastSquares.scala:105) finished in 0.103 s
20/02/17 18:13:52 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:13:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
20/02/17 18:13:52 INFO DAGScheduler: Job 8 finished: treeAggregate at WeightedLeastSquares.scala:105, took 0.106508 s
20/02/17 18:13:52 INFO Instrumentation: [31194636] Number of instances: 32.
20/02/17 18:13:52 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
20/02/17 18:13:52 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
20/02/17 18:13:52 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:56102 in memory (size: 17.3 KiB, free: 413.9 MiB)
20/02/17 18:13:52 INFO CodeGenerator: Code generated in 11.4209 ms
20/02/17 18:13:52 INFO SparkContext: Starting job: treeAggregate at RegressionMetrics.scala:68
20/02/17 18:13:52 INFO DAGScheduler: Got job 9 (treeAggregate at RegressionMetrics.scala:68) with 1 output partitions
20/02/17 18:13:52 INFO DAGScheduler: Final stage: ResultStage 12 (treeAggregate at RegressionMetrics.scala:68)
20/02/17 18:13:52 INFO DAGScheduler: Parents of final stage: List()
20/02/17 18:13:52 INFO DAGScheduler: Missing parents: List()
20/02/17 18:13:52 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[90] at treeAggregate at RegressionMetrics.scala:68), which has no missing parents
20/02/17 18:13:52 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 46.2 KiB, free 413.8 MiB)
20/02/17 18:13:52 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 413.7 MiB)
20/02/17 18:13:52 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:56102 (size: 18.8 KiB, free: 413.9 MiB)
20/02/17 18:13:52 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1196
20/02/17 18:13:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[90] at treeAggregate at RegressionMetrics.scala:68) (first 15 tasks are for partitions Vector(0))
20/02/17 18:13:52 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
20/02/17 18:13:52 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 15, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/17 18:13:52 INFO Executor: Running task 0.0 in stage 12.0 (TID 15)
20/02/17 18:13:52 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 18:13:52 INFO CodeGenerator: Code generated in 4.1343 ms
20/02/17 18:13:52 INFO Executor: Finished task 0.0 in stage 12.0 (TID 15). 2199 bytes result sent to driver
20/02/17 18:13:52 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 15) in 40 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:13:52 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
20/02/17 18:13:52 INFO DAGScheduler: ResultStage 12 (treeAggregate at RegressionMetrics.scala:68) finished in 0.049 s
20/02/17 18:13:52 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:13:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
20/02/17 18:13:52 INFO DAGScheduler: Job 9 finished: treeAggregate at RegressionMetrics.scala:68, took 0.054331 s
20/02/17 18:13:52 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:56102 in memory (size: 18.8 KiB, free: 413.9 MiB)
20/02/17 18:13:52 INFO SparkContext: Starting job: count at LinearRegression.scala:930
20/02/17 18:13:52 INFO DAGScheduler: Registering RDD 95 (count at LinearRegression.scala:930) as input to shuffle 3
20/02/17 18:13:52 INFO DAGScheduler: Got job 10 (count at LinearRegression.scala:930) with 1 output partitions
20/02/17 18:13:52 INFO DAGScheduler: Final stage: ResultStage 14 (count at LinearRegression.scala:930)
20/02/17 18:13:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
20/02/17 18:13:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
20/02/17 18:13:52 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[95] at count at LinearRegression.scala:930), which has no missing parents
20/02/17 18:13:52 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 26.9 KiB, free 413.8 MiB)
20/02/17 18:13:52 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 413.8 MiB)
20/02/17 18:13:52 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:56102 (size: 10.9 KiB, free: 413.9 MiB)
20/02/17 18:13:52 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1196
20/02/17 18:13:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[95] at count at LinearRegression.scala:930) (first 15 tasks are for partitions Vector(0))
20/02/17 18:13:52 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
20/02/17 18:13:52 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 16, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/17 18:13:52 INFO Executor: Running task 0.0 in stage 13.0 (TID 16)
20/02/17 18:13:52 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 18:13:52 INFO Executor: Finished task 0.0 in stage 13.0 (TID 16). 2326 bytes result sent to driver
20/02/17 18:13:52 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 16) in 16 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:13:52 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
20/02/17 18:13:52 INFO DAGScheduler: ShuffleMapStage 13 (count at LinearRegression.scala:930) finished in 0.025 s
20/02/17 18:13:52 INFO DAGScheduler: looking for newly runnable stages
20/02/17 18:13:52 INFO DAGScheduler: running: Set()
20/02/17 18:13:52 INFO DAGScheduler: waiting: Set(ResultStage 14)
20/02/17 18:13:52 INFO DAGScheduler: failed: Set()
20/02/17 18:13:52 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[98] at count at LinearRegression.scala:930), which has no missing parents
20/02/17 18:13:52 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 10.2 KiB, free 413.8 MiB)
20/02/17 18:13:52 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.7 MiB)
20/02/17 18:13:52 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:56102 (size: 5.0 KiB, free: 413.9 MiB)
20/02/17 18:13:52 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1196
20/02/17 18:13:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[98] at count at LinearRegression.scala:930) (first 15 tasks are for partitions Vector(0))
20/02/17 18:13:52 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
20/02/17 18:13:52 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 17, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/17 18:13:52 INFO Executor: Running task 0.0 in stage 14.0 (TID 17)
20/02/17 18:13:52 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:13:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:13:52 INFO Executor: Finished task 0.0 in stage 14.0 (TID 17). 2760 bytes result sent to driver
20/02/17 18:13:52 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 17) in 7 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:13:52 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
20/02/17 18:13:52 INFO DAGScheduler: ResultStage 14 (count at LinearRegression.scala:930) finished in 0.014 s
20/02/17 18:13:52 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:13:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
20/02/17 18:13:52 INFO DAGScheduler: Job 10 finished: count at LinearRegression.scala:930, took 0.045686 s
20/02/17 18:13:52 INFO Instrumentation: [fcf36479] training finished
20/02/17 18:13:52 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:56102 in memory (size: 10.9 KiB, free: 413.9 MiB)
20/02/17 18:13:52 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:56102 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/17 18:13:53 INFO Instrumentation: [f5f03f88] training finished
20/02/17 18:13:59 INFO SparkContext: Starting job: count at <unknown>:0
20/02/17 18:13:59 INFO DAGScheduler: Registering RDD 103 (count at <unknown>:0) as input to shuffle 4
20/02/17 18:13:59 INFO DAGScheduler: Got job 11 (count at <unknown>:0) with 1 output partitions
20/02/17 18:13:59 INFO DAGScheduler: Final stage: ResultStage 16 (count at <unknown>:0)
20/02/17 18:13:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
20/02/17 18:13:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
20/02/17 18:13:59 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[103] at count at <unknown>:0), which has no missing parents
20/02/17 18:13:59 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 26.8 KiB, free 413.8 MiB)
20/02/17 18:13:59 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.8 MiB)
20/02/17 18:13:59 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:56102 (size: 10.8 KiB, free: 413.9 MiB)
20/02/17 18:13:59 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1196
20/02/17 18:13:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[103] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/17 18:13:59 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
20/02/17 18:13:59 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 18, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/17 18:13:59 INFO Executor: Running task 0.0 in stage 15.0 (TID 18)
20/02/17 18:13:59 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 18:13:59 INFO Executor: Finished task 0.0 in stage 15.0 (TID 18). 2326 bytes result sent to driver
20/02/17 18:13:59 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 18) in 18 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:13:59 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
20/02/17 18:13:59 INFO DAGScheduler: ShuffleMapStage 15 (count at <unknown>:0) finished in 0.026 s
20/02/17 18:13:59 INFO DAGScheduler: looking for newly runnable stages
20/02/17 18:13:59 INFO DAGScheduler: running: Set()
20/02/17 18:13:59 INFO DAGScheduler: waiting: Set(ResultStage 16)
20/02/17 18:13:59 INFO DAGScheduler: failed: Set()
20/02/17 18:13:59 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[106] at count at <unknown>:0), which has no missing parents
20/02/17 18:13:59 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 10.2 KiB, free 413.8 MiB)
20/02/17 18:13:59 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.7 MiB)
20/02/17 18:13:59 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:56102 (size: 5.0 KiB, free: 413.9 MiB)
20/02/17 18:13:59 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1196
20/02/17 18:13:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[106] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/17 18:13:59 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
20/02/17 18:13:59 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 19, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/17 18:13:59 INFO Executor: Running task 0.0 in stage 16.0 (TID 19)
20/02/17 18:13:59 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:13:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:13:59 INFO Executor: Finished task 0.0 in stage 16.0 (TID 19). 2803 bytes result sent to driver
20/02/17 18:13:59 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 19) in 6 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:13:59 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
20/02/17 18:13:59 INFO DAGScheduler: ResultStage 16 (count at <unknown>:0) finished in 0.012 s
20/02/17 18:13:59 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:13:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
20/02/17 18:13:59 INFO DAGScheduler: Job 11 finished: count at <unknown>:0, took 0.044466 s
20/02/17 18:13:59 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:56102 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/17 18:13:59 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:56102 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/17 18:13:59 INFO CodeGenerator: Code generated in 20.834 ms
20/02/17 18:13:59 INFO SparkContext: Starting job: collect at utils.scala:34
20/02/17 18:13:59 INFO DAGScheduler: Got job 12 (collect at utils.scala:34) with 1 output partitions
20/02/17 18:13:59 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:34)
20/02/17 18:13:59 INFO DAGScheduler: Parents of final stage: List()
20/02/17 18:13:59 INFO DAGScheduler: Missing parents: List()
20/02/17 18:13:59 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[114] at map at utils.scala:34), which has no missing parents
20/02/17 18:13:59 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 46.8 KiB, free 413.8 MiB)
20/02/17 18:13:59 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 413.7 MiB)
20/02/17 18:13:59 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:56102 (size: 19.2 KiB, free: 413.9 MiB)
20/02/17 18:13:59 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1196
20/02/17 18:13:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[114] at map at utils.scala:34) (first 15 tasks are for partitions Vector(0))
20/02/17 18:13:59 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
20/02/17 18:13:59 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 20, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11371 bytes)
20/02/17 18:13:59 INFO Executor: Running task 0.0 in stage 17.0 (TID 20)
20/02/17 18:13:59 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 18:13:59 INFO CodeGenerator: Code generated in 5.586 ms
20/02/17 18:13:59 INFO Executor: Finished task 0.0 in stage 17.0 (TID 20). 1951 bytes result sent to driver
20/02/17 18:13:59 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 20) in 29 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:13:59 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
20/02/17 18:13:59 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:34) finished in 0.036 s
20/02/17 18:13:59 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:13:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
20/02/17 18:13:59 INFO DAGScheduler: Job 12 finished: collect at utils.scala:34, took 0.039430 s
20/02/17 18:14:01 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:56102 in memory (size: 19.2 KiB, free: 413.9 MiB)
20/02/17 18:14:01 INFO CodeGenerator: Code generated in 4.4136 ms
20/02/17 18:14:01 INFO SparkContext: Starting job: collect at utils.scala:41
20/02/17 18:14:01 INFO DAGScheduler: Got job 13 (collect at utils.scala:41) with 4 output partitions
20/02/17 18:14:01 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:41)
20/02/17 18:14:01 INFO DAGScheduler: Parents of final stage: List()
20/02/17 18:14:01 INFO DAGScheduler: Missing parents: List()
20/02/17 18:14:01 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[120] at map at utils.scala:41), which has no missing parents
20/02/17 18:14:01 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 8.8 KiB, free 413.8 MiB)
20/02/17 18:14:01 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.6 KiB, free 413.8 MiB)
20/02/17 18:14:01 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:56102 (size: 4.6 KiB, free: 413.9 MiB)
20/02/17 18:14:01 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1196
20/02/17 18:14:01 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 18 (MapPartitionsRDD[120] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/17 18:14:01 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
20/02/17 18:14:01 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 21, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7533 bytes)
20/02/17 18:14:01 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 22, 127.0.0.1, executor driver, partition 1, PROCESS_LOCAL, 7557 bytes)
20/02/17 18:14:01 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 23, 127.0.0.1, executor driver, partition 2, PROCESS_LOCAL, 7557 bytes)
20/02/17 18:14:01 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 24, 127.0.0.1, executor driver, partition 3, PROCESS_LOCAL, 7614 bytes)
20/02/17 18:14:01 INFO Executor: Running task 1.0 in stage 18.0 (TID 22)
20/02/17 18:14:01 INFO Executor: Running task 2.0 in stage 18.0 (TID 23)
20/02/17 18:14:01 INFO Executor: Running task 3.0 in stage 18.0 (TID 24)
20/02/17 18:14:01 INFO Executor: Running task 0.0 in stage 18.0 (TID 21)
20/02/17 18:14:01 INFO Executor: Finished task 3.0 in stage 18.0 (TID 24). 1115 bytes result sent to driver
20/02/17 18:14:01 INFO Executor: Finished task 0.0 in stage 18.0 (TID 21). 1112 bytes result sent to driver
20/02/17 18:14:01 INFO Executor: Finished task 2.0 in stage 18.0 (TID 23). 1131 bytes result sent to driver
20/02/17 18:14:01 INFO Executor: Finished task 1.0 in stage 18.0 (TID 22). 1088 bytes result sent to driver
20/02/17 18:14:01 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 24) in 18 ms on 127.0.0.1 (executor driver) (1/4)
20/02/17 18:14:01 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 21) in 20 ms on 127.0.0.1 (executor driver) (2/4)
20/02/17 18:14:01 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 23) in 19 ms on 127.0.0.1 (executor driver) (3/4)
20/02/17 18:14:01 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 22) in 20 ms on 127.0.0.1 (executor driver) (4/4)
20/02/17 18:14:01 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
20/02/17 18:14:01 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:41) finished in 0.031 s
20/02/17 18:14:01 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:14:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
20/02/17 18:14:01 INFO DAGScheduler: Job 13 finished: collect at utils.scala:41, took 0.034593 s
20/02/17 18:14:01 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:56102 in memory (size: 4.6 KiB, free: 413.9 MiB)
20/02/17 18:14:01 INFO CodeGenerator: Code generated in 4.9361 ms
20/02/17 18:14:01 INFO SparkContext: Starting job: sql at <unknown>:0
20/02/17 18:14:01 INFO DAGScheduler: Registering RDD 129 (sql at <unknown>:0) as input to shuffle 5
20/02/17 18:14:01 INFO DAGScheduler: Got job 14 (sql at <unknown>:0) with 1 output partitions
20/02/17 18:14:01 INFO DAGScheduler: Final stage: ResultStage 20 (sql at <unknown>:0)
20/02/17 18:14:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
20/02/17 18:14:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
20/02/17 18:14:01 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[129] at sql at <unknown>:0), which has no missing parents
20/02/17 18:14:01 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 18.9 KiB, free 413.8 MiB)
20/02/17 18:14:01 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.8 MiB)
20/02/17 18:14:01 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:56102 (size: 8.2 KiB, free: 413.9 MiB)
20/02/17 18:14:01 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1196
20/02/17 18:14:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[129] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/17 18:14:01 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
20/02/17 18:14:01 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 25, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/17 18:14:01 INFO Executor: Running task 0.0 in stage 19.0 (TID 25)
20/02/17 18:14:01 INFO MemoryStore: Block rdd_124_0 stored as values in memory (estimated size 312.0 B, free 413.8 MiB)
20/02/17 18:14:01 INFO BlockManagerInfo: Added rdd_124_0 in memory on 127.0.0.1:56102 (size: 312.0 B, free: 413.9 MiB)
20/02/17 18:14:01 INFO Executor: Finished task 0.0 in stage 19.0 (TID 25). 2283 bytes result sent to driver
20/02/17 18:14:01 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 25) in 26 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:14:01 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
20/02/17 18:14:01 INFO DAGScheduler: ShuffleMapStage 19 (sql at <unknown>:0) finished in 0.039 s
20/02/17 18:14:01 INFO DAGScheduler: looking for newly runnable stages
20/02/17 18:14:01 INFO DAGScheduler: running: Set()
20/02/17 18:14:01 INFO DAGScheduler: waiting: Set(ResultStage 20)
20/02/17 18:14:01 INFO DAGScheduler: failed: Set()
20/02/17 18:14:01 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[132] at sql at <unknown>:0), which has no missing parents
20/02/17 18:14:01 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 10.2 KiB, free 413.8 MiB)
20/02/17 18:14:01 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 413.8 MiB)
20/02/17 18:14:01 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:56102 (size: 5.0 KiB, free: 413.9 MiB)
20/02/17 18:14:01 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1196
20/02/17 18:14:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[132] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
20/02/17 18:14:01 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
20/02/17 18:14:01 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 26, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/17 18:14:01 INFO Executor: Running task 0.0 in stage 20.0 (TID 26)
20/02/17 18:14:01 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:14:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:14:01 INFO Executor: Finished task 0.0 in stage 20.0 (TID 26). 2760 bytes result sent to driver
20/02/17 18:14:01 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 26) in 5 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:14:01 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
20/02/17 18:14:01 INFO DAGScheduler: ResultStage 20 (sql at <unknown>:0) finished in 0.011 s
20/02/17 18:14:01 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:14:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
20/02/17 18:14:01 INFO DAGScheduler: Job 14 finished: sql at <unknown>:0, took 0.055635 s
20/02/17 18:14:01 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:56102 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/17 18:14:01 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:56102 in memory (size: 5.0 KiB, free: 413.9 MiB)
20/02/17 18:14:01 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/17 18:14:01 INFO DAGScheduler: Registering RDD 137 (collect at arrowconverters.scala:270) as input to shuffle 6
20/02/17 18:14:01 INFO DAGScheduler: Got job 15 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/17 18:14:01 INFO DAGScheduler: Final stage: ResultStage 22 (collect at arrowconverters.scala:270)
20/02/17 18:14:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
20/02/17 18:14:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
20/02/17 18:14:01 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[137] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 18:14:01 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 18.9 KiB, free 413.8 MiB)
20/02/17 18:14:01 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 413.8 MiB)
20/02/17 18:14:01 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:56102 (size: 8.2 KiB, free: 413.9 MiB)
20/02/17 18:14:01 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1196
20/02/17 18:14:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[137] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 18:14:01 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
20/02/17 18:14:01 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 27, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/17 18:14:01 INFO Executor: Running task 0.0 in stage 21.0 (TID 27)
20/02/17 18:14:01 INFO BlockManager: Found block rdd_124_0 locally
20/02/17 18:14:01 INFO Executor: Finished task 0.0 in stage 21.0 (TID 27). 2326 bytes result sent to driver
20/02/17 18:14:01 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 27) in 15 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:14:01 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
20/02/17 18:14:01 INFO DAGScheduler: ShuffleMapStage 21 (collect at arrowconverters.scala:270) finished in 0.027 s
20/02/17 18:14:01 INFO DAGScheduler: looking for newly runnable stages
20/02/17 18:14:01 INFO DAGScheduler: running: Set()
20/02/17 18:14:01 INFO DAGScheduler: waiting: Set(ResultStage 22)
20/02/17 18:14:01 INFO DAGScheduler: failed: Set()
20/02/17 18:14:01 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[143] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 18:14:01 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 28.9 KiB, free 413.7 MiB)
20/02/17 18:14:01 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 12.0 KiB, free 413.7 MiB)
20/02/17 18:14:01 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:56102 (size: 12.0 KiB, free: 413.9 MiB)
20/02/17 18:14:01 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1196
20/02/17 18:14:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[143] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 18:14:01 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
20/02/17 18:14:01 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 28, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/17 18:14:01 INFO Executor: Running task 0.0 in stage 22.0 (TID 28)
20/02/17 18:14:01 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:14:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:14:01 INFO Executor: Finished task 0.0 in stage 22.0 (TID 28). 4285 bytes result sent to driver
20/02/17 18:14:01 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 28) in 12 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:14:01 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
20/02/17 18:14:01 INFO DAGScheduler: ResultStage 22 (collect at arrowconverters.scala:270) finished in 0.017 s
20/02/17 18:14:01 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:14:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
20/02/17 18:14:01 INFO DAGScheduler: Job 15 finished: collect at arrowconverters.scala:270, took 0.049933 s
20/02/17 18:14:01 INFO Instrumentation: [d81f6d47] training finished
20/02/17 18:14:01 INFO Instrumentation: [8ad749be] training finished
20/02/17 18:14:01 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:56102 in memory (size: 8.2 KiB, free: 413.9 MiB)
20/02/17 18:14:01 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:56102 in memory (size: 12.0 KiB, free: 413.9 MiB)
20/02/17 18:14:02 INFO CodeGenerator: Code generated in 4.8938 ms
20/02/17 18:14:02 INFO CodeGenerator: Code generated in 5.6179 ms
20/02/17 18:14:02 INFO CodeGenerator: Code generated in 18.9762 ms
20/02/17 18:14:02 INFO CodeGenerator: Code generated in 11.0697 ms
20/02/17 18:14:02 INFO CodeGenerator: Code generated in 7.7254 ms
20/02/17 18:14:02 INFO CodeGenerator: Code generated in 9.3492 ms
20/02/17 18:14:02 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/17 18:14:02 INFO DAGScheduler: Registering RDD 155 (collect at arrowconverters.scala:270) as input to shuffle 8
20/02/17 18:14:02 INFO DAGScheduler: Registering RDD 148 (collect at arrowconverters.scala:270) as input to shuffle 7
20/02/17 18:14:02 INFO DAGScheduler: Got job 16 (collect at arrowconverters.scala:270) with 4 output partitions
20/02/17 18:14:02 INFO DAGScheduler: Final stage: ResultStage 25 (collect at arrowconverters.scala:270)
20/02/17 18:14:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24, ShuffleMapStage 23)
20/02/17 18:14:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 24, ShuffleMapStage 23)
20/02/17 18:14:02 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[155] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 18:14:02 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 27.4 KiB, free 413.8 MiB)
20/02/17 18:14:02 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 413.8 MiB)
20/02/17 18:14:02 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:56102 (size: 10.8 KiB, free: 413.9 MiB)
20/02/17 18:14:02 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1196
20/02/17 18:14:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[155] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 18:14:02 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
20/02/17 18:14:02 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[148] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 18:14:02 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 29, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/17 18:14:02 INFO Executor: Running task 0.0 in stage 23.0 (TID 29)
20/02/17 18:14:02 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 32.1 KiB, free 413.7 MiB)
20/02/17 18:14:02 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 18:14:02 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 413.7 MiB)
20/02/17 18:14:02 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:56102 (size: 13.4 KiB, free: 413.9 MiB)
20/02/17 18:14:02 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1196
20/02/17 18:14:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[148] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 18:14:02 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
20/02/17 18:14:02 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 30, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 7680 bytes)
20/02/17 18:14:02 INFO Executor: Running task 0.0 in stage 24.0 (TID 30)
20/02/17 18:14:02 INFO BlockManager: Found block rdd_124_0 locally
20/02/17 18:14:02 INFO CodeGenerator: Code generated in 111.8938 ms
20/02/17 18:14:02 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:56102 in memory (size: 17.6 KiB, free: 413.9 MiB)
20/02/17 18:14:02 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:56102 in memory (size: 18.3 KiB, free: 413.9 MiB)
20/02/17 18:14:02 INFO CodeGenerator: Code generated in 110.9209 ms
20/02/17 18:14:02 INFO Executor: Finished task 0.0 in stage 24.0 (TID 30). 2246 bytes result sent to driver
20/02/17 18:14:02 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 30) in 172 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:14:02 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
20/02/17 18:14:02 INFO DAGScheduler: ShuffleMapStage 24 (collect at arrowconverters.scala:270) finished in 0.180 s
20/02/17 18:14:02 INFO DAGScheduler: looking for newly runnable stages
20/02/17 18:14:02 INFO DAGScheduler: running: Set(ShuffleMapStage 23)
20/02/17 18:14:02 INFO DAGScheduler: waiting: Set(ResultStage 25)
20/02/17 18:14:02 INFO DAGScheduler: failed: Set()
20/02/17 18:14:02 INFO Executor: Finished task 0.0 in stage 23.0 (TID 29). 2246 bytes result sent to driver
20/02/17 18:14:02 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 29) in 187 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:14:02 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
20/02/17 18:14:02 INFO DAGScheduler: ShuffleMapStage 23 (collect at arrowconverters.scala:270) finished in 0.194 s
20/02/17 18:14:02 INFO DAGScheduler: looking for newly runnable stages
20/02/17 18:14:02 INFO DAGScheduler: running: Set()
20/02/17 18:14:02 INFO DAGScheduler: waiting: Set(ResultStage 25)
20/02/17 18:14:02 INFO DAGScheduler: failed: Set()
20/02/17 18:14:02 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[163] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 18:14:02 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 56.3 KiB, free 413.8 MiB)
20/02/17 18:14:02 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 413.8 MiB)
20/02/17 18:14:02 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:56102 (size: 23.0 KiB, free: 413.9 MiB)
20/02/17 18:14:02 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1196
20/02/17 18:14:02 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 25 (MapPartitionsRDD[163] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
20/02/17 18:14:02 INFO TaskSchedulerImpl: Adding task set 25.0 with 4 tasks
20/02/17 18:14:02 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 31, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7528 bytes)
20/02/17 18:14:02 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 32, 127.0.0.1, executor driver, partition 1, NODE_LOCAL, 7528 bytes)
20/02/17 18:14:02 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 33, 127.0.0.1, executor driver, partition 2, NODE_LOCAL, 7528 bytes)
20/02/17 18:14:02 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 34, 127.0.0.1, executor driver, partition 3, NODE_LOCAL, 7528 bytes)
20/02/17 18:14:02 INFO Executor: Running task 0.0 in stage 25.0 (TID 31)
20/02/17 18:14:02 INFO Executor: Running task 2.0 in stage 25.0 (TID 33)
20/02/17 18:14:02 INFO Executor: Running task 3.0 in stage 25.0 (TID 34)
20/02/17 18:14:02 INFO Executor: Running task 1.0 in stage 25.0 (TID 32)
20/02/17 18:14:02 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:14:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:14:02 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:14:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:14:02 INFO ShuffleBlockFetcherIterator: Getting 1 (66.0 B) non-empty blocks including 1 (66.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:14:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:14:02 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:14:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:14:02 INFO CodeGenerator: Code generated in 35.0492 ms
20/02/17 18:14:02 INFO CodeGenerator: Code generated in 16.5171 ms
20/02/17 18:14:03 INFO ShuffleBlockFetcherIterator: Getting 1 (171.0 B) non-empty blocks including 1 (171.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:14:03 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:14:03 INFO ShuffleBlockFetcherIterator: Getting 1 (117.0 B) non-empty blocks including 1 (117.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:14:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:14:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:14:03 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:14:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:14:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:14:03 INFO CodeGenerator: Code generated in 15.0322 ms
20/02/17 18:14:03 INFO CodeGenerator: Code generated in 12.2737 ms
20/02/17 18:14:03 INFO CodeGenerator: Code generated in 15.3063 ms
20/02/17 18:14:03 INFO CodeGenerator: Code generated in 6.7465 ms
20/02/17 18:14:03 INFO Executor: Finished task 1.0 in stage 25.0 (TID 32). 5833 bytes result sent to driver
20/02/17 18:14:03 INFO Executor: Finished task 0.0 in stage 25.0 (TID 31). 5857 bytes result sent to driver
20/02/17 18:14:03 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 32) in 348 ms on 127.0.0.1 (executor driver) (1/4)
20/02/17 18:14:03 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 31) in 352 ms on 127.0.0.1 (executor driver) (2/4)
20/02/17 18:14:03 INFO Executor: Finished task 2.0 in stage 25.0 (TID 33). 5952 bytes result sent to driver
20/02/17 18:14:03 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 33) in 350 ms on 127.0.0.1 (executor driver) (3/4)
20/02/17 18:14:03 INFO Executor: Finished task 3.0 in stage 25.0 (TID 34). 5850 bytes result sent to driver
20/02/17 18:14:03 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 34) in 352 ms on 127.0.0.1 (executor driver) (4/4)
20/02/17 18:14:03 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
20/02/17 18:14:03 INFO DAGScheduler: ResultStage 25 (collect at arrowconverters.scala:270) finished in 0.363 s
20/02/17 18:14:03 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:14:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
20/02/17 18:14:03 INFO DAGScheduler: Job 16 finished: collect at arrowconverters.scala:270, took 0.566990 s
20/02/17 18:14:19 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:56102 in memory (size: 13.4 KiB, free: 413.9 MiB)
20/02/17 18:14:19 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:56102 in memory (size: 23.0 KiB, free: 413.9 MiB)
20/02/17 18:14:19 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:56102 in memory (size: 10.8 KiB, free: 413.9 MiB)
20/02/17 18:14:19 INFO CodeGenerator: Code generated in 28.7361 ms
20/02/17 18:14:19 INFO CodeGenerator: Code generated in 21.734 ms
20/02/17 18:14:19 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/17 18:14:19 INFO DAGScheduler: Registering RDD 168 (collect at arrowconverters.scala:270) as input to shuffle 9
20/02/17 18:14:19 INFO DAGScheduler: Got job 17 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/17 18:14:19 INFO DAGScheduler: Final stage: ResultStage 27 (collect at arrowconverters.scala:270)
20/02/17 18:14:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
20/02/17 18:14:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
20/02/17 18:14:19 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[168] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 18:14:19 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 55.4 KiB, free 413.9 MiB)
20/02/17 18:14:19 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 18.8 KiB, free 413.8 MiB)
20/02/17 18:14:19 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:56102 (size: 18.8 KiB, free: 413.9 MiB)
20/02/17 18:14:19 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1196
20/02/17 18:14:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[168] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 18:14:19 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
20/02/17 18:14:19 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 35, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/17 18:14:19 INFO Executor: Running task 0.0 in stage 26.0 (TID 35)
20/02/17 18:14:19 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 18:14:19 INFO Executor: Finished task 0.0 in stage 26.0 (TID 35). 2326 bytes result sent to driver
20/02/17 18:14:19 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 35) in 19 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:14:19 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
20/02/17 18:14:19 INFO DAGScheduler: ShuffleMapStage 26 (collect at arrowconverters.scala:270) finished in 0.025 s
20/02/17 18:14:19 INFO DAGScheduler: looking for newly runnable stages
20/02/17 18:14:19 INFO DAGScheduler: running: Set()
20/02/17 18:14:19 INFO DAGScheduler: waiting: Set(ResultStage 27)
20/02/17 18:14:19 INFO DAGScheduler: failed: Set()
20/02/17 18:14:19 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[174] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 18:14:19 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 75.2 KiB, free 413.8 MiB)
20/02/17 18:14:19 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 27.1 KiB, free 413.7 MiB)
20/02/17 18:14:19 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:56102 (size: 27.1 KiB, free: 413.9 MiB)
20/02/17 18:14:19 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1196
20/02/17 18:14:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[174] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 18:14:19 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
20/02/17 18:14:19 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 36, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/17 18:14:19 INFO Executor: Running task 0.0 in stage 27.0 (TID 36)
20/02/17 18:14:19 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:14:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:14:19 INFO CodeGenerator: Code generated in 6.7645 ms
20/02/17 18:14:19 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:56102 in memory (size: 18.8 KiB, free: 413.9 MiB)
20/02/17 18:14:19 INFO CodeGenerator: Code generated in 24.2858 ms
20/02/17 18:14:19 INFO Executor: Finished task 0.0 in stage 27.0 (TID 36). 4566 bytes result sent to driver
20/02/17 18:14:19 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 36) in 80 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:14:19 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
20/02/17 18:14:19 INFO DAGScheduler: ResultStage 27 (collect at arrowconverters.scala:270) finished in 0.086 s
20/02/17 18:14:19 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:14:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
20/02/17 18:14:19 INFO DAGScheduler: Job 17 finished: collect at arrowconverters.scala:270, took 0.116640 s
20/02/17 18:14:27 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:56102 in memory (size: 27.1 KiB, free: 413.9 MiB)
20/02/17 18:14:27 INFO CodeGenerator: Code generated in 27.0216 ms
20/02/17 18:14:27 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/17 18:14:27 INFO DAGScheduler: Registering RDD 179 (collect at arrowconverters.scala:270) as input to shuffle 10
20/02/17 18:14:27 INFO DAGScheduler: Got job 18 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/17 18:14:27 INFO DAGScheduler: Final stage: ResultStage 29 (collect at arrowconverters.scala:270)
20/02/17 18:14:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
20/02/17 18:14:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
20/02/17 18:14:27 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[179] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 18:14:27 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 55.4 KiB, free 413.9 MiB)
20/02/17 18:14:27 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 413.8 MiB)
20/02/17 18:14:27 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:56102 (size: 18.9 KiB, free: 413.9 MiB)
20/02/17 18:14:27 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1196
20/02/17 18:14:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[179] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 18:14:27 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
20/02/17 18:14:27 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 37, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/17 18:14:27 INFO Executor: Running task 0.0 in stage 28.0 (TID 37)
20/02/17 18:14:27 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 18:14:27 INFO Executor: Finished task 0.0 in stage 28.0 (TID 37). 2369 bytes result sent to driver
20/02/17 18:14:27 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 37) in 29 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:14:27 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
20/02/17 18:14:27 INFO DAGScheduler: ShuffleMapStage 28 (collect at arrowconverters.scala:270) finished in 0.035 s
20/02/17 18:14:27 INFO DAGScheduler: looking for newly runnable stages
20/02/17 18:14:27 INFO DAGScheduler: running: Set()
20/02/17 18:14:27 INFO DAGScheduler: waiting: Set(ResultStage 29)
20/02/17 18:14:27 INFO DAGScheduler: failed: Set()
20/02/17 18:14:27 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[185] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 18:14:27 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 75.2 KiB, free 413.8 MiB)
20/02/17 18:14:27 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 27.1 KiB, free 413.7 MiB)
20/02/17 18:14:27 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:56102 (size: 27.1 KiB, free: 413.9 MiB)
20/02/17 18:14:27 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1196
20/02/17 18:14:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[185] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 18:14:27 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
20/02/17 18:14:27 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 38, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/17 18:14:27 INFO Executor: Running task 0.0 in stage 29.0 (TID 38)
20/02/17 18:14:27 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:14:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:14:27 INFO Executor: Finished task 0.0 in stage 29.0 (TID 38). 4523 bytes result sent to driver
20/02/17 18:14:27 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 38) in 52 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:14:27 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
20/02/17 18:14:27 INFO DAGScheduler: ResultStage 29 (collect at arrowconverters.scala:270) finished in 0.062 s
20/02/17 18:14:27 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:14:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
20/02/17 18:14:27 INFO DAGScheduler: Job 18 finished: collect at arrowconverters.scala:270, took 0.105918 s
20/02/17 18:14:30 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:56102 in memory (size: 27.1 KiB, free: 413.9 MiB)
20/02/17 18:14:30 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:56102 in memory (size: 18.9 KiB, free: 413.9 MiB)
20/02/17 18:14:30 INFO CodeGenerator: Code generated in 36.8475 ms
20/02/17 18:14:31 INFO SparkContext: Starting job: collect at arrowconverters.scala:270
20/02/17 18:14:31 INFO DAGScheduler: Registering RDD 190 (collect at arrowconverters.scala:270) as input to shuffle 11
20/02/17 18:14:31 INFO DAGScheduler: Got job 19 (collect at arrowconverters.scala:270) with 1 output partitions
20/02/17 18:14:31 INFO DAGScheduler: Final stage: ResultStage 31 (collect at arrowconverters.scala:270)
20/02/17 18:14:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
20/02/17 18:14:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 30)
20/02/17 18:14:31 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[190] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 18:14:31 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 55.4 KiB, free 413.9 MiB)
20/02/17 18:14:31 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 413.8 MiB)
20/02/17 18:14:31 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:56102 (size: 18.9 KiB, free: 413.9 MiB)
20/02/17 18:14:31 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1196
20/02/17 18:14:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[190] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 18:14:31 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
20/02/17 18:14:31 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 39, 127.0.0.1, executor driver, partition 0, PROCESS_LOCAL, 11360 bytes)
20/02/17 18:14:31 INFO Executor: Running task 0.0 in stage 30.0 (TID 39)
20/02/17 18:14:31 INFO BlockManager: Found block rdd_9_0 locally
20/02/17 18:14:31 INFO Executor: Finished task 0.0 in stage 30.0 (TID 39). 2369 bytes result sent to driver
20/02/17 18:14:31 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 39) in 18 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:14:31 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
20/02/17 18:14:31 INFO DAGScheduler: ShuffleMapStage 30 (collect at arrowconverters.scala:270) finished in 0.032 s
20/02/17 18:14:31 INFO DAGScheduler: looking for newly runnable stages
20/02/17 18:14:31 INFO DAGScheduler: running: Set()
20/02/17 18:14:31 INFO DAGScheduler: waiting: Set(ResultStage 31)
20/02/17 18:14:31 INFO DAGScheduler: failed: Set()
20/02/17 18:14:31 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[196] at collect at arrowconverters.scala:270), which has no missing parents
20/02/17 18:14:31 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 75.2 KiB, free 413.8 MiB)
20/02/17 18:14:31 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 27.1 KiB, free 413.7 MiB)
20/02/17 18:14:31 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:56102 (size: 27.1 KiB, free: 413.9 MiB)
20/02/17 18:14:31 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1196
20/02/17 18:14:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[196] at collect at arrowconverters.scala:270) (first 15 tasks are for partitions Vector(0))
20/02/17 18:14:31 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
20/02/17 18:14:31 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 40, 127.0.0.1, executor driver, partition 0, NODE_LOCAL, 7248 bytes)
20/02/17 18:14:31 INFO Executor: Running task 0.0 in stage 31.0 (TID 40)
20/02/17 18:14:31 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local blocks and 0 (0.0 B) remote blocks
20/02/17 18:14:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
20/02/17 18:14:31 INFO Executor: Finished task 0.0 in stage 31.0 (TID 40). 4523 bytes result sent to driver
20/02/17 18:14:31 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 40) in 58 ms on 127.0.0.1 (executor driver) (1/1)
20/02/17 18:14:31 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
20/02/17 18:14:31 INFO DAGScheduler: ResultStage 31 (collect at arrowconverters.scala:270) finished in 0.067 s
20/02/17 18:14:31 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
20/02/17 18:14:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
20/02/17 18:14:31 INFO DAGScheduler: Job 19 finished: collect at arrowconverters.scala:270, took 0.106604 s
20/02/17 18:14:37 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:56102 in memory (size: 18.9 KiB, free: 413.9 MiB)
20/02/17 18:14:37 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:56102 in memory (size: 27.1 KiB, free: 413.9 MiB)
